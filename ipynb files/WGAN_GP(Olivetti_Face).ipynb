{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from models.WGANGP import WGANGP\n",
    "\n",
    "x_train = fetch_olivetti_faces().images\n",
    "x_train = np.expand_dims(x_train, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '007'\n",
    "DATA_NAME = 'olivettiface'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f69f7ffd160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tf.keras.backend.int_shape(x_train))\n",
    "plt.imshow((x_train[22][:,:,0]), cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hongbeom/.conda/envs/jktest3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "gan = WGANGP(input_dim = (IMAGE_SIZE, IMAGE_SIZE,1)\n",
    "        , critic_conv_filters = [64,128,256,512]\n",
    "        , critic_conv_kernel_size = [4,4,4,4]\n",
    "        , critic_conv_strides = [2,2,2,2]\n",
    "        , critic_batch_norm_momentum = None\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = 0.5\n",
    "        , critic_learning_rate = 0.0002\n",
    "        , generator_initial_dense_layer_size = (4, 4, 512)\n",
    "        , generator_upsample = [2,2,2,2]\n",
    "        , generator_conv_filters = [512,256,128,64]\n",
    "        , generator_conv_kernel_size = [3,3,3,3]\n",
    "        , generator_conv_strides = [1,1,1,1,1]\n",
    "        , generator_compress_filters = [256,128,64,1]\n",
    "        , generator_compress_kernel_size = [3,3,3,3]\n",
    "        , generator_compress_strides = [1,1,1,1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = 0.5\n",
    "        , generator_learning_rate = 0.0002\n",
    "        , optimiser = 'adam'\n",
    "        , grad_weight = 10\n",
    "        , z_dim = 100\n",
    "        , batch_size = BATCH_SIZE\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       multiple                  1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       multiple                  131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       multiple                  524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       multiple                  2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  8193      \n",
      "=================================================================\n",
      "Total params: 2,762,689\n",
      "Trainable params: 2,762,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "compress_0 (Conv2D)          (None, 8, 8, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "compress_1 (Conv2D)          (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2D)    (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "compress_2 (Conv2D)          (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2D)    (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "compress_3 (Conv2D)          (None, 64, 64, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 1)         0         \n",
      "=================================================================\n",
      "Total params: 5,549,505\n",
      "Trainable params: 5,530,305\n",
      "Non-trainable params: 19,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.critic.summary()\n",
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000\n",
    "PRINT_EVERY_N_BATCHES = 50\n",
    "N_CRITIC = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "0 (5, 1) [D loss: (6.3306)(R -1.0904, F 0.0051, G 0.7416)] [G loss: -0.1143]\n",
      "1 (5, 1) [D loss: (-28.1611)(R -28.4409, F 0.2050, G 0.0075)] [G loss: 0.8186]\n",
      "2 (5, 1) [D loss: (-53.5874)(R -72.9830, F 1.1502, G 1.8245)] [G loss: -10.2366]\n",
      "3 (5, 1) [D loss: (-56.9424)(R -89.1757, F 5.0751, G 2.7158)] [G loss: -26.8022]\n",
      "4 (5, 1) [D loss: (-53.6369)(R -85.5237, F 7.1375, G 2.4749)] [G loss: -36.1362]\n",
      "5 (5, 1) [D loss: (-65.4090)(R -99.5607, F 4.2789, G 2.9873)] [G loss: -46.9074]\n",
      "6 (5, 1) [D loss: (-92.6509)(R -116.1010, F -8.0283, G 3.1478)] [G loss: -64.4371]\n",
      "7 (5, 1) [D loss: (-147.5378)(R -122.2680, F -87.4169, G 6.2147)] [G loss: -50.4027]\n",
      "8 (5, 1) [D loss: (-220.7833)(R -191.8780, F -190.3376, G 16.1432)] [G loss: -153.7328]\n",
      "9 (5, 1) [D loss: (-256.9280)(R -214.0045, F -213.8755, G 17.0952)] [G loss: -169.0666]\n",
      "10 (5, 1) [D loss: (-268.3142)(R -175.5823, F -269.7857, G 17.7054)] [G loss: -72.4179]\n",
      "11 (5, 1) [D loss: (-251.6074)(R -265.6572, F -183.1025, G 19.7152)] [G loss: -188.2177]\n",
      "12 (5, 1) [D loss: (-257.9235)(R -108.9204, F -331.7012, G 18.2698)] [G loss: -116.0080]\n",
      "13 (5, 1) [D loss: (-264.0768)(R -178.7632, F -266.6968, G 18.1383)] [G loss: -189.0055]\n",
      "14 (5, 1) [D loss: (-256.4649)(R -206.4804, F -221.4209, G 17.1436)] [G loss: -203.3547]\n",
      "15 (5, 1) [D loss: (-225.8690)(R -120.1703, F -267.9109, G 16.2212)] [G loss: -115.8903]\n",
      "16 (5, 1) [D loss: (-164.8239)(R -117.3179, F -150.8932, G 10.3387)] [G loss: -95.0517]\n",
      "17 (5, 1) [D loss: (-152.9441)(R -96.3090, F -130.8864, G 7.4251)] [G loss: -83.5389]\n",
      "18 (5, 1) [D loss: (-106.1911)(R -81.8414, F -89.2107, G 6.4861)] [G loss: -72.7742]\n",
      "19 (5, 1) [D loss: (-86.6662)(R -91.8309, F -50.6358, G 5.5800)] [G loss: -75.3758]\n",
      "20 (5, 1) [D loss: (-68.0546)(R -64.2128, F -31.6069, G 2.7765)] [G loss: -61.4945]\n",
      "21 (5, 1) [D loss: (-44.6649)(R -52.2151, F -12.0462, G 1.9596)] [G loss: -39.6854]\n",
      "22 (5, 1) [D loss: (-32.6980)(R -40.3832, F -4.7912, G 1.2476)] [G loss: -27.3852]\n",
      "23 (5, 1) [D loss: (-23.7624)(R -42.4025, F 8.4411, G 1.0199)] [G loss: -26.8479]\n",
      "24 (5, 1) [D loss: (-21.4049)(R -29.8782, F 1.5068, G 0.6967)] [G loss: -7.8314]\n",
      "25 (5, 1) [D loss: (-25.3903)(R -20.3791, F -9.4640, G 0.4453)] [G loss: -1.1372]\n",
      "26 (5, 1) [D loss: (-18.2088)(R -4.3497, F -17.2096, G 0.3351)] [G loss: 16.3971]\n",
      "27 (5, 1) [D loss: (-12.6585)(R 1.1534, F -17.3346, G 0.3523)] [G loss: 16.7511]\n",
      "28 (5, 1) [D loss: (-12.0291)(R 11.2452, F -26.0868, G 0.2813)] [G loss: 27.4474]\n",
      "29 (5, 1) [D loss: (-12.5557)(R 24.0124, F -39.6490, G 0.3081)] [G loss: 44.6483]\n",
      "30 (5, 1) [D loss: (-10.2734)(R 25.8459, F -39.5197, G 0.3400)] [G loss: 41.0733]\n",
      "31 (5, 1) [D loss: (-13.7408)(R 22.7318, F -39.8171, G 0.3344)] [G loss: 42.8617]\n",
      "32 (5, 1) [D loss: (-11.4807)(R 35.9630, F -50.6949, G 0.3251)] [G loss: 50.1098]\n",
      "33 (5, 1) [D loss: (-2.0396)(R 37.1902, F -41.6191, G 0.2389)] [G loss: 51.4501]\n",
      "34 (5, 1) [D loss: (-4.8512)(R 68.5607, F -75.1612, G 0.1749)] [G loss: 70.4095]\n",
      "35 (5, 1) [D loss: (-4.5862)(R 76.7975, F -83.1368, G 0.1753)] [G loss: 67.5121]\n",
      "36 (5, 1) [D loss: (-3.1213)(R 60.5242, F -64.2741, G 0.0629)] [G loss: 55.9795]\n",
      "37 (5, 1) [D loss: (-5.0807)(R 52.2749, F -58.3467, G 0.0991)] [G loss: 55.1555]\n",
      "38 (5, 1) [D loss: (-12.8169)(R 80.8584, F -97.6613, G 0.3986)] [G loss: 64.9887]\n",
      "39 (5, 1) [D loss: (-16.7902)(R 75.5167, F -97.4890, G 0.5182)] [G loss: 60.0669]\n",
      "40 (5, 1) [D loss: (-13.3114)(R 68.3014, F -84.7302, G 0.3117)] [G loss: 59.5491]\n",
      "41 (5, 1) [D loss: (-8.6764)(R 47.4383, F -57.2124, G 0.1098)] [G loss: 42.4810]\n",
      "42 (5, 1) [D loss: (-9.8462)(R 6.6799, F -16.6972, G 0.0171)] [G loss: 12.8693]\n",
      "43 (5, 1) [D loss: (-18.4749)(R -54.4476, F 33.2140, G 0.2759)] [G loss: -29.2817]\n",
      "44 (5, 1) [D loss: (-18.7713)(R -69.0512, F 46.1854, G 0.4094)] [G loss: -39.4019]\n",
      "45 (5, 1) [D loss: (-1.2197)(R -54.3606, F 51.2364, G 0.1904)] [G loss: -31.5679]\n",
      "46 (5, 1) [D loss: (-0.2861)(R -47.8450, F 46.6773, G 0.0882)] [G loss: -32.0924]\n",
      "47 (5, 1) [D loss: (0.5548)(R -29.3745, F 29.3949, G 0.0534)] [G loss: -22.5152]\n",
      "48 (5, 1) [D loss: (-0.9642)(R -18.9782, F 17.7800, G 0.0234)] [G loss: -13.6300]\n",
      "49 (5, 1) [D loss: (-3.3787)(R -31.8481, F 28.2736, G 0.0196)] [G loss: -25.2766]\n",
      "50 (5, 1) [D loss: (-5.9464)(R -28.2428, F 22.2094, G 0.0087)] [G loss: -18.0478]\n",
      "51 (5, 1) [D loss: (-4.1195)(R -10.1078, F 5.9337, G 0.0055)] [G loss: -2.9936]\n",
      "52 (5, 1) [D loss: (-1.9524)(R 4.2282, F -6.2032, G 0.0022)] [G loss: 14.5163]\n",
      "53 (5, 1) [D loss: (-0.1416)(R 19.4073, F -19.9768, G 0.0428)] [G loss: 28.0436]\n",
      "54 (5, 1) [D loss: (-0.7982)(R 11.6350, F -12.6441, G 0.0211)] [G loss: 7.3969]\n",
      "55 (5, 1) [D loss: (-0.5477)(R -5.0150, F 4.3169, G 0.0150)] [G loss: -5.1541]\n",
      "56 (5, 1) [D loss: (-2.2114)(R -15.4420, F 12.8621, G 0.0369)] [G loss: -16.8001]\n",
      "57 (5, 1) [D loss: (3.5720)(R -13.7767, F 17.1243, G 0.0224)] [G loss: -15.0280]\n",
      "58 (5, 1) [D loss: (-2.6786)(R -21.1274, F 18.3147, G 0.0134)] [G loss: -20.1252]\n",
      "59 (5, 1) [D loss: (-4.9477)(R -21.8780, F 16.6327, G 0.0298)] [G loss: -18.9485]\n",
      "60 (5, 1) [D loss: (-2.1647)(R 7.3778, F -9.8374, G 0.0295)] [G loss: 15.7607]\n",
      "61 (5, 1) [D loss: (1.0177)(R 40.2309, F -39.5425, G 0.0329)] [G loss: 42.7720]\n",
      "62 (5, 1) [D loss: (7.7825)(R 59.1733, F -51.4991, G 0.0108)] [G loss: 55.1011]\n",
      "63 (5, 1) [D loss: (0.9451)(R 50.1267, F -49.2594, G 0.0078)] [G loss: 50.8767]\n",
      "64 (5, 1) [D loss: (-0.4307)(R 27.5514, F -28.1055, G 0.0123)] [G loss: 21.9725]\n",
      "65 (5, 1) [D loss: (-0.7405)(R 7.4033, F -8.2237, G 0.0080)] [G loss: 3.4201]\n",
      "66 (5, 1) [D loss: (-0.4755)(R -9.4666, F 8.4481, G 0.0543)] [G loss: -9.4364]\n",
      "67 (5, 1) [D loss: (-0.4673)(R -5.4252, F 4.8182, G 0.0140)] [G loss: -5.2435]\n",
      "68 (5, 1) [D loss: (0.5986)(R 16.6395, F -16.0740, G 0.0033)] [G loss: 24.9102]\n",
      "69 (5, 1) [D loss: (-2.3078)(R 68.4891, F -71.7107, G 0.0914)] [G loss: 86.2592]\n",
      "70 (5, 1) [D loss: (-5.0412)(R 87.0901, F -94.3731, G 0.2242)] [G loss: 95.6412]\n",
      "71 (5, 1) [D loss: (-4.6259)(R 86.0113, F -91.9804, G 0.1343)] [G loss: 95.3837]\n",
      "72 (5, 1) [D loss: (-9.3603)(R 75.5851, F -85.5743, G 0.0629)] [G loss: 84.1111]\n",
      "73 (5, 1) [D loss: (-5.6293)(R 67.1561, F -72.9533, G 0.0168)] [G loss: 70.3083]\n",
      "74 (5, 1) [D loss: (-3.9375)(R 62.0828, F -66.2483, G 0.0228)] [G loss: 62.1478]\n",
      "75 (5, 1) [D loss: (-4.8570)(R 29.6791, F -34.6545, G 0.0118)] [G loss: 27.1841]\n",
      "76 (5, 1) [D loss: (-6.0459)(R -17.3321, F 10.9599, G 0.0326)] [G loss: -23.0951]\n",
      "77 (5, 1) [D loss: (-3.2145)(R -26.4610, F 22.6715, G 0.0575)] [G loss: -19.8102]\n",
      "78 (5, 1) [D loss: (0.1733)(R -13.1093, F 13.1629, G 0.0120)] [G loss: -12.5995]\n",
      "79 (5, 1) [D loss: (1.6692)(R 8.6251, F -6.9849, G 0.0029)] [G loss: 8.5878]\n",
      "80 (5, 1) [D loss: (-3.3707)(R 28.6356, F -32.0552, G 0.0049)] [G loss: 33.4416]\n",
      "81 (5, 1) [D loss: (-1.7931)(R 65.3570, F -68.0102, G 0.0860)] [G loss: 67.0797]\n",
      "82 (5, 1) [D loss: (-2.5768)(R 63.0962, F -66.3174, G 0.0644)] [G loss: 63.3918]\n",
      "83 (5, 1) [D loss: (0.6846)(R 47.8786, F -47.2955, G 0.0101)] [G loss: 49.6356]\n",
      "84 (5, 1) [D loss: (-1.8180)(R 25.5190, F -27.4022, G 0.0065)] [G loss: 20.6567]\n",
      "85 (5, 1) [D loss: (-5.8653)(R -4.6327, F -1.6165, G 0.0384)] [G loss: -7.6632]\n",
      "86 (5, 1) [D loss: (-2.4794)(R -6.0072, F 3.1777, G 0.0350)] [G loss: -8.2277]\n",
      "87 (5, 1) [D loss: (-7.9468)(R 7.9201, F -15.9052, G 0.0038)] [G loss: 13.8131]\n",
      "88 (5, 1) [D loss: (-9.9548)(R 44.8691, F -55.2588, G 0.0435)] [G loss: 57.4085]\n",
      "89 (5, 1) [D loss: (-10.1003)(R 52.9590, F -64.0498, G 0.0991)] [G loss: 56.9507]\n",
      "90 (5, 1) [D loss: (-7.7160)(R 37.8560, F -46.3397, G 0.0768)] [G loss: 40.9146]\n",
      "91 (5, 1) [D loss: (-0.7535)(R 16.6236, F -17.4251, G 0.0048)] [G loss: 12.6101]\n",
      "92 (5, 1) [D loss: (-6.3062)(R -24.3427, F 17.9432, G 0.0093)] [G loss: -33.9811]\n",
      "93 (5, 1) [D loss: (-4.3040)(R -34.5391, F 29.8953, G 0.0340)] [G loss: -36.7900]\n",
      "94 (5, 1) [D loss: (-4.7640)(R -20.6724, F 15.8206, G 0.0088)] [G loss: -10.8316]\n",
      "95 (5, 1) [D loss: (-7.8803)(R 42.9238, F -51.2990, G 0.0495)] [G loss: 61.7423]\n",
      "96 (5, 1) [D loss: (2.4232)(R 78.1514, F -77.1926, G 0.1464)] [G loss: 77.1799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 (5, 1) [D loss: (-3.0174)(R 89.5294, F -93.7948, G 0.1248)] [G loss: 93.3112]\n",
      "98 (5, 1) [D loss: (-3.5290)(R 91.8902, F -96.8456, G 0.1426)] [G loss: 87.6286]\n",
      "99 (5, 1) [D loss: (-6.4365)(R 85.4474, F -92.9597, G 0.1076)] [G loss: 80.7506]\n",
      "100 (5, 1) [D loss: (-8.9381)(R 81.2346, F -91.2530, G 0.1080)] [G loss: 77.7171]\n",
      "101 (5, 1) [D loss: (-5.9467)(R 68.8324, F -76.0797, G 0.1301)] [G loss: 62.6801]\n",
      "102 (5, 1) [D loss: (-10.1045)(R 58.6432, F -70.6210, G 0.1873)] [G loss: 53.5572]\n",
      "103 (5, 1) [D loss: (-10.0580)(R 33.2238, F -44.1817, G 0.0900)] [G loss: 33.2508]\n",
      "104 (5, 1) [D loss: (-9.5632)(R -10.7061, F 0.4083, G 0.0735)] [G loss: -8.4904]\n",
      "105 (5, 1) [D loss: (-13.7217)(R -85.3095, F 62.7477, G 0.8840)] [G loss: -72.5793]\n",
      "106 (5, 1) [D loss: (-30.7151)(R -81.0859, F 41.6957, G 0.8675)] [G loss: -68.7679]\n",
      "107 (5, 1) [D loss: (-11.6723)(R -47.1839, F 33.4819, G 0.2030)] [G loss: -41.5729]\n",
      "108 (5, 1) [D loss: (-1.2063)(R -31.3405, F 29.9778, G 0.0156)] [G loss: -25.9482]\n",
      "109 (5, 1) [D loss: (-1.1676)(R -9.0305, F 7.5468, G 0.0316)] [G loss: -6.8520]\n",
      "110 (5, 1) [D loss: (-4.0491)(R 10.0328, F -14.4209, G 0.0339)] [G loss: 22.1319]\n",
      "111 (5, 1) [D loss: (-0.4640)(R 71.1227, F -73.0670, G 0.1480)] [G loss: 75.2655]\n",
      "112 (5, 1) [D loss: (-2.9585)(R 62.4332, F -65.8189, G 0.0427)] [G loss: 66.9366]\n",
      "113 (5, 1) [D loss: (-2.5550)(R 57.7369, F -60.4432, G 0.0151)] [G loss: 55.1376]\n",
      "114 (5, 1) [D loss: (-2.6267)(R 54.6762, F -57.5993, G 0.0296)] [G loss: 57.1886]\n",
      "115 (5, 1) [D loss: (-2.5614)(R 44.2607, F -46.8944, G 0.0072)] [G loss: 46.8687]\n",
      "116 (5, 1) [D loss: (0.5566)(R 31.3777, F -30.8918, G 0.0071)] [G loss: 32.5626]\n",
      "117 (5, 1) [D loss: (0.5245)(R 10.0569, F -9.5618, G 0.0029)] [G loss: 1.7604]\n",
      "118 (5, 1) [D loss: (-5.0199)(R -29.1060, F 23.3156, G 0.0771)] [G loss: -25.0486]\n",
      "119 (5, 1) [D loss: (-0.4836)(R -24.4633, F 23.5191, G 0.0461)] [G loss: -25.5705]\n",
      "120 (5, 1) [D loss: (-1.8852)(R -26.7168, F 24.6928, G 0.0139)] [G loss: -24.9039]\n",
      "121 (5, 1) [D loss: (0.2558)(R -22.2829, F 22.4473, G 0.0091)] [G loss: -22.3603]\n",
      "122 (5, 1) [D loss: (-1.3029)(R -19.1792, F 17.7872, G 0.0089)] [G loss: -19.0520]\n",
      "123 (5, 1) [D loss: (-0.1881)(R -15.6128, F 15.2770, G 0.0148)] [G loss: -13.2435]\n",
      "124 (5, 1) [D loss: (-0.6391)(R -4.6507, F 3.9141, G 0.0097)] [G loss: -0.6411]\n",
      "125 (5, 1) [D loss: (-2.7285)(R 21.3355, F -24.0850, G 0.0021)] [G loss: 27.0586]\n",
      "126 (5, 1) [D loss: (-1.7481)(R 54.9173, F -57.3835, G 0.0718)] [G loss: 64.4645]\n",
      "127 (5, 1) [D loss: (-2.7660)(R 49.6879, F -52.5519, G 0.0098)] [G loss: 52.8304]\n",
      "128 (5, 1) [D loss: (3.8169)(R 50.2555, F -46.4770, G 0.0038)] [G loss: 47.5311]\n",
      "129 (5, 1) [D loss: (-0.7009)(R 49.4433, F -50.2227, G 0.0079)] [G loss: 44.3936]\n",
      "130 (5, 1) [D loss: (0.4447)(R 35.7374, F -35.3628, G 0.0070)] [G loss: 35.4144]\n",
      "131 (5, 1) [D loss: (0.9947)(R 32.6997, F -31.7728, G 0.0068)] [G loss: 26.6489]\n",
      "132 (5, 1) [D loss: (-2.0103)(R 14.3070, F -16.3448, G 0.0028)] [G loss: 11.9742]\n",
      "133 (5, 1) [D loss: (-0.7415)(R 7.9430, F -8.7638, G 0.0079)] [G loss: 7.8615]\n",
      "134 (5, 1) [D loss: (-1.5855)(R 13.7565, F -15.3870, G 0.0045)] [G loss: 15.4292]\n",
      "135 (5, 1) [D loss: (-0.8648)(R 20.2694, F -21.1611, G 0.0027)] [G loss: 22.1160]\n",
      "136 (5, 1) [D loss: (2.1895)(R 31.5540, F -29.4056, G 0.0041)] [G loss: 32.7614]\n",
      "137 (5, 1) [D loss: (-4.5673)(R 38.5115, F -43.1344, G 0.0056)] [G loss: 40.9275]\n",
      "138 (5, 1) [D loss: (-4.3902)(R 37.2945, F -41.8584, G 0.0174)] [G loss: 41.6609]\n",
      "139 (5, 1) [D loss: (0.2750)(R 41.3038, F -41.0993, G 0.0070)] [G loss: 42.7551]\n",
      "140 (5, 1) [D loss: (-1.9635)(R 38.9229, F -40.9547, G 0.0068)] [G loss: 37.3778]\n",
      "141 (5, 1) [D loss: (-2.2950)(R 22.5393, F -24.9046, G 0.0070)] [G loss: 19.3641]\n",
      "142 (5, 1) [D loss: (-4.3016)(R -7.2095, F 2.7531, G 0.0155)] [G loss: -12.2737]\n",
      "143 (5, 1) [D loss: (-4.5526)(R -21.3531, F 16.1837, G 0.0617)] [G loss: -16.8676]\n",
      "144 (5, 1) [D loss: (-3.1321)(R -16.8378, F 13.6404, G 0.0065)] [G loss: -18.6520]\n",
      "145 (5, 1) [D loss: (2.2090)(R -19.1591, F 21.2826, G 0.0085)] [G loss: -21.8294]\n",
      "146 (5, 1) [D loss: (-0.7110)(R -21.8063, F 21.0656, G 0.0030)] [G loss: -21.7893]\n",
      "147 (5, 1) [D loss: (-1.4805)(R -21.1559, F 19.6538, G 0.0022)] [G loss: -23.0663]\n",
      "148 (5, 1) [D loss: (1.3728)(R -14.4044, F 15.7027, G 0.0074)] [G loss: -15.4251]\n",
      "149 (5, 1) [D loss: (0.5703)(R -1.3922, F 1.7719, G 0.0191)] [G loss: -1.5090]\n",
      "150 (5, 1) [D loss: (0.8112)(R 27.0011, F -26.2195, G 0.0030)] [G loss: 41.0466]\n",
      "151 (5, 1) [D loss: (-4.6152)(R 73.9202, F -80.4260, G 0.1891)] [G loss: 82.0375]\n",
      "152 (5, 1) [D loss: (-4.7202)(R 69.8412, F -75.0931, G 0.0532)] [G loss: 80.0359]\n",
      "153 (5, 1) [D loss: (-1.9198)(R 66.9514, F -69.2277, G 0.0357)] [G loss: 72.4888]\n",
      "154 (5, 1) [D loss: (-1.9968)(R 69.9211, F -72.0850, G 0.0167)] [G loss: 65.9100]\n",
      "155 (5, 1) [D loss: (-0.8589)(R 70.7097, F -71.8035, G 0.0235)] [G loss: 72.8702]\n",
      "156 (5, 1) [D loss: (-4.4024)(R 65.3783, F -69.8398, G 0.0059)] [G loss: 64.9378]\n",
      "157 (5, 1) [D loss: (1.2590)(R 63.3203, F -62.1262, G 0.0065)] [G loss: 56.8293]\n",
      "158 (5, 1) [D loss: (-4.1624)(R 52.9750, F -57.3967, G 0.0259)] [G loss: 55.3729]\n",
      "159 (5, 1) [D loss: (0.7096)(R 56.1243, F -55.5213, G 0.0107)] [G loss: 56.3290]\n",
      "160 (5, 1) [D loss: (-1.6035)(R 55.2032, F -56.8923, G 0.0086)] [G loss: 55.2878]\n",
      "161 (5, 1) [D loss: (0.4247)(R 56.0395, F -55.6438, G 0.0029)] [G loss: 54.0604]\n",
      "162 (5, 1) [D loss: (-1.0326)(R 47.9915, F -49.0657, G 0.0042)] [G loss: 47.3641]\n",
      "163 (5, 1) [D loss: (-0.1728)(R 44.4457, F -44.6414, G 0.0023)] [G loss: 46.1255]\n",
      "164 (5, 1) [D loss: (-1.9539)(R 37.2982, F -39.2837, G 0.0032)] [G loss: 36.1071]\n",
      "165 (5, 1) [D loss: (-1.5064)(R 29.0412, F -30.5879, G 0.0040)] [G loss: 28.6483]\n",
      "166 (5, 1) [D loss: (0.0187)(R 23.2135, F -23.2587, G 0.0064)] [G loss: 23.4607]\n",
      "167 (5, 1) [D loss: (-3.7332)(R 18.4362, F -22.1994, G 0.0030)] [G loss: 22.3125]\n",
      "168 (5, 1) [D loss: (-1.0582)(R 19.3631, F -20.4547, G 0.0033)] [G loss: 21.0349]\n",
      "169 (5, 1) [D loss: (1.5071)(R 18.9514, F -17.4682, G 0.0024)] [G loss: 18.2375]\n",
      "170 (5, 1) [D loss: (-2.8569)(R 18.1769, F -21.0487, G 0.0015)] [G loss: 22.2293]\n",
      "171 (5, 1) [D loss: (-1.2521)(R 25.8605, F -27.1273, G 0.0015)] [G loss: 27.6046]\n",
      "172 (5, 1) [D loss: (-1.3758)(R 32.9257, F -34.4171, G 0.0116)] [G loss: 34.0203]\n",
      "173 (5, 1) [D loss: (-6.4948)(R 28.5315, F -35.1869, G 0.0161)] [G loss: 33.0760]\n",
      "174 (5, 1) [D loss: (-3.2318)(R 23.5134, F -26.9627, G 0.0218)] [G loss: 26.2243]\n",
      "175 (5, 1) [D loss: (-4.8455)(R 3.8861, F -8.9293, G 0.0198)] [G loss: 3.6774]\n",
      "176 (5, 1) [D loss: (-5.0600)(R -10.3005, F 4.8225, G 0.0418)] [G loss: -7.6683]\n",
      "177 (5, 1) [D loss: (-3.7405)(R -14.6367, F 10.5024, G 0.0394)] [G loss: -14.8607]\n",
      "178 (5, 1) [D loss: (-1.8501)(R -14.1584, F 12.0492, G 0.0259)] [G loss: -12.8503]\n",
      "179 (5, 1) [D loss: (-5.4548)(R -14.3229, F 8.7756, G 0.0092)] [G loss: -12.9595]\n",
      "180 (5, 1) [D loss: (-0.6523)(R -8.6019, F 7.8251, G 0.0125)] [G loss: -10.9591]\n",
      "181 (5, 1) [D loss: (-0.6624)(R -1.5189, F 0.7965, G 0.0060)] [G loss: 1.1490]\n",
      "182 (5, 1) [D loss: (0.2846)(R 2.4931, F -2.2323, G 0.0024)] [G loss: 3.8553]\n",
      "183 (5, 1) [D loss: (-4.6096)(R 5.2519, F -9.8770, G 0.0015)] [G loss: 2.5355]\n",
      "184 (5, 1) [D loss: (-1.5607)(R 5.3503, F -6.9401, G 0.0029)] [G loss: 2.8615]\n",
      "185 (5, 1) [D loss: (0.0312)(R -0.6571, F 0.6713, G 0.0017)] [G loss: -4.1250]\n",
      "186 (5, 1) [D loss: (1.2173)(R 1.1644, F 0.0205, G 0.0032)] [G loss: -3.3609]\n",
      "187 (5, 1) [D loss: (-0.0963)(R 17.0213, F -17.2563, G 0.0139)] [G loss: 21.6962]\n",
      "188 (5, 1) [D loss: (-2.9101)(R 57.7970, F -61.3270, G 0.0620)] [G loss: 66.8290]\n",
      "189 (5, 1) [D loss: (-2.3050)(R 71.4280, F -74.5582, G 0.0825)] [G loss: 80.6264]\n",
      "190 (5, 1) [D loss: (-5.7456)(R 70.3380, F -76.3898, G 0.0306)] [G loss: 77.5785]\n",
      "191 (5, 1) [D loss: (0.0359)(R 72.7392, F -72.9359, G 0.0233)] [G loss: 69.5012]\n",
      "192 (5, 1) [D loss: (-2.0647)(R 67.0036, F -69.1355, G 0.0067)] [G loss: 69.1864]\n",
      "193 (5, 1) [D loss: (-8.4101)(R 73.9784, F -82.7898, G 0.0401)] [G loss: 81.1673]\n",
      "194 (5, 1) [D loss: (-1.9779)(R 77.0898, F -79.5399, G 0.0472)] [G loss: 76.9297]\n",
      "195 (5, 1) [D loss: (-9.9130)(R 73.6368, F -84.2085, G 0.0659)] [G loss: 81.4714]\n",
      "196 (5, 1) [D loss: (-2.4023)(R 67.8819, F -70.6081, G 0.0324)] [G loss: 67.6094]\n",
      "197 (5, 1) [D loss: (-0.2165)(R 65.7328, F -66.3877, G 0.0438)] [G loss: 60.5839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 (5, 1) [D loss: (-6.1345)(R 54.1029, F -60.7774, G 0.0540)] [G loss: 56.8668]\n",
      "199 (5, 1) [D loss: (1.5513)(R 40.6455, F -39.1684, G 0.0074)] [G loss: 38.6874]\n",
      "200 (5, 1) [D loss: (-1.5317)(R 26.5473, F -28.1342, G 0.0055)] [G loss: 25.4445]\n",
      "201 (5, 1) [D loss: (-2.2186)(R 12.4477, F -14.7963, G 0.0130)] [G loss: 12.7062]\n",
      "202 (5, 1) [D loss: (-1.0821)(R 9.3736, F -10.5306, G 0.0075)] [G loss: 8.2559]\n",
      "203 (5, 1) [D loss: (1.7591)(R 7.4760, F -5.8014, G 0.0085)] [G loss: 6.5421]\n",
      "204 (5, 1) [D loss: (3.3002)(R 8.4016, F -5.3010, G 0.0200)] [G loss: 7.0484]\n",
      "205 (5, 1) [D loss: (0.2677)(R 10.9544, F -10.8960, G 0.0209)] [G loss: 10.7775]\n",
      "206 (5, 1) [D loss: (-0.1559)(R 26.7372, F -26.9217, G 0.0029)] [G loss: 32.9940]\n",
      "207 (5, 1) [D loss: (0.2446)(R 47.9957, F -48.4960, G 0.0745)] [G loss: 48.5100]\n",
      "208 (5, 1) [D loss: (-6.3543)(R 48.8365, F -55.6142, G 0.0423)] [G loss: 52.8039]\n",
      "209 (5, 1) [D loss: (-5.4432)(R 39.8261, F -45.4319, G 0.0163)] [G loss: 44.0981]\n",
      "210 (5, 1) [D loss: (-6.0327)(R 31.0597, F -37.4842, G 0.0392)] [G loss: 32.1169]\n",
      "211 (5, 1) [D loss: (-7.8667)(R 3.5853, F -12.6215, G 0.1169)] [G loss: 4.7529]\n",
      "212 (5, 1) [D loss: (0.8051)(R -5.7185, F 6.2908, G 0.0233)] [G loss: -1.7794]\n",
      "213 (5, 1) [D loss: (1.5595)(R -4.7070, F 6.2423, G 0.0024)] [G loss: -5.6680]\n",
      "214 (5, 1) [D loss: (-3.0724)(R -9.7692, F 6.6745, G 0.0022)] [G loss: -8.7773]\n",
      "215 (5, 1) [D loss: (0.8652)(R -12.2387, F 12.9478, G 0.0156)] [G loss: -12.2395]\n",
      "216 (5, 1) [D loss: (-0.0380)(R -11.8410, F 11.4316, G 0.0371)] [G loss: -9.9270]\n",
      "217 (5, 1) [D loss: (-4.0863)(R -5.1332, F 0.7045, G 0.0342)] [G loss: -2.2978]\n",
      "218 (5, 1) [D loss: (-2.2454)(R -14.2468, F 11.7324, G 0.0269)] [G loss: -16.3108]\n",
      "219 (5, 1) [D loss: (-3.3283)(R -33.3907, F 29.5243, G 0.0538)] [G loss: -32.7869]\n",
      "220 (5, 1) [D loss: (-6.4091)(R -43.2362, F 35.8948, G 0.0932)] [G loss: -46.6908]\n",
      "221 (5, 1) [D loss: (0.6376)(R -29.3787, F 29.9576, G 0.0059)] [G loss: -30.1353]\n",
      "222 (5, 1) [D loss: (1.8185)(R -24.6032, F 26.3707, G 0.0051)] [G loss: -26.9265]\n",
      "223 (5, 1) [D loss: (0.7712)(R -24.8982, F 25.3704, G 0.0299)] [G loss: -25.4487]\n",
      "224 (5, 1) [D loss: (-0.7288)(R -27.7351, F 26.6241, G 0.0382)] [G loss: -28.1109]\n",
      "225 (5, 1) [D loss: (-1.5653)(R -26.9838, F 25.1844, G 0.0234)] [G loss: -24.1840]\n",
      "226 (5, 1) [D loss: (-3.4926)(R -31.0696, F 25.9001, G 0.1677)] [G loss: -27.4226]\n",
      "227 (5, 1) [D loss: (-4.2218)(R -35.4376, F 30.1959, G 0.1020)] [G loss: -28.4616]\n",
      "228 (5, 1) [D loss: (-5.6370)(R -33.5836, F 27.2966, G 0.0650)] [G loss: -30.4051]\n",
      "229 (5, 1) [D loss: (-2.4771)(R -32.1649, F 29.1976, G 0.0490)] [G loss: -30.3497]\n",
      "230 (5, 1) [D loss: (-4.4050)(R -31.5738, F 26.8720, G 0.0297)] [G loss: -27.5220]\n",
      "231 (5, 1) [D loss: (-1.7758)(R -31.2695, F 29.3891, G 0.0105)] [G loss: -26.1929]\n",
      "232 (5, 1) [D loss: (-3.3107)(R -21.9100, F 18.3002, G 0.0299)] [G loss: -13.4901]\n",
      "233 (5, 1) [D loss: (-5.9087)(R -20.2384, F 13.8316, G 0.0498)] [G loss: -13.6290]\n",
      "234 (5, 1) [D loss: (-6.9972)(R -22.4132, F 14.3492, G 0.1067)] [G loss: -13.6605]\n",
      "235 (5, 1) [D loss: (-4.8272)(R -25.3086, F 20.0719, G 0.0410)] [G loss: -18.0811]\n",
      "236 (5, 1) [D loss: (-1.6780)(R -18.7007, F 16.9517, G 0.0071)] [G loss: -20.2718]\n",
      "237 (5, 1) [D loss: (2.9081)(R -16.9091, F 19.7857, G 0.0031)] [G loss: -19.8264]\n",
      "238 (5, 1) [D loss: (-5.2484)(R -22.3887, F 17.1050, G 0.0035)] [G loss: -22.1250]\n",
      "239 (5, 1) [D loss: (-1.7790)(R -19.3223, F 17.5135, G 0.0030)] [G loss: -15.3310]\n",
      "240 (5, 1) [D loss: (-4.3578)(R -9.1700, F 4.7353, G 0.0077)] [G loss: 1.3461]\n",
      "241 (5, 1) [D loss: (-11.4630)(R 13.2512, F -24.9420, G 0.0228)] [G loss: 23.9419]\n",
      "242 (5, 1) [D loss: (-3.3674)(R 20.9969, F -24.4209, G 0.0057)] [G loss: 29.9259]\n",
      "243 (5, 1) [D loss: (-1.9286)(R 23.2743, F -25.2181, G 0.0015)] [G loss: 25.7739]\n",
      "244 (5, 1) [D loss: (-2.8235)(R 9.4000, F -12.2979, G 0.0074)] [G loss: 11.5540]\n",
      "245 (5, 1) [D loss: (0.3167)(R 7.4954, F -7.3533, G 0.0175)] [G loss: 7.6317]\n",
      "246 (5, 1) [D loss: (1.6661)(R 8.2146, F -6.6464, G 0.0098)] [G loss: 6.9743]\n",
      "247 (5, 1) [D loss: (-1.3535)(R 3.1050, F -4.4965, G 0.0038)] [G loss: 6.3440]\n",
      "248 (5, 1) [D loss: (-6.2138)(R -1.5632, F -4.8462, G 0.0196)] [G loss: 1.0366]\n",
      "249 (5, 1) [D loss: (-0.3653)(R -1.2138, F 0.5324, G 0.0316)] [G loss: 1.0744]\n",
      "250 (5, 1) [D loss: (-0.4405)(R 0.2492, F -0.8287, G 0.0139)] [G loss: 0.3838]\n",
      "251 (5, 1) [D loss: (1.9991)(R 5.5350, F -3.5881, G 0.0052)] [G loss: 4.5162]\n",
      "252 (5, 1) [D loss: (-2.1279)(R 4.0976, F -6.2520, G 0.0026)] [G loss: 4.7269]\n",
      "253 (5, 1) [D loss: (2.8203)(R 8.7147, F -5.9517, G 0.0057)] [G loss: 5.8588]\n",
      "254 (5, 1) [D loss: (-2.4049)(R 13.7005, F -16.3544, G 0.0249)] [G loss: 18.7893]\n",
      "255 (5, 1) [D loss: (-2.6189)(R 16.1713, F -18.9481, G 0.0158)] [G loss: 18.0604]\n",
      "256 (5, 1) [D loss: (2.5666)(R 25.0025, F -22.4810, G 0.0045)] [G loss: 25.6788]\n",
      "257 (5, 1) [D loss: (-7.2753)(R 42.0548, F -49.8550, G 0.0525)] [G loss: 57.1746]\n",
      "258 (5, 1) [D loss: (-11.1654)(R 60.7421, F -73.1795, G 0.1272)] [G loss: 75.8937]\n",
      "259 (5, 1) [D loss: (-11.0421)(R 63.3913, F -75.2162, G 0.0783)] [G loss: 76.6036]\n",
      "260 (5, 1) [D loss: (-4.7395)(R 74.4224, F -80.0412, G 0.0879)] [G loss: 71.6161]\n",
      "261 (5, 1) [D loss: (-2.3264)(R 55.9521, F -58.3262, G 0.0048)] [G loss: 58.4841]\n",
      "262 (5, 1) [D loss: (-3.5465)(R 49.7013, F -53.3644, G 0.0117)] [G loss: 52.5908]\n",
      "263 (5, 1) [D loss: (-4.4708)(R 50.4465, F -55.1937, G 0.0276)] [G loss: 55.1893]\n",
      "264 (5, 1) [D loss: (-5.0078)(R 52.3428, F -57.6661, G 0.0315)] [G loss: 60.8356]\n",
      "265 (5, 1) [D loss: (-6.0703)(R 76.1494, F -82.8286, G 0.0609)] [G loss: 82.2721]\n",
      "266 (5, 1) [D loss: (-4.9932)(R 66.5279, F -71.8100, G 0.0289)] [G loss: 73.6889]\n",
      "267 (5, 1) [D loss: (1.2452)(R 69.7650, F -68.6696, G 0.0150)] [G loss: 66.2537]\n",
      "268 (5, 1) [D loss: (1.2569)(R 65.8876, F -64.7585, G 0.0128)] [G loss: 60.6713]\n",
      "269 (5, 1) [D loss: (-3.5486)(R 48.7940, F -52.3739, G 0.0031)] [G loss: 52.1120]\n",
      "270 (5, 1) [D loss: (-2.5698)(R 36.6467, F -39.2659, G 0.0049)] [G loss: 36.2474]\n",
      "271 (5, 1) [D loss: (2.1349)(R 22.1503, F -20.0867, G 0.0071)] [G loss: 16.1576]\n",
      "272 (5, 1) [D loss: (-2.0255)(R 1.3648, F -3.4964, G 0.0106)] [G loss: 1.0459]\n",
      "273 (5, 1) [D loss: (-4.2685)(R -4.8407, F 0.5153, G 0.0057)] [G loss: 0.2812]\n",
      "274 (5, 1) [D loss: (2.0627)(R -3.8202, F 5.8508, G 0.0032)] [G loss: -1.1377]\n",
      "275 (5, 1) [D loss: (-4.0904)(R -6.9558, F 2.7716, G 0.0094)] [G loss: -0.6085]\n",
      "276 (5, 1) [D loss: (-5.1968)(R -7.1171, F 1.5123, G 0.0408)] [G loss: -6.1663]\n",
      "277 (5, 1) [D loss: (-4.3391)(R -12.6067, F 7.7615, G 0.0506)] [G loss: -9.2728]\n",
      "278 (5, 1) [D loss: (-6.4592)(R -10.5975, F 3.3456, G 0.0793)] [G loss: -9.7331]\n",
      "279 (5, 1) [D loss: (-6.7588)(R -15.6881, F 7.8752, G 0.1054)] [G loss: -15.6501]\n",
      "280 (5, 1) [D loss: (-7.8023)(R -25.6225, F 17.0624, G 0.0758)] [G loss: -25.0772]\n",
      "281 (5, 1) [D loss: (-8.7867)(R -21.2746, F 12.1797, G 0.0308)] [G loss: -16.7625]\n",
      "282 (5, 1) [D loss: (-2.4024)(R -14.1355, F 11.5023, G 0.0231)] [G loss: -17.2942]\n",
      "283 (5, 1) [D loss: (-1.6884)(R -22.1703, F 20.3915, G 0.0091)] [G loss: -25.5084]\n",
      "284 (5, 1) [D loss: (-3.3063)(R -17.0747, F 13.7448, G 0.0024)] [G loss: -17.3723]\n",
      "285 (5, 1) [D loss: (-0.2274)(R -21.4692, F 21.2246, G 0.0017)] [G loss: -21.9916]\n",
      "286 (5, 1) [D loss: (1.4498)(R -11.4701, F 12.8621, G 0.0058)] [G loss: -13.6266]\n",
      "287 (5, 1) [D loss: (3.9838)(R -0.4446, F 4.3225, G 0.0106)] [G loss: -0.1822]\n",
      "288 (5, 1) [D loss: (0.8238)(R 23.8011, F -23.1703, G 0.0193)] [G loss: 25.9175]\n",
      "289 (5, 1) [D loss: (-2.3508)(R 57.8667, F -60.5231, G 0.0306)] [G loss: 79.9294]\n",
      "290 (5, 1) [D loss: (-9.4930)(R 79.0438, F -88.9301, G 0.0393)] [G loss: 92.7436]\n",
      "291 (5, 1) [D loss: (2.7186)(R 92.3109, F -90.1774, G 0.0585)] [G loss: 89.8873]\n",
      "292 (5, 1) [D loss: (-1.3221)(R 79.9233, F -81.3697, G 0.0124)] [G loss: 77.4497]\n",
      "293 (5, 1) [D loss: (-8.5301)(R 74.6236, F -83.2467, G 0.0093)] [G loss: 87.2800]\n",
      "294 (5, 1) [D loss: (-1.2257)(R 64.5390, F -65.8198, G 0.0055)] [G loss: 61.5928]\n",
      "295 (5, 1) [D loss: (-4.1606)(R 55.1256, F -59.4116, G 0.0125)] [G loss: 60.4268]\n",
      "296 (5, 1) [D loss: (1.0309)(R 53.1537, F -52.3442, G 0.0221)] [G loss: 47.3856]\n",
      "297 (5, 1) [D loss: (-1.9678)(R 35.1606, F -37.2442, G 0.0116)] [G loss: 34.7111]\n",
      "298 (5, 1) [D loss: (-9.5853)(R 16.8683, F -26.9446, G 0.0491)] [G loss: 23.6465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 (5, 1) [D loss: (-11.6352)(R 22.4528, F -34.6340, G 0.0546)] [G loss: 23.0986]\n",
      "300 (5, 1) [D loss: (-3.8420)(R 38.3794, F -42.9193, G 0.0698)] [G loss: 41.4153]\n",
      "301 (5, 1) [D loss: (-10.4549)(R 60.2527, F -72.9545, G 0.2247)] [G loss: 72.8712]\n",
      "302 (5, 1) [D loss: (-6.3968)(R 72.6848, F -81.0183, G 0.1937)] [G loss: 79.0099]\n",
      "303 (5, 1) [D loss: (-7.7522)(R 60.6834, F -69.1922, G 0.0757)] [G loss: 71.0466]\n",
      "304 (5, 1) [D loss: (-9.4871)(R 51.9896, F -61.8367, G 0.0360)] [G loss: 57.7351]\n",
      "305 (5, 1) [D loss: (-3.3240)(R 44.0145, F -47.4370, G 0.0098)] [G loss: 42.5680]\n",
      "306 (5, 1) [D loss: (-4.7818)(R 22.4177, F -27.2529, G 0.0053)] [G loss: 23.3467]\n",
      "307 (5, 1) [D loss: (-12.1726)(R -9.3998, F -3.4306, G 0.0658)] [G loss: 4.1911]\n",
      "308 (5, 1) [D loss: (-13.8197)(R 2.5302, F -19.0098, G 0.2660)] [G loss: 15.0711]\n",
      "309 (5, 1) [D loss: (-8.8629)(R 10.3459, F -20.9426, G 0.1734)] [G loss: 17.6070]\n",
      "310 (5, 1) [D loss: (-4.0173)(R 15.6503, F -20.0015, G 0.0334)] [G loss: 18.0044]\n",
      "311 (5, 1) [D loss: (-11.5269)(R 25.9923, F -37.6460, G 0.0127)] [G loss: 28.3715]\n",
      "312 (5, 1) [D loss: (0.5780)(R 21.1817, F -20.8558, G 0.0252)] [G loss: 16.7280]\n",
      "313 (5, 1) [D loss: (-1.6173)(R 37.4356, F -39.1992, G 0.0146)] [G loss: 46.6592]\n",
      "314 (5, 1) [D loss: (1.2494)(R 62.7748, F -62.1808, G 0.0655)] [G loss: 68.5591]\n",
      "315 (5, 1) [D loss: (-7.3512)(R 57.8856, F -65.3266, G 0.0090)] [G loss: 55.1542]\n",
      "316 (5, 1) [D loss: (3.6256)(R 61.6308, F -58.1165, G 0.0111)] [G loss: 56.9300]\n",
      "317 (5, 1) [D loss: (-9.7918)(R 67.3432, F -77.6841, G 0.0549)] [G loss: 73.9889]\n",
      "318 (5, 1) [D loss: (1.3011)(R 69.5452, F -68.3686, G 0.0125)] [G loss: 70.7060]\n",
      "319 (5, 1) [D loss: (-4.7700)(R 74.3755, F -80.2317, G 0.1086)] [G loss: 72.4321]\n",
      "320 (5, 1) [D loss: (-5.3550)(R 37.3779, F -43.0113, G 0.0278)] [G loss: 45.4708]\n",
      "321 (5, 1) [D loss: (0.2382)(R 26.3087, F -26.2213, G 0.0151)] [G loss: 26.6857]\n",
      "322 (5, 1) [D loss: (1.1599)(R 23.9142, F -23.1695, G 0.0415)] [G loss: 11.9177]\n",
      "323 (5, 1) [D loss: (-0.4059)(R 15.2369, F -15.6735, G 0.0031)] [G loss: 13.3565]\n",
      "324 (5, 1) [D loss: (-6.9254)(R 0.0559, F -7.0136, G 0.0032)] [G loss: 7.6312]\n",
      "325 (5, 1) [D loss: (-1.3416)(R 3.7934, F -5.2281, G 0.0093)] [G loss: 4.1979]\n",
      "326 (5, 1) [D loss: (-9.8411)(R 2.9862, F -12.9518, G 0.0125)] [G loss: 5.7509]\n",
      "327 (5, 1) [D loss: (0.0699)(R 8.7930, F -8.9512, G 0.0228)] [G loss: 1.8967]\n",
      "328 (5, 1) [D loss: (-2.1196)(R 5.4868, F -7.7558, G 0.0149)] [G loss: 17.3223]\n",
      "329 (5, 1) [D loss: (8.2407)(R 12.9272, F -5.0190, G 0.0332)] [G loss: 14.7825]\n",
      "330 (5, 1) [D loss: (-4.7906)(R 14.1117, F -19.0705, G 0.0168)] [G loss: 21.4420]\n",
      "331 (5, 1) [D loss: (-0.8629)(R 21.0127, F -22.1383, G 0.0263)] [G loss: 27.6778]\n",
      "332 (5, 1) [D loss: (-8.9627)(R 19.9110, F -29.0917, G 0.0218)] [G loss: 26.6198]\n",
      "333 (5, 1) [D loss: (4.8980)(R 40.9431, F -36.4154, G 0.0370)] [G loss: 40.5703]\n",
      "334 (5, 1) [D loss: (-3.2251)(R 34.3827, F -37.6751, G 0.0067)] [G loss: 32.4187]\n",
      "335 (5, 1) [D loss: (-0.4675)(R 36.4597, F -36.9833, G 0.0056)] [G loss: 32.0028]\n",
      "336 (5, 1) [D loss: (-0.0184)(R 42.1308, F -42.2243, G 0.0075)] [G loss: 41.1550]\n",
      "337 (5, 1) [D loss: (13.5159)(R 57.0462, F -44.6571, G 0.1127)] [G loss: 43.6995]\n",
      "338 (5, 1) [D loss: (-9.2232)(R 30.6224, F -40.0896, G 0.0244)] [G loss: 43.3595]\n",
      "339 (5, 1) [D loss: (-3.5389)(R 44.2048, F -48.2054, G 0.0462)] [G loss: 46.0874]\n",
      "340 (5, 1) [D loss: (9.5982)(R 50.6692, F -41.0990, G 0.0028)] [G loss: 44.1114]\n",
      "341 (5, 1) [D loss: (-1.2502)(R 51.1803, F -52.4896, G 0.0059)] [G loss: 48.9622]\n",
      "342 (5, 1) [D loss: (1.7436)(R 57.7189, F -56.0287, G 0.0053)] [G loss: 49.0418]\n",
      "343 (5, 1) [D loss: (-0.7987)(R 50.7584, F -51.6660, G 0.0109)] [G loss: 52.0813]\n",
      "344 (5, 1) [D loss: (-0.6412)(R 51.1943, F -51.8887, G 0.0053)] [G loss: 53.0492]\n",
      "345 (5, 1) [D loss: (-0.1539)(R 62.9573, F -63.3453, G 0.0234)] [G loss: 56.5957]\n",
      "346 (5, 1) [D loss: (-1.4960)(R 61.4704, F -63.2964, G 0.0330)] [G loss: 63.1977]\n",
      "347 (5, 1) [D loss: (-9.6735)(R 56.1540, F -65.9481, G 0.0121)] [G loss: 71.2140]\n",
      "348 (5, 1) [D loss: (-2.0952)(R 63.4704, F -65.6625, G 0.0097)] [G loss: 62.1621]\n",
      "349 (5, 1) [D loss: (0.8898)(R 68.8166, F -68.4218, G 0.0495)] [G loss: 65.3767]\n",
      "350 (5, 1) [D loss: (5.1137)(R 58.6278, F -53.8816, G 0.0368)] [G loss: 52.5527]\n",
      "351 (5, 1) [D loss: (0.1155)(R 43.6064, F -43.9460, G 0.0455)] [G loss: 42.1980]\n",
      "352 (5, 1) [D loss: (0.6493)(R 45.6527, F -45.9551, G 0.0952)] [G loss: 48.1696]\n",
      "353 (5, 1) [D loss: (-5.1999)(R 44.9502, F -51.4504, G 0.1300)] [G loss: 49.9196]\n",
      "354 (5, 1) [D loss: (-8.9493)(R 48.8764, F -58.6623, G 0.0837)] [G loss: 50.2349]\n",
      "355 (5, 1) [D loss: (-8.9464)(R 59.6231, F -69.2601, G 0.0691)] [G loss: 62.3015]\n",
      "356 (5, 1) [D loss: (-3.9822)(R 51.5260, F -55.9978, G 0.0490)] [G loss: 53.7922]\n",
      "357 (5, 1) [D loss: (-1.1435)(R 52.7468, F -53.9320, G 0.0042)] [G loss: 53.2147]\n",
      "358 (5, 1) [D loss: (-6.6501)(R 31.1243, F -38.1002, G 0.0326)] [G loss: 33.4165]\n",
      "359 (5, 1) [D loss: (-0.2613)(R 27.2234, F -27.6626, G 0.0178)] [G loss: 20.3375]\n",
      "360 (5, 1) [D loss: (2.9865)(R 20.5604, F -17.6122, G 0.0038)] [G loss: 18.0138]\n",
      "361 (5, 1) [D loss: (-0.7216)(R 14.5553, F -15.3319, G 0.0055)] [G loss: 9.6947]\n",
      "362 (5, 1) [D loss: (-6.1215)(R 4.0405, F -10.2125, G 0.0050)] [G loss: 5.4994]\n",
      "363 (5, 1) [D loss: (-8.4191)(R 3.6478, F -12.0838, G 0.0017)] [G loss: 4.7713]\n",
      "364 (5, 1) [D loss: (-5.9244)(R 12.4153, F -18.4985, G 0.0159)] [G loss: 22.6463]\n",
      "365 (5, 1) [D loss: (-1.6446)(R 21.3149, F -23.0940, G 0.0135)] [G loss: 27.8483]\n",
      "366 (5, 1) [D loss: (3.2078)(R 28.3425, F -25.3045, G 0.0170)] [G loss: 29.7569]\n",
      "367 (5, 1) [D loss: (-0.0363)(R 16.7051, F -16.8053, G 0.0064)] [G loss: 18.8158]\n",
      "368 (5, 1) [D loss: (-11.8493)(R 23.6222, F -35.6204, G 0.0149)] [G loss: 39.3625]\n",
      "369 (5, 1) [D loss: (-7.5130)(R 25.3971, F -33.5955, G 0.0685)] [G loss: 31.0491]\n",
      "370 (5, 1) [D loss: (-2.3470)(R 41.8023, F -44.5500, G 0.0401)] [G loss: 49.1632]\n",
      "371 (5, 1) [D loss: (-5.1711)(R 48.5556, F -53.9216, G 0.0195)] [G loss: 50.7493]\n",
      "372 (5, 1) [D loss: (-1.8769)(R 51.8211, F -53.9813, G 0.0283)] [G loss: 52.0100]\n",
      "373 (5, 1) [D loss: (-8.7552)(R 53.1613, F -63.1253, G 0.1209)] [G loss: 59.7177]\n",
      "374 (5, 1) [D loss: (-11.6819)(R 51.2829, F -64.2489, G 0.1284)] [G loss: 68.6142]\n",
      "375 (5, 1) [D loss: (-8.6566)(R 57.9393, F -69.5070, G 0.2911)] [G loss: 66.1079]\n",
      "376 (5, 1) [D loss: (-7.2442)(R 77.2490, F -85.0075, G 0.0514)] [G loss: 68.0964]\n",
      "377 (5, 1) [D loss: (-6.4228)(R 91.9716, F -98.4930, G 0.0099)] [G loss: 105.4285]\n",
      "378 (5, 1) [D loss: (3.1616)(R 107.3651, F -104.4092, G 0.0206)] [G loss: 113.8360]\n",
      "379 (5, 1) [D loss: (-10.3384)(R 115.5848, F -126.1695, G 0.0246)] [G loss: 141.8061]\n",
      "380 (5, 1) [D loss: (1.2682)(R 174.4738, F -173.9097, G 0.0704)] [G loss: 167.5910]\n",
      "381 (5, 1) [D loss: (12.7048)(R 199.2713, F -186.6796, G 0.0113)] [G loss: 161.3842]\n",
      "382 (5, 1) [D loss: (-3.5426)(R 158.2917, F -161.9315, G 0.0097)] [G loss: 168.4317]\n",
      "383 (5, 1) [D loss: (3.8598)(R 139.6471, F -135.9880, G 0.0201)] [G loss: 137.3810]\n",
      "384 (5, 1) [D loss: (-5.1368)(R 125.0711, F -130.9483, G 0.0740)] [G loss: 124.7720]\n",
      "385 (5, 1) [D loss: (-7.3195)(R 99.0618, F -106.6324, G 0.0251)] [G loss: 106.3469]\n",
      "386 (5, 1) [D loss: (-5.0949)(R 99.8399, F -105.4343, G 0.0500)] [G loss: 105.8820]\n",
      "387 (5, 1) [D loss: (-0.0484)(R 82.2415, F -82.3573, G 0.0067)] [G loss: 79.8677]\n",
      "388 (5, 1) [D loss: (0.5024)(R 55.8023, F -55.3611, G 0.0061)] [G loss: 55.0884]\n",
      "389 (5, 1) [D loss: (-6.0940)(R 56.5375, F -62.9063, G 0.0275)] [G loss: 58.9631]\n",
      "390 (5, 1) [D loss: (-1.2294)(R 49.4525, F -50.9669, G 0.0285)] [G loss: 55.3778]\n",
      "391 (5, 1) [D loss: (-1.4209)(R 61.6259, F -63.2294, G 0.0183)] [G loss: 59.7438]\n",
      "392 (5, 1) [D loss: (-5.5127)(R 54.7037, F -60.4639, G 0.0248)] [G loss: 59.3878]\n",
      "393 (5, 1) [D loss: (-15.2371)(R 56.9006, F -72.1574, G 0.0020)] [G loss: 67.3633]\n",
      "394 (5, 1) [D loss: (3.7849)(R 78.6653, F -75.0396, G 0.0159)] [G loss: 62.9403]\n",
      "395 (5, 1) [D loss: (-2.6088)(R 59.1848, F -61.8468, G 0.0053)] [G loss: 56.9967]\n",
      "396 (5, 1) [D loss: (4.9675)(R 59.5907, F -54.6811, G 0.0058)] [G loss: 61.9202]\n",
      "397 (5, 1) [D loss: (-5.7012)(R 67.9499, F -73.6827, G 0.0032)] [G loss: 78.2180]\n",
      "398 (5, 1) [D loss: (-9.5033)(R 77.4308, F -86.9569, G 0.0023)] [G loss: 72.1462]\n",
      "399 (5, 1) [D loss: (6.9377)(R 89.4996, F -82.6143, G 0.0052)] [G loss: 74.3076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 (5, 1) [D loss: (9.9693)(R 117.5745, F -108.5909, G 0.0986)] [G loss: 106.8669]\n",
      "401 (5, 1) [D loss: (-2.1100)(R 86.0903, F -88.2830, G 0.0083)] [G loss: 85.2883]\n",
      "402 (5, 1) [D loss: (22.1542)(R 102.2467, F -80.1874, G 0.0095)] [G loss: 80.0617]\n",
      "403 (5, 1) [D loss: (-3.7532)(R 41.1253, F -44.9435, G 0.0065)] [G loss: 49.1747]\n",
      "404 (5, 1) [D loss: (0.6461)(R 50.5442, F -50.0019, G 0.0104)] [G loss: 53.8664]\n",
      "405 (5, 1) [D loss: (-5.6924)(R 74.1354, F -80.0059, G 0.0178)] [G loss: 83.2115]\n",
      "406 (5, 1) [D loss: (-7.3077)(R 78.7098, F -86.2821, G 0.0265)] [G loss: 84.0508]\n",
      "407 (5, 1) [D loss: (-0.8148)(R 79.8099, F -80.6665, G 0.0042)] [G loss: 80.9338]\n",
      "408 (5, 1) [D loss: (-5.1369)(R 88.1181, F -93.4270, G 0.0172)] [G loss: 96.7093]\n",
      "409 (5, 1) [D loss: (-3.9563)(R 93.8921, F -97.9361, G 0.0088)] [G loss: 95.2855]\n",
      "410 (5, 1) [D loss: (12.1450)(R 110.5733, F -98.8756, G 0.0447)] [G loss: 91.8381]\n",
      "411 (5, 1) [D loss: (-12.0157)(R 88.3594, F -100.4182, G 0.0043)] [G loss: 106.3649]\n",
      "412 (5, 1) [D loss: (-6.0767)(R 97.4308, F -103.5571, G 0.0050)] [G loss: 100.7868]\n",
      "413 (5, 1) [D loss: (4.2407)(R 86.7600, F -83.0550, G 0.0536)] [G loss: 89.0114]\n",
      "414 (5, 1) [D loss: (-1.3283)(R 75.2972, F -76.9799, G 0.0354)] [G loss: 74.7357]\n",
      "415 (5, 1) [D loss: (-0.9534)(R 75.5109, F -76.8389, G 0.0375)] [G loss: 83.4411]\n",
      "416 (5, 1) [D loss: (-1.8390)(R 72.9851, F -75.2069, G 0.0383)] [G loss: 75.3994]\n",
      "417 (5, 1) [D loss: (-12.7499)(R 66.4117, F -79.3541, G 0.0193)] [G loss: 84.2639]\n",
      "418 (5, 1) [D loss: (6.3122)(R 97.5495, F -91.7238, G 0.0487)] [G loss: 90.5284]\n",
      "419 (5, 1) [D loss: (-13.3181)(R 68.3895, F -81.8083, G 0.0101)] [G loss: 81.1800]\n",
      "420 (5, 1) [D loss: (-2.8989)(R 111.8034, F -115.2048, G 0.0503)] [G loss: 126.5883]\n",
      "421 (5, 1) [D loss: (-4.9396)(R 98.7381, F -103.7300, G 0.0052)] [G loss: 101.8142]\n",
      "422 (5, 1) [D loss: (-4.3343)(R 91.1462, F -95.6741, G 0.0194)] [G loss: 106.2002]\n",
      "423 (5, 1) [D loss: (2.4290)(R 98.5040, F -96.1550, G 0.0080)] [G loss: 84.3447]\n",
      "424 (5, 1) [D loss: (-2.6485)(R 90.9334, F -93.6194, G 0.0038)] [G loss: 98.7423]\n",
      "425 (5, 1) [D loss: (-0.1993)(R 89.5619, F -90.0984, G 0.0337)] [G loss: 82.8754]\n",
      "426 (5, 1) [D loss: (3.0825)(R 70.0322, F -68.0382, G 0.1089)] [G loss: 72.9336]\n",
      "427 (5, 1) [D loss: (3.8670)(R 87.3115, F -83.5980, G 0.0154)] [G loss: 94.7114]\n",
      "428 (5, 1) [D loss: (-0.8707)(R 90.7004, F -91.8117, G 0.0241)] [G loss: 97.0958]\n",
      "429 (5, 1) [D loss: (-1.5406)(R 122.4510, F -124.3807, G 0.0389)] [G loss: 128.5112]\n",
      "430 (5, 1) [D loss: (-5.4666)(R 115.1234, F -120.7902, G 0.0200)] [G loss: 123.5552]\n",
      "431 (5, 1) [D loss: (-5.3715)(R 112.9077, F -118.5331, G 0.0254)] [G loss: 115.8639]\n",
      "432 (5, 1) [D loss: (9.8061)(R 105.9932, F -96.2895, G 0.0102)] [G loss: 94.4939]\n",
      "433 (5, 1) [D loss: (-5.3385)(R 91.6876, F -97.0738, G 0.0048)] [G loss: 93.2218]\n",
      "434 (5, 1) [D loss: (-1.0262)(R 84.2238, F -85.2991, G 0.0049)] [G loss: 83.7937]\n",
      "435 (5, 1) [D loss: (1.0052)(R 65.3318, F -64.4917, G 0.0165)] [G loss: 65.9700]\n",
      "436 (5, 1) [D loss: (-3.3102)(R 59.9361, F -63.3182, G 0.0072)] [G loss: 62.8839]\n",
      "437 (5, 1) [D loss: (-5.8433)(R 42.8492, F -48.7464, G 0.0054)] [G loss: 47.7779]\n",
      "438 (5, 1) [D loss: (-3.5777)(R 39.4251, F -43.9559, G 0.0953)] [G loss: 53.1252]\n",
      "439 (5, 1) [D loss: (-7.1426)(R 46.6724, F -54.0338, G 0.0219)] [G loss: 49.6943]\n",
      "440 (5, 1) [D loss: (-3.1155)(R 47.6104, F -50.8759, G 0.0150)] [G loss: 61.0744]\n",
      "441 (5, 1) [D loss: (-4.7414)(R 50.6042, F -55.3882, G 0.0043)] [G loss: 62.3540]\n",
      "442 (5, 1) [D loss: (-9.0940)(R 42.8454, F -51.9652, G 0.0026)] [G loss: 51.9827]\n",
      "443 (5, 1) [D loss: (0.8619)(R 59.8663, F -59.0364, G 0.0032)] [G loss: 55.4386]\n",
      "444 (5, 1) [D loss: (18.2407)(R 90.4011, F -72.5151, G 0.0355)] [G loss: 88.0881]\n",
      "445 (5, 1) [D loss: (-13.7677)(R 89.8552, F -103.6695, G 0.0047)] [G loss: 117.3923]\n",
      "446 (5, 1) [D loss: (5.6178)(R 126.6693, F -121.3372, G 0.0286)] [G loss: 111.3948]\n",
      "447 (5, 1) [D loss: (3.8631)(R 101.7105, F -97.8846, G 0.0037)] [G loss: 89.2154]\n",
      "448 (5, 1) [D loss: (2.5265)(R 93.1527, F -90.7949, G 0.0169)] [G loss: 90.1971]\n",
      "449 (5, 1) [D loss: (12.5775)(R 91.4095, F -78.9975, G 0.0165)] [G loss: 81.9157]\n",
      "450 (5, 1) [D loss: (-9.5754)(R 76.4794, F -86.1216, G 0.0067)] [G loss: 97.1191]\n",
      "451 (5, 1) [D loss: (4.3764)(R 125.0541, F -123.2577, G 0.2580)] [G loss: 93.5987]\n",
      "452 (5, 1) [D loss: (-1.7691)(R 102.9429, F -104.8109, G 0.0099)] [G loss: 110.8978]\n",
      "453 (5, 1) [D loss: (2.8093)(R 99.4601, F -96.8946, G 0.0244)] [G loss: 92.2209]\n",
      "454 (5, 1) [D loss: (-15.0034)(R 52.8058, F -68.3151, G 0.0506)] [G loss: 71.3455]\n",
      "455 (5, 1) [D loss: (-1.3348)(R 65.1330, F -67.3925, G 0.0925)] [G loss: 52.7195]\n",
      "456 (5, 1) [D loss: (11.2016)(R 20.0420, F -9.2506, G 0.0410)] [G loss: 4.1693]\n",
      "457 (5, 1) [D loss: (-15.2916)(R -16.9177, F 1.1575, G 0.0469)] [G loss: -11.5261]\n",
      "458 (5, 1) [D loss: (6.7414)(R -7.3064, F 13.9319, G 0.0116)] [G loss: -8.3059]\n",
      "459 (5, 1) [D loss: (5.6040)(R 3.4077, F 2.0969, G 0.0099)] [G loss: 12.0022]\n",
      "460 (5, 1) [D loss: (1.7867)(R 2.2135, F -0.8979, G 0.0471)] [G loss: 1.2406]\n",
      "461 (5, 1) [D loss: (-3.5721)(R -19.7263, F 15.8864, G 0.0268)] [G loss: -12.6070]\n",
      "462 (5, 1) [D loss: (-4.6101)(R -31.9973, F 25.7910, G 0.1596)] [G loss: -35.8014]\n",
      "463 (5, 1) [D loss: (-0.4224)(R -37.8251, F 36.7017, G 0.0701)] [G loss: -43.7844]\n",
      "464 (5, 1) [D loss: (-15.5222)(R -66.9553, F 51.1933, G 0.0240)] [G loss: -70.2604]\n",
      "465 (5, 1) [D loss: (1.3710)(R -73.7893, F 73.9356, G 0.1225)] [G loss: -72.8738]\n",
      "466 (5, 1) [D loss: (5.0218)(R -54.9808, F 59.9648, G 0.0038)] [G loss: -62.3566]\n",
      "467 (5, 1) [D loss: (-9.0356)(R -87.8882, F 78.6252, G 0.0227)] [G loss: -81.4513]\n",
      "468 (5, 1) [D loss: (3.1108)(R -79.8404, F 82.6359, G 0.0315)] [G loss: -73.8341]\n",
      "469 (5, 1) [D loss: (-5.6256)(R -115.5886, F 107.6840, G 0.2279)] [G loss: -96.6083]\n",
      "470 (5, 1) [D loss: (8.4872)(R -123.5178, F 131.3324, G 0.0673)] [G loss: -128.7048]\n",
      "471 (5, 1) [D loss: (-12.8971)(R -139.2995, F 125.9472, G 0.0455)] [G loss: -154.1929]\n",
      "472 (5, 1) [D loss: (5.4158)(R -142.5744, F 145.8520, G 0.2138)] [G loss: -154.7265]\n",
      "473 (5, 1) [D loss: (4.3843)(R -106.4920, F 110.7483, G 0.0128)] [G loss: -104.4674]\n",
      "474 (5, 1) [D loss: (-17.5557)(R -104.5304, F 86.8679, G 0.0107)] [G loss: -87.8897]\n",
      "475 (5, 1) [D loss: (1.9011)(R -46.3215, F 47.3582, G 0.0864)] [G loss: -38.5463]\n",
      "476 (5, 1) [D loss: (-27.8560)(R -80.0225, F 51.3201, G 0.0846)] [G loss: -72.3666]\n",
      "477 (5, 1) [D loss: (2.5168)(R -62.9933, F 64.6346, G 0.0876)] [G loss: -57.7839]\n",
      "478 (5, 1) [D loss: (-9.7214)(R -43.2528, F 33.2743, G 0.0257)] [G loss: -34.4973]\n",
      "479 (5, 1) [D loss: (-6.8177)(R -34.1185, F 26.9115, G 0.0389)] [G loss: -20.5911]\n",
      "480 (5, 1) [D loss: (-11.3489)(R -13.6200, F 2.0693, G 0.0202)] [G loss: -12.0346]\n",
      "481 (5, 1) [D loss: (-6.0083)(R 14.7367, F -21.1708, G 0.0426)] [G loss: 29.4479]\n",
      "482 (5, 1) [D loss: (-10.0010)(R 25.8948, F -35.9590, G 0.0063)] [G loss: 22.5796]\n",
      "483 (5, 1) [D loss: (18.6289)(R 46.7056, F -28.2070, G 0.0130)] [G loss: 24.2606]\n",
      "484 (5, 1) [D loss: (-7.3910)(R 32.0390, F -39.5040, G 0.0074)] [G loss: 38.7731]\n",
      "485 (5, 1) [D loss: (15.2025)(R 50.5413, F -35.6245, G 0.0286)] [G loss: 38.8312]\n",
      "486 (5, 1) [D loss: (-1.4816)(R 44.1052, F -45.9130, G 0.0326)] [G loss: 55.2169]\n",
      "487 (5, 1) [D loss: (3.1975)(R 64.8169, F -61.8939, G 0.0274)] [G loss: 57.7689]\n",
      "488 (5, 1) [D loss: (-17.8842)(R 43.6016, F -61.7898, G 0.0304)] [G loss: 66.6902]\n",
      "489 (5, 1) [D loss: (-12.8323)(R 44.0906, F -57.4164, G 0.0493)] [G loss: 41.5248]\n",
      "490 (5, 1) [D loss: (-12.7782)(R 18.5195, F -31.4293, G 0.0132)] [G loss: 33.3009]\n",
      "491 (5, 1) [D loss: (1.8146)(R 22.8871, F -21.7982, G 0.0726)] [G loss: 19.4114]\n",
      "492 (5, 1) [D loss: (3.3397)(R 31.8617, F -28.7050, G 0.0183)] [G loss: 34.4564]\n",
      "493 (5, 1) [D loss: (10.2372)(R 30.3046, F -20.2092, G 0.0142)] [G loss: 20.8856]\n",
      "494 (5, 1) [D loss: (16.3559)(R 30.9125, F -14.8640, G 0.0307)] [G loss: 30.7339]\n",
      "495 (5, 1) [D loss: (-2.0597)(R 23.8317, F -26.0000, G 0.0109)] [G loss: 24.0432]\n",
      "496 (5, 1) [D loss: (-6.3007)(R 27.1044, F -33.7124, G 0.0307)] [G loss: 29.1644]\n",
      "497 (5, 1) [D loss: (10.2463)(R 18.5541, F -8.6600, G 0.0352)] [G loss: 30.4437]\n",
      "498 (5, 1) [D loss: (4.3861)(R 13.7032, F -9.7613, G 0.0444)] [G loss: 18.5248]\n",
      "499 (5, 1) [D loss: (-1.7253)(R 19.5367, F -21.5047, G 0.0243)] [G loss: 17.7632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 (5, 1) [D loss: (-11.6233)(R 12.9319, F -25.0699, G 0.0515)] [G loss: 22.5497]\n",
      "501 (5, 1) [D loss: (-2.0821)(R 25.8304, F -28.8164, G 0.0904)] [G loss: 28.3796]\n",
      "502 (5, 1) [D loss: (-2.7027)(R 28.3651, F -31.9330, G 0.0865)] [G loss: 33.4460]\n",
      "503 (5, 1) [D loss: (-13.4981)(R 32.7562, F -46.6670, G 0.0413)] [G loss: 52.7021]\n",
      "504 (5, 1) [D loss: (-9.9522)(R 47.4756, F -58.1683, G 0.0740)] [G loss: 44.5874]\n",
      "505 (5, 1) [D loss: (-8.8619)(R 56.6533, F -65.5911, G 0.0076)] [G loss: 53.3857]\n",
      "506 (5, 1) [D loss: (8.4368)(R 52.5886, F -44.2987, G 0.0147)] [G loss: 47.7062]\n",
      "507 (5, 1) [D loss: (5.4788)(R 44.0695, F -38.6335, G 0.0043)] [G loss: 36.7670]\n",
      "508 (5, 1) [D loss: (15.4913)(R 50.1790, F -34.7308, G 0.0043)] [G loss: 52.2251]\n",
      "509 (5, 1) [D loss: (1.3192)(R 51.8569, F -50.5749, G 0.0037)] [G loss: 35.1496]\n",
      "510 (5, 1) [D loss: (6.3773)(R 70.0061, F -63.6659, G 0.0037)] [G loss: 73.3687]\n",
      "511 (5, 1) [D loss: (-2.1542)(R 66.1295, F -68.3442, G 0.0060)] [G loss: 68.2493]\n",
      "512 (5, 1) [D loss: (-3.7542)(R 57.4371, F -61.2277, G 0.0036)] [G loss: 49.4442]\n",
      "513 (5, 1) [D loss: (2.1819)(R 47.1819, F -45.2207, G 0.0221)] [G loss: 50.3416]\n",
      "514 (5, 1) [D loss: (3.2822)(R 45.6293, F -42.6890, G 0.0342)] [G loss: 41.1129]\n",
      "515 (5, 1) [D loss: (-3.1330)(R 37.7236, F -41.8958, G 0.1039)] [G loss: 41.9759]\n",
      "516 (5, 1) [D loss: (-4.9282)(R 31.6180, F -36.8894, G 0.0343)] [G loss: 30.4052]\n",
      "517 (5, 1) [D loss: (-4.0382)(R 23.0424, F -27.3819, G 0.0301)] [G loss: 27.0461]\n",
      "518 (5, 1) [D loss: (-9.3044)(R 28.0819, F -38.0187, G 0.0632)] [G loss: 33.3076]\n",
      "519 (5, 1) [D loss: (-22.8443)(R 16.6960, F -40.6343, G 0.1094)] [G loss: 42.1335]\n",
      "520 (5, 1) [D loss: (-6.7544)(R 8.4993, F -15.8452, G 0.0592)] [G loss: 27.2654]\n",
      "521 (5, 1) [D loss: (-7.8384)(R 23.3137, F -31.4311, G 0.0279)] [G loss: 22.8146]\n",
      "522 (5, 1) [D loss: (1.7964)(R 32.2856, F -30.7207, G 0.0231)] [G loss: 36.9415]\n",
      "523 (5, 1) [D loss: (3.9815)(R 43.7065, F -39.8204, G 0.0095)] [G loss: 37.9076]\n",
      "524 (5, 1) [D loss: (-5.5593)(R 41.5532, F -47.1556, G 0.0043)] [G loss: 43.9406]\n",
      "525 (5, 1) [D loss: (-5.9783)(R 40.6372, F -46.7491, G 0.0134)] [G loss: 42.3031]\n",
      "526 (5, 1) [D loss: (-6.8602)(R 38.0727, F -46.3968, G 0.1464)] [G loss: 43.9482]\n",
      "527 (5, 1) [D loss: (-3.8190)(R 51.1905, F -55.5851, G 0.0576)] [G loss: 54.8814]\n",
      "528 (5, 1) [D loss: (-6.0294)(R 47.5046, F -53.8615, G 0.0328)] [G loss: 53.5216]\n",
      "529 (5, 1) [D loss: (-0.7783)(R 51.6439, F -52.7439, G 0.0322)] [G loss: 49.0532]\n",
      "530 (5, 1) [D loss: (7.2302)(R 53.3009, F -46.3550, G 0.0284)] [G loss: 52.7845]\n",
      "531 (5, 1) [D loss: (2.5749)(R 43.6088, F -41.5694, G 0.0535)] [G loss: 40.4398]\n",
      "532 (5, 1) [D loss: (-1.4334)(R 50.1562, F -52.0219, G 0.0432)] [G loss: 53.2273]\n",
      "533 (5, 1) [D loss: (-3.8582)(R 61.0950, F -65.9400, G 0.0987)] [G loss: 66.7185]\n",
      "534 (5, 1) [D loss: (-7.1080)(R 48.8167, F -56.2173, G 0.0293)] [G loss: 57.4916]\n",
      "535 (5, 1) [D loss: (0.0591)(R 48.5335, F -48.7268, G 0.0252)] [G loss: 51.0463]\n",
      "536 (5, 1) [D loss: (-2.7922)(R 34.9156, F -38.1802, G 0.0472)] [G loss: 38.3256]\n",
      "537 (5, 1) [D loss: (-8.5186)(R 15.1041, F -24.1821, G 0.0559)] [G loss: 19.0234]\n",
      "538 (5, 1) [D loss: (-2.3575)(R 8.1165, F -10.5208, G 0.0047)] [G loss: 9.0712]\n",
      "539 (5, 1) [D loss: (-3.2548)(R 18.0019, F -21.3741, G 0.0117)] [G loss: 23.8521]\n",
      "540 (5, 1) [D loss: (6.6014)(R 30.8091, F -24.2503, G 0.0043)] [G loss: 28.6063]\n",
      "541 (5, 1) [D loss: (-0.5239)(R 18.2735, F -19.5005, G 0.0703)] [G loss: 18.8310]\n",
      "542 (5, 1) [D loss: (-3.8458)(R 12.7984, F -16.8612, G 0.0217)] [G loss: 15.3333]\n",
      "543 (5, 1) [D loss: (-2.0854)(R 20.3293, F -22.6094, G 0.0195)] [G loss: 23.8797]\n",
      "544 (5, 1) [D loss: (-4.9076)(R 26.0690, F -31.3077, G 0.0331)] [G loss: 29.5858]\n",
      "545 (5, 1) [D loss: (-8.7467)(R 21.2194, F -30.1205, G 0.0155)] [G loss: 35.4785]\n",
      "546 (5, 1) [D loss: (-1.3305)(R 31.6631, F -33.1228, G 0.0129)] [G loss: 35.7572]\n",
      "547 (5, 1) [D loss: (-11.4512)(R 23.3798, F -34.9109, G 0.0080)] [G loss: 35.2060]\n",
      "548 (5, 1) [D loss: (-17.3263)(R -2.6129, F -14.7460, G 0.0033)] [G loss: 2.5164]\n",
      "549 (5, 1) [D loss: (-2.4943)(R -11.0941, F 8.3476, G 0.0252)] [G loss: -12.9920]\n",
      "550 (5, 1) [D loss: (-0.1207)(R -14.8842, F 14.6418, G 0.0122)] [G loss: -6.1475]\n",
      "551 (5, 1) [D loss: (-1.4127)(R -7.4126, F 5.8356, G 0.0164)] [G loss: -2.5428]\n",
      "552 (5, 1) [D loss: (3.8294)(R 0.0536, F 3.7077, G 0.0068)] [G loss: -9.4612]\n",
      "553 (5, 1) [D loss: (-9.8047)(R -6.1943, F -4.0217, G 0.0411)] [G loss: -6.8353]\n",
      "554 (5, 1) [D loss: (0.9319)(R 7.0870, F -7.4155, G 0.1260)] [G loss: 9.7715]\n",
      "555 (5, 1) [D loss: (-16.9068)(R -9.3486, F -8.1319, G 0.0574)] [G loss: 6.8617]\n",
      "556 (5, 1) [D loss: (-4.1867)(R -10.6889, F 6.2529, G 0.0249)] [G loss: -5.1388]\n",
      "557 (5, 1) [D loss: (-21.7850)(R -36.7544, F 14.8969, G 0.0073)] [G loss: -26.9822]\n",
      "558 (5, 1) [D loss: (0.2556)(R -29.9263, F 30.1079, G 0.0074)] [G loss: -29.3871]\n",
      "559 (5, 1) [D loss: (4.4105)(R -47.4739, F 51.8107, G 0.0074)] [G loss: -47.1751]\n",
      "560 (5, 1) [D loss: (5.7399)(R -59.6788, F 65.2560, G 0.0163)] [G loss: -55.8394]\n",
      "561 (5, 1) [D loss: (-4.1406)(R -53.6915, F 49.4629, G 0.0088)] [G loss: -51.2963]\n",
      "562 (5, 1) [D loss: (8.3857)(R -44.1164, F 52.4049, G 0.0097)] [G loss: -44.1769]\n",
      "563 (5, 1) [D loss: (-14.7192)(R -45.4230, F 30.5944, G 0.0109)] [G loss: -42.7369]\n",
      "564 (5, 1) [D loss: (-7.5130)(R -62.2037, F 53.7091, G 0.0982)] [G loss: -61.9700]\n",
      "565 (5, 1) [D loss: (-6.7257)(R -87.2306, F 80.0919, G 0.0413)] [G loss: -80.8234]\n",
      "566 (5, 1) [D loss: (6.5179)(R -99.2089, F 104.8106, G 0.0916)] [G loss: -95.9654]\n",
      "567 (5, 1) [D loss: (-0.0705)(R -96.1942, F 96.0466, G 0.0077)] [G loss: -101.5346]\n",
      "568 (5, 1) [D loss: (0.2999)(R -123.0326, F 123.2579, G 0.0075)] [G loss: -138.6342]\n",
      "569 (5, 1) [D loss: (-4.8120)(R -160.6672, F 155.3286, G 0.0527)] [G loss: -159.4659]\n",
      "570 (5, 1) [D loss: (1.9139)(R -136.2807, F 138.1273, G 0.0067)] [G loss: -140.5744]\n",
      "571 (5, 1) [D loss: (1.0365)(R -125.8052, F 126.7970, G 0.0045)] [G loss: -123.8173]\n",
      "572 (5, 1) [D loss: (-0.4078)(R -127.8152, F 127.3773, G 0.0030)] [G loss: -138.4887]\n",
      "573 (5, 1) [D loss: (-7.1579)(R -146.0546, F 138.8662, G 0.0030)] [G loss: -143.5358]\n",
      "574 (5, 1) [D loss: (-5.8600)(R -124.9110, F 118.7310, G 0.0320)] [G loss: -123.1424]\n",
      "575 (5, 1) [D loss: (8.2462)(R -132.9205, F 141.0998, G 0.0067)] [G loss: -118.0737]\n",
      "576 (5, 1) [D loss: (-13.8533)(R -116.5661, F 102.6540, G 0.0059)] [G loss: -107.9657]\n",
      "577 (5, 1) [D loss: (2.4315)(R -133.2149, F 135.2561, G 0.0390)] [G loss: -123.3049]\n",
      "578 (5, 1) [D loss: (13.9545)(R -111.6899, F 125.6124, G 0.0032)] [G loss: -109.6078]\n",
      "579 (5, 1) [D loss: (1.3351)(R -110.3269, F 111.6085, G 0.0054)] [G loss: -118.1888]\n",
      "580 (5, 1) [D loss: (-7.7486)(R -111.0778, F 103.3084, G 0.0021)] [G loss: -107.8720]\n",
      "581 (5, 1) [D loss: (-1.3380)(R -111.9934, F 110.5957, G 0.0060)] [G loss: -110.7728]\n",
      "582 (5, 1) [D loss: (-2.0447)(R -121.2544, F 118.5760, G 0.0634)] [G loss: -105.6321]\n",
      "583 (5, 1) [D loss: (0.4225)(R -114.1662, F 113.9430, G 0.0646)] [G loss: -111.1535]\n",
      "584 (5, 1) [D loss: (-4.4421)(R -107.1349, F 102.5772, G 0.0116)] [G loss: -119.0558]\n",
      "585 (5, 1) [D loss: (2.9443)(R -104.9798, F 107.8723, G 0.0052)] [G loss: -97.3741]\n",
      "586 (5, 1) [D loss: (9.4726)(R -96.5618, F 105.9096, G 0.0125)] [G loss: -91.4816]\n",
      "587 (5, 1) [D loss: (-13.4123)(R -73.9431, F 60.4942, G 0.0037)] [G loss: -70.1918]\n",
      "588 (5, 1) [D loss: (-5.4382)(R -82.3024, F 76.8057, G 0.0059)] [G loss: -77.5295]\n",
      "589 (5, 1) [D loss: (2.7585)(R -88.1421, F 90.8592, G 0.0041)] [G loss: -98.3439]\n",
      "590 (5, 1) [D loss: (-5.9974)(R -90.6374, F 84.5824, G 0.0058)] [G loss: -87.6479]\n",
      "591 (5, 1) [D loss: (-2.6843)(R -97.3655, F 94.4891, G 0.0192)] [G loss: -110.0060]\n",
      "592 (5, 1) [D loss: (-13.0228)(R -113.6234, F 100.5382, G 0.0062)] [G loss: -129.6682]\n",
      "593 (5, 1) [D loss: (9.4086)(R -130.2408, F 139.6042, G 0.0045)] [G loss: -122.5724]\n",
      "594 (5, 1) [D loss: (0.5540)(R -93.6723, F 94.1192, G 0.0107)] [G loss: -83.3441]\n",
      "595 (5, 1) [D loss: (-7.8523)(R -78.5903, F 69.5425, G 0.1196)] [G loss: -75.2310]\n",
      "596 (5, 1) [D loss: (-6.8129)(R -68.6876, F 60.9380, G 0.0937)] [G loss: -64.1394]\n",
      "597 (5, 1) [D loss: (-11.1200)(R -72.1240, F 60.1970, G 0.0807)] [G loss: -66.5943]\n",
      "598 (5, 1) [D loss: (-7.6526)(R -88.9077, F 80.4151, G 0.0840)] [G loss: -78.5782]\n",
      "599 (5, 1) [D loss: (-6.9037)(R -90.1820, F 82.8265, G 0.0452)] [G loss: -85.9949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 (5, 1) [D loss: (-17.2058)(R -101.1253, F 83.8831, G 0.0036)] [G loss: -100.9018]\n",
      "601 (5, 1) [D loss: (-4.6320)(R -130.2415, F 123.4975, G 0.2112)] [G loss: -118.9444]\n",
      "602 (5, 1) [D loss: (2.4199)(R -88.7031, F 90.5181, G 0.0605)] [G loss: -78.3270]\n",
      "603 (5, 1) [D loss: (-1.0154)(R -79.3494, F 77.8475, G 0.0486)] [G loss: -72.9219]\n",
      "604 (5, 1) [D loss: (-12.1242)(R -74.3774, F 62.0509, G 0.0202)] [G loss: -74.5008]\n",
      "605 (5, 1) [D loss: (2.9778)(R -85.3435, F 88.2327, G 0.0089)] [G loss: -84.3655]\n",
      "606 (5, 1) [D loss: (4.7071)(R -77.7851, F 82.4685, G 0.0024)] [G loss: -67.4906]\n",
      "607 (5, 1) [D loss: (7.0096)(R -77.6035, F 84.5462, G 0.0067)] [G loss: -78.4061]\n",
      "608 (5, 1) [D loss: (-12.8442)(R -87.4779, F 74.4594, G 0.0174)] [G loss: -87.9675]\n",
      "609 (5, 1) [D loss: (-13.9813)(R -97.8946, F 83.5230, G 0.0390)] [G loss: -96.5955]\n",
      "610 (5, 1) [D loss: (-9.5021)(R -105.1361, F 95.4906, G 0.0143)] [G loss: -99.0185]\n",
      "611 (5, 1) [D loss: (5.7006)(R -97.4353, F 103.0404, G 0.0096)] [G loss: -97.7676]\n",
      "612 (5, 1) [D loss: (-14.9526)(R -112.4482, F 97.4465, G 0.0049)] [G loss: -102.1883]\n",
      "613 (5, 1) [D loss: (2.0566)(R -116.7588, F 118.7468, G 0.0069)] [G loss: -116.8916]\n",
      "614 (5, 1) [D loss: (4.8185)(R -97.7143, F 102.3652, G 0.0168)] [G loss: -94.2368]\n",
      "615 (5, 1) [D loss: (17.3454)(R -125.5563, F 142.7258, G 0.0176)] [G loss: -119.9430]\n",
      "616 (5, 1) [D loss: (1.9477)(R -94.0147, F 95.5587, G 0.0404)] [G loss: -100.1492]\n",
      "617 (5, 1) [D loss: (-9.3601)(R -103.8676, F 94.1664, G 0.0341)] [G loss: -100.8269]\n",
      "618 (5, 1) [D loss: (-9.4471)(R -99.9674, F 90.3193, G 0.0201)] [G loss: -98.9202]\n",
      "619 (5, 1) [D loss: (-1.7260)(R -81.7930, F 79.9330, G 0.0134)] [G loss: -75.7897]\n",
      "620 (5, 1) [D loss: (-4.4625)(R -90.9211, F 86.3324, G 0.0126)] [G loss: -84.8924]\n",
      "621 (5, 1) [D loss: (-1.3806)(R -84.0377, F 82.6348, G 0.0022)] [G loss: -87.7823]\n",
      "622 (5, 1) [D loss: (-10.9358)(R -87.0099, F 76.0564, G 0.0018)] [G loss: -92.0904]\n",
      "623 (5, 1) [D loss: (13.8387)(R -108.0314, F 121.4647, G 0.0405)] [G loss: -110.7164]\n",
      "624 (5, 1) [D loss: (2.0725)(R -122.9844, F 124.8265, G 0.0230)] [G loss: -126.9776]\n",
      "625 (5, 1) [D loss: (6.5990)(R -127.8162, F 134.0306, G 0.0385)] [G loss: -115.8193]\n",
      "626 (5, 1) [D loss: (-5.4581)(R -145.1550, F 139.4422, G 0.0255)] [G loss: -153.1050]\n",
      "627 (5, 1) [D loss: (3.6947)(R -157.6325, F 161.2287, G 0.0098)] [G loss: -162.7889]\n",
      "628 (5, 1) [D loss: (-6.9978)(R -134.1143, F 126.6508, G 0.0466)] [G loss: -131.9647]\n",
      "629 (5, 1) [D loss: (-4.1387)(R -101.9605, F 95.4774, G 0.2344)] [G loss: -89.1855]\n",
      "630 (5, 1) [D loss: (2.5638)(R -87.9464, F 90.0941, G 0.0416)] [G loss: -69.1652]\n",
      "631 (5, 1) [D loss: (1.7202)(R -75.8920, F 77.2922, G 0.0320)] [G loss: -72.3494]\n",
      "632 (5, 1) [D loss: (3.7547)(R -60.6604, F 64.1696, G 0.0245)] [G loss: -59.0094]\n",
      "633 (5, 1) [D loss: (-0.9156)(R -62.9665, F 61.9084, G 0.0143)] [G loss: -65.2791]\n",
      "634 (5, 1) [D loss: (3.1781)(R -46.7263, F 49.7089, G 0.0196)] [G loss: -44.1270]\n",
      "635 (5, 1) [D loss: (0.0305)(R -43.7123, F 43.6391, G 0.0104)] [G loss: -41.6627]\n",
      "636 (5, 1) [D loss: (-12.2776)(R -41.7006, F 29.3429, G 0.0080)] [G loss: -41.8279]\n",
      "637 (5, 1) [D loss: (4.8519)(R -43.2487, F 47.9098, G 0.0191)] [G loss: -38.2586]\n",
      "638 (5, 1) [D loss: (-3.7116)(R -39.5412, F 35.6678, G 0.0162)] [G loss: -28.9755]\n",
      "639 (5, 1) [D loss: (-1.7326)(R -46.7319, F 44.8593, G 0.0140)] [G loss: -41.4606]\n",
      "640 (5, 1) [D loss: (-13.4696)(R -54.8039, F 41.2538, G 0.0081)] [G loss: -57.6264]\n",
      "641 (5, 1) [D loss: (-2.8391)(R -77.9759, F 74.6517, G 0.0485)] [G loss: -87.8461]\n",
      "642 (5, 1) [D loss: (-3.9809)(R -83.0851, F 78.9634, G 0.0141)] [G loss: -70.0733]\n",
      "643 (5, 1) [D loss: (9.8162)(R -63.3815, F 72.4691, G 0.0729)] [G loss: -50.0675]\n",
      "644 (5, 1) [D loss: (-6.7388)(R -57.6104, F 49.9884, G 0.0883)] [G loss: -53.7695]\n",
      "645 (5, 1) [D loss: (3.5564)(R -46.3432, F 48.6282, G 0.1271)] [G loss: -41.8474]\n",
      "646 (5, 1) [D loss: (-11.9773)(R -54.0995, F 40.5829, G 0.1539)] [G loss: -61.4918]\n",
      "647 (5, 1) [D loss: (2.4587)(R -48.3247, F 49.2280, G 0.1555)] [G loss: -51.2013]\n",
      "648 (5, 1) [D loss: (-0.4051)(R -52.6536, F 51.9797, G 0.0269)] [G loss: -67.3508]\n",
      "649 (5, 1) [D loss: (-4.5034)(R -61.2411, F 56.6701, G 0.0068)] [G loss: -64.5552]\n",
      "650 (5, 1) [D loss: (2.7313)(R -64.1797, F 66.5558, G 0.0355)] [G loss: -64.9793]\n",
      "651 (5, 1) [D loss: (-5.5879)(R -79.4885, F 73.8049, G 0.0096)] [G loss: -79.4743]\n",
      "652 (5, 1) [D loss: (-7.9833)(R -116.9733, F 107.3077, G 0.1682)] [G loss: -117.3298]\n",
      "653 (5, 1) [D loss: (-8.6134)(R -129.6538, F 119.0263, G 0.2014)] [G loss: -113.8615]\n",
      "654 (5, 1) [D loss: (-3.7209)(R -118.1214, F 113.4881, G 0.0912)] [G loss: -105.7684]\n",
      "655 (5, 1) [D loss: (-10.0329)(R -121.3931, F 110.5054, G 0.0855)] [G loss: -115.6782]\n",
      "656 (5, 1) [D loss: (-5.4411)(R -100.3777, F 94.8895, G 0.0047)] [G loss: -104.1122]\n",
      "657 (5, 1) [D loss: (-13.2587)(R -106.4651, F 93.0689, G 0.0137)] [G loss: -99.6512]\n",
      "658 (5, 1) [D loss: (2.2495)(R -95.6004, F 97.8062, G 0.0044)] [G loss: -101.0546]\n",
      "659 (5, 1) [D loss: (11.2832)(R -84.1413, F 95.3916, G 0.0033)] [G loss: -76.8733]\n",
      "660 (5, 1) [D loss: (-11.2504)(R -72.9678, F 61.6278, G 0.0090)] [G loss: -69.7432]\n",
      "661 (5, 1) [D loss: (6.1779)(R -75.0234, F 81.1475, G 0.0054)] [G loss: -72.1095]\n",
      "662 (5, 1) [D loss: (4.8414)(R -70.5499, F 75.3201, G 0.0071)] [G loss: -67.7808]\n",
      "663 (5, 1) [D loss: (8.9623)(R -76.4163, F 85.2087, G 0.0170)] [G loss: -79.9182]\n",
      "664 (5, 1) [D loss: (4.3670)(R -75.5446, F 79.8154, G 0.0096)] [G loss: -68.7038]\n",
      "665 (5, 1) [D loss: (8.7926)(R -67.2453, F 75.8584, G 0.0179)] [G loss: -65.6714]\n",
      "666 (5, 1) [D loss: (-6.6717)(R -76.8536, F 69.9946, G 0.0187)] [G loss: -71.7571]\n",
      "667 (5, 1) [D loss: (6.4914)(R -58.5257, F 64.9529, G 0.0064)] [G loss: -60.4291]\n",
      "668 (5, 1) [D loss: (-1.5721)(R -54.9296, F 53.3246, G 0.0033)] [G loss: -51.7843]\n",
      "669 (5, 1) [D loss: (-0.8159)(R -35.4972, F 34.6166, G 0.0065)] [G loss: -30.4508]\n",
      "670 (5, 1) [D loss: (3.8033)(R -33.7626, F 37.5371, G 0.0029)] [G loss: -29.1159]\n",
      "671 (5, 1) [D loss: (0.5889)(R -28.2150, F 28.7357, G 0.0068)] [G loss: -30.3557]\n",
      "672 (5, 1) [D loss: (-2.1098)(R -21.8790, F 19.6439, G 0.0125)] [G loss: -19.7547]\n",
      "673 (5, 1) [D loss: (2.5227)(R -19.6509, F 22.0788, G 0.0095)] [G loss: -15.5732]\n",
      "674 (5, 1) [D loss: (-2.5151)(R -15.1125, F 12.2340, G 0.0363)] [G loss: -14.3021]\n",
      "675 (5, 1) [D loss: (-7.9974)(R -16.7197, F 8.4714, G 0.0251)] [G loss: -13.4616]\n",
      "676 (5, 1) [D loss: (2.0788)(R -19.2966, F 20.8887, G 0.0487)] [G loss: -15.6173]\n",
      "677 (5, 1) [D loss: (-4.7319)(R -30.8722, F 25.3636, G 0.0777)] [G loss: -22.9395]\n",
      "678 (5, 1) [D loss: (-9.3626)(R -38.5363, F 28.5561, G 0.0618)] [G loss: -33.4758]\n",
      "679 (5, 1) [D loss: (0.5816)(R -46.4867, F 46.6016, G 0.0467)] [G loss: -43.6803]\n",
      "680 (5, 1) [D loss: (3.3087)(R -61.6971, F 64.9078, G 0.0098)] [G loss: -55.9678]\n",
      "681 (5, 1) [D loss: (4.2373)(R -47.5586, F 51.5410, G 0.0255)] [G loss: -50.0666]\n",
      "682 (5, 1) [D loss: (-5.9814)(R -48.1869, F 42.1560, G 0.0049)] [G loss: -53.0155]\n",
      "683 (5, 1) [D loss: (-8.5883)(R -64.4437, F 55.7789, G 0.0077)] [G loss: -71.6313]\n",
      "684 (5, 1) [D loss: (8.0984)(R -82.1385, F 89.7601, G 0.0477)] [G loss: -86.1562]\n",
      "685 (5, 1) [D loss: (-9.2437)(R -92.4639, F 82.7927, G 0.0428)] [G loss: -88.6045]\n",
      "686 (5, 1) [D loss: (-3.3855)(R -83.3784, F 79.5888, G 0.0404)] [G loss: -79.5738]\n",
      "687 (5, 1) [D loss: (-5.4514)(R -99.2092, F 93.2038, G 0.0554)] [G loss: -93.8008]\n",
      "688 (5, 1) [D loss: (1.2624)(R -80.8466, F 81.9521, G 0.0157)] [G loss: -81.9817]\n",
      "689 (5, 1) [D loss: (0.4881)(R -78.9629, F 79.3584, G 0.0093)] [G loss: -81.6857]\n",
      "690 (5, 1) [D loss: (-0.2477)(R -62.6801, F 62.1542, G 0.0278)] [G loss: -66.5552]\n",
      "691 (5, 1) [D loss: (1.9460)(R -62.4922, F 64.3475, G 0.0091)] [G loss: -56.6593]\n",
      "692 (5, 1) [D loss: (-2.8060)(R -50.2066, F 47.3661, G 0.0035)] [G loss: -38.9220]\n",
      "693 (5, 1) [D loss: (-0.4899)(R -44.1304, F 43.4781, G 0.0162)] [G loss: -42.8977]\n",
      "694 (5, 1) [D loss: (0.5756)(R -40.2182, F 40.7442, G 0.0050)] [G loss: -36.6212]\n",
      "695 (5, 1) [D loss: (2.5197)(R -30.9921, F 33.4254, G 0.0086)] [G loss: -30.7860]\n",
      "696 (5, 1) [D loss: (-1.5727)(R -29.0382, F 27.3998, G 0.0066)] [G loss: -27.4541]\n",
      "697 (5, 1) [D loss: (-0.9588)(R -32.8790, F 31.8365, G 0.0084)] [G loss: -35.2111]\n",
      "698 (5, 1) [D loss: (0.1815)(R -34.5747, F 34.7229, G 0.0033)] [G loss: -32.2238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 (5, 1) [D loss: (-1.6988)(R -26.1623, F 24.4225, G 0.0041)] [G loss: -25.1764]\n",
      "700 (5, 1) [D loss: (-3.0534)(R -26.4622, F 23.2709, G 0.0138)] [G loss: -27.6548]\n",
      "701 (5, 1) [D loss: (-1.3089)(R -33.5055, F 32.0471, G 0.0149)] [G loss: -35.9604]\n",
      "702 (5, 1) [D loss: (-0.8944)(R -28.1692, F 27.0839, G 0.0191)] [G loss: -27.6925]\n",
      "703 (5, 1) [D loss: (-3.9543)(R -30.7206, F 26.5897, G 0.0177)] [G loss: -29.1195]\n",
      "704 (5, 1) [D loss: (-2.8224)(R -37.6770, F 34.7550, G 0.0100)] [G loss: -39.5352]\n",
      "705 (5, 1) [D loss: (-6.7713)(R -49.4734, F 42.6741, G 0.0028)] [G loss: -49.4023]\n",
      "706 (5, 1) [D loss: (2.5845)(R -78.3913, F 80.3634, G 0.0612)] [G loss: -72.5036]\n",
      "707 (5, 1) [D loss: (1.2852)(R -78.7458, F 79.8529, G 0.0178)] [G loss: -76.6489]\n",
      "708 (5, 1) [D loss: (2.4354)(R -75.3987, F 77.7414, G 0.0093)] [G loss: -69.2799]\n",
      "709 (5, 1) [D loss: (-0.7911)(R -75.3269, F 74.3821, G 0.0154)] [G loss: -67.4683]\n",
      "710 (5, 1) [D loss: (-4.0458)(R -58.7448, F 54.6593, G 0.0040)] [G loss: -57.7370]\n",
      "711 (5, 1) [D loss: (-2.9372)(R -44.5027, F 41.5087, G 0.0057)] [G loss: -44.9123]\n",
      "712 (5, 1) [D loss: (-2.0265)(R -36.9658, F 34.9110, G 0.0028)] [G loss: -35.4416]\n",
      "713 (5, 1) [D loss: (0.2837)(R -43.4913, F 43.7075, G 0.0067)] [G loss: -47.5738]\n",
      "714 (5, 1) [D loss: (1.7906)(R -55.6556, F 57.4099, G 0.0036)] [G loss: -53.6143]\n",
      "715 (5, 1) [D loss: (-1.9343)(R -42.3736, F 40.4100, G 0.0029)] [G loss: -42.3308]\n",
      "716 (5, 1) [D loss: (-2.2265)(R -43.5875, F 41.2412, G 0.0120)] [G loss: -41.3236]\n",
      "717 (5, 1) [D loss: (-2.8594)(R -35.1223, F 32.1837, G 0.0079)] [G loss: -27.4473]\n",
      "718 (5, 1) [D loss: (-7.5031)(R -39.8107, F 32.1271, G 0.0181)] [G loss: -41.3057]\n",
      "719 (5, 1) [D loss: (-4.5902)(R -49.4391, F 44.6949, G 0.0154)] [G loss: -43.1894]\n",
      "720 (5, 1) [D loss: (-4.9876)(R -57.8356, F 52.7512, G 0.0097)] [G loss: -54.5334]\n",
      "721 (5, 1) [D loss: (-3.1829)(R -55.8733, F 52.5828, G 0.0108)] [G loss: -49.0651]\n",
      "722 (5, 1) [D loss: (-8.0010)(R -56.8640, F 48.7854, G 0.0078)] [G loss: -47.9326]\n",
      "723 (5, 1) [D loss: (3.1987)(R -58.5536, F 61.6893, G 0.0063)] [G loss: -58.7320]\n",
      "724 (5, 1) [D loss: (-1.7640)(R -59.8163, F 58.0133, G 0.0039)] [G loss: -54.0435]\n",
      "725 (5, 1) [D loss: (-9.7721)(R -75.5574, F 65.7043, G 0.0081)] [G loss: -74.3629]\n",
      "726 (5, 1) [D loss: (-1.3555)(R -66.8615, F 65.2852, G 0.0221)] [G loss: -69.1934]\n",
      "727 (5, 1) [D loss: (-10.5169)(R -80.4225, F 69.8851, G 0.0020)] [G loss: -76.9655]\n",
      "728 (5, 1) [D loss: (1.3667)(R -71.9964, F 73.1507, G 0.0212)] [G loss: -70.4957]\n",
      "729 (5, 1) [D loss: (-9.2190)(R -66.7580, F 57.5122, G 0.0027)] [G loss: -65.7059]\n",
      "730 (5, 1) [D loss: (-1.3686)(R -75.4606, F 74.0147, G 0.0077)] [G loss: -70.9786]\n",
      "731 (5, 1) [D loss: (0.4358)(R -71.0930, F 71.4141, G 0.0115)] [G loss: -70.4390]\n",
      "732 (5, 1) [D loss: (3.8792)(R -82.3036, F 86.1399, G 0.0043)] [G loss: -72.4849]\n",
      "733 (5, 1) [D loss: (-1.5713)(R -61.0529, F 59.4528, G 0.0029)] [G loss: -61.7970]\n",
      "734 (5, 1) [D loss: (-4.2832)(R -74.9156, F 70.5574, G 0.0075)] [G loss: -81.4717]\n",
      "735 (5, 1) [D loss: (-3.5174)(R -99.7183, F 95.8219, G 0.0379)] [G loss: -95.9400]\n",
      "736 (5, 1) [D loss: (7.6051)(R -83.7142, F 91.0597, G 0.0260)] [G loss: -91.9536]\n",
      "737 (5, 1) [D loss: (-3.2147)(R -84.0543, F 80.7523, G 0.0087)] [G loss: -78.3438]\n",
      "738 (5, 1) [D loss: (19.9757)(R -71.7007, F 91.5711, G 0.0105)] [G loss: -76.7563]\n",
      "739 (5, 1) [D loss: (-10.0263)(R -66.0051, F 55.7943, G 0.0185)] [G loss: -61.1091]\n",
      "740 (5, 1) [D loss: (1.0947)(R -37.5116, F 38.2713, G 0.0335)] [G loss: -38.1068]\n",
      "741 (5, 1) [D loss: (-3.0830)(R -23.2859, F 20.0972, G 0.0106)] [G loss: -22.2803]\n",
      "742 (5, 1) [D loss: (-2.6457)(R -32.2661, F 29.5763, G 0.0044)] [G loss: -25.9170]\n",
      "743 (5, 1) [D loss: (-4.8132)(R -27.2388, F 22.3628, G 0.0063)] [G loss: -28.5340]\n",
      "744 (5, 1) [D loss: (-1.0430)(R -38.6953, F 37.5635, G 0.0089)] [G loss: -34.5790]\n",
      "745 (5, 1) [D loss: (1.8564)(R -51.2105, F 52.9328, G 0.0134)] [G loss: -51.1435]\n",
      "746 (5, 1) [D loss: (-1.7928)(R -53.7365, F 51.9234, G 0.0020)] [G loss: -52.1282]\n",
      "747 (5, 1) [D loss: (-5.4636)(R -52.9713, F 47.4653, G 0.0042)] [G loss: -54.0364]\n",
      "748 (5, 1) [D loss: (-5.7623)(R -49.5352, F 43.7424, G 0.0030)] [G loss: -45.6837]\n",
      "749 (5, 1) [D loss: (-1.4898)(R -45.0077, F 43.2240, G 0.0294)] [G loss: -41.8317]\n",
      "750 (5, 1) [D loss: (-9.3071)(R -60.1149, F 50.3799, G 0.0428)] [G loss: -57.8992]\n",
      "751 (5, 1) [D loss: (5.5830)(R -68.1783, F 73.5330, G 0.0228)] [G loss: -76.9042]\n",
      "752 (5, 1) [D loss: (-12.3139)(R -38.2359, F 25.6467, G 0.0275)] [G loss: -24.5393]\n",
      "753 (5, 1) [D loss: (13.7408)(R -44.5623, F 58.2531, G 0.0050)] [G loss: -57.5988]\n",
      "754 (5, 1) [D loss: (-16.3440)(R -77.0272, F 60.5867, G 0.0097)] [G loss: -68.8892]\n",
      "755 (5, 1) [D loss: (2.3734)(R -94.9468, F 97.1752, G 0.0145)] [G loss: -84.7077]\n",
      "756 (5, 1) [D loss: (13.1525)(R -101.4843, F 114.3994, G 0.0237)] [G loss: -100.6806]\n",
      "757 (5, 1) [D loss: (-5.8541)(R -107.0637, F 100.9548, G 0.0255)] [G loss: -96.8566]\n",
      "758 (5, 1) [D loss: (-5.5720)(R -79.5744, F 73.8503, G 0.0152)] [G loss: -76.0971]\n",
      "759 (5, 1) [D loss: (9.2494)(R -67.8841, F 77.0808, G 0.0053)] [G loss: -77.2691]\n",
      "760 (5, 1) [D loss: (0.6928)(R -59.8222, F 59.1212, G 0.1394)] [G loss: -59.8461]\n",
      "761 (5, 1) [D loss: (4.1095)(R -58.9586, F 62.5239, G 0.0544)] [G loss: -59.8759]\n",
      "762 (5, 1) [D loss: (-8.7493)(R -78.2888, F 69.2279, G 0.0312)] [G loss: -87.6341]\n",
      "763 (5, 1) [D loss: (8.8785)(R -72.0002, F 80.5805, G 0.0298)] [G loss: -67.8533]\n",
      "764 (5, 1) [D loss: (-0.5810)(R -62.9156, F 62.2798, G 0.0055)] [G loss: -67.0775]\n",
      "765 (5, 1) [D loss: (0.7201)(R -76.3492, F 77.0168, G 0.0052)] [G loss: -78.8572]\n",
      "766 (5, 1) [D loss: (-10.7290)(R -94.0834, F 82.5917, G 0.0763)] [G loss: -85.0774]\n",
      "767 (5, 1) [D loss: (-2.6445)(R -97.7143, F 94.6657, G 0.0404)] [G loss: -92.2828]\n",
      "768 (5, 1) [D loss: (-9.4771)(R -93.1069, F 83.4052, G 0.0225)] [G loss: -102.3486]\n",
      "769 (5, 1) [D loss: (0.0900)(R -91.8940, F 91.8402, G 0.0144)] [G loss: -91.3310]\n",
      "770 (5, 1) [D loss: (13.0292)(R -77.1572, F 90.1104, G 0.0076)] [G loss: -74.7483]\n",
      "771 (5, 1) [D loss: (0.3403)(R -70.8431, F 71.1295, G 0.0054)] [G loss: -75.1956]\n",
      "772 (5, 1) [D loss: (-9.5223)(R -76.4405, F 66.8952, G 0.0023)] [G loss: -77.9845]\n",
      "773 (5, 1) [D loss: (-0.8092)(R -59.6416, F 58.7493, G 0.0083)] [G loss: -63.1190]\n",
      "774 (5, 1) [D loss: (-0.5063)(R -59.0743, F 58.3225, G 0.0245)] [G loss: -46.5513]\n",
      "775 (5, 1) [D loss: (-3.5284)(R -52.2681, F 48.6271, G 0.0113)] [G loss: -47.9635]\n",
      "776 (5, 1) [D loss: (-4.7520)(R -46.9470, F 42.1230, G 0.0072)] [G loss: -48.0345]\n",
      "777 (5, 1) [D loss: (3.1133)(R -44.6666, F 47.6878, G 0.0092)] [G loss: -47.0880]\n",
      "778 (5, 1) [D loss: (-5.6491)(R -38.9175, F 33.2156, G 0.0053)] [G loss: -36.8324]\n",
      "779 (5, 1) [D loss: (-2.7490)(R -35.6617, F 32.8278, G 0.0085)] [G loss: -35.5369]\n",
      "780 (5, 1) [D loss: (-4.3765)(R -34.4567, F 29.9829, G 0.0097)] [G loss: -31.1361]\n",
      "781 (5, 1) [D loss: (2.0800)(R -39.4132, F 41.4450, G 0.0048)] [G loss: -40.8897]\n",
      "782 (5, 1) [D loss: (-3.4558)(R -46.3466, F 42.8393, G 0.0051)] [G loss: -42.1646]\n",
      "783 (5, 1) [D loss: (2.7682)(R -47.1543, F 49.8428, G 0.0080)] [G loss: -50.7872]\n",
      "784 (5, 1) [D loss: (5.1946)(R -46.2925, F 51.4379, G 0.0049)] [G loss: -42.4690]\n",
      "785 (5, 1) [D loss: (-7.8816)(R -44.1272, F 36.2231, G 0.0022)] [G loss: -38.8227]\n",
      "786 (5, 1) [D loss: (-4.4430)(R -38.6292, F 34.0211, G 0.0165)] [G loss: -42.7839]\n",
      "787 (5, 1) [D loss: (-6.6983)(R -45.9677, F 38.8518, G 0.0418)] [G loss: -45.3554]\n",
      "788 (5, 1) [D loss: (3.6215)(R -41.0174, F 44.3533, G 0.0286)] [G loss: -45.8214]\n",
      "789 (5, 1) [D loss: (-11.7283)(R -52.2076, F 40.2551, G 0.0224)] [G loss: -40.3850]\n",
      "790 (5, 1) [D loss: (-8.0545)(R -56.7846, F 48.6377, G 0.0092)] [G loss: -57.5824]\n",
      "791 (5, 1) [D loss: (-2.1122)(R -51.9648, F 49.6345, G 0.0218)] [G loss: -61.7326]\n",
      "792 (5, 1) [D loss: (2.1590)(R -53.6462, F 55.7758, G 0.0029)] [G loss: -58.8728]\n",
      "793 (5, 1) [D loss: (0.8131)(R -53.4730, F 54.2057, G 0.0080)] [G loss: -53.6111]\n",
      "794 (5, 1) [D loss: (-3.8700)(R -75.1818, F 71.1349, G 0.0177)] [G loss: -74.7449]\n",
      "795 (5, 1) [D loss: (-2.5532)(R -79.1080, F 76.2193, G 0.0336)] [G loss: -78.6918]\n",
      "796 (5, 1) [D loss: (-3.8532)(R -83.9074, F 79.8404, G 0.0214)] [G loss: -77.7835]\n",
      "797 (5, 1) [D loss: (-12.1742)(R -96.7115, F 84.2834, G 0.0254)] [G loss: -99.0049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798 (5, 1) [D loss: (-2.0748)(R -95.9976, F 93.8310, G 0.0092)] [G loss: -87.8279]\n",
      "799 (5, 1) [D loss: (-3.4140)(R -95.5832, F 92.0699, G 0.0099)] [G loss: -99.4367]\n",
      "800 (5, 1) [D loss: (7.8483)(R -92.3295, F 99.9729, G 0.0205)] [G loss: -95.8317]\n",
      "801 (5, 1) [D loss: (2.4172)(R -85.9848, F 88.1746, G 0.0227)] [G loss: -81.6172]\n",
      "802 (5, 1) [D loss: (-7.7543)(R -76.8268, F 68.9976, G 0.0075)] [G loss: -80.0395]\n",
      "803 (5, 1) [D loss: (-1.3636)(R -61.5432, F 59.7909, G 0.0389)] [G loss: -56.6918]\n",
      "804 (5, 1) [D loss: (-4.8617)(R -42.5893, F 37.5111, G 0.0216)] [G loss: -35.3112]\n",
      "805 (5, 1) [D loss: (-16.7503)(R -63.9779, F 47.0848, G 0.0143)] [G loss: -70.3708]\n",
      "806 (5, 1) [D loss: (-0.3700)(R -77.1702, F 76.7502, G 0.0050)] [G loss: -68.3147]\n",
      "807 (5, 1) [D loss: (-11.3912)(R -80.0230, F 68.4978, G 0.0134)] [G loss: -73.4163]\n",
      "808 (5, 1) [D loss: (-5.9782)(R -76.2083, F 68.9613, G 0.1269)] [G loss: -84.7599]\n",
      "809 (5, 1) [D loss: (1.5624)(R -80.6577, F 82.0246, G 0.0195)] [G loss: -74.0132]\n",
      "810 (5, 1) [D loss: (-0.1873)(R -78.7296, F 77.6944, G 0.0848)] [G loss: -66.6570]\n",
      "811 (5, 1) [D loss: (-3.4871)(R -72.3912, F 68.5819, G 0.0322)] [G loss: -75.9765]\n",
      "812 (5, 1) [D loss: (-3.6933)(R -80.1828, F 75.9859, G 0.0504)] [G loss: -84.6601]\n",
      "813 (5, 1) [D loss: (4.5970)(R -96.6590, F 101.1927, G 0.0063)] [G loss: -100.3039]\n",
      "814 (5, 1) [D loss: (-4.3699)(R -109.7182, F 105.2451, G 0.0103)] [G loss: -92.6840]\n",
      "815 (5, 1) [D loss: (-3.7734)(R -112.3957, F 108.5740, G 0.0048)] [G loss: -123.1419]\n",
      "816 (5, 1) [D loss: (12.5175)(R -152.5482, F 164.7888, G 0.0277)] [G loss: -135.9413]\n",
      "817 (5, 1) [D loss: (-5.8763)(R -165.8769, F 159.4339, G 0.0567)] [G loss: -167.7067]\n",
      "818 (5, 1) [D loss: (-18.0786)(R -182.8616, F 164.6733, G 0.0110)] [G loss: -170.6571]\n",
      "819 (5, 1) [D loss: (-12.9444)(R -184.0786, F 170.9537, G 0.0180)] [G loss: -197.5769]\n",
      "820 (5, 1) [D loss: (13.0710)(R -167.3907, F 179.9012, G 0.0560)] [G loss: -178.6838]\n",
      "821 (5, 1) [D loss: (3.9992)(R -134.3436, F 137.9108, G 0.0432)] [G loss: -144.5569]\n",
      "822 (5, 1) [D loss: (11.4363)(R -158.3513, F 169.7257, G 0.0062)] [G loss: -142.3075]\n",
      "823 (5, 1) [D loss: (0.5811)(R -173.1646, F 173.7100, G 0.0036)] [G loss: -176.7191]\n",
      "824 (5, 1) [D loss: (-17.8055)(R -214.1491, F 196.2639, G 0.0080)] [G loss: -202.7417]\n",
      "825 (5, 1) [D loss: (8.5079)(R -217.5887, F 225.9384, G 0.0158)] [G loss: -211.4948]\n",
      "826 (5, 1) [D loss: (-26.5617)(R -194.7611, F 168.0970, G 0.0102)] [G loss: -203.5445]\n",
      "827 (5, 1) [D loss: (41.1570)(R -199.1573, F 240.1873, G 0.0127)] [G loss: -171.1810]\n",
      "828 (5, 1) [D loss: (13.2661)(R -197.9173, F 209.6005, G 0.1583)] [G loss: -196.4022]\n",
      "829 (5, 1) [D loss: (6.3578)(R -178.6448, F 184.8930, G 0.0110)] [G loss: -181.3522]\n",
      "830 (5, 1) [D loss: (0.7616)(R -181.6676, F 182.3866, G 0.0043)] [G loss: -159.1935]\n",
      "831 (5, 1) [D loss: (27.5141)(R -168.4196, F 195.8627, G 0.0071)] [G loss: -158.1134]\n",
      "832 (5, 1) [D loss: (1.9569)(R -144.3982, F 146.2292, G 0.0126)] [G loss: -141.6558]\n",
      "833 (5, 1) [D loss: (1.7477)(R -144.6877, F 146.3915, G 0.0044)] [G loss: -141.0424]\n",
      "834 (5, 1) [D loss: (6.0746)(R -145.5028, F 151.5283, G 0.0049)] [G loss: -136.1502]\n",
      "835 (5, 1) [D loss: (-3.2798)(R -148.5980, F 145.2734, G 0.0045)] [G loss: -143.6793]\n",
      "836 (5, 1) [D loss: (-16.2944)(R -180.7205, F 164.3183, G 0.0108)] [G loss: -198.0379]\n",
      "837 (5, 1) [D loss: (3.0857)(R -179.1695, F 182.1443, G 0.0111)] [G loss: -196.9792]\n",
      "838 (5, 1) [D loss: (-4.2576)(R -195.3420, F 190.9016, G 0.0183)] [G loss: -212.3519]\n",
      "839 (5, 1) [D loss: (-3.2456)(R -181.6335, F 178.3460, G 0.0042)] [G loss: -188.4062]\n",
      "840 (5, 1) [D loss: (1.0583)(R -151.2409, F 152.1769, G 0.0122)] [G loss: -137.6985]\n",
      "841 (5, 1) [D loss: (-1.2659)(R -131.4247, F 130.0673, G 0.0091)] [G loss: -118.7643]\n",
      "842 (5, 1) [D loss: (-4.1404)(R -152.5231, F 148.2743, G 0.0108)] [G loss: -143.5623]\n",
      "843 (5, 1) [D loss: (-0.5277)(R -184.5128, F 183.8930, G 0.0092)] [G loss: -198.2786]\n",
      "844 (5, 1) [D loss: (-19.3800)(R -194.7004, F 175.2616, G 0.0059)] [G loss: -199.6592]\n",
      "845 (5, 1) [D loss: (1.3518)(R -196.0022, F 197.1310, G 0.0223)] [G loss: -205.9094]\n",
      "846 (5, 1) [D loss: (-0.0997)(R -193.4831, F 193.3154, G 0.0068)] [G loss: -205.0822]\n",
      "847 (5, 1) [D loss: (-14.3461)(R -163.5122, F 149.0362, G 0.0130)] [G loss: -174.9188]\n",
      "848 (5, 1) [D loss: (-6.9281)(R -162.0316, F 154.7996, G 0.0304)] [G loss: -149.7678]\n",
      "849 (5, 1) [D loss: (4.4143)(R -206.2638, F 210.6125, G 0.0066)] [G loss: -202.3155]\n",
      "850 (5, 1) [D loss: (-4.6800)(R -199.8842, F 195.0544, G 0.0150)] [G loss: -206.0338]\n",
      "851 (5, 1) [D loss: (15.0771)(R -204.8450, F 219.6700, G 0.0252)] [G loss: -204.0381]\n",
      "852 (5, 1) [D loss: (8.5386)(R -164.4726, F 172.8304, G 0.0181)] [G loss: -160.7770]\n",
      "853 (5, 1) [D loss: (-2.9978)(R -165.5723, F 162.4958, G 0.0079)] [G loss: -166.8284]\n",
      "854 (5, 1) [D loss: (-9.0549)(R -155.1945, F 146.0816, G 0.0058)] [G loss: -164.2925]\n",
      "855 (5, 1) [D loss: (-2.9341)(R -170.2455, F 167.1339, G 0.0177)] [G loss: -170.9125]\n",
      "856 (5, 1) [D loss: (17.5313)(R -157.4149, F 174.8808, G 0.0065)] [G loss: -161.8089]\n",
      "857 (5, 1) [D loss: (17.6801)(R -168.3154, F 185.8984, G 0.0097)] [G loss: -162.6977]\n",
      "858 (5, 1) [D loss: (-6.2385)(R -150.6019, F 144.2358, G 0.0128)] [G loss: -153.2262]\n",
      "859 (5, 1) [D loss: (-7.7158)(R -177.1537, F 169.3820, G 0.0056)] [G loss: -162.8877]\n",
      "860 (5, 1) [D loss: (-18.7298)(R -190.3599, F 171.4050, G 0.0225)] [G loss: -192.9551]\n",
      "861 (5, 1) [D loss: (5.7706)(R -203.3187, F 208.9688, G 0.0120)] [G loss: -200.4839]\n",
      "862 (5, 1) [D loss: (-2.3054)(R -204.5523, F 202.0806, G 0.0166)] [G loss: -214.4600]\n",
      "863 (5, 1) [D loss: (-11.7240)(R -227.3588, F 215.3142, G 0.0321)] [G loss: -217.8770]\n",
      "864 (5, 1) [D loss: (8.0860)(R -192.7259, F 199.0227, G 0.1789)] [G loss: -196.5982]\n",
      "865 (5, 1) [D loss: (6.4397)(R -180.5091, F 186.4155, G 0.0533)] [G loss: -176.1647]\n",
      "866 (5, 1) [D loss: (-12.4510)(R -190.4521, F 177.9718, G 0.0029)] [G loss: -195.6511]\n",
      "867 (5, 1) [D loss: (-12.0179)(R -202.7232, F 190.6522, G 0.0053)] [G loss: -196.2778]\n",
      "868 (5, 1) [D loss: (14.0360)(R -219.6229, F 232.1866, G 0.1472)] [G loss: -203.2763]\n",
      "869 (5, 1) [D loss: (-28.1606)(R -209.6461, F 181.4110, G 0.0075)] [G loss: -214.8795]\n",
      "870 (5, 1) [D loss: (-20.0504)(R -212.1073, F 191.8582, G 0.0199)] [G loss: -210.5091]\n",
      "871 (5, 1) [D loss: (1.3377)(R -239.0810, F 240.2637, G 0.0155)] [G loss: -242.4757]\n",
      "872 (5, 1) [D loss: (-7.5344)(R -251.6720, F 244.0130, G 0.0125)] [G loss: -246.8861]\n",
      "873 (5, 1) [D loss: (5.2561)(R -231.5801, F 236.3955, G 0.0441)] [G loss: -243.1790]\n",
      "874 (5, 1) [D loss: (-10.2689)(R -249.8658, F 239.5214, G 0.0076)] [G loss: -255.9083]\n",
      "875 (5, 1) [D loss: (-12.1962)(R -263.0151, F 250.7634, G 0.0055)] [G loss: -288.4511]\n",
      "876 (5, 1) [D loss: (-40.9102)(R -324.3974, F 283.1321, G 0.0355)] [G loss: -346.1867]\n",
      "877 (5, 1) [D loss: (-5.4013)(R -278.3307, F 272.8235, G 0.0106)] [G loss: -277.8046]\n",
      "878 (5, 1) [D loss: (10.9817)(R -269.1482, F 279.9254, G 0.0205)] [G loss: -270.4987]\n",
      "879 (5, 1) [D loss: (35.5964)(R -235.2518, F 270.4064, G 0.0442)] [G loss: -206.8781]\n",
      "880 (5, 1) [D loss: (7.1419)(R -163.0149, F 169.6953, G 0.0461)] [G loss: -140.7760]\n",
      "881 (5, 1) [D loss: (-2.1696)(R -161.4675, F 159.0059, G 0.0292)] [G loss: -197.7139]\n",
      "882 (5, 1) [D loss: (-33.4302)(R -175.7435, F 142.1036, G 0.0210)] [G loss: -158.6503]\n",
      "883 (5, 1) [D loss: (-8.8033)(R -163.6133, F 154.3394, G 0.0471)] [G loss: -166.8322]\n",
      "884 (5, 1) [D loss: (7.2684)(R -159.5105, F 166.3472, G 0.0432)] [G loss: -149.6275]\n",
      "885 (5, 1) [D loss: (-19.4369)(R -158.5483, F 138.0121, G 0.1099)] [G loss: -167.0175]\n",
      "886 (5, 1) [D loss: (2.6791)(R -148.5766, F 150.3748, G 0.0881)] [G loss: -160.7543]\n",
      "887 (5, 1) [D loss: (19.0514)(R -167.0789, F 185.9851, G 0.0145)] [G loss: -157.5967]\n",
      "888 (5, 1) [D loss: (-5.1894)(R -197.6025, F 192.3799, G 0.0033)] [G loss: -185.4065]\n",
      "889 (5, 1) [D loss: (-43.1099)(R -219.6657, F 176.5030, G 0.0053)] [G loss: -227.7735]\n",
      "890 (5, 1) [D loss: (-20.9627)(R -261.9890, F 240.9404, G 0.0086)] [G loss: -303.0095]\n",
      "891 (5, 1) [D loss: (9.8727)(R -214.5973, F 224.3482, G 0.0122)] [G loss: -221.0478]\n",
      "892 (5, 1) [D loss: (-8.4961)(R -180.7326, F 172.1190, G 0.0118)] [G loss: -205.3802]\n",
      "893 (5, 1) [D loss: (-5.3896)(R -231.9191, F 226.3040, G 0.0225)] [G loss: -217.3070]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 (5, 1) [D loss: (13.1633)(R -282.6576, F 295.0478, G 0.0773)] [G loss: -294.2961]\n",
      "895 (5, 1) [D loss: (-7.1011)(R -296.5528, F 288.5123, G 0.0939)] [G loss: -273.6449]\n",
      "896 (5, 1) [D loss: (26.4628)(R -259.3986, F 285.6631, G 0.0198)] [G loss: -239.3076]\n",
      "897 (5, 1) [D loss: (14.3260)(R -280.7005, F 294.8727, G 0.0154)] [G loss: -229.6322]\n",
      "898 (5, 1) [D loss: (26.4563)(R -230.8854, F 257.0646, G 0.0277)] [G loss: -227.9907]\n",
      "899 (5, 1) [D loss: (-2.6514)(R -225.9440, F 222.8591, G 0.0433)] [G loss: -213.6105]\n",
      "900 (5, 1) [D loss: (-6.3746)(R -208.7109, F 202.0057, G 0.0331)] [G loss: -222.6460]\n",
      "901 (5, 1) [D loss: (16.3415)(R -188.8780, F 205.1047, G 0.0115)] [G loss: -206.5819]\n",
      "902 (5, 1) [D loss: (-8.8153)(R -241.4186, F 232.5755, G 0.0028)] [G loss: -234.7028]\n",
      "903 (5, 1) [D loss: (2.5571)(R -265.2676, F 266.2134, G 0.1611)] [G loss: -247.8252]\n",
      "904 (5, 1) [D loss: (8.6550)(R -256.4900, F 265.0621, G 0.0083)] [G loss: -275.6990]\n",
      "905 (5, 1) [D loss: (28.3300)(R -273.7888, F 301.0794, G 0.1039)] [G loss: -243.0925]\n",
      "906 (5, 1) [D loss: (-5.1987)(R -244.5742, F 238.9322, G 0.0443)] [G loss: -238.3908]\n",
      "907 (5, 1) [D loss: (-6.5555)(R -217.9081, F 211.2418, G 0.0111)] [G loss: -232.8013]\n",
      "908 (5, 1) [D loss: (-3.1420)(R -239.8576, F 236.6265, G 0.0089)] [G loss: -214.0858]\n",
      "909 (5, 1) [D loss: (-7.5402)(R -245.2046, F 237.5143, G 0.0150)] [G loss: -258.3521]\n",
      "910 (5, 1) [D loss: (14.0501)(R -216.3348, F 230.2951, G 0.0090)] [G loss: -217.3647]\n",
      "911 (5, 1) [D loss: (19.3170)(R -144.1954, F 163.1251, G 0.0387)] [G loss: -151.7801]\n",
      "912 (5, 1) [D loss: (1.3091)(R -134.2942, F 135.3857, G 0.0218)] [G loss: -136.6323]\n",
      "913 (5, 1) [D loss: (2.0523)(R -141.0014, F 142.9303, G 0.0123)] [G loss: -120.8323]\n",
      "914 (5, 1) [D loss: (9.5523)(R -132.7424, F 142.1763, G 0.0118)] [G loss: -115.6834]\n",
      "915 (5, 1) [D loss: (-4.1512)(R -183.1106, F 178.9109, G 0.0048)] [G loss: -171.4936]\n",
      "916 (5, 1) [D loss: (-5.3876)(R -219.3455, F 213.7767, G 0.0181)] [G loss: -217.5344]\n",
      "917 (5, 1) [D loss: (-16.9081)(R -191.6994, F 174.6983, G 0.0093)] [G loss: -173.4814]\n",
      "918 (5, 1) [D loss: (32.2474)(R -226.3495, F 258.4225, G 0.0174)] [G loss: -242.1972]\n",
      "919 (5, 1) [D loss: (-9.5596)(R -264.6470, F 255.0493, G 0.0038)] [G loss: -241.5250]\n",
      "920 (5, 1) [D loss: (20.2746)(R -176.8844, F 196.4299, G 0.0729)] [G loss: -168.0263]\n",
      "921 (5, 1) [D loss: (7.3854)(R -154.0771, F 161.2824, G 0.0180)] [G loss: -158.2236]\n",
      "922 (5, 1) [D loss: (-6.9116)(R -181.7409, F 174.6617, G 0.0168)] [G loss: -207.6606]\n",
      "923 (5, 1) [D loss: (-9.7329)(R -174.4073, F 163.9909, G 0.0683)] [G loss: -157.4437]\n",
      "924 (5, 1) [D loss: (-7.3604)(R -185.4347, F 178.0395, G 0.0035)] [G loss: -187.0494]\n",
      "925 (5, 1) [D loss: (-26.2780)(R -227.6066, F 200.7806, G 0.0548)] [G loss: -221.2595]\n",
      "926 (5, 1) [D loss: (-20.1383)(R -188.3878, F 168.2240, G 0.0026)] [G loss: -185.3536]\n",
      "927 (5, 1) [D loss: (6.5161)(R -226.1872, F 230.8027, G 0.1901)] [G loss: -194.6191]\n",
      "928 (5, 1) [D loss: (-8.7302)(R -210.1986, F 201.1826, G 0.0286)] [G loss: -218.4299]\n",
      "929 (5, 1) [D loss: (-28.3033)(R -237.5198, F 208.9891, G 0.0227)] [G loss: -238.8622]\n",
      "930 (5, 1) [D loss: (2.2823)(R -218.1799, F 220.3144, G 0.0148)] [G loss: -235.0456]\n",
      "931 (5, 1) [D loss: (14.4844)(R -163.6430, F 177.7795, G 0.0348)] [G loss: -160.8367]\n",
      "932 (5, 1) [D loss: (4.6790)(R -187.5182, F 192.0627, G 0.0135)] [G loss: -211.2540]\n",
      "933 (5, 1) [D loss: (19.6161)(R -157.8282, F 177.3349, G 0.0109)] [G loss: -179.3155]\n",
      "934 (5, 1) [D loss: (-0.3054)(R -183.6465, F 183.2955, G 0.0046)] [G loss: -182.1239]\n",
      "935 (5, 1) [D loss: (17.9965)(R -169.4509, F 187.3862, G 0.0061)] [G loss: -146.1206]\n",
      "936 (5, 1) [D loss: (-10.4386)(R -143.9132, F 133.1492, G 0.0325)] [G loss: -146.4730]\n",
      "937 (5, 1) [D loss: (-10.6836)(R -159.9824, F 149.2522, G 0.0047)] [G loss: -157.6512]\n",
      "938 (5, 1) [D loss: (-7.0181)(R -182.2671, F 174.9438, G 0.0305)] [G loss: -151.2675]\n",
      "939 (5, 1) [D loss: (5.4689)(R -161.3912, F 166.7405, G 0.0120)] [G loss: -148.2425]\n",
      "940 (5, 1) [D loss: (11.5678)(R -121.9536, F 133.3507, G 0.0171)] [G loss: -127.3024]\n",
      "941 (5, 1) [D loss: (1.0808)(R -108.0245, F 109.0172, G 0.0088)] [G loss: -105.3078]\n",
      "942 (5, 1) [D loss: (15.4837)(R -111.5474, F 126.9952, G 0.0036)] [G loss: -105.7904]\n",
      "943 (5, 1) [D loss: (-21.1803)(R -105.1570, F 83.8913, G 0.0085)] [G loss: -100.2583]\n",
      "944 (5, 1) [D loss: (-14.5042)(R -116.2911, F 101.7392, G 0.0048)] [G loss: -109.4957]\n",
      "945 (5, 1) [D loss: (0.5031)(R -131.0400, F 131.5035, G 0.0040)] [G loss: -120.7472]\n",
      "946 (5, 1) [D loss: (7.2548)(R -122.6780, F 129.5943, G 0.0338)] [G loss: -121.1276]\n",
      "947 (5, 1) [D loss: (6.3605)(R -111.1334, F 117.3302, G 0.0164)] [G loss: -122.0153]\n",
      "948 (5, 1) [D loss: (8.0595)(R -97.0134, F 104.9468, G 0.0126)] [G loss: -105.2379]\n",
      "949 (5, 1) [D loss: (-0.5768)(R -110.5159, F 109.8944, G 0.0045)] [G loss: -108.7141]\n",
      "950 (5, 1) [D loss: (-17.5692)(R -146.2053, F 128.5800, G 0.0056)] [G loss: -153.8078]\n",
      "951 (5, 1) [D loss: (-8.0927)(R -148.2189, F 140.0821, G 0.0044)] [G loss: -142.6776]\n",
      "952 (5, 1) [D loss: (-16.7544)(R -180.9149, F 162.9807, G 0.1180)] [G loss: -166.1581]\n",
      "953 (5, 1) [D loss: (10.6108)(R -139.6629, F 150.1909, G 0.0083)] [G loss: -138.9950]\n",
      "954 (5, 1) [D loss: (-18.7693)(R -130.9383, F 112.1031, G 0.0066)] [G loss: -124.1889]\n",
      "955 (5, 1) [D loss: (0.8622)(R -139.3168, F 139.5953, G 0.0584)] [G loss: -142.3692]\n",
      "956 (5, 1) [D loss: (-0.7515)(R -144.0957, F 143.1011, G 0.0243)] [G loss: -151.4784]\n",
      "957 (5, 1) [D loss: (7.7709)(R -162.7265, F 170.3484, G 0.0149)] [G loss: -167.0742]\n",
      "958 (5, 1) [D loss: (-0.1964)(R -178.6433, F 178.2864, G 0.0161)] [G loss: -179.5987]\n",
      "959 (5, 1) [D loss: (3.5766)(R -162.8545, F 165.8877, G 0.0543)] [G loss: -171.6459]\n",
      "960 (5, 1) [D loss: (3.2556)(R -184.7909, F 187.9013, G 0.0145)] [G loss: -184.2825]\n",
      "961 (5, 1) [D loss: (20.9561)(R -172.5478, F 193.4058, G 0.0098)] [G loss: -179.4048]\n",
      "962 (5, 1) [D loss: (9.7314)(R -176.0695, F 185.7261, G 0.0075)] [G loss: -185.3667]\n",
      "963 (5, 1) [D loss: (-1.5699)(R -165.5540, F 163.8459, G 0.0138)] [G loss: -156.8431]\n",
      "964 (5, 1) [D loss: (7.2606)(R -153.9513, F 161.1319, G 0.0080)] [G loss: -163.0595]\n",
      "965 (5, 1) [D loss: (-2.8891)(R -155.3141, F 152.2172, G 0.0208)] [G loss: -144.7370]\n",
      "966 (5, 1) [D loss: (21.1397)(R -124.0808, F 145.1290, G 0.0092)] [G loss: -136.1013]\n",
      "967 (5, 1) [D loss: (-2.7632)(R -108.0557, F 105.1959, G 0.0097)] [G loss: -110.3043]\n",
      "968 (5, 1) [D loss: (-7.3153)(R -114.6150, F 107.1864, G 0.0113)] [G loss: -116.0789]\n",
      "969 (5, 1) [D loss: (8.8088)(R -109.7397, F 118.2633, G 0.0285)] [G loss: -111.7295]\n",
      "970 (5, 1) [D loss: (8.6904)(R -100.9288, F 109.2835, G 0.0336)] [G loss: -108.2736]\n",
      "971 (5, 1) [D loss: (-8.0648)(R -103.8232, F 95.6517, G 0.0107)] [G loss: -122.9825]\n",
      "972 (5, 1) [D loss: (-13.0824)(R -134.5560, F 121.4118, G 0.0062)] [G loss: -146.9637]\n",
      "973 (5, 1) [D loss: (5.6340)(R -132.5355, F 137.8567, G 0.0313)] [G loss: -132.4626]\n",
      "974 (5, 1) [D loss: (-5.1608)(R -130.1073, F 124.8722, G 0.0074)] [G loss: -116.4361]\n",
      "975 (5, 1) [D loss: (-20.8320)(R -119.0522, F 98.0594, G 0.0161)] [G loss: -116.9701]\n",
      "976 (5, 1) [D loss: (-13.5372)(R -128.6163, F 115.0175, G 0.0062)] [G loss: -126.9539]\n",
      "977 (5, 1) [D loss: (2.4372)(R -134.1860, F 136.5311, G 0.0092)] [G loss: -124.6697]\n",
      "978 (5, 1) [D loss: (-4.9350)(R -114.7792, F 109.6935, G 0.0151)] [G loss: -129.2550]\n",
      "979 (5, 1) [D loss: (-5.9188)(R -107.3939, F 101.2553, G 0.0220)] [G loss: -100.3111]\n",
      "980 (5, 1) [D loss: (-16.9843)(R -134.8169, F 117.4163, G 0.0416)] [G loss: -131.8925]\n",
      "981 (5, 1) [D loss: (5.5801)(R -126.8793, F 132.3963, G 0.0063)] [G loss: -116.2030]\n",
      "982 (5, 1) [D loss: (5.9699)(R -86.9774, F 92.9058, G 0.0042)] [G loss: -95.2569]\n",
      "983 (5, 1) [D loss: (7.7574)(R -69.0208, F 76.6463, G 0.0132)] [G loss: -68.0958]\n",
      "984 (5, 1) [D loss: (9.8645)(R -63.9436, F 73.7233, G 0.0085)] [G loss: -62.2850]\n",
      "985 (5, 1) [D loss: (2.1980)(R -56.2136, F 58.2984, G 0.0113)] [G loss: -52.7112]\n",
      "986 (5, 1) [D loss: (3.4754)(R -46.6033, F 49.9670, G 0.0112)] [G loss: -48.4922]\n",
      "987 (5, 1) [D loss: (-11.9016)(R -59.6305, F 47.6667, G 0.0062)] [G loss: -52.7336]\n",
      "988 (5, 1) [D loss: (12.3337)(R -57.4225, F 69.4759, G 0.0280)] [G loss: -59.4346]\n",
      "989 (5, 1) [D loss: (6.1711)(R -62.9953, F 69.1301, G 0.0036)] [G loss: -55.5579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990 (5, 1) [D loss: (5.5730)(R -56.5900, F 62.0864, G 0.0077)] [G loss: -62.0680]\n",
      "991 (5, 1) [D loss: (-5.5383)(R -56.7647, F 51.1444, G 0.0082)] [G loss: -51.6928]\n",
      "992 (5, 1) [D loss: (6.3678)(R -40.7902, F 47.0380, G 0.0120)] [G loss: -38.0157]\n",
      "993 (5, 1) [D loss: (3.4250)(R -24.3860, F 27.6943, G 0.0117)] [G loss: -19.9250]\n",
      "994 (5, 1) [D loss: (-2.3435)(R -28.4898, F 25.8824, G 0.0264)] [G loss: -25.0960]\n",
      "995 (5, 1) [D loss: (-5.0134)(R -34.3232, F 29.1852, G 0.0125)] [G loss: -23.7955]\n",
      "996 (5, 1) [D loss: (-2.3250)(R -51.1932, F 48.7581, G 0.0110)] [G loss: -41.6036]\n",
      "997 (5, 1) [D loss: (-1.3993)(R -40.0515, F 38.6117, G 0.0040)] [G loss: -35.7795]\n",
      "998 (5, 1) [D loss: (0.5178)(R -32.1103, F 32.5647, G 0.0063)] [G loss: -32.1541]\n",
      "999 (5, 1) [D loss: (-6.2384)(R -33.0045, F 26.6989, G 0.0067)] [G loss: -36.3602]\n",
      "1000 (5, 1) [D loss: (-0.8072)(R -51.5391, F 50.4297, G 0.0302)] [G loss: -51.9621]\n",
      "1001 (5, 1) [D loss: (3.3930)(R -46.8521, F 49.8213, G 0.0424)] [G loss: -33.9258]\n",
      "1002 (5, 1) [D loss: (4.9352)(R -45.0707, F 49.8177, G 0.0188)] [G loss: -45.5317]\n",
      "1003 (5, 1) [D loss: (-7.2846)(R -44.5261, F 37.1794, G 0.0062)] [G loss: -44.8509]\n",
      "1004 (5, 1) [D loss: (7.6063)(R -36.5424, F 44.1006, G 0.0048)] [G loss: -30.4408]\n",
      "1005 (5, 1) [D loss: (0.4480)(R -27.3363, F 27.7590, G 0.0025)] [G loss: -19.1773]\n",
      "1006 (5, 1) [D loss: (-3.1530)(R -26.0794, F 22.7564, G 0.0170)] [G loss: -24.4737]\n",
      "1007 (5, 1) [D loss: (-3.1297)(R -26.2017, F 23.0170, G 0.0055)] [G loss: -17.0662]\n",
      "1008 (5, 1) [D loss: (-4.6554)(R -26.3507, F 21.6512, G 0.0044)] [G loss: -26.8880]\n",
      "1009 (5, 1) [D loss: (-7.6917)(R -22.9785, F 15.1962, G 0.0091)] [G loss: -27.0349]\n",
      "1010 (5, 1) [D loss: (-0.3165)(R -14.8499, F 14.3988, G 0.0135)] [G loss: -19.0931]\n",
      "1011 (5, 1) [D loss: (2.7894)(R -16.7252, F 19.4530, G 0.0062)] [G loss: -19.2738]\n",
      "1012 (5, 1) [D loss: (-6.1083)(R -23.3668, F 16.5827, G 0.0676)] [G loss: -13.9508]\n",
      "1013 (5, 1) [D loss: (2.3673)(R -13.8534, F 16.1961, G 0.0025)] [G loss: -8.0536]\n",
      "1014 (5, 1) [D loss: (-6.3531)(R -14.0307, F 7.5147, G 0.0163)] [G loss: -10.7599]\n",
      "1015 (5, 1) [D loss: (-1.1804)(R -8.8323, F 7.5832, G 0.0069)] [G loss: -11.8626]\n",
      "1016 (5, 1) [D loss: (-3.1052)(R -9.5436, F 6.3233, G 0.0115)] [G loss: -6.0971]\n",
      "1017 (5, 1) [D loss: (-3.4437)(R -3.5366, F 0.0521, G 0.0041)] [G loss: 5.3423]\n",
      "1018 (5, 1) [D loss: (-5.8120)(R 4.4302, F -10.3033, G 0.0061)] [G loss: 11.3145]\n",
      "1019 (5, 1) [D loss: (-3.0028)(R 7.5395, F -10.9096, G 0.0367)] [G loss: 7.5301]\n",
      "1020 (5, 1) [D loss: (1.9832)(R 1.5699, F 0.2204, G 0.0193)] [G loss: 2.1963]\n",
      "1021 (5, 1) [D loss: (0.0930)(R 3.6563, F -3.6327, G 0.0069)] [G loss: 1.0950]\n",
      "1022 (5, 1) [D loss: (0.6149)(R 1.1232, F -0.5395, G 0.0031)] [G loss: 1.1741]\n",
      "1023 (5, 1) [D loss: (-4.2358)(R -3.9175, F -0.3494, G 0.0031)] [G loss: -9.1872]\n",
      "1024 (5, 1) [D loss: (-13.0488)(R -11.9791, F -1.2485, G 0.0179)] [G loss: -1.3610]\n",
      "1025 (5, 1) [D loss: (3.7488)(R -11.7117, F 15.2946, G 0.0166)] [G loss: -22.8689]\n",
      "1026 (5, 1) [D loss: (-4.8267)(R -17.1518, F 12.1790, G 0.0146)] [G loss: -16.5263]\n",
      "1027 (5, 1) [D loss: (10.0995)(R -18.7250, F 28.4751, G 0.0349)] [G loss: -22.8268]\n",
      "1028 (5, 1) [D loss: (0.8203)(R -21.2491, F 22.0079, G 0.0061)] [G loss: -20.0911]\n",
      "1029 (5, 1) [D loss: (1.9567)(R -17.1299, F 19.0372, G 0.0049)] [G loss: -25.3913]\n",
      "1030 (5, 1) [D loss: (11.2034)(R -13.1448, F 24.2531, G 0.0095)] [G loss: -21.7248]\n",
      "1031 (5, 1) [D loss: (1.0376)(R -11.4729, F 12.3940, G 0.0117)] [G loss: -8.4267]\n",
      "1032 (5, 1) [D loss: (-6.6013)(R -14.5201, F 7.8689, G 0.0050)] [G loss: -6.1153]\n",
      "1033 (5, 1) [D loss: (-4.6270)(R -15.1760, F 10.5095, G 0.0040)] [G loss: -10.6381]\n",
      "1034 (5, 1) [D loss: (-2.1578)(R -18.5026, F 16.2993, G 0.0046)] [G loss: -18.5315]\n",
      "1035 (5, 1) [D loss: (2.4853)(R -23.5772, F 26.0451, G 0.0017)] [G loss: -23.8549]\n",
      "1036 (5, 1) [D loss: (2.0891)(R -23.8712, F 25.9164, G 0.0044)] [G loss: -27.5172]\n",
      "1037 (5, 1) [D loss: (4.8079)(R -33.1671, F 37.7987, G 0.0176)] [G loss: -44.3095]\n",
      "1038 (5, 1) [D loss: (-0.7564)(R -28.0132, F 27.1993, G 0.0057)] [G loss: -28.6870]\n",
      "1039 (5, 1) [D loss: (-5.1181)(R -30.0140, F 24.8459, G 0.0050)] [G loss: -25.0850]\n",
      "1040 (5, 1) [D loss: (-8.6376)(R -26.6973, F 18.0192, G 0.0040)] [G loss: -22.7314]\n",
      "1041 (5, 1) [D loss: (-0.7401)(R -26.0635, F 25.2700, G 0.0053)] [G loss: -22.0249]\n",
      "1042 (5, 1) [D loss: (-11.8666)(R -25.6989, F 13.6085, G 0.0224)] [G loss: -28.8596]\n",
      "1043 (5, 1) [D loss: (0.7871)(R -21.9170, F 22.4740, G 0.0230)] [G loss: -24.0342]\n",
      "1044 (5, 1) [D loss: (-9.5382)(R -26.7976, F 17.1390, G 0.0120)] [G loss: -20.7353]\n",
      "1045 (5, 1) [D loss: (-2.6758)(R -17.3217, F 14.5368, G 0.0109)] [G loss: -25.3419]\n",
      "1046 (5, 1) [D loss: (-6.9966)(R -26.3907, F 19.2728, G 0.0121)] [G loss: -20.6499]\n",
      "1047 (5, 1) [D loss: (0.4312)(R -24.5169, F 24.7753, G 0.0173)] [G loss: -20.7336]\n",
      "1048 (5, 1) [D loss: (4.2011)(R -23.5766, F 27.6778, G 0.0100)] [G loss: -23.0354]\n",
      "1049 (5, 1) [D loss: (1.1033)(R -23.2913, F 24.3186, G 0.0076)] [G loss: -30.7212]\n",
      "1050 (5, 1) [D loss: (0.1543)(R -28.3696, F 28.3573, G 0.0167)] [G loss: -28.9201]\n",
      "1051 (5, 1) [D loss: (-0.3182)(R -26.3763, F 25.9546, G 0.0103)] [G loss: -33.9247]\n",
      "1052 (5, 1) [D loss: (5.2677)(R -21.4477, F 26.4214, G 0.0294)] [G loss: -6.2313]\n",
      "1053 (5, 1) [D loss: (-14.0477)(R -7.9311, F -6.1614, G 0.0045)] [G loss: -1.8553]\n",
      "1054 (5, 1) [D loss: (3.8725)(R 3.9082, F -0.2028, G 0.0167)] [G loss: 3.3167]\n",
      "1055 (5, 1) [D loss: (-6.0010)(R -2.4980, F -3.5858, G 0.0083)] [G loss: -0.8792]\n",
      "1056 (5, 1) [D loss: (0.0693)(R -6.6411, F 6.5923, G 0.0118)] [G loss: -1.7569]\n",
      "1057 (5, 1) [D loss: (-1.0327)(R -3.0471, F 1.9378, G 0.0077)] [G loss: 1.1906]\n",
      "1058 (5, 1) [D loss: (-0.1381)(R -2.6849, F 2.4811, G 0.0066)] [G loss: -6.0208]\n",
      "1059 (5, 1) [D loss: (-4.6218)(R -7.1136, F 2.3848, G 0.0107)] [G loss: -10.1181]\n",
      "1060 (5, 1) [D loss: (-3.9934)(R -12.4590, F 8.3707, G 0.0095)] [G loss: -14.5005]\n",
      "1061 (5, 1) [D loss: (-8.8696)(R -21.5978, F 12.6510, G 0.0077)] [G loss: -21.2474]\n",
      "1062 (5, 1) [D loss: (1.5429)(R -20.8398, F 22.2224, G 0.0160)] [G loss: -23.1886]\n",
      "1063 (5, 1) [D loss: (-14.0111)(R -35.8362, F 21.6702, G 0.0155)] [G loss: -21.5271]\n",
      "1064 (5, 1) [D loss: (-3.1053)(R -24.8445, F 21.6442, G 0.0095)] [G loss: -28.2740]\n",
      "1065 (5, 1) [D loss: (-2.7284)(R -27.3708, F 24.5449, G 0.0098)] [G loss: -24.2915]\n",
      "1066 (5, 1) [D loss: (-1.7122)(R -27.0694, F 25.2889, G 0.0068)] [G loss: -38.5610]\n",
      "1067 (5, 1) [D loss: (1.3190)(R -33.5642, F 34.8458, G 0.0037)] [G loss: -33.1686]\n",
      "1068 (5, 1) [D loss: (-19.5248)(R -42.8010, F 23.0168, G 0.0259)] [G loss: -26.0118]\n",
      "1069 (5, 1) [D loss: (-2.7377)(R -36.0572, F 33.1164, G 0.0203)] [G loss: -35.8960]\n",
      "1070 (5, 1) [D loss: (-5.1373)(R -39.7418, F 34.4911, G 0.0113)] [G loss: -33.0560]\n",
      "1071 (5, 1) [D loss: (-5.7607)(R -46.1060, F 40.2971, G 0.0048)] [G loss: -48.9163]\n",
      "1072 (5, 1) [D loss: (-6.7283)(R -52.3983, F 45.5929, G 0.0077)] [G loss: -54.5444]\n",
      "1073 (5, 1) [D loss: (1.6663)(R -43.5832, F 45.1958, G 0.0054)] [G loss: -44.3113]\n",
      "1074 (5, 1) [D loss: (15.9707)(R -46.9487, F 62.6317, G 0.0288)] [G loss: -49.0572]\n",
      "1075 (5, 1) [D loss: (-7.2539)(R -50.1663, F 42.8654, G 0.0047)] [G loss: -49.9102]\n",
      "1076 (5, 1) [D loss: (1.6165)(R -46.0043, F 47.5400, G 0.0081)] [G loss: -48.2406]\n",
      "1077 (5, 1) [D loss: (-7.5718)(R -56.4108, F 48.8038, G 0.0035)] [G loss: -49.6273]\n",
      "1078 (5, 1) [D loss: (-0.5287)(R -54.3346, F 53.6700, G 0.0136)] [G loss: -52.8155]\n",
      "1079 (5, 1) [D loss: (3.2123)(R -30.0635, F 33.0589, G 0.0217)] [G loss: -32.8662]\n",
      "1080 (5, 1) [D loss: (-5.6407)(R -28.8317, F 22.3854, G 0.0806)] [G loss: -29.3568]\n",
      "1081 (5, 1) [D loss: (-6.4964)(R -33.3203, F 26.7054, G 0.0119)] [G loss: -32.7415]\n",
      "1082 (5, 1) [D loss: (-17.4641)(R -46.2926, F 28.6923, G 0.0136)] [G loss: -33.2866]\n",
      "1083 (5, 1) [D loss: (-4.9712)(R -72.0112, F 66.9969, G 0.0043)] [G loss: -66.7115]\n",
      "1084 (5, 1) [D loss: (-12.8161)(R -59.6091, F 46.5680, G 0.0225)] [G loss: -52.9317]\n",
      "1085 (5, 1) [D loss: (4.1981)(R -79.0709, F 83.1899, G 0.0079)] [G loss: -59.6821]\n",
      "1086 (5, 1) [D loss: (0.9975)(R -96.5019, F 97.4154, G 0.0084)] [G loss: -96.5079]\n",
      "1087 (5, 1) [D loss: (-24.2502)(R -125.9674, F 101.3732, G 0.0344)] [G loss: -121.8493]\n",
      "1088 (5, 1) [D loss: (1.7724)(R -142.8271, F 144.5045, G 0.0095)] [G loss: -142.2345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089 (5, 1) [D loss: (5.5492)(R -145.0555, F 150.4366, G 0.0168)] [G loss: -157.2327]\n",
      "1090 (5, 1) [D loss: (1.4945)(R -130.6516, F 131.9534, G 0.0193)] [G loss: -151.8808]\n",
      "1091 (5, 1) [D loss: (10.2824)(R -135.8599, F 145.9767, G 0.0166)] [G loss: -133.3132]\n",
      "1092 (5, 1) [D loss: (-0.7473)(R -99.7670, F 98.9011, G 0.0119)] [G loss: -98.0681]\n",
      "1093 (5, 1) [D loss: (-10.2773)(R -110.0809, F 99.1585, G 0.0645)] [G loss: -109.6743]\n",
      "1094 (5, 1) [D loss: (-10.5790)(R -157.5337, F 146.8581, G 0.0097)] [G loss: -178.4216]\n",
      "1095 (5, 1) [D loss: (-27.4972)(R -176.0811, F 148.4200, G 0.0164)] [G loss: -160.7132]\n",
      "1096 (5, 1) [D loss: (-31.1746)(R -202.4871, F 171.2323, G 0.0080)] [G loss: -197.4731]\n",
      "1097 (5, 1) [D loss: (32.3210)(R -172.8633, F 204.6062, G 0.0578)] [G loss: -181.9558]\n",
      "1098 (5, 1) [D loss: (11.6730)(R -162.4038, F 173.9934, G 0.0083)] [G loss: -168.2393]\n",
      "1099 (5, 1) [D loss: (14.5448)(R -146.3444, F 160.7216, G 0.0168)] [G loss: -145.4033]\n",
      "1100 (5, 1) [D loss: (-13.2840)(R -132.5538, F 119.2310, G 0.0039)] [G loss: -143.8899]\n",
      "1101 (5, 1) [D loss: (8.1037)(R -160.4659, F 168.1707, G 0.0399)] [G loss: -181.7705]\n",
      "1102 (5, 1) [D loss: (-14.0560)(R -148.6583, F 134.5802, G 0.0022)] [G loss: -159.2661]\n",
      "1103 (5, 1) [D loss: (-17.3167)(R -155.5869, F 138.1686, G 0.0102)] [G loss: -163.2179]\n",
      "1104 (5, 1) [D loss: (-27.8609)(R -173.4905, F 145.5655, G 0.0064)] [G loss: -159.2579]\n",
      "1105 (5, 1) [D loss: (-17.5909)(R -121.6003, F 103.4631, G 0.0546)] [G loss: -123.8873]\n",
      "1106 (5, 1) [D loss: (11.7068)(R -141.7273, F 152.8218, G 0.0612)] [G loss: -128.0357]\n",
      "1107 (5, 1) [D loss: (-1.6110)(R -115.8847, F 114.0904, G 0.0183)] [G loss: -106.2703]\n",
      "1108 (5, 1) [D loss: (16.8189)(R -110.9204, F 127.6536, G 0.0086)] [G loss: -107.6952]\n",
      "1109 (5, 1) [D loss: (11.7033)(R -84.1394, F 95.7244, G 0.0118)] [G loss: -102.3351]\n",
      "1110 (5, 1) [D loss: (-32.7361)(R -146.7232, F 113.6694, G 0.0318)] [G loss: -133.6786]\n",
      "1111 (5, 1) [D loss: (-4.9546)(R -149.1235, F 144.1258, G 0.0043)] [G loss: -140.1067]\n",
      "1112 (5, 1) [D loss: (11.2238)(R -136.5215, F 147.7210, G 0.0024)] [G loss: -129.3047]\n",
      "1113 (5, 1) [D loss: (-37.6205)(R -124.6836, F 86.9881, G 0.0075)] [G loss: -116.8376]\n",
      "1114 (5, 1) [D loss: (24.5019)(R -97.8340, F 122.2583, G 0.0078)] [G loss: -96.6994]\n",
      "1115 (5, 1) [D loss: (-2.2395)(R -108.9446, F 106.5379, G 0.0167)] [G loss: -96.9717]\n",
      "1116 (5, 1) [D loss: (2.3322)(R -108.9491, F 111.0921, G 0.0189)] [G loss: -87.4660]\n",
      "1117 (5, 1) [D loss: (-1.2690)(R -103.2824, F 101.9022, G 0.0111)] [G loss: -97.1479]\n",
      "1118 (5, 1) [D loss: (-17.0405)(R -106.2982, F 89.1747, G 0.0083)] [G loss: -105.3186]\n",
      "1119 (5, 1) [D loss: (-12.0169)(R -92.7522, F 80.5350, G 0.0200)] [G loss: -82.7947]\n",
      "1120 (5, 1) [D loss: (12.3909)(R -74.1885, F 86.3857, G 0.0194)] [G loss: -59.7516]\n",
      "1121 (5, 1) [D loss: (-19.1228)(R -104.6635, F 85.4175, G 0.0123)] [G loss: -107.9261]\n",
      "1122 (5, 1) [D loss: (-7.4287)(R -132.7931, F 124.3577, G 0.1007)] [G loss: -118.6495]\n",
      "1123 (5, 1) [D loss: (32.4865)(R -119.2104, F 151.5945, G 0.0102)] [G loss: -115.9226]\n",
      "1124 (5, 1) [D loss: (49.5038)(R -99.6270, F 149.0382, G 0.0093)] [G loss: -135.3171]\n",
      "1125 (5, 1) [D loss: (-17.5232)(R -135.0905, F 117.4912, G 0.0076)] [G loss: -143.4960]\n",
      "1126 (5, 1) [D loss: (5.0527)(R -149.7705, F 154.6182, G 0.0205)] [G loss: -172.0074]\n",
      "1127 (5, 1) [D loss: (15.7308)(R -143.6880, F 159.1178, G 0.0301)] [G loss: -159.3497]\n",
      "1128 (5, 1) [D loss: (40.0447)(R -106.0527, F 145.8235, G 0.0274)] [G loss: -108.8319]\n",
      "1129 (5, 1) [D loss: (-19.3033)(R -124.3601, F 104.7544, G 0.0302)] [G loss: -112.1512]\n",
      "1130 (5, 1) [D loss: (-14.7339)(R -137.9676, F 123.1947, G 0.0039)] [G loss: -136.7769]\n",
      "1131 (5, 1) [D loss: (-0.8005)(R -128.6104, F 127.5107, G 0.0299)] [G loss: -119.3714]\n",
      "1132 (5, 1) [D loss: (28.9809)(R -108.3977, F 137.2667, G 0.0112)] [G loss: -142.2765]\n",
      "1133 (5, 1) [D loss: (-7.6503)(R -114.6028, F 106.3375, G 0.0615)] [G loss: -127.8455]\n",
      "1134 (5, 1) [D loss: (-12.5439)(R -109.3815, F 96.5973, G 0.0240)] [G loss: -125.8725]\n",
      "1135 (5, 1) [D loss: (21.1963)(R -128.8148, F 149.7425, G 0.0269)] [G loss: -119.2063]\n",
      "1136 (5, 1) [D loss: (-16.7360)(R -120.2221, F 103.3415, G 0.0145)] [G loss: -125.7832]\n",
      "1137 (5, 1) [D loss: (-16.0206)(R -144.1075, F 127.6516, G 0.0435)] [G loss: -140.8235]\n",
      "1138 (5, 1) [D loss: (-4.0094)(R -142.3000, F 137.9930, G 0.0298)] [G loss: -122.4752]\n",
      "1139 (5, 1) [D loss: (16.1640)(R -132.1947, F 148.2709, G 0.0088)] [G loss: -129.8065]\n",
      "1140 (5, 1) [D loss: (-5.8307)(R -140.9725, F 134.6946, G 0.0447)] [G loss: -162.6415]\n",
      "1141 (5, 1) [D loss: (45.6231)(R -110.6142, F 156.1296, G 0.0108)] [G loss: -131.6809]\n",
      "1142 (5, 1) [D loss: (6.1103)(R -115.9695, F 121.7400, G 0.0340)] [G loss: -94.3111]\n",
      "1143 (5, 1) [D loss: (-15.1974)(R -131.5179, F 115.9214, G 0.0399)] [G loss: -146.8904]\n",
      "1144 (5, 1) [D loss: (-2.0279)(R -127.2160, F 124.3505, G 0.0838)] [G loss: -114.7096]\n",
      "1145 (5, 1) [D loss: (7.2796)(R -115.0745, F 122.2864, G 0.0068)] [G loss: -121.3256]\n",
      "1146 (5, 1) [D loss: (11.3562)(R -106.0191, F 117.2416, G 0.0134)] [G loss: -110.0231]\n",
      "1147 (5, 1) [D loss: (29.0140)(R -123.2003, F 151.7302, G 0.0484)] [G loss: -111.1290]\n",
      "1148 (5, 1) [D loss: (-3.4352)(R -156.1903, F 152.6160, G 0.0139)] [G loss: -143.6711]\n",
      "1149 (5, 1) [D loss: (-4.5949)(R -182.7576, F 177.0926, G 0.1070)] [G loss: -171.2036]\n",
      "1150 (5, 1) [D loss: (40.3016)(R -154.3303, F 194.4296, G 0.0202)] [G loss: -156.1002]\n",
      "1151 (5, 1) [D loss: (-49.4655)(R -193.6525, F 144.0327, G 0.0154)] [G loss: -200.9218]\n",
      "1152 (5, 1) [D loss: (18.5009)(R -205.6526, F 223.4042, G 0.0749)] [G loss: -204.1646]\n",
      "1153 (5, 1) [D loss: (0.5806)(R -201.9312, F 202.2692, G 0.0243)] [G loss: -196.9112]\n",
      "1154 (5, 1) [D loss: (20.4272)(R -213.0126, F 233.2147, G 0.0225)] [G loss: -240.0454]\n",
      "1155 (5, 1) [D loss: (0.6441)(R -235.7697, F 236.3315, G 0.0082)] [G loss: -219.8931]\n",
      "1156 (5, 1) [D loss: (3.0615)(R -162.2810, F 165.1574, G 0.0185)] [G loss: -167.2058]\n",
      "1157 (5, 1) [D loss: (-11.3847)(R -150.6823, F 138.9711, G 0.0326)] [G loss: -146.7489]\n",
      "1158 (5, 1) [D loss: (23.1726)(R -115.6106, F 138.6813, G 0.0102)] [G loss: -103.3452]\n",
      "1159 (5, 1) [D loss: (32.9681)(R -80.3568, F 113.1544, G 0.0171)] [G loss: -94.0133]\n",
      "1160 (5, 1) [D loss: (3.7167)(R -68.3147, F 71.9245, G 0.0107)] [G loss: -74.0402]\n",
      "1161 (5, 1) [D loss: (-6.6502)(R -65.7222, F 58.9801, G 0.0092)] [G loss: -76.3669]\n",
      "1162 (5, 1) [D loss: (-12.4347)(R -76.0990, F 62.9296, G 0.0735)] [G loss: -71.2805]\n",
      "1163 (5, 1) [D loss: (-9.3267)(R -65.2141, F 55.4002, G 0.0487)] [G loss: -77.8135]\n",
      "1164 (5, 1) [D loss: (-8.7082)(R -76.9615, F 68.0556, G 0.0198)] [G loss: -78.3763]\n",
      "1165 (5, 1) [D loss: (-15.6726)(R -73.7971, F 58.0795, G 0.0045)] [G loss: -73.0441]\n",
      "1166 (5, 1) [D loss: (-9.7426)(R -76.2707, F 66.4821, G 0.0046)] [G loss: -64.0678]\n",
      "1167 (5, 1) [D loss: (28.9917)(R -54.3725, F 83.2706, G 0.0094)] [G loss: -78.7202]\n",
      "1168 (5, 1) [D loss: (7.4666)(R -67.0407, F 74.1201, G 0.0387)] [G loss: -71.4328]\n",
      "1169 (5, 1) [D loss: (1.9688)(R -58.7534, F 60.4090, G 0.0313)] [G loss: -67.4487]\n",
      "1170 (5, 1) [D loss: (1.6960)(R -66.1762, F 67.7123, G 0.0160)] [G loss: -59.1499]\n",
      "1171 (5, 1) [D loss: (0.6644)(R -42.1593, F 42.7186, G 0.0105)] [G loss: -46.6056]\n",
      "1172 (5, 1) [D loss: (-6.2470)(R -36.3338, F 29.8860, G 0.0201)] [G loss: -28.1990]\n",
      "1173 (5, 1) [D loss: (-0.7028)(R -42.5277, F 40.8027, G 0.1022)] [G loss: -27.7471]\n",
      "1174 (5, 1) [D loss: (-2.9032)(R -29.6742, F 26.3002, G 0.0471)] [G loss: -21.4868]\n",
      "1175 (5, 1) [D loss: (0.2709)(R -31.2521, F 31.2380, G 0.0285)] [G loss: -33.8023]\n",
      "1176 (5, 1) [D loss: (0.3831)(R -32.8768, F 33.0310, G 0.0229)] [G loss: -31.9698]\n",
      "1177 (5, 1) [D loss: (-2.6441)(R -39.5723, F 36.7093, G 0.0219)] [G loss: -37.2747]\n",
      "1178 (5, 1) [D loss: (4.4063)(R -39.8911, F 44.1265, G 0.0171)] [G loss: -41.3662]\n",
      "1179 (5, 1) [D loss: (0.8951)(R -37.9532, F 38.6474, G 0.0201)] [G loss: -35.9693]\n",
      "1180 (5, 1) [D loss: (-10.1113)(R -47.1891, F 36.1187, G 0.0959)] [G loss: -38.4553]\n",
      "1181 (5, 1) [D loss: (-2.6554)(R -47.9021, F 44.7899, G 0.0457)] [G loss: -48.7463]\n",
      "1182 (5, 1) [D loss: (-0.0851)(R -46.9497, F 46.7287, G 0.0136)] [G loss: -46.0052]\n",
      "1183 (5, 1) [D loss: (-2.6991)(R -42.2086, F 39.4316, G 0.0078)] [G loss: -46.9382]\n",
      "1184 (5, 1) [D loss: (-2.4790)(R -39.2930, F 36.7127, G 0.0101)] [G loss: -34.0322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185 (5, 1) [D loss: (-2.8502)(R -34.2852, F 31.4062, G 0.0029)] [G loss: -39.4217]\n",
      "1186 (5, 1) [D loss: (-4.5106)(R -44.8754, F 39.9622, G 0.0403)] [G loss: -37.7013]\n",
      "1187 (5, 1) [D loss: (-2.4756)(R -30.7633, F 27.8840, G 0.0404)] [G loss: -30.4129]\n",
      "1188 (5, 1) [D loss: (-11.4244)(R -58.4954, F 47.0011, G 0.0070)] [G loss: -47.2550]\n",
      "1189 (5, 1) [D loss: (1.2751)(R -67.1602, F 68.3350, G 0.0100)] [G loss: -60.9355]\n",
      "1190 (5, 1) [D loss: (1.8584)(R -66.9620, F 68.7480, G 0.0072)] [G loss: -69.0172]\n",
      "1191 (5, 1) [D loss: (8.4551)(R -68.2365, F 76.5361, G 0.0155)] [G loss: -62.1464]\n",
      "1192 (5, 1) [D loss: (0.7135)(R -83.5760, F 83.7167, G 0.0573)] [G loss: -85.6980]\n",
      "1193 (5, 1) [D loss: (2.4202)(R -92.0636, F 94.0559, G 0.0428)] [G loss: -85.7145]\n",
      "1194 (5, 1) [D loss: (-9.8746)(R -93.0741, F 83.1643, G 0.0035)] [G loss: -93.9647]\n",
      "1195 (5, 1) [D loss: (-16.9211)(R -120.0430, F 102.9423, G 0.0180)] [G loss: -111.1161]\n",
      "1196 (5, 1) [D loss: (10.0577)(R -122.0701, F 131.9453, G 0.0183)] [G loss: -110.2560]\n",
      "1197 (5, 1) [D loss: (-4.2444)(R -114.7897, F 110.5100, G 0.0035)] [G loss: -108.6272]\n",
      "1198 (5, 1) [D loss: (18.1918)(R -97.8896, F 115.9169, G 0.0165)] [G loss: -89.8680]\n",
      "1199 (5, 1) [D loss: (4.0941)(R -128.9286, F 132.9414, G 0.0081)] [G loss: -111.5449]\n",
      "1200 (5, 1) [D loss: (4.5582)(R -125.0880, F 129.5826, G 0.0064)] [G loss: -128.5815]\n",
      "1201 (5, 1) [D loss: (-27.4275)(R -131.3607, F 103.8638, G 0.0069)] [G loss: -93.4459]\n",
      "1202 (5, 1) [D loss: (-10.1357)(R -131.3632, F 121.1455, G 0.0082)] [G loss: -129.3540]\n",
      "1203 (5, 1) [D loss: (-2.6851)(R -112.9396, F 110.2021, G 0.0052)] [G loss: -117.3967]\n",
      "1204 (5, 1) [D loss: (-12.6878)(R -109.7285, F 96.9678, G 0.0073)] [G loss: -118.4682]\n",
      "1205 (5, 1) [D loss: (6.0875)(R -109.0139, F 115.0478, G 0.0054)] [G loss: -104.3335]\n",
      "1206 (5, 1) [D loss: (-11.1755)(R -100.6227, F 89.3487, G 0.0099)] [G loss: -101.1848]\n",
      "1207 (5, 1) [D loss: (4.7045)(R -124.1395, F 128.5973, G 0.0247)] [G loss: -126.3904]\n",
      "1208 (5, 1) [D loss: (-1.7377)(R -113.1379, F 111.3507, G 0.0050)] [G loss: -118.4843]\n",
      "1209 (5, 1) [D loss: (5.3440)(R -125.9315, F 131.2076, G 0.0068)] [G loss: -105.2278]\n",
      "1210 (5, 1) [D loss: (2.1599)(R -99.1401, F 101.2441, G 0.0056)] [G loss: -105.1215]\n",
      "1211 (5, 1) [D loss: (-2.7382)(R -85.3619, F 82.5425, G 0.0081)] [G loss: -84.2823]\n",
      "1212 (5, 1) [D loss: (-4.2705)(R -106.9556, F 102.5994, G 0.0086)] [G loss: -83.7220]\n",
      "1213 (5, 1) [D loss: (-5.6081)(R -107.5858, F 101.7402, G 0.0237)] [G loss: -95.5154]\n",
      "1214 (5, 1) [D loss: (-22.3864)(R -110.1907, F 87.5865, G 0.0218)] [G loss: -90.2507]\n",
      "1215 (5, 1) [D loss: (12.0762)(R -73.3668, F 85.3017, G 0.0141)] [G loss: -72.0195]\n",
      "1216 (5, 1) [D loss: (12.2103)(R -80.7168, F 92.8867, G 0.0040)] [G loss: -71.4024]\n",
      "1217 (5, 1) [D loss: (12.4478)(R -74.3819, F 86.7741, G 0.0056)] [G loss: -75.9033]\n",
      "1218 (5, 1) [D loss: (-1.9388)(R -87.1589, F 85.1620, G 0.0058)] [G loss: -83.6148]\n",
      "1219 (5, 1) [D loss: (-3.0631)(R -72.3038, F 69.1381, G 0.0103)] [G loss: -85.9146]\n",
      "1220 (5, 1) [D loss: (3.2010)(R -64.9619, F 68.1231, G 0.0040)] [G loss: -77.8717]\n",
      "1221 (5, 1) [D loss: (-9.5589)(R -81.6639, F 71.8290, G 0.0276)] [G loss: -84.3183]\n",
      "1222 (5, 1) [D loss: (2.7121)(R -78.3393, F 80.7230, G 0.0328)] [G loss: -71.2904]\n",
      "1223 (5, 1) [D loss: (-23.1881)(R -86.2087, F 62.8395, G 0.0181)] [G loss: -79.9027]\n",
      "1224 (5, 1) [D loss: (-2.4601)(R -92.3875, F 89.8069, G 0.0120)] [G loss: -110.1936]\n",
      "1225 (5, 1) [D loss: (12.4455)(R -94.9239, F 107.2689, G 0.0100)] [G loss: -97.1036]\n",
      "1226 (5, 1) [D loss: (12.9901)(R -102.4662, F 115.3656, G 0.0091)] [G loss: -109.9323]\n",
      "1227 (5, 1) [D loss: (7.4884)(R -113.7207, F 121.1291, G 0.0080)] [G loss: -105.8245]\n",
      "1228 (5, 1) [D loss: (5.6171)(R -92.0401, F 97.6203, G 0.0037)] [G loss: -104.4492]\n",
      "1229 (5, 1) [D loss: (-9.6159)(R -105.0921, F 95.4186, G 0.0058)] [G loss: -93.7013]\n",
      "1230 (5, 1) [D loss: (7.2126)(R -104.7338, F 111.8013, G 0.0145)] [G loss: -120.4371]\n",
      "1231 (5, 1) [D loss: (6.9244)(R -119.6956, F 126.4373, G 0.0183)] [G loss: -108.2320]\n",
      "1232 (5, 1) [D loss: (5.1360)(R -106.9743, F 111.9917, G 0.0119)] [G loss: -108.6592]\n",
      "1233 (5, 1) [D loss: (9.5199)(R -104.9995, F 114.3656, G 0.0154)] [G loss: -100.2812]\n",
      "1234 (5, 1) [D loss: (-1.9791)(R -92.1928, F 90.1301, G 0.0084)] [G loss: -84.9357]\n",
      "1235 (5, 1) [D loss: (3.2262)(R -74.4094, F 77.4491, G 0.0187)] [G loss: -69.8891]\n",
      "1236 (5, 1) [D loss: (2.1612)(R -68.5866, F 70.4781, G 0.0270)] [G loss: -76.3817]\n",
      "1237 (5, 1) [D loss: (2.7189)(R -59.5979, F 61.8890, G 0.0428)] [G loss: -49.7103]\n",
      "1238 (5, 1) [D loss: (-3.1232)(R -44.2107, F 40.6051, G 0.0482)] [G loss: -40.1986]\n",
      "1239 (5, 1) [D loss: (-13.9153)(R -71.5794, F 57.4743, G 0.0190)] [G loss: -78.5036]\n",
      "1240 (5, 1) [D loss: (-2.1509)(R -102.5685, F 100.0893, G 0.0328)] [G loss: -103.3174]\n",
      "1241 (5, 1) [D loss: (-6.0237)(R -81.3361, F 74.7294, G 0.0583)] [G loss: -78.3123]\n",
      "1242 (5, 1) [D loss: (-11.0153)(R -73.2696, F 62.1295, G 0.0125)] [G loss: -67.4934]\n",
      "1243 (5, 1) [D loss: (-18.4886)(R -82.7869, F 64.2354, G 0.0063)] [G loss: -72.2096]\n",
      "1244 (5, 1) [D loss: (3.0466)(R -97.2561, F 100.2391, G 0.0064)] [G loss: -113.4248]\n",
      "1245 (5, 1) [D loss: (10.8948)(R -95.4434, F 106.0645, G 0.0274)] [G loss: -84.4524]\n",
      "1246 (5, 1) [D loss: (14.9683)(R -73.5400, F 88.1972, G 0.0311)] [G loss: -65.5744]\n",
      "1247 (5, 1) [D loss: (7.4582)(R -66.9234, F 74.1425, G 0.0239)] [G loss: -63.2667]\n",
      "1248 (5, 1) [D loss: (3.3040)(R -51.6253, F 54.8122, G 0.0117)] [G loss: -53.5927]\n",
      "1249 (5, 1) [D loss: (-3.4335)(R -58.4677, F 54.6042, G 0.0430)] [G loss: -54.8216]\n",
      "1250 (5, 1) [D loss: (-6.4654)(R -55.7497, F 49.1644, G 0.0120)] [G loss: -45.1507]\n",
      "1251 (5, 1) [D loss: (2.3357)(R -61.7474, F 64.0383, G 0.0045)] [G loss: -41.4650]\n",
      "1252 (5, 1) [D loss: (-1.8314)(R -40.4115, F 38.5512, G 0.0029)] [G loss: -34.8871]\n",
      "1253 (5, 1) [D loss: (3.4924)(R -22.3395, F 25.7478, G 0.0084)] [G loss: -15.4159]\n",
      "1254 (5, 1) [D loss: (0.5418)(R -15.3266, F 15.7151, G 0.0153)] [G loss: -15.8074]\n",
      "1255 (5, 1) [D loss: (6.3127)(R -17.9924, F 24.1242, G 0.0181)] [G loss: -20.8272]\n",
      "1256 (5, 1) [D loss: (-1.9694)(R -26.6404, F 24.6299, G 0.0041)] [G loss: -34.6364]\n",
      "1257 (5, 1) [D loss: (10.5959)(R -37.2091, F 47.7616, G 0.0043)] [G loss: -39.8726]\n",
      "1258 (5, 1) [D loss: (15.6340)(R -44.7502, F 60.3507, G 0.0034)] [G loss: -48.0411]\n",
      "1259 (5, 1) [D loss: (-5.5411)(R -55.8857, F 50.1969, G 0.0148)] [G loss: -64.4342]\n",
      "1260 (5, 1) [D loss: (-9.2611)(R -63.6297, F 54.2504, G 0.0118)] [G loss: -58.1064]\n",
      "1261 (5, 1) [D loss: (2.7183)(R -69.7646, F 72.3976, G 0.0085)] [G loss: -74.3138]\n",
      "1262 (5, 1) [D loss: (14.2877)(R -64.3161, F 78.5604, G 0.0043)] [G loss: -60.5919]\n",
      "1263 (5, 1) [D loss: (-1.0773)(R -61.4310, F 60.2219, G 0.0132)] [G loss: -64.6421]\n",
      "1264 (5, 1) [D loss: (5.0128)(R -64.4067, F 69.3124, G 0.0107)] [G loss: -63.0694]\n",
      "1265 (5, 1) [D loss: (-6.1717)(R -70.3932, F 63.9636, G 0.0258)] [G loss: -62.2505]\n",
      "1266 (5, 1) [D loss: (-1.9514)(R -70.2068, F 68.0928, G 0.0163)] [G loss: -68.2601]\n",
      "1267 (5, 1) [D loss: (-3.8275)(R -86.9468, F 83.0029, G 0.0116)] [G loss: -89.1984]\n",
      "1268 (5, 1) [D loss: (-3.3758)(R -99.8104, F 96.3833, G 0.0051)] [G loss: -96.4875]\n",
      "1269 (5, 1) [D loss: (10.9306)(R -101.4606, F 112.0481, G 0.0343)] [G loss: -99.3291]\n",
      "1270 (5, 1) [D loss: (-6.7389)(R -91.0901, F 84.0724, G 0.0279)] [G loss: -101.3534]\n",
      "1271 (5, 1) [D loss: (-7.4069)(R -113.8454, F 106.0897, G 0.0349)] [G loss: -109.6987]\n",
      "1272 (5, 1) [D loss: (4.4328)(R -90.5923, F 94.8916, G 0.0133)] [G loss: -107.2031]\n",
      "1273 (5, 1) [D loss: (-4.9803)(R -98.7308, F 93.6335, G 0.0117)] [G loss: -101.7816]\n",
      "1274 (5, 1) [D loss: (-10.6814)(R -99.2548, F 88.5201, G 0.0053)] [G loss: -84.8753]\n",
      "1275 (5, 1) [D loss: (-7.4099)(R -85.7856, F 78.3246, G 0.0051)] [G loss: -73.2306]\n",
      "1276 (5, 1) [D loss: (-3.1042)(R -81.0003, F 77.8607, G 0.0035)] [G loss: -77.0009]\n",
      "1277 (5, 1) [D loss: (8.5578)(R -66.7591, F 75.2614, G 0.0056)] [G loss: -69.6575]\n",
      "1278 (5, 1) [D loss: (-5.4273)(R -51.1791, F 45.6745, G 0.0077)] [G loss: -48.8071]\n",
      "1279 (5, 1) [D loss: (-1.6693)(R -44.7550, F 42.9416, G 0.0144)] [G loss: -44.1137]\n",
      "1280 (5, 1) [D loss: (-6.4981)(R -50.3563, F 43.7440, G 0.0114)] [G loss: -42.9244]\n",
      "1281 (5, 1) [D loss: (1.7581)(R -54.3989, F 56.0638, G 0.0093)] [G loss: -46.7947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282 (5, 1) [D loss: (-1.3462)(R -46.3830, F 44.9699, G 0.0067)] [G loss: -45.7592]\n",
      "1283 (5, 1) [D loss: (1.1268)(R -29.8523, F 30.8842, G 0.0095)] [G loss: -29.3448]\n",
      "1284 (5, 1) [D loss: (-0.9528)(R -33.8265, F 32.8280, G 0.0046)] [G loss: -42.9803]\n",
      "1285 (5, 1) [D loss: (1.9866)(R -40.7711, F 42.4135, G 0.0344)] [G loss: -33.5309]\n",
      "1286 (5, 1) [D loss: (-1.9836)(R -32.8069, F 30.7055, G 0.0118)] [G loss: -31.1721]\n",
      "1287 (5, 1) [D loss: (-0.5726)(R -44.1970, F 43.4536, G 0.0171)] [G loss: -40.0302]\n",
      "1288 (5, 1) [D loss: (3.7581)(R -41.4765, F 45.2020, G 0.0033)] [G loss: -37.6835]\n",
      "1289 (5, 1) [D loss: (-0.1531)(R -39.5397, F 39.3388, G 0.0048)] [G loss: -35.0281]\n",
      "1290 (5, 1) [D loss: (-9.9837)(R -43.3666, F 33.3181, G 0.0065)] [G loss: -44.7722]\n",
      "1291 (5, 1) [D loss: (7.5640)(R -34.1528, F 41.4467, G 0.0270)] [G loss: -37.6400]\n",
      "1292 (5, 1) [D loss: (-2.4759)(R -23.0572, F 20.2209, G 0.0360)] [G loss: -21.1379]\n",
      "1293 (5, 1) [D loss: (-1.0321)(R -36.2450, F 35.1271, G 0.0086)] [G loss: -38.7467]\n",
      "1294 (5, 1) [D loss: (7.8316)(R -38.9043, F 46.5789, G 0.0157)] [G loss: -38.8400]\n",
      "1295 (5, 1) [D loss: (0.6473)(R -32.4668, F 33.0343, G 0.0080)] [G loss: -34.6679]\n",
      "1296 (5, 1) [D loss: (-1.1115)(R -40.3516, F 39.1052, G 0.0135)] [G loss: -40.7774]\n",
      "1297 (5, 1) [D loss: (-2.2400)(R -48.5730, F 45.6215, G 0.0711)] [G loss: -49.6853]\n",
      "1298 (5, 1) [D loss: (0.3017)(R -43.7923, F 43.9368, G 0.0157)] [G loss: -46.8054]\n",
      "1299 (5, 1) [D loss: (1.0529)(R -46.7540, F 47.6802, G 0.0127)] [G loss: -41.7132]\n",
      "1300 (5, 1) [D loss: (2.3884)(R -55.2987, F 57.3469, G 0.0340)] [G loss: -51.8368]\n",
      "1301 (5, 1) [D loss: (-8.2900)(R -60.1045, F 51.7383, G 0.0076)] [G loss: -57.8691]\n",
      "1302 (5, 1) [D loss: (-8.2350)(R -54.4117, F 46.1358, G 0.0041)] [G loss: -58.4845]\n",
      "1303 (5, 1) [D loss: (-5.5576)(R -62.3189, F 56.7146, G 0.0047)] [G loss: -56.8990]\n",
      "1304 (5, 1) [D loss: (2.7237)(R -54.6965, F 57.3536, G 0.0067)] [G loss: -43.8047]\n",
      "1305 (5, 1) [D loss: (-0.8828)(R -48.2126, F 47.0948, G 0.0235)] [G loss: -38.6716]\n",
      "1306 (5, 1) [D loss: (5.3081)(R -32.4525, F 37.3784, G 0.0382)] [G loss: -25.5444]\n",
      "1307 (5, 1) [D loss: (5.4506)(R -28.9314, F 34.1035, G 0.0278)] [G loss: -23.5708]\n",
      "1308 (5, 1) [D loss: (-5.1235)(R -20.8678, F 15.5796, G 0.0165)] [G loss: -21.7015]\n",
      "1309 (5, 1) [D loss: (1.4930)(R -23.9484, F 25.3546, G 0.0087)] [G loss: -20.4398]\n",
      "1310 (5, 1) [D loss: (-3.3710)(R -22.7480, F 19.3284, G 0.0049)] [G loss: -26.3105]\n",
      "1311 (5, 1) [D loss: (-0.6326)(R -28.5188, F 27.8085, G 0.0078)] [G loss: -30.6354]\n",
      "1312 (5, 1) [D loss: (-0.6227)(R -35.8481, F 34.4992, G 0.0726)] [G loss: -31.7624]\n",
      "1313 (5, 1) [D loss: (2.7871)(R -37.4841, F 39.6583, G 0.0613)] [G loss: -31.9524]\n",
      "1314 (5, 1) [D loss: (-3.4012)(R -41.1062, F 37.2656, G 0.0439)] [G loss: -43.2215]\n",
      "1315 (5, 1) [D loss: (-0.9017)(R -40.2971, F 39.2646, G 0.0131)] [G loss: -43.6393]\n",
      "1316 (5, 1) [D loss: (2.7417)(R -29.0871, F 31.3497, G 0.0479)] [G loss: -27.2374]\n",
      "1317 (5, 1) [D loss: (0.7705)(R -28.0070, F 28.5150, G 0.0262)] [G loss: -26.7796]\n",
      "1318 (5, 1) [D loss: (0.1848)(R -21.5656, F 21.5005, G 0.0250)] [G loss: -17.3439]\n",
      "1319 (5, 1) [D loss: (-2.4400)(R -18.4158, F 15.8904, G 0.0085)] [G loss: -18.3703]\n",
      "1320 (5, 1) [D loss: (0.2489)(R -25.4177, F 25.2763, G 0.0390)] [G loss: -24.6185]\n",
      "1321 (5, 1) [D loss: (-3.3636)(R -31.5993, F 28.0660, G 0.0170)] [G loss: -28.4302]\n",
      "1322 (5, 1) [D loss: (-1.5805)(R -35.4985, F 33.8347, G 0.0083)] [G loss: -36.7042]\n",
      "1323 (5, 1) [D loss: (-0.1769)(R -50.7048, F 50.3621, G 0.0166)] [G loss: -50.1170]\n",
      "1324 (5, 1) [D loss: (-1.6922)(R -61.5405, F 59.5299, G 0.0318)] [G loss: -58.0883]\n",
      "1325 (5, 1) [D loss: (0.8168)(R -42.6922, F 43.4628, G 0.0046)] [G loss: -40.0220]\n",
      "1326 (5, 1) [D loss: (1.7992)(R -37.5286, F 39.2707, G 0.0057)] [G loss: -37.5917]\n",
      "1327 (5, 1) [D loss: (-3.7140)(R -32.4064, F 28.6179, G 0.0074)] [G loss: -31.2545]\n",
      "1328 (5, 1) [D loss: (0.5279)(R -26.3231, F 26.7644, G 0.0087)] [G loss: -26.0670]\n",
      "1329 (5, 1) [D loss: (-1.9404)(R -22.7097, F 20.7178, G 0.0051)] [G loss: -21.7745]\n",
      "1330 (5, 1) [D loss: (1.5936)(R -21.1425, F 22.6923, G 0.0044)] [G loss: -19.2561]\n",
      "1331 (5, 1) [D loss: (-0.8007)(R -18.2057, F 17.3704, G 0.0035)] [G loss: -14.0002]\n",
      "1332 (5, 1) [D loss: (0.4746)(R -18.6136, F 19.0122, G 0.0076)] [G loss: -16.3337]\n",
      "1333 (5, 1) [D loss: (-3.2878)(R -18.7021, F 15.3562, G 0.0058)] [G loss: -16.4462]\n",
      "1334 (5, 1) [D loss: (2.0951)(R -22.3817, F 24.3941, G 0.0083)] [G loss: -21.5735]\n",
      "1335 (5, 1) [D loss: (0.0908)(R -15.4677, F 15.5140, G 0.0045)] [G loss: -12.4115]\n",
      "1336 (5, 1) [D loss: (-1.4873)(R -15.3586, F 13.7169, G 0.0154)] [G loss: -13.8919]\n",
      "1337 (5, 1) [D loss: (1.5237)(R -17.3167, F 18.6055, G 0.0235)] [G loss: -19.7304]\n",
      "1338 (5, 1) [D loss: (1.9765)(R -27.9261, F 29.8622, G 0.0040)] [G loss: -32.4419]\n",
      "1339 (5, 1) [D loss: (6.1132)(R -20.9784, F 27.0570, G 0.0035)] [G loss: -19.4239]\n",
      "1340 (5, 1) [D loss: (-0.4704)(R -19.4201, F 18.9078, G 0.0042)] [G loss: -24.2200]\n",
      "1341 (5, 1) [D loss: (-0.2218)(R -26.0760, F 25.8062, G 0.0048)] [G loss: -22.8894]\n",
      "1342 (5, 1) [D loss: (-4.4566)(R -38.8703, F 33.8198, G 0.0594)] [G loss: -37.0143]\n",
      "1343 (5, 1) [D loss: (-10.3764)(R -41.0540, F 30.6001, G 0.0078)] [G loss: -39.2150]\n",
      "1344 (5, 1) [D loss: (-1.6974)(R -48.2857, F 46.4899, G 0.0098)] [G loss: -46.6952]\n",
      "1345 (5, 1) [D loss: (1.8759)(R -34.3205, F 36.0585, G 0.0138)] [G loss: -34.7372]\n",
      "1346 (5, 1) [D loss: (-5.1976)(R -30.8813, F 25.5747, G 0.0109)] [G loss: -26.5844]\n",
      "1347 (5, 1) [D loss: (-6.4556)(R -44.2911, F 37.4640, G 0.0371)] [G loss: -43.1954]\n",
      "1348 (5, 1) [D loss: (-10.9135)(R -57.9022, F 46.8450, G 0.0144)] [G loss: -56.5574]\n",
      "1349 (5, 1) [D loss: (-4.1316)(R -46.9720, F 42.7952, G 0.0045)] [G loss: -41.9879]\n",
      "1350 (5, 1) [D loss: (-6.0537)(R -37.7665, F 31.6639, G 0.0049)] [G loss: -35.9974]\n",
      "1351 (5, 1) [D loss: (2.6537)(R -40.6752, F 43.2761, G 0.0053)] [G loss: -43.9595]\n",
      "1352 (5, 1) [D loss: (-0.6962)(R -59.2372, F 58.4507, G 0.0090)] [G loss: -58.8170]\n",
      "1353 (5, 1) [D loss: (2.1697)(R -65.8279, F 67.9044, G 0.0093)] [G loss: -63.7507]\n",
      "1354 (5, 1) [D loss: (-8.5364)(R -74.2727, F 65.6369, G 0.0099)] [G loss: -77.5285]\n",
      "1355 (5, 1) [D loss: (-8.8091)(R -93.5478, F 84.5327, G 0.0206)] [G loss: -84.0490]\n",
      "1356 (5, 1) [D loss: (-0.2076)(R -84.3463, F 84.1017, G 0.0037)] [G loss: -71.0243]\n",
      "1357 (5, 1) [D loss: (-6.1508)(R -91.0490, F 84.6974, G 0.0201)] [G loss: -82.6247]\n",
      "1358 (5, 1) [D loss: (5.6474)(R -102.4666, F 107.8281, G 0.0286)] [G loss: -102.3181]\n",
      "1359 (5, 1) [D loss: (0.6361)(R -133.5110, F 134.1175, G 0.0030)] [G loss: -136.5805]\n",
      "1360 (5, 1) [D loss: (10.0530)(R -118.7392, F 128.7499, G 0.0042)] [G loss: -114.6739]\n",
      "1361 (5, 1) [D loss: (-9.5183)(R -100.6846, F 90.8946, G 0.0272)] [G loss: -97.6040]\n",
      "1362 (5, 1) [D loss: (-7.1218)(R -111.1464, F 103.8728, G 0.0152)] [G loss: -109.8325]\n",
      "1363 (5, 1) [D loss: (-10.3821)(R -127.1597, F 116.5479, G 0.0230)] [G loss: -132.4953]\n",
      "1364 (5, 1) [D loss: (-15.6153)(R -143.6659, F 127.9338, G 0.0117)] [G loss: -136.3895]\n",
      "1365 (5, 1) [D loss: (0.5299)(R -145.3967, F 145.6103, G 0.0316)] [G loss: -147.2902]\n",
      "1366 (5, 1) [D loss: (2.4086)(R -143.6171, F 145.9865, G 0.0039)] [G loss: -142.5623]\n",
      "1367 (5, 1) [D loss: (-5.2553)(R -140.7762, F 135.4086, G 0.0112)] [G loss: -138.1717]\n",
      "1368 (5, 1) [D loss: (-9.6529)(R -145.9734, F 136.1923, G 0.0128)] [G loss: -157.8485]\n",
      "1369 (5, 1) [D loss: (-0.0930)(R -132.4557, F 132.1448, G 0.0218)] [G loss: -119.8002]\n",
      "1370 (5, 1) [D loss: (7.4315)(R -111.2340, F 118.4321, G 0.0233)] [G loss: -95.3755]\n",
      "1371 (5, 1) [D loss: (7.4115)(R -110.3966, F 117.7156, G 0.0092)] [G loss: -107.2510]\n",
      "1372 (5, 1) [D loss: (0.3886)(R -102.9859, F 103.3047, G 0.0070)] [G loss: -95.9835]\n",
      "1373 (5, 1) [D loss: (-7.6406)(R -99.7902, F 92.1135, G 0.0036)] [G loss: -110.9366]\n",
      "1374 (5, 1) [D loss: (-3.1722)(R -100.9234, F 96.9524, G 0.0799)] [G loss: -113.2617]\n",
      "1375 (5, 1) [D loss: (2.6884)(R -115.1199, F 117.3914, G 0.0417)] [G loss: -106.6409]\n",
      "1376 (5, 1) [D loss: (-9.3128)(R -123.3773, F 113.8652, G 0.0199)] [G loss: -121.3702]\n",
      "1377 (5, 1) [D loss: (1.9473)(R -120.6447, F 122.5011, G 0.0091)] [G loss: -112.8694]\n",
      "1378 (5, 1) [D loss: (-1.8086)(R -114.3261, F 112.2642, G 0.0253)] [G loss: -106.1784]\n",
      "1379 (5, 1) [D loss: (-2.0847)(R -85.0512, F 82.9177, G 0.0049)] [G loss: -81.4472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380 (5, 1) [D loss: (9.5815)(R -95.5347, F 104.9004, G 0.0216)] [G loss: -83.5801]\n",
      "1381 (5, 1) [D loss: (-3.5751)(R -103.5521, F 99.7784, G 0.0198)] [G loss: -100.7898]\n",
      "1382 (5, 1) [D loss: (4.1028)(R -110.6314, F 114.6037, G 0.0131)] [G loss: -103.5182]\n",
      "1383 (5, 1) [D loss: (4.7490)(R -103.2693, F 107.9815, G 0.0037)] [G loss: -103.7530]\n",
      "1384 (5, 1) [D loss: (-5.9190)(R -119.6843, F 113.6708, G 0.0095)] [G loss: -120.0482]\n",
      "1385 (5, 1) [D loss: (-6.3812)(R -126.0283, F 119.5386, G 0.0109)] [G loss: -136.0497]\n",
      "1386 (5, 1) [D loss: (-5.5998)(R -141.6723, F 136.0392, G 0.0033)] [G loss: -135.6883]\n",
      "1387 (5, 1) [D loss: (2.6992)(R -110.3335, F 112.4510, G 0.0582)] [G loss: -101.3274]\n",
      "1388 (5, 1) [D loss: (4.7823)(R -94.0399, F 98.6935, G 0.0129)] [G loss: -83.3502]\n",
      "1389 (5, 1) [D loss: (1.9343)(R -89.7444, F 91.5756, G 0.0103)] [G loss: -91.5418]\n",
      "1390 (5, 1) [D loss: (-11.9128)(R -110.5423, F 98.6070, G 0.0023)] [G loss: -114.4261]\n",
      "1391 (5, 1) [D loss: (5.4593)(R -129.5669, F 133.7871, G 0.1239)] [G loss: -126.9283]\n",
      "1392 (5, 1) [D loss: (-15.1860)(R -161.0593, F 145.7253, G 0.0148)] [G loss: -152.5465]\n",
      "1393 (5, 1) [D loss: (0.6394)(R -151.8873, F 152.3975, G 0.0129)] [G loss: -146.2758]\n",
      "1394 (5, 1) [D loss: (25.0849)(R -157.8638, F 182.6340, G 0.0315)] [G loss: -151.7557]\n",
      "1395 (5, 1) [D loss: (0.6273)(R -143.5810, F 144.0456, G 0.0163)] [G loss: -133.1961]\n",
      "1396 (5, 1) [D loss: (-6.3179)(R -152.0581, F 145.6741, G 0.0066)] [G loss: -155.7108]\n",
      "1397 (5, 1) [D loss: (-11.6689)(R -176.1043, F 163.9989, G 0.0436)] [G loss: -167.5434]\n",
      "1398 (5, 1) [D loss: (2.9312)(R -152.8671, F 155.6900, G 0.0108)] [G loss: -134.5942]\n",
      "1399 (5, 1) [D loss: (-10.5882)(R -153.3878, F 142.6723, G 0.0127)] [G loss: -149.0309]\n",
      "1400 (5, 1) [D loss: (1.7168)(R -147.9513, F 149.4183, G 0.0250)] [G loss: -153.2543]\n",
      "1401 (5, 1) [D loss: (9.4712)(R -151.3707, F 160.6570, G 0.0185)] [G loss: -153.2144]\n",
      "1402 (5, 1) [D loss: (8.2032)(R -143.3904, F 151.4465, G 0.0147)] [G loss: -146.5612]\n",
      "1403 (5, 1) [D loss: (11.5935)(R -126.1421, F 137.6428, G 0.0093)] [G loss: -123.9760]\n",
      "1404 (5, 1) [D loss: (-8.5480)(R -126.1314, F 117.3727, G 0.0211)] [G loss: -108.6486]\n",
      "1405 (5, 1) [D loss: (6.9858)(R -112.4666, F 119.4015, G 0.0051)] [G loss: -113.7563]\n",
      "1406 (5, 1) [D loss: (-2.7270)(R -119.8121, F 116.5032, G 0.0582)] [G loss: -114.6769]\n",
      "1407 (5, 1) [D loss: (-4.9442)(R -121.5844, F 116.3557, G 0.0284)] [G loss: -120.6910]\n",
      "1408 (5, 1) [D loss: (2.1780)(R -105.5860, F 107.7352, G 0.0029)] [G loss: -102.9724]\n",
      "1409 (5, 1) [D loss: (11.8108)(R -83.1870, F 94.9144, G 0.0083)] [G loss: -77.0261]\n",
      "1410 (5, 1) [D loss: (-2.5220)(R -73.5820, F 71.0201, G 0.0040)] [G loss: -69.0721]\n",
      "1411 (5, 1) [D loss: (-1.0218)(R -78.3840, F 77.2730, G 0.0089)] [G loss: -83.0602]\n",
      "1412 (5, 1) [D loss: (2.5591)(R -101.1725, F 103.6778, G 0.0054)] [G loss: -109.1980]\n",
      "1413 (5, 1) [D loss: (2.9892)(R -96.0166, F 98.9548, G 0.0051)] [G loss: -90.4767]\n",
      "1414 (5, 1) [D loss: (3.6000)(R -92.6486, F 96.2014, G 0.0047)] [G loss: -93.1403]\n",
      "1415 (5, 1) [D loss: (-8.7924)(R -106.7561, F 97.9147, G 0.0049)] [G loss: -107.7588]\n",
      "1416 (5, 1) [D loss: (-3.2062)(R -109.2526, F 106.0208, G 0.0026)] [G loss: -109.4041]\n",
      "1417 (5, 1) [D loss: (-8.7835)(R -107.0359, F 98.1958, G 0.0057)] [G loss: -103.7392]\n",
      "1418 (5, 1) [D loss: (6.9873)(R -97.6477, F 104.5709, G 0.0064)] [G loss: -93.2125]\n",
      "1419 (5, 1) [D loss: (-0.1244)(R -85.4821, F 85.2937, G 0.0064)] [G loss: -90.4005]\n",
      "1420 (5, 1) [D loss: (-0.8525)(R -86.0390, F 85.0838, G 0.0103)] [G loss: -84.1374]\n",
      "1421 (5, 1) [D loss: (9.3034)(R -74.7625, F 83.9666, G 0.0099)] [G loss: -77.3150]\n",
      "1422 (5, 1) [D loss: (4.4964)(R -61.6181, F 65.9672, G 0.0147)] [G loss: -61.1374]\n",
      "1423 (5, 1) [D loss: (0.0859)(R -71.1827, F 71.2399, G 0.0029)] [G loss: -74.6137]\n",
      "1424 (5, 1) [D loss: (-2.3064)(R -78.3719, F 75.5005, G 0.0565)] [G loss: -67.6171]\n",
      "1425 (5, 1) [D loss: (5.2312)(R -66.9334, F 72.0335, G 0.0131)] [G loss: -61.5142]\n",
      "1426 (5, 1) [D loss: (-2.5038)(R -55.2632, F 52.6923, G 0.0067)] [G loss: -54.0501]\n",
      "1427 (5, 1) [D loss: (-2.8605)(R -51.1180, F 48.2409, G 0.0017)] [G loss: -48.4396]\n",
      "1428 (5, 1) [D loss: (10.1104)(R -51.6960, F 61.7272, G 0.0079)] [G loss: -46.7617]\n",
      "1429 (5, 1) [D loss: (-2.3514)(R -61.1075, F 58.7236, G 0.0033)] [G loss: -57.5323]\n",
      "1430 (5, 1) [D loss: (-1.1696)(R -72.7833, F 71.5792, G 0.0034)] [G loss: -75.5610]\n",
      "1431 (5, 1) [D loss: (-7.0714)(R -68.2579, F 61.1549, G 0.0032)] [G loss: -59.1787]\n",
      "1432 (5, 1) [D loss: (-6.1855)(R -70.4396, F 64.1855, G 0.0069)] [G loss: -67.4282]\n",
      "1433 (5, 1) [D loss: (-8.9878)(R -74.5340, F 65.4005, G 0.0146)] [G loss: -69.7006]\n",
      "1434 (5, 1) [D loss: (-5.1433)(R -75.8564, F 70.1527, G 0.0560)] [G loss: -78.9166]\n",
      "1435 (5, 1) [D loss: (6.6449)(R -70.6262, F 77.1569, G 0.0114)] [G loss: -71.8518]\n",
      "1436 (5, 1) [D loss: (5.0361)(R -82.1123, F 86.7940, G 0.0354)] [G loss: -77.7017]\n",
      "1437 (5, 1) [D loss: (-0.3560)(R -86.8219, F 86.4344, G 0.0031)] [G loss: -88.2490]\n",
      "1438 (5, 1) [D loss: (6.7924)(R -83.4642, F 90.2121, G 0.0044)] [G loss: -71.4681]\n",
      "1439 (5, 1) [D loss: (-2.9631)(R -89.2506, F 86.2397, G 0.0048)] [G loss: -85.1811]\n",
      "1440 (5, 1) [D loss: (6.8037)(R -87.5770, F 94.2810, G 0.0100)] [G loss: -85.2594]\n",
      "1441 (5, 1) [D loss: (-2.7550)(R -66.9151, F 64.1175, G 0.0043)] [G loss: -63.5030]\n",
      "1442 (5, 1) [D loss: (-0.3167)(R -75.5791, F 75.0859, G 0.0176)] [G loss: -74.1815]\n",
      "1443 (5, 1) [D loss: (2.9996)(R -70.9046, F 73.8433, G 0.0061)] [G loss: -68.5095]\n",
      "1444 (5, 1) [D loss: (-4.8400)(R -75.0895, F 70.0747, G 0.0175)] [G loss: -66.0800]\n",
      "1445 (5, 1) [D loss: (-5.8501)(R -75.1392, F 69.2380, G 0.0051)] [G loss: -70.1780]\n",
      "1446 (5, 1) [D loss: (-0.7980)(R -60.0787, F 59.2463, G 0.0034)] [G loss: -58.8954]\n",
      "1447 (5, 1) [D loss: (-4.3099)(R -68.1412, F 63.7818, G 0.0049)] [G loss: -71.3955]\n",
      "1448 (5, 1) [D loss: (0.3320)(R -80.1996, F 80.5069, G 0.0025)] [G loss: -73.0455]\n",
      "1449 (5, 1) [D loss: (-2.3613)(R -77.2124, F 74.8142, G 0.0037)] [G loss: -76.6442]\n",
      "1450 (5, 1) [D loss: (-6.2867)(R -76.9424, F 70.5674, G 0.0088)] [G loss: -74.3345]\n",
      "1451 (5, 1) [D loss: (-6.7107)(R -79.3827, F 72.6385, G 0.0033)] [G loss: -77.6012]\n",
      "1452 (5, 1) [D loss: (-7.0669)(R -76.6780, F 69.5318, G 0.0079)] [G loss: -72.2568]\n",
      "1453 (5, 1) [D loss: (-6.6848)(R -94.2763, F 87.3900, G 0.0201)] [G loss: -90.2844]\n",
      "1454 (5, 1) [D loss: (14.0626)(R -90.0681, F 104.0391, G 0.0092)] [G loss: -87.5567]\n",
      "1455 (5, 1) [D loss: (3.0748)(R -77.0281, F 80.0092, G 0.0094)] [G loss: -73.9315]\n",
      "1456 (5, 1) [D loss: (2.9842)(R -64.1375, F 66.9590, G 0.0163)] [G loss: -58.3043]\n",
      "1457 (5, 1) [D loss: (-12.2869)(R -65.8063, F 53.2159, G 0.0304)] [G loss: -71.1288]\n",
      "1458 (5, 1) [D loss: (-4.3201)(R -65.7921, F 61.3962, G 0.0076)] [G loss: -64.9588]\n",
      "1459 (5, 1) [D loss: (-4.9189)(R -60.8911, F 55.8976, G 0.0075)] [G loss: -69.2644]\n",
      "1460 (5, 1) [D loss: (1.3602)(R -63.1077, F 64.4006, G 0.0067)] [G loss: -60.1345]\n",
      "1461 (5, 1) [D loss: (-4.0585)(R -64.2469, F 60.1567, G 0.0032)] [G loss: -72.1019]\n",
      "1462 (5, 1) [D loss: (2.4324)(R -70.7647, F 73.1193, G 0.0078)] [G loss: -69.1976]\n",
      "1463 (5, 1) [D loss: (-1.5368)(R -63.5162, F 61.9357, G 0.0044)] [G loss: -66.4711]\n",
      "1464 (5, 1) [D loss: (4.1242)(R -61.6017, F 65.6816, G 0.0044)] [G loss: -60.0876]\n",
      "1465 (5, 1) [D loss: (0.0479)(R -61.1588, F 61.1608, G 0.0046)] [G loss: -48.9635]\n",
      "1466 (5, 1) [D loss: (1.4974)(R -64.3573, F 65.7982, G 0.0056)] [G loss: -67.6991]\n",
      "1467 (5, 1) [D loss: (-6.0496)(R -72.1313, F 66.0221, G 0.0060)] [G loss: -71.2671]\n",
      "1468 (5, 1) [D loss: (-12.3007)(R -81.3330, F 68.8797, G 0.0153)] [G loss: -73.4037]\n",
      "1469 (5, 1) [D loss: (-6.5030)(R -86.3892, F 79.8194, G 0.0067)] [G loss: -88.8084]\n",
      "1470 (5, 1) [D loss: (6.2304)(R -90.3219, F 96.4929, G 0.0059)] [G loss: -99.1393]\n",
      "1471 (5, 1) [D loss: (3.7484)(R -86.6050, F 90.3069, G 0.0047)] [G loss: -82.5716]\n",
      "1472 (5, 1) [D loss: (-0.5923)(R -69.5458, F 68.9193, G 0.0034)] [G loss: -61.8617]\n",
      "1473 (5, 1) [D loss: (-5.5741)(R -80.1389, F 74.4860, G 0.0079)] [G loss: -77.4970]\n",
      "1474 (5, 1) [D loss: (6.7340)(R -87.9588, F 94.6551, G 0.0038)] [G loss: -82.6709]\n",
      "1475 (5, 1) [D loss: (-8.5039)(R -90.2906, F 81.7467, G 0.0040)] [G loss: -86.7534]\n",
      "1476 (5, 1) [D loss: (0.6510)(R -90.4170, F 91.0223, G 0.0046)] [G loss: -81.8165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477 (5, 1) [D loss: (-10.4634)(R -91.1631, F 80.4094, G 0.0290)] [G loss: -94.2872]\n",
      "1478 (5, 1) [D loss: (-0.4015)(R -92.0352, F 91.5148, G 0.0119)] [G loss: -88.3444]\n",
      "1479 (5, 1) [D loss: (14.1621)(R -87.8731, F 101.8573, G 0.0178)] [G loss: -88.9195]\n",
      "1480 (5, 1) [D loss: (-7.9583)(R -78.3963, F 70.3839, G 0.0054)] [G loss: -70.8544]\n",
      "1481 (5, 1) [D loss: (1.8681)(R -79.8219, F 81.6640, G 0.0026)] [G loss: -88.7424]\n",
      "1482 (5, 1) [D loss: (-0.5122)(R -84.5505, F 83.9809, G 0.0057)] [G loss: -91.6579]\n",
      "1483 (5, 1) [D loss: (7.7811)(R -73.9091, F 81.6460, G 0.0044)] [G loss: -77.9583]\n",
      "1484 (5, 1) [D loss: (3.0198)(R -64.4994, F 67.4436, G 0.0076)] [G loss: -56.2099]\n",
      "1485 (5, 1) [D loss: (-5.6510)(R -64.2890, F 58.4949, G 0.0143)] [G loss: -62.0683]\n",
      "1486 (5, 1) [D loss: (2.0962)(R -80.0676, F 82.1236, G 0.0040)] [G loss: -67.6493]\n",
      "1487 (5, 1) [D loss: (-8.6478)(R -99.0167, F 90.2762, G 0.0093)] [G loss: -97.6676]\n",
      "1488 (5, 1) [D loss: (-7.3116)(R -93.0528, F 85.6499, G 0.0091)] [G loss: -93.4229]\n",
      "1489 (5, 1) [D loss: (-4.4853)(R -108.6829, F 104.1404, G 0.0057)] [G loss: -103.4573]\n",
      "1490 (5, 1) [D loss: (-5.1225)(R -96.7955, F 91.6367, G 0.0036)] [G loss: -104.1574]\n",
      "1491 (5, 1) [D loss: (-6.5677)(R -99.8123, F 93.0341, G 0.0210)] [G loss: -108.6675]\n",
      "1492 (5, 1) [D loss: (-1.0379)(R -125.6357, F 124.4555, G 0.0142)] [G loss: -129.6825]\n",
      "1493 (5, 1) [D loss: (-15.3303)(R -108.2113, F 92.8201, G 0.0061)] [G loss: -120.9629]\n",
      "1494 (5, 1) [D loss: (5.5819)(R -121.3568, F 126.7958, G 0.0143)] [G loss: -120.7147]\n",
      "1495 (5, 1) [D loss: (-3.0355)(R -132.2171, F 129.0889, G 0.0093)] [G loss: -124.2150]\n",
      "1496 (5, 1) [D loss: (-2.6417)(R -139.5194, F 136.7727, G 0.0105)] [G loss: -140.3615]\n",
      "1497 (5, 1) [D loss: (-14.6260)(R -135.6622, F 120.9247, G 0.0111)] [G loss: -140.2004]\n",
      "1498 (5, 1) [D loss: (15.7802)(R -156.8234, F 172.5485, G 0.0055)] [G loss: -162.3554]\n",
      "1499 (5, 1) [D loss: (5.9943)(R -144.3689, F 150.2697, G 0.0094)] [G loss: -145.2488]\n",
      "1500 (5, 1) [D loss: (-0.8238)(R -167.3826, F 166.5144, G 0.0044)] [G loss: -174.8719]\n",
      "1501 (5, 1) [D loss: (-1.2140)(R -169.8159, F 168.5139, G 0.0088)] [G loss: -168.3444]\n",
      "1502 (5, 1) [D loss: (-1.7720)(R -185.5151, F 183.6597, G 0.0083)] [G loss: -176.9652]\n",
      "1503 (5, 1) [D loss: (-5.0871)(R -208.4499, F 203.2797, G 0.0083)] [G loss: -204.5058]\n",
      "1504 (5, 1) [D loss: (8.7389)(R -184.9279, F 192.9993, G 0.0668)] [G loss: -168.4298]\n",
      "1505 (5, 1) [D loss: (-7.3081)(R -175.8711, F 168.4833, G 0.0080)] [G loss: -187.0080]\n",
      "1506 (5, 1) [D loss: (-16.0851)(R -216.0920, F 199.9298, G 0.0077)] [G loss: -212.9662]\n",
      "1507 (5, 1) [D loss: (17.1903)(R -255.3210, F 271.7078, G 0.0803)] [G loss: -224.9356]\n",
      "1508 (5, 1) [D loss: (-5.8659)(R -232.5760, F 226.4821, G 0.0228)] [G loss: -262.6688]\n",
      "1509 (5, 1) [D loss: (-22.7526)(R -181.6017, F 158.5302, G 0.0319)] [G loss: -159.6683]\n",
      "1510 (5, 1) [D loss: (9.5919)(R -150.0903, F 159.6015, G 0.0081)] [G loss: -173.5688]\n",
      "1511 (5, 1) [D loss: (-78.7971)(R -215.1889, F 136.3059, G 0.0086)] [G loss: -190.7879]\n",
      "1512 (5, 1) [D loss: (18.6886)(R -218.1439, F 236.7782, G 0.0054)] [G loss: -261.4318]\n",
      "1513 (5, 1) [D loss: (28.9671)(R -239.1486, F 268.0562, G 0.0060)] [G loss: -267.4697]\n",
      "1514 (5, 1) [D loss: (4.5950)(R -276.8485, F 279.7373, G 0.1706)] [G loss: -230.1679]\n",
      "1515 (5, 1) [D loss: (12.4957)(R -205.3717, F 217.7464, G 0.0121)] [G loss: -209.8077]\n",
      "1516 (5, 1) [D loss: (-8.8003)(R -252.7709, F 243.7800, G 0.0191)] [G loss: -237.7168]\n",
      "1517 (5, 1) [D loss: (26.2310)(R -177.3126, F 202.2695, G 0.1274)] [G loss: -208.8429]\n",
      "1518 (5, 1) [D loss: (-26.9135)(R -219.2049, F 192.1115, G 0.0180)] [G loss: -228.2804]\n",
      "1519 (5, 1) [D loss: (-16.9168)(R -218.2367, F 201.2589, G 0.0061)] [G loss: -218.3138]\n",
      "1520 (5, 1) [D loss: (-34.3268)(R -238.7706, F 204.3532, G 0.0091)] [G loss: -218.4527]\n",
      "1521 (5, 1) [D loss: (19.9658)(R -229.2324, F 248.8445, G 0.0354)] [G loss: -236.8232]\n",
      "1522 (5, 1) [D loss: (-37.3765)(R -250.0030, F 212.3645, G 0.0262)] [G loss: -243.5930]\n",
      "1523 (5, 1) [D loss: (42.9864)(R -222.4753, F 265.2166, G 0.0245)] [G loss: -237.7939]\n",
      "1524 (5, 1) [D loss: (-27.8319)(R -288.4801, F 259.4201, G 0.1228)] [G loss: -233.2518]\n",
      "1525 (5, 1) [D loss: (8.8196)(R -196.8549, F 205.1327, G 0.0542)] [G loss: -247.4547]\n",
      "1526 (5, 1) [D loss: (19.6595)(R -175.5421, F 194.5337, G 0.0668)] [G loss: -170.1275]\n",
      "1527 (5, 1) [D loss: (31.6427)(R -168.2941, F 199.3736, G 0.0563)] [G loss: -147.2638]\n",
      "1528 (5, 1) [D loss: (10.3043)(R -145.9199, F 156.1736, G 0.0051)] [G loss: -136.2199]\n",
      "1529 (5, 1) [D loss: (1.0534)(R -124.1259, F 125.1121, G 0.0067)] [G loss: -131.1291]\n",
      "1530 (5, 1) [D loss: (-9.0790)(R -111.2979, F 102.1472, G 0.0072)] [G loss: -110.4763]\n",
      "1531 (5, 1) [D loss: (10.4409)(R -104.3288, F 114.7048, G 0.0065)] [G loss: -103.0705]\n",
      "1532 (5, 1) [D loss: (-6.6540)(R -83.4588, F 76.7645, G 0.0040)] [G loss: -91.3760]\n",
      "1533 (5, 1) [D loss: (0.9887)(R -76.3509, F 77.0858, G 0.0254)] [G loss: -80.2283]\n",
      "1534 (5, 1) [D loss: (-13.7418)(R -87.2911, F 73.2136, G 0.0336)] [G loss: -82.8412]\n",
      "1535 (5, 1) [D loss: (-7.8329)(R -89.5471, F 81.6869, G 0.0027)] [G loss: -69.3416]\n",
      "1536 (5, 1) [D loss: (4.2342)(R -64.7928, F 68.8063, G 0.0221)] [G loss: -86.5006]\n",
      "1537 (5, 1) [D loss: (7.7148)(R -84.1422, F 91.7305, G 0.0127)] [G loss: -71.0349]\n",
      "1538 (5, 1) [D loss: (-5.7709)(R -98.4874, F 92.6708, G 0.0046)] [G loss: -112.6472]\n",
      "1539 (5, 1) [D loss: (12.5417)(R -112.6367, F 125.0805, G 0.0098)] [G loss: -145.1588]\n",
      "1540 (5, 1) [D loss: (-12.1252)(R -155.0227, F 142.8703, G 0.0027)] [G loss: -140.4221]\n",
      "1541 (5, 1) [D loss: (12.9318)(R -141.1877, F 154.0565, G 0.0063)] [G loss: -136.2872]\n",
      "1542 (5, 1) [D loss: (12.8549)(R -117.1685, F 129.9716, G 0.0052)] [G loss: -104.5072]\n",
      "1543 (5, 1) [D loss: (1.3191)(R -117.8575, F 119.1226, G 0.0054)] [G loss: -104.3266]\n",
      "1544 (5, 1) [D loss: (-6.5500)(R -127.5913, F 121.0184, G 0.0023)] [G loss: -115.9113]\n",
      "1545 (5, 1) [D loss: (-5.2154)(R -144.6262, F 138.8047, G 0.0606)] [G loss: -120.2294]\n",
      "1546 (5, 1) [D loss: (-10.7351)(R -129.1959, F 118.3514, G 0.0109)] [G loss: -113.5144]\n",
      "1547 (5, 1) [D loss: (-11.6665)(R -142.3182, F 130.4765, G 0.0175)] [G loss: -141.2148]\n",
      "1548 (5, 1) [D loss: (-6.0680)(R -129.0431, F 122.7085, G 0.0267)] [G loss: -123.3135]\n",
      "1549 (5, 1) [D loss: (11.5693)(R -107.8649, F 119.3540, G 0.0080)] [G loss: -118.0971]\n",
      "1550 (5, 1) [D loss: (-5.2759)(R -163.9539, F 158.5657, G 0.0112)] [G loss: -182.0488]\n",
      "1551 (5, 1) [D loss: (-38.1569)(R -145.3551, F 107.1621, G 0.0036)] [G loss: -153.5484]\n",
      "1552 (5, 1) [D loss: (22.8386)(R -167.7662, F 190.5515, G 0.0053)] [G loss: -156.3168]\n",
      "1553 (5, 1) [D loss: (22.1123)(R -155.3737, F 177.3792, G 0.0107)] [G loss: -196.7883]\n",
      "1554 (5, 1) [D loss: (-8.6336)(R -202.4011, F 193.6877, G 0.0080)] [G loss: -190.6144]\n",
      "1555 (5, 1) [D loss: (12.4831)(R -237.6690, F 249.8131, G 0.0339)] [G loss: -228.5505]\n",
      "1556 (5, 1) [D loss: (-24.0369)(R -318.8139, F 293.4441, G 0.1333)] [G loss: -273.2105]\n",
      "1557 (5, 1) [D loss: (-45.2628)(R -308.8415, F 263.5358, G 0.0043)] [G loss: -289.4558]\n",
      "1558 (5, 1) [D loss: (74.7023)(R -364.9639, F 439.3370, G 0.0329)] [G loss: -366.4234]\n",
      "1559 (5, 1) [D loss: (18.6629)(R -212.2920, F 230.5647, G 0.0390)] [G loss: -253.8467]\n",
      "1560 (5, 1) [D loss: (39.0605)(R -247.6795, F 286.6111, G 0.0129)] [G loss: -196.4959]\n",
      "1561 (5, 1) [D loss: (-31.3553)(R -256.0196, F 224.6017, G 0.0063)] [G loss: -207.3811]\n",
      "1562 (5, 1) [D loss: (-2.2193)(R -273.1140, F 270.5869, G 0.0308)] [G loss: -268.3921]\n",
      "1563 (5, 1) [D loss: (17.4526)(R -239.7097, F 256.7594, G 0.0403)] [G loss: -259.9567]\n",
      "1564 (5, 1) [D loss: (5.4513)(R -246.8663, F 252.0924, G 0.0225)] [G loss: -261.5378]\n",
      "1565 (5, 1) [D loss: (79.7258)(R -303.7665, F 379.7051, G 0.3787)] [G loss: -237.3790]\n",
      "1566 (5, 1) [D loss: (-16.4329)(R -150.6798, F 133.6454, G 0.0601)] [G loss: -197.1790]\n",
      "1567 (5, 1) [D loss: (-28.6418)(R -171.8710, F 143.1053, G 0.0124)] [G loss: -203.4671]\n",
      "1568 (5, 1) [D loss: (21.4826)(R -165.8656, F 186.9287, G 0.0419)] [G loss: -150.1057]\n",
      "1569 (5, 1) [D loss: (47.8402)(R -112.4713, F 160.0815, G 0.0230)] [G loss: -116.4895]\n",
      "1570 (5, 1) [D loss: (14.4060)(R -105.0272, F 119.3112, G 0.0122)] [G loss: -126.3283]\n",
      "1571 (5, 1) [D loss: (-19.4019)(R -116.8589, F 97.3081, G 0.0149)] [G loss: -104.6061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572 (5, 1) [D loss: (-15.9754)(R -149.2668, F 133.1485, G 0.0143)] [G loss: -122.9032]\n",
      "1573 (5, 1) [D loss: (-15.0901)(R -126.0149, F 110.8758, G 0.0049)] [G loss: -102.5470]\n",
      "1574 (5, 1) [D loss: (3.4133)(R -120.9351, F 124.1744, G 0.0174)] [G loss: -113.2861]\n",
      "1575 (5, 1) [D loss: (22.2104)(R -111.6373, F 133.7312, G 0.0116)] [G loss: -104.5485]\n",
      "1576 (5, 1) [D loss: (-12.7691)(R -148.6315, F 135.8225, G 0.0040)] [G loss: -128.7983]\n",
      "1577 (5, 1) [D loss: (-56.8711)(R -185.7245, F 128.4482, G 0.0405)] [G loss: -191.2213]\n",
      "1578 (5, 1) [D loss: (-22.8510)(R -171.2035, F 148.2806, G 0.0072)] [G loss: -176.7584]\n",
      "1579 (5, 1) [D loss: (7.1165)(R -163.0275, F 170.0705, G 0.0074)] [G loss: -155.5196]\n",
      "1580 (5, 1) [D loss: (18.4183)(R -164.7470, F 183.0937, G 0.0072)] [G loss: -195.8990]\n",
      "1581 (5, 1) [D loss: (10.5762)(R -147.9876, F 158.4218, G 0.0142)] [G loss: -151.0315]\n",
      "1582 (5, 1) [D loss: (56.2097)(R -86.5447, F 142.7112, G 0.0043)] [G loss: -70.1023]\n",
      "1583 (5, 1) [D loss: (-24.6439)(R -143.6414, F 118.9132, G 0.0084)] [G loss: -152.3486]\n",
      "1584 (5, 1) [D loss: (-47.4503)(R -155.9107, F 108.3963, G 0.0064)] [G loss: -153.2150]\n",
      "1585 (5, 1) [D loss: (52.0225)(R -107.9306, F 159.8110, G 0.0142)] [G loss: -207.2436]\n",
      "1586 (5, 1) [D loss: (28.4182)(R -198.2973, F 226.5096, G 0.0206)] [G loss: -232.9725]\n",
      "1587 (5, 1) [D loss: (93.4016)(R -176.8209, F 269.0167, G 0.1206)] [G loss: -185.2338]\n",
      "1588 (5, 1) [D loss: (-9.9111)(R -177.9333, F 167.7505, G 0.0272)] [G loss: -234.6950]\n",
      "1589 (5, 1) [D loss: (-25.7624)(R -153.5104, F 127.6452, G 0.0103)] [G loss: -161.9418]\n",
      "1590 (5, 1) [D loss: (-30.3320)(R -187.8128, F 156.8485, G 0.0632)] [G loss: -176.4233]\n",
      "1591 (5, 1) [D loss: (35.4998)(R -126.3936, F 160.7394, G 0.1154)] [G loss: -127.3710]\n",
      "1592 (5, 1) [D loss: (-5.1306)(R -116.9347, F 111.4300, G 0.0374)] [G loss: -60.4207]\n",
      "1593 (5, 1) [D loss: (-67.1552)(R -199.8004, F 130.7951, G 0.1850)] [G loss: -161.7612]\n",
      "1594 (5, 1) [D loss: (31.7896)(R -145.7511, F 177.4444, G 0.0096)] [G loss: -167.7031]\n",
      "1595 (5, 1) [D loss: (7.2741)(R -181.4990, F 187.5724, G 0.1201)] [G loss: -137.7487]\n",
      "1596 (5, 1) [D loss: (-49.5015)(R -216.8889, F 167.2897, G 0.0098)] [G loss: -295.3084]\n",
      "1597 (5, 1) [D loss: (15.5253)(R -135.8601, F 151.3353, G 0.0050)] [G loss: -145.2509]\n",
      "1598 (5, 1) [D loss: (10.5926)(R -158.0193, F 167.6744, G 0.0938)] [G loss: -177.5704]\n",
      "1599 (5, 1) [D loss: (-38.9848)(R -161.0326, F 121.2540, G 0.0794)] [G loss: -164.0605]\n",
      "1600 (5, 1) [D loss: (8.0060)(R -167.9055, F 175.8676, G 0.0044)] [G loss: -198.7943]\n",
      "1601 (5, 1) [D loss: (19.3967)(R -178.0067, F 197.2438, G 0.0160)] [G loss: -150.2830]\n",
      "1602 (5, 1) [D loss: (76.9003)(R -154.7880, F 231.4316, G 0.0257)] [G loss: -124.8005]\n",
      "1603 (5, 1) [D loss: (-16.0618)(R -121.9721, F 105.8365, G 0.0074)] [G loss: -102.2562]\n",
      "1604 (5, 1) [D loss: (-19.6524)(R -126.6695, F 106.9786, G 0.0039)] [G loss: -123.9207]\n",
      "1605 (5, 1) [D loss: (-8.7512)(R -92.0550, F 83.2654, G 0.0038)] [G loss: -142.3168]\n",
      "1606 (5, 1) [D loss: (-13.5484)(R -116.3196, F 102.7181, G 0.0053)] [G loss: -79.2470]\n",
      "1607 (5, 1) [D loss: (25.2615)(R -99.4684, F 124.3861, G 0.0344)] [G loss: -92.3092]\n",
      "1608 (5, 1) [D loss: (63.3143)(R -83.6725, F 146.0307, G 0.0956)] [G loss: -130.0606]\n",
      "1609 (5, 1) [D loss: (26.9987)(R -91.1892, F 118.0705, G 0.0117)] [G loss: -91.1286]\n",
      "1610 (5, 1) [D loss: (41.5948)(R -76.1498, F 117.7158, G 0.0029)] [G loss: -53.1186]\n",
      "1611 (5, 1) [D loss: (-2.8252)(R -57.5247, F 54.5943, G 0.0105)] [G loss: -64.4625]\n",
      "1612 (5, 1) [D loss: (-17.5809)(R -76.2666, F 58.6034, G 0.0082)] [G loss: -66.0647]\n",
      "1613 (5, 1) [D loss: (-10.5746)(R -77.6064, F 66.9950, G 0.0037)] [G loss: -71.9332]\n",
      "1614 (5, 1) [D loss: (5.4730)(R -69.4506, F 74.8843, G 0.0039)] [G loss: -67.1285]\n",
      "1615 (5, 1) [D loss: (9.5821)(R -66.6422, F 76.2010, G 0.0023)] [G loss: -57.0046]\n",
      "1616 (5, 1) [D loss: (-14.9079)(R -94.8264, F 79.9009, G 0.0018)] [G loss: -97.6277]\n",
      "1617 (5, 1) [D loss: (2.4607)(R -87.2632, F 89.6929, G 0.0031)] [G loss: -93.9305]\n",
      "1618 (5, 1) [D loss: (2.5350)(R -78.0848, F 80.5963, G 0.0024)] [G loss: -97.0726]\n",
      "1619 (5, 1) [D loss: (-2.6738)(R -76.7380, F 74.0426, G 0.0022)] [G loss: -77.6792]\n",
      "1620 (5, 1) [D loss: (2.6270)(R -134.6725, F 137.2681, G 0.0031)] [G loss: -88.0218]\n",
      "1621 (5, 1) [D loss: (-32.1505)(R -118.1818, F 85.9865, G 0.0045)] [G loss: -130.5989]\n",
      "1622 (5, 1) [D loss: (38.1907)(R -80.2258, F 118.3756, G 0.0041)] [G loss: -141.4841]\n",
      "1623 (5, 1) [D loss: (11.4775)(R -114.0994, F 125.4762, G 0.0101)] [G loss: -123.1013]\n",
      "1624 (5, 1) [D loss: (15.0147)(R -91.8462, F 106.8210, G 0.0040)] [G loss: -126.2421]\n",
      "1625 (5, 1) [D loss: (-22.7906)(R -143.2961, F 120.2036, G 0.0302)] [G loss: -123.1659]\n",
      "1626 (5, 1) [D loss: (-4.7779)(R -115.5577, F 110.7480, G 0.0032)] [G loss: -93.4200]\n",
      "1627 (5, 1) [D loss: (-14.4030)(R -152.3646, F 137.9034, G 0.0058)] [G loss: -132.4079]\n",
      "1628 (5, 1) [D loss: (-11.5888)(R -162.0733, F 150.2007, G 0.0284)] [G loss: -137.6853]\n",
      "1629 (5, 1) [D loss: (-73.9717)(R -185.7083, F 111.6467, G 0.0090)] [G loss: -146.8643]\n",
      "1630 (5, 1) [D loss: (-7.5808)(R -158.9110, F 151.0609, G 0.0269)] [G loss: -182.6180]\n",
      "1631 (5, 1) [D loss: (1.6564)(R -158.0742, F 159.6609, G 0.0070)] [G loss: -160.1764]\n",
      "1632 (5, 1) [D loss: (54.8350)(R -127.1268, F 181.7980, G 0.0164)] [G loss: -152.1282]\n",
      "1633 (5, 1) [D loss: (29.0681)(R -116.6762, F 145.6881, G 0.0056)] [G loss: -181.4018]\n",
      "1634 (5, 1) [D loss: (13.4748)(R -157.2715, F 170.7195, G 0.0027)] [G loss: -171.3642]\n",
      "1635 (5, 1) [D loss: (8.5607)(R -168.2377, F 176.7253, G 0.0073)] [G loss: -152.2946]\n",
      "1636 (5, 1) [D loss: (-26.9161)(R -180.0763, F 153.1341, G 0.0026)] [G loss: -202.1238]\n",
      "1637 (5, 1) [D loss: (-2.6130)(R -223.9965, F 221.3312, G 0.0052)] [G loss: -185.1861]\n",
      "1638 (5, 1) [D loss: (0.8876)(R -147.8388, F 148.6645, G 0.0062)] [G loss: -151.6208]\n",
      "1639 (5, 1) [D loss: (3.5142)(R -147.2890, F 150.6998, G 0.0103)] [G loss: -175.0019]\n",
      "1640 (5, 1) [D loss: (-35.6410)(R -181.7671, F 145.9869, G 0.0139)] [G loss: -189.7488]\n",
      "1641 (5, 1) [D loss: (58.9313)(R -221.6003, F 279.9884, G 0.0543)] [G loss: -218.3893]\n",
      "1642 (5, 1) [D loss: (-15.4437)(R -202.0158, F 186.5330, G 0.0039)] [G loss: -201.7921]\n",
      "1643 (5, 1) [D loss: (-48.6618)(R -203.3809, F 154.5580, G 0.0161)] [G loss: -178.9632]\n",
      "1644 (5, 1) [D loss: (103.0174)(R -198.8070, F 301.7163, G 0.0108)] [G loss: -168.4972]\n",
      "1645 (5, 1) [D loss: (15.2798)(R -174.0454, F 189.2161, G 0.0109)] [G loss: -150.7503]\n",
      "1646 (5, 1) [D loss: (-4.2354)(R -168.6872, F 164.4040, G 0.0048)] [G loss: -143.6732]\n",
      "1647 (5, 1) [D loss: (77.6198)(R -167.4405, F 244.7146, G 0.0346)] [G loss: -179.1650]\n",
      "1648 (5, 1) [D loss: (-11.2366)(R -208.2412, F 196.8464, G 0.0158)] [G loss: -202.0054]\n",
      "1649 (5, 1) [D loss: (29.3518)(R -140.4972, F 169.6919, G 0.0157)] [G loss: -195.5654]\n",
      "1650 (5, 1) [D loss: (23.8923)(R -181.2674, F 205.0391, G 0.0121)] [G loss: -217.3190]\n",
      "1651 (5, 1) [D loss: (1.8262)(R -219.1249, F 220.8286, G 0.0123)] [G loss: -220.9587]\n",
      "1652 (5, 1) [D loss: (-12.3307)(R -184.5647, F 172.0473, G 0.0187)] [G loss: -196.8542]\n",
      "1653 (5, 1) [D loss: (-48.4729)(R -210.6683, F 161.0538, G 0.1142)] [G loss: -190.2955]\n",
      "1654 (5, 1) [D loss: (38.5847)(R -173.0569, F 211.5409, G 0.0101)] [G loss: -180.0574]\n",
      "1655 (5, 1) [D loss: (-7.5133)(R -202.0208, F 194.4464, G 0.0061)] [G loss: -188.0614]\n",
      "1656 (5, 1) [D loss: (-4.1545)(R -193.8561, F 189.6254, G 0.0076)] [G loss: -189.6516]\n",
      "1657 (5, 1) [D loss: (-12.3468)(R -156.7432, F 143.9765, G 0.0420)] [G loss: -125.3520]\n",
      "1658 (5, 1) [D loss: (22.0293)(R -103.8191, F 125.6870, G 0.0161)] [G loss: -121.0758]\n",
      "1659 (5, 1) [D loss: (41.6393)(R -92.3815, F 133.9776, G 0.0043)] [G loss: -116.6933]\n",
      "1660 (5, 1) [D loss: (-17.5012)(R -93.2939, F 75.7238, G 0.0069)] [G loss: -84.8653]\n",
      "1661 (5, 1) [D loss: (5.7034)(R -111.9152, F 117.5430, G 0.0076)] [G loss: -100.8449]\n",
      "1662 (5, 1) [D loss: (31.2354)(R -76.4924, F 107.6941, G 0.0034)] [G loss: -87.0714]\n",
      "1663 (5, 1) [D loss: (-18.0846)(R -91.5408, F 73.4112, G 0.0045)] [G loss: -100.4015]\n",
      "1664 (5, 1) [D loss: (-17.7961)(R -91.0765, F 73.0799, G 0.0200)] [G loss: -93.6395]\n",
      "1665 (5, 1) [D loss: (-14.8509)(R -77.1640, F 62.2394, G 0.0074)] [G loss: -70.6055]\n",
      "1666 (5, 1) [D loss: (32.4175)(R -62.7461, F 94.8352, G 0.0328)] [G loss: -73.6298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1667 (5, 1) [D loss: (-4.2691)(R -67.9205, F 63.6065, G 0.0045)] [G loss: -60.6283]\n",
      "1668 (5, 1) [D loss: (11.8440)(R -50.5424, F 62.3215, G 0.0065)] [G loss: -54.8537]\n",
      "1669 (5, 1) [D loss: (-5.6054)(R -35.3313, F 29.4487, G 0.0277)] [G loss: -27.5417]\n",
      "1670 (5, 1) [D loss: (3.8672)(R -44.3428, F 48.1797, G 0.0030)] [G loss: -50.1413]\n",
      "1671 (5, 1) [D loss: (-0.5973)(R -48.0912, F 47.3069, G 0.0187)] [G loss: -58.5891]\n",
      "1672 (5, 1) [D loss: (-11.7540)(R -62.3959, F 50.3884, G 0.0253)] [G loss: -45.9638]\n",
      "1673 (5, 1) [D loss: (22.6983)(R -52.6688, F 75.2767, G 0.0090)] [G loss: -53.0781]\n",
      "1674 (5, 1) [D loss: (12.0006)(R -47.1897, F 59.1295, G 0.0061)] [G loss: -56.6277]\n",
      "1675 (5, 1) [D loss: (-8.2321)(R -48.3232, F 39.9906, G 0.0100)] [G loss: -52.4330]\n",
      "1676 (5, 1) [D loss: (-6.9647)(R -50.5538, F 43.4806, G 0.0108)] [G loss: -47.0544]\n",
      "1677 (5, 1) [D loss: (-7.5017)(R -69.5120, F 61.8994, G 0.0111)] [G loss: -53.9430]\n",
      "1678 (5, 1) [D loss: (1.3495)(R -73.6050, F 74.8227, G 0.0132)] [G loss: -55.2672]\n",
      "1679 (5, 1) [D loss: (-14.1687)(R -86.8338, F 72.6221, G 0.0043)] [G loss: -74.7197]\n",
      "1680 (5, 1) [D loss: (-3.9258)(R -63.7682, F 59.6926, G 0.0150)] [G loss: -68.8811]\n",
      "1681 (5, 1) [D loss: (-16.0779)(R -58.0067, F 41.8712, G 0.0058)] [G loss: -86.2314]\n",
      "1682 (5, 1) [D loss: (-10.4388)(R -71.9613, F 61.2758, G 0.0247)] [G loss: -66.4261]\n",
      "1683 (5, 1) [D loss: (-9.7602)(R -76.9456, F 66.6208, G 0.0565)] [G loss: -72.0253]\n",
      "1684 (5, 1) [D loss: (14.0415)(R -73.5117, F 87.4375, G 0.0116)] [G loss: -82.2841]\n",
      "1685 (5, 1) [D loss: (31.0738)(R -60.6880, F 91.7147, G 0.0047)] [G loss: -83.3486]\n",
      "1686 (5, 1) [D loss: (21.2854)(R -72.7206, F 93.9458, G 0.0060)] [G loss: -78.1925]\n",
      "1687 (5, 1) [D loss: (19.2808)(R -60.2142, F 79.4352, G 0.0060)] [G loss: -66.8555]\n",
      "1688 (5, 1) [D loss: (-11.2361)(R -55.4418, F 44.1564, G 0.0049)] [G loss: -59.3468]\n",
      "1689 (5, 1) [D loss: (-4.6844)(R -63.2385, F 58.5128, G 0.0041)] [G loss: -64.4595]\n",
      "1690 (5, 1) [D loss: (12.7300)(R -67.4092, F 80.1094, G 0.0030)] [G loss: -66.8256]\n",
      "1691 (5, 1) [D loss: (-1.7692)(R -70.8971, F 68.8758, G 0.0252)] [G loss: -61.1310]\n",
      "1692 (5, 1) [D loss: (4.7171)(R -58.3848, F 63.0420, G 0.0060)] [G loss: -50.2942]\n",
      "1693 (5, 1) [D loss: (-0.9282)(R -61.1874, F 60.1924, G 0.0067)] [G loss: -57.6337]\n",
      "1694 (5, 1) [D loss: (-10.4484)(R -78.0517, F 67.5719, G 0.0031)] [G loss: -54.8815]\n",
      "1695 (5, 1) [D loss: (-1.7371)(R -79.3054, F 77.5211, G 0.0047)] [G loss: -65.4498]\n",
      "1696 (5, 1) [D loss: (36.4706)(R -59.2062, F 95.5682, G 0.0109)] [G loss: -83.9124]\n",
      "1697 (5, 1) [D loss: (-14.2418)(R -72.3271, F 57.7747, G 0.0311)] [G loss: -74.7671]\n",
      "1698 (5, 1) [D loss: (-28.5382)(R -72.7122, F 44.0805, G 0.0093)] [G loss: -56.4946]\n",
      "1699 (5, 1) [D loss: (13.8664)(R -65.5451, F 79.2698, G 0.0142)] [G loss: -82.8356]\n",
      "1700 (5, 1) [D loss: (-20.1301)(R -114.9708, F 94.5025, G 0.0338)] [G loss: -95.2274]\n",
      "1701 (5, 1) [D loss: (10.2950)(R -101.0615, F 111.2474, G 0.0109)] [G loss: -138.5057]\n",
      "1702 (5, 1) [D loss: (-25.1849)(R -114.6212, F 88.6218, G 0.0815)] [G loss: -130.7086]\n",
      "1703 (5, 1) [D loss: (21.3137)(R -104.8748, F 126.1104, G 0.0078)] [G loss: -79.0797]\n",
      "1704 (5, 1) [D loss: (-30.5575)(R -124.0096, F 93.3427, G 0.0109)] [G loss: -101.4493]\n",
      "1705 (5, 1) [D loss: (3.7268)(R -126.3685, F 130.0320, G 0.0063)] [G loss: -106.3558]\n",
      "1706 (5, 1) [D loss: (-11.3329)(R -104.2983, F 92.8370, G 0.0128)] [G loss: -111.0480]\n",
      "1707 (5, 1) [D loss: (5.4755)(R -91.0897, F 96.4269, G 0.0138)] [G loss: -99.6626]\n",
      "1708 (5, 1) [D loss: (19.8714)(R -79.8541, F 99.6512, G 0.0074)] [G loss: -98.6452]\n",
      "1709 (5, 1) [D loss: (-16.3564)(R -91.0859, F 74.6901, G 0.0039)] [G loss: -92.6921]\n",
      "1710 (5, 1) [D loss: (17.8497)(R -77.5157, F 95.1979, G 0.0167)] [G loss: -76.3852]\n",
      "1711 (5, 1) [D loss: (3.4441)(R -82.5083, F 85.7515, G 0.0201)] [G loss: -64.0444]\n",
      "1712 (5, 1) [D loss: (4.9362)(R -67.5001, F 72.3014, G 0.0135)] [G loss: -87.5635]\n",
      "1713 (5, 1) [D loss: (-3.4676)(R -67.5052, F 63.9020, G 0.0136)] [G loss: -62.9098]\n",
      "1714 (5, 1) [D loss: (21.2286)(R -75.6311, F 96.8015, G 0.0058)] [G loss: -68.5563]\n",
      "1715 (5, 1) [D loss: (2.0067)(R -73.7503, F 75.6803, G 0.0077)] [G loss: -68.2659]\n",
      "1716 (5, 1) [D loss: (10.3949)(R -54.8492, F 65.2044, G 0.0040)] [G loss: -48.4665]\n",
      "1717 (5, 1) [D loss: (6.6858)(R -42.5914, F 49.1885, G 0.0089)] [G loss: -40.4441]\n",
      "1718 (5, 1) [D loss: (8.7813)(R -25.5133, F 34.2178, G 0.0077)] [G loss: -36.6739]\n",
      "1719 (5, 1) [D loss: (0.7216)(R -30.0522, F 30.5989, G 0.0175)] [G loss: -25.4692]\n",
      "1720 (5, 1) [D loss: (4.9401)(R -17.7243, F 22.4551, G 0.0209)] [G loss: -17.9458]\n",
      "1721 (5, 1) [D loss: (-4.8907)(R -19.1843, F 14.1158, G 0.0178)] [G loss: -22.6629]\n",
      "1722 (5, 1) [D loss: (1.6110)(R -30.5729, F 31.9869, G 0.0197)] [G loss: -40.1508]\n",
      "1723 (5, 1) [D loss: (-6.7312)(R -51.9351, F 44.7525, G 0.0451)] [G loss: -43.6105]\n",
      "1724 (5, 1) [D loss: (-1.3639)(R -47.9545, F 45.8068, G 0.0784)] [G loss: -40.9078]\n",
      "1725 (5, 1) [D loss: (-7.1598)(R -50.1751, F 42.6536, G 0.0362)] [G loss: -50.2252]\n",
      "1726 (5, 1) [D loss: (2.7204)(R -68.7773, F 70.9574, G 0.0540)] [G loss: -58.8544]\n",
      "1727 (5, 1) [D loss: (-1.5565)(R -54.2996, F 52.7105, G 0.0033)] [G loss: -47.9609]\n",
      "1728 (5, 1) [D loss: (2.4727)(R -48.9507, F 51.2233, G 0.0200)] [G loss: -50.1632]\n",
      "1729 (5, 1) [D loss: (5.0825)(R -64.5320, F 69.3579, G 0.0257)] [G loss: -57.8131]\n",
      "1730 (5, 1) [D loss: (6.5173)(R -37.6509, F 44.1120, G 0.0056)] [G loss: -31.5383]\n",
      "1731 (5, 1) [D loss: (3.7928)(R -28.2143, F 31.8139, G 0.0193)] [G loss: -35.7321]\n",
      "1732 (5, 1) [D loss: (2.8953)(R -35.7276, F 38.4926, G 0.0130)] [G loss: -37.9993]\n",
      "1733 (5, 1) [D loss: (14.9479)(R -23.0726, F 37.8911, G 0.0129)] [G loss: -21.7552]\n",
      "1734 (5, 1) [D loss: (4.1405)(R -9.1523, F 13.0203, G 0.0272)] [G loss: -11.1829]\n",
      "1735 (5, 1) [D loss: (-1.4605)(R -8.2293, F 6.3781, G 0.0391)] [G loss: -9.5706]\n",
      "1736 (5, 1) [D loss: (0.2455)(R -9.0750, F 9.1808, G 0.0140)] [G loss: -8.9660]\n",
      "1737 (5, 1) [D loss: (-1.1401)(R -8.9421, F 7.5415, G 0.0260)] [G loss: -10.4776]\n",
      "1738 (5, 1) [D loss: (-4.3662)(R -12.1507, F 7.4898, G 0.0295)] [G loss: -9.8930]\n",
      "1739 (5, 1) [D loss: (-4.7361)(R -15.2941, F 10.3745, G 0.0183)] [G loss: -11.0015]\n",
      "1740 (5, 1) [D loss: (-1.3256)(R -11.7898, F 10.3632, G 0.0101)] [G loss: -5.6524]\n",
      "1741 (5, 1) [D loss: (3.4914)(R -6.3111, F 9.7362, G 0.0066)] [G loss: -8.3367]\n",
      "1742 (5, 1) [D loss: (-0.6984)(R -1.4897, F 0.6768, G 0.0115)] [G loss: -0.4657]\n",
      "1743 (5, 1) [D loss: (-1.5416)(R 3.0817, F -5.8412, G 0.1218)] [G loss: 6.5427]\n",
      "1744 (5, 1) [D loss: (-11.5152)(R -2.3073, F -9.3341, G 0.0126)] [G loss: 7.9241]\n",
      "1745 (5, 1) [D loss: (-7.9147)(R 6.0856, F -14.3677, G 0.0367)] [G loss: 16.6018]\n",
      "1746 (5, 1) [D loss: (-5.7747)(R 10.0005, F -15.9529, G 0.0178)] [G loss: 7.2245]\n",
      "1747 (5, 1) [D loss: (-9.7977)(R 7.8563, F -17.7356, G 0.0082)] [G loss: 9.9305]\n",
      "1748 (5, 1) [D loss: (4.3568)(R 5.7201, F -1.4221, G 0.0059)] [G loss: -4.0637]\n",
      "1749 (5, 1) [D loss: (-3.5001)(R 5.2654, F -8.8213, G 0.0056)] [G loss: -11.3727]\n",
      "1750 (5, 1) [D loss: (-2.8634)(R -9.5286, F 6.6214, G 0.0044)] [G loss: -5.1098]\n",
      "1751 (5, 1) [D loss: (23.8939)(R 2.3331, F 21.3660, G 0.0195)] [G loss: -6.9825]\n",
      "1752 (5, 1) [D loss: (-12.5841)(R -16.8685, F 4.1739, G 0.0110)] [G loss: -24.4322]\n",
      "1753 (5, 1) [D loss: (1.7252)(R -13.9391, F 15.5361, G 0.0128)] [G loss: -13.3496]\n",
      "1754 (5, 1) [D loss: (-12.2845)(R -8.5864, F -3.7797, G 0.0082)] [G loss: -12.6838]\n",
      "1755 (5, 1) [D loss: (15.6956)(R -15.9360, F 31.5009, G 0.0131)] [G loss: -7.7845]\n",
      "1756 (5, 1) [D loss: (22.3648)(R 6.5302, F 15.7492, G 0.0085)] [G loss: -3.6291]\n",
      "1757 (5, 1) [D loss: (-2.2806)(R 8.4039, F -10.7181, G 0.0034)] [G loss: 6.9332]\n",
      "1758 (5, 1) [D loss: (-17.2152)(R -10.0791, F -7.3332, G 0.0197)] [G loss: 14.7662]\n",
      "1759 (5, 1) [D loss: (8.5313)(R 26.1083, F -17.6153, G 0.0038)] [G loss: 39.6915]\n",
      "1760 (5, 1) [D loss: (16.5138)(R 31.7352, F -15.2421, G 0.0021)] [G loss: 29.6657]\n",
      "1761 (5, 1) [D loss: (-23.2999)(R -6.1641, F -17.1702, G 0.0034)] [G loss: -3.3288]\n",
      "1762 (5, 1) [D loss: (-30.5985)(R -3.5638, F -27.1753, G 0.0141)] [G loss: 25.5280]\n",
      "1763 (5, 1) [D loss: (49.0045)(R 62.5982, F -14.3626, G 0.0769)] [G loss: 15.9642]\n",
      "1764 (5, 1) [D loss: (-5.9157)(R -15.0128, F 8.8316, G 0.0266)] [G loss: -23.5667]\n",
      "1765 (5, 1) [D loss: (11.2158)(R 9.9770, F 0.8052, G 0.0434)] [G loss: 4.2378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766 (5, 1) [D loss: (12.0753)(R 11.0821, F 0.9556, G 0.0038)] [G loss: -14.1257]\n",
      "1767 (5, 1) [D loss: (0.9548)(R -5.8791, F 6.7809, G 0.0053)] [G loss: -13.9487]\n",
      "1768 (5, 1) [D loss: (13.1913)(R -0.7640, F 13.8558, G 0.0099)] [G loss: 34.1163]\n",
      "1769 (5, 1) [D loss: (0.3635)(R 5.5171, F -5.2083, G 0.0055)] [G loss: 1.0120]\n",
      "1770 (5, 1) [D loss: (26.5670)(R -9.9180, F 36.4531, G 0.0032)] [G loss: 17.2011]\n",
      "1771 (5, 1) [D loss: (-24.7049)(R -15.6105, F -9.5458, G 0.0451)] [G loss: 23.3091]\n",
      "1772 (5, 1) [D loss: (19.7465)(R 1.9031, F 17.8172, G 0.0026)] [G loss: -18.1184]\n",
      "1773 (5, 1) [D loss: (8.9003)(R 4.4471, F 4.3717, G 0.0082)] [G loss: -5.1397]\n",
      "1774 (5, 1) [D loss: (12.6281)(R 27.3229, F -14.8570, G 0.0162)] [G loss: -10.2377]\n",
      "1775 (5, 1) [D loss: (-52.4071)(R -20.0179, F -32.4262, G 0.0037)] [G loss: -19.1245]\n",
      "1776 (5, 1) [D loss: (3.9198)(R -38.3315, F 42.2192, G 0.0032)] [G loss: -31.8772]\n",
      "1777 (5, 1) [D loss: (24.6687)(R -51.7030, F 76.3471, G 0.0025)] [G loss: -46.1089]\n",
      "1778 (5, 1) [D loss: (20.7933)(R -36.4184, F 57.1395, G 0.0072)] [G loss: -44.2447]\n",
      "1779 (5, 1) [D loss: (21.0229)(R -15.5526, F 36.5319, G 0.0044)] [G loss: -37.8566]\n",
      "1780 (5, 1) [D loss: (-14.5360)(R -40.4274, F 25.8501, G 0.0041)] [G loss: -38.5119]\n",
      "1781 (5, 1) [D loss: (3.7194)(R -15.3447, F 19.0207, G 0.0043)] [G loss: -43.6736]\n",
      "1782 (5, 1) [D loss: (12.6903)(R -14.8399, F 27.4753, G 0.0055)] [G loss: 15.9265]\n",
      "1783 (5, 1) [D loss: (4.5818)(R -12.9627, F 17.4425, G 0.0102)] [G loss: -7.5170]\n",
      "1784 (5, 1) [D loss: (-24.2283)(R -49.9090, F 25.6325, G 0.0048)] [G loss: -35.7022]\n",
      "1785 (5, 1) [D loss: (-6.0379)(R -23.3212, F 17.1869, G 0.0096)] [G loss: -14.3078]\n",
      "1786 (5, 1) [D loss: (-0.8375)(R -3.9582, F 3.0607, G 0.0060)] [G loss: -18.2293]\n",
      "1787 (5, 1) [D loss: (9.7360)(R -16.5566, F 26.2087, G 0.0084)] [G loss: -1.8527]\n",
      "1788 (5, 1) [D loss: (21.3186)(R 7.7275, F 13.4179, G 0.0173)] [G loss: -34.6889]\n",
      "1789 (5, 1) [D loss: (-0.0055)(R -19.4738, F 19.4388, G 0.0029)] [G loss: -39.2577]\n",
      "1790 (5, 1) [D loss: (3.9287)(R -66.3717, F 70.2631, G 0.0037)] [G loss: -20.4868]\n",
      "1791 (5, 1) [D loss: (-45.2802)(R -104.0033, F 58.5787, G 0.0144)] [G loss: -48.6774]\n",
      "1792 (5, 1) [D loss: (-17.8872)(R -64.4388, F 46.4817, G 0.0070)] [G loss: -47.7326]\n",
      "1793 (5, 1) [D loss: (42.1811)(R -55.4800, F 97.4294, G 0.0232)] [G loss: -67.2255]\n",
      "1794 (5, 1) [D loss: (41.8012)(R -67.3799, F 109.0616, G 0.0119)] [G loss: -75.4466]\n",
      "1795 (5, 1) [D loss: (-14.1787)(R -63.0764, F 48.7918, G 0.0106)] [G loss: -76.8922]\n",
      "1796 (5, 1) [D loss: (0.3030)(R -56.1174, F 55.9881, G 0.0432)] [G loss: -60.3539]\n",
      "1797 (5, 1) [D loss: (13.6011)(R -38.6207, F 52.1604, G 0.0061)] [G loss: -33.0411]\n",
      "1798 (5, 1) [D loss: (19.0794)(R -48.8619, F 67.4545, G 0.0487)] [G loss: -54.3044]\n",
      "1799 (5, 1) [D loss: (4.8300)(R -61.1582, F 65.7574, G 0.0231)] [G loss: -48.5315]\n",
      "1800 (5, 1) [D loss: (43.5576)(R -23.9959, F 67.4216, G 0.0132)] [G loss: -59.0938]\n",
      "1801 (5, 1) [D loss: (-31.5787)(R -77.9477, F 46.0306, G 0.0338)] [G loss: -78.5302]\n",
      "1802 (5, 1) [D loss: (1.0120)(R -100.2556, F 101.1668, G 0.0101)] [G loss: -115.9890]\n",
      "1803 (5, 1) [D loss: (-0.6695)(R -95.6559, F 94.9094, G 0.0077)] [G loss: -75.7748]\n",
      "1804 (5, 1) [D loss: (27.3185)(R -65.6479, F 92.8768, G 0.0089)] [G loss: -75.3345]\n",
      "1805 (5, 1) [D loss: (-39.0299)(R -104.0703, F 64.9983, G 0.0042)] [G loss: -95.2704]\n",
      "1806 (5, 1) [D loss: (-71.9371)(R -156.5653, F 83.8787, G 0.0749)] [G loss: -135.8912]\n",
      "1807 (5, 1) [D loss: (16.7371)(R -112.9059, F 129.5671, G 0.0076)] [G loss: -115.1864]\n",
      "1808 (5, 1) [D loss: (8.3887)(R -99.3770, F 107.7013, G 0.0064)] [G loss: -85.0416]\n",
      "1809 (5, 1) [D loss: (-57.1660)(R -123.6651, F 66.3519, G 0.0147)] [G loss: -132.7313]\n",
      "1810 (5, 1) [D loss: (-49.2552)(R -171.0287, F 121.6939, G 0.0080)] [G loss: -144.5171]\n",
      "1811 (5, 1) [D loss: (-23.4090)(R -162.1158, F 138.5252, G 0.0182)] [G loss: -117.8306]\n",
      "1812 (5, 1) [D loss: (55.0719)(R -122.8002, F 177.8235, G 0.0049)] [G loss: -154.5683]\n",
      "1813 (5, 1) [D loss: (-14.5589)(R -121.1223, F 106.4852, G 0.0078)] [G loss: -117.0675]\n",
      "1814 (5, 1) [D loss: (34.4370)(R -118.5485, F 152.8946, G 0.0091)] [G loss: -120.9886]\n",
      "1815 (5, 1) [D loss: (-78.7078)(R -193.9160, F 115.1448, G 0.0063)] [G loss: -171.9388]\n",
      "1816 (5, 1) [D loss: (-28.2540)(R -172.0652, F 142.1651, G 0.1646)] [G loss: -140.1980]\n",
      "1817 (5, 1) [D loss: (78.1465)(R -136.6644, F 213.6685, G 0.1142)] [G loss: -247.6886]\n",
      "1818 (5, 1) [D loss: (-66.0024)(R -146.8987, F 79.5486, G 0.1348)] [G loss: -150.3184]\n",
      "1819 (5, 1) [D loss: (3.2826)(R -70.3098, F 70.3209, G 0.3271)] [G loss: -132.0357]\n",
      "1820 (5, 1) [D loss: (34.5312)(R -103.6311, F 137.8671, G 0.0295)] [G loss: -95.6894]\n",
      "1821 (5, 1) [D loss: (-11.5127)(R -58.5408, F 46.9407, G 0.0087)] [G loss: -49.6062]\n",
      "1822 (5, 1) [D loss: (-19.5736)(R -45.8608, F 26.2547, G 0.0032)] [G loss: -111.2571]\n",
      "1823 (5, 1) [D loss: (-7.9895)(R -32.8778, F 24.7958, G 0.0092)] [G loss: -118.5345]\n",
      "1824 (5, 1) [D loss: (123.1748)(R 36.2719, F 86.8413, G 0.0062)] [G loss: -33.5770]\n",
      "1825 (5, 1) [D loss: (9.8216)(R -15.9390, F 25.4732, G 0.0287)] [G loss: -6.0490]\n",
      "1826 (5, 1) [D loss: (-109.9934)(R -49.7969, F -60.6805, G 0.0484)] [G loss: -39.8510]\n",
      "1827 (5, 1) [D loss: (-18.2771)(R -36.7739, F 15.1250, G 0.3372)] [G loss: 16.1489]\n",
      "1828 (5, 1) [D loss: (54.0791)(R -35.1377, F 88.9760, G 0.0241)] [G loss: -124.3937]\n",
      "1829 (5, 1) [D loss: (-154.0172)(R -135.1869, F -20.9783, G 0.2148)] [G loss: -95.7158]\n",
      "1830 (5, 1) [D loss: (85.9663)(R -95.9877, F 178.5194, G 0.3435)] [G loss: -85.5631]\n",
      "1831 (5, 1) [D loss: (-48.6437)(R -70.7047, F 21.7620, G 0.0299)] [G loss: -110.8177]\n",
      "1832 (5, 1) [D loss: (30.5859)(R 0.6462, F 29.5358, G 0.0404)] [G loss: -114.5389]\n",
      "1833 (5, 1) [D loss: (15.2787)(R 25.9165, F -10.7238, G 0.0086)] [G loss: -15.1372]\n",
      "1834 (5, 1) [D loss: (88.9694)(R 4.7967, F 83.8876, G 0.0285)] [G loss: -175.7115]\n",
      "1835 (5, 1) [D loss: (-138.1248)(R -55.9002, F -82.3251, G 0.0100)] [G loss: -13.2998]\n",
      "1836 (5, 1) [D loss: (-36.2687)(R -88.0349, F 47.6423, G 0.4124)] [G loss: -86.6379]\n",
      "1837 (5, 1) [D loss: (-31.2271)(R -77.7510, F 46.2511, G 0.0273)] [G loss: -130.9694]\n",
      "1838 (5, 1) [D loss: (-20.9115)(R 4.6886, F -25.7946, G 0.0195)] [G loss: -70.2513]\n",
      "1839 (5, 1) [D loss: (-36.4792)(R -69.4168, F 32.5420, G 0.0396)] [G loss: 3.1933]\n",
      "1840 (5, 1) [D loss: (-29.0325)(R -76.6929, F 46.4258, G 0.1235)] [G loss: -154.1939]\n",
      "1841 (5, 1) [D loss: (-21.3057)(R -43.8218, F 22.4036, G 0.0113)] [G loss: -29.7740]\n",
      "1842 (5, 1) [D loss: (-77.1441)(R -142.8956, F 65.5698, G 0.0182)] [G loss: -88.2289]\n",
      "1843 (5, 1) [D loss: (17.5672)(R -106.4133, F 123.7966, G 0.0184)] [G loss: -20.4097]\n",
      "1844 (5, 1) [D loss: (3.1855)(R -25.2887, F 28.2918, G 0.0182)] [G loss: -37.6973]\n",
      "1845 (5, 1) [D loss: (18.7774)(R -32.9606, F 51.5335, G 0.0205)] [G loss: -67.3468]\n",
      "1846 (5, 1) [D loss: (-27.9586)(R -51.2621, F 23.2695, G 0.0034)] [G loss: -63.1896]\n",
      "1847 (5, 1) [D loss: (9.9808)(R -81.5225, F 91.3105, G 0.0193)] [G loss: -91.6707]\n",
      "1848 (5, 1) [D loss: (10.8558)(R -78.0265, F 88.8110, G 0.0071)] [G loss: -54.9109]\n",
      "1849 (5, 1) [D loss: (-11.7961)(R -71.0941, F 59.2304, G 0.0068)] [G loss: -26.8277]\n",
      "1850 (5, 1) [D loss: (-71.2338)(R -143.0330, F 70.8170, G 0.0982)] [G loss: -90.7469]\n",
      "1851 (5, 1) [D loss: (106.1789)(R -67.7825, F 173.2280, G 0.0733)] [G loss: -105.7939]\n",
      "1852 (5, 1) [D loss: (90.1508)(R -5.3662, F 95.2779, G 0.0239)] [G loss: -74.6559]\n",
      "1853 (5, 1) [D loss: (83.9227)(R -26.6222, F 110.1533, G 0.0392)] [G loss: -50.7350]\n",
      "1854 (5, 1) [D loss: (22.7200)(R -23.9523, F 46.5275, G 0.0145)] [G loss: -45.5079]\n",
      "1855 (5, 1) [D loss: (-22.9219)(R -63.8531, F 40.3679, G 0.0563)] [G loss: -87.4368]\n",
      "1856 (5, 1) [D loss: (29.6800)(R -22.8298, F 52.2946, G 0.0215)] [G loss: -48.8999]\n",
      "1857 (5, 1) [D loss: (11.0296)(R -25.1191, F 35.9562, G 0.0192)] [G loss: -29.4670]\n",
      "1858 (5, 1) [D loss: (6.6569)(R -49.4190, F 56.0176, G 0.0058)] [G loss: -69.2897]\n",
      "1859 (5, 1) [D loss: (-28.1603)(R -90.4205, F 62.0109, G 0.0249)] [G loss: -58.1993]\n",
      "1860 (5, 1) [D loss: (40.5659)(R -54.9433, F 95.4470, G 0.0062)] [G loss: -71.6227]\n",
      "1861 (5, 1) [D loss: (-24.0440)(R -86.5174, F 62.3468, G 0.0127)] [G loss: -81.3415]\n",
      "1862 (5, 1) [D loss: (0.0795)(R -89.5494, F 89.5872, G 0.0042)] [G loss: -82.4342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1863 (5, 1) [D loss: (11.5042)(R -71.4695, F 82.9257, G 0.0048)] [G loss: -58.8812]\n",
      "1864 (5, 1) [D loss: (-0.2322)(R -93.2106, F 92.7776, G 0.0201)] [G loss: -63.3771]\n",
      "1865 (5, 1) [D loss: (-17.6967)(R -107.4633, F 89.4865, G 0.0280)] [G loss: -93.6472]\n",
      "1866 (5, 1) [D loss: (-58.9740)(R -142.7437, F 83.5780, G 0.0192)] [G loss: -119.3614]\n",
      "1867 (5, 1) [D loss: (37.3061)(R -113.9871, F 151.0270, G 0.0266)] [G loss: -124.5662]\n",
      "1868 (5, 1) [D loss: (-10.3049)(R -138.8234, F 128.3522, G 0.0166)] [G loss: -133.0745]\n",
      "1869 (5, 1) [D loss: (7.0721)(R -154.2057, F 161.1405, G 0.0137)] [G loss: -133.9755]\n",
      "1870 (5, 1) [D loss: (26.2484)(R -113.6541, F 139.8176, G 0.0085)] [G loss: -145.9962]\n",
      "1871 (5, 1) [D loss: (-42.4369)(R -142.3135, F 99.8233, G 0.0053)] [G loss: -112.0738]\n",
      "1872 (5, 1) [D loss: (-2.3883)(R -161.6922, F 159.2158, G 0.0088)] [G loss: -112.0972]\n",
      "1873 (5, 1) [D loss: (41.2446)(R -121.1966, F 162.4026, G 0.0039)] [G loss: -126.6228]\n",
      "1874 (5, 1) [D loss: (11.7758)(R -137.9382, F 149.6194, G 0.0095)] [G loss: -146.2648]\n",
      "1875 (5, 1) [D loss: (35.2351)(R -122.1335, F 157.3115, G 0.0057)] [G loss: -119.9445]\n",
      "1876 (5, 1) [D loss: (-28.2825)(R -144.4613, F 116.0887, G 0.0090)] [G loss: -129.9914]\n",
      "1877 (5, 1) [D loss: (13.5621)(R -155.7320, F 169.2190, G 0.0075)] [G loss: -132.5501]\n",
      "1878 (5, 1) [D loss: (24.4697)(R -101.9923, F 126.3572, G 0.0105)] [G loss: -103.0159]\n",
      "1879 (5, 1) [D loss: (-11.5718)(R -127.3223, F 115.6565, G 0.0094)] [G loss: -125.2556]\n",
      "1880 (5, 1) [D loss: (5.8957)(R -89.6005, F 95.4001, G 0.0096)] [G loss: -89.4044]\n",
      "1881 (5, 1) [D loss: (-17.6790)(R -107.8454, F 90.0831, G 0.0083)] [G loss: -101.4236]\n",
      "1882 (5, 1) [D loss: (-11.4076)(R -87.7112, F 76.2318, G 0.0072)] [G loss: -90.3215]\n",
      "1883 (5, 1) [D loss: (-1.1576)(R -111.2440, F 110.0322, G 0.0054)] [G loss: -127.9842]\n",
      "1884 (5, 1) [D loss: (-23.4757)(R -114.6548, F 91.1178, G 0.0061)] [G loss: -121.0144]\n",
      "1885 (5, 1) [D loss: (16.0946)(R -102.1413, F 118.2013, G 0.0035)] [G loss: -107.6247]\n",
      "1886 (5, 1) [D loss: (-24.1130)(R -134.8237, F 110.5886, G 0.0122)] [G loss: -122.1481]\n",
      "1887 (5, 1) [D loss: (-25.4308)(R -149.6504, F 124.1634, G 0.0056)] [G loss: -125.8830]\n",
      "1888 (5, 1) [D loss: (32.4706)(R -124.4545, F 156.8657, G 0.0059)] [G loss: -152.9501]\n",
      "1889 (5, 1) [D loss: (28.2620)(R -111.7301, F 139.9130, G 0.0079)] [G loss: -126.4752]\n",
      "1890 (5, 1) [D loss: (-13.2096)(R -135.9454, F 122.5996, G 0.0136)] [G loss: -126.7143]\n",
      "1891 (5, 1) [D loss: (-11.2308)(R -136.6638, F 125.2309, G 0.0202)] [G loss: -107.6280]\n",
      "1892 (5, 1) [D loss: (8.6172)(R -133.0041, F 141.1676, G 0.0454)] [G loss: -114.4337]\n",
      "1893 (5, 1) [D loss: (-20.0779)(R -176.9671, F 156.6007, G 0.0288)] [G loss: -186.4371]\n",
      "1894 (5, 1) [D loss: (-41.5997)(R -211.4050, F 169.6019, G 0.0203)] [G loss: -148.1701]\n",
      "1895 (5, 1) [D loss: (-11.9048)(R -162.6109, F 150.4516, G 0.0254)] [G loss: -138.2436]\n",
      "1896 (5, 1) [D loss: (39.3277)(R -139.6942, F 178.8626, G 0.0159)] [G loss: -200.1231]\n",
      "1897 (5, 1) [D loss: (-14.9570)(R -153.5104, F 138.3311, G 0.0222)] [G loss: -179.6472]\n",
      "1898 (5, 1) [D loss: (25.3959)(R -175.0693, F 200.4165, G 0.0049)] [G loss: -145.1882]\n",
      "1899 (5, 1) [D loss: (-27.3999)(R -180.9272, F 153.4814, G 0.0046)] [G loss: -211.1298]\n",
      "1900 (5, 1) [D loss: (-37.7292)(R -171.6297, F 133.8501, G 0.0050)] [G loss: -179.9495]\n",
      "1901 (5, 1) [D loss: (13.8695)(R -188.0690, F 201.7328, G 0.0206)] [G loss: -164.0658]\n",
      "1902 (5, 1) [D loss: (-10.8410)(R -207.2878, F 196.0034, G 0.0443)] [G loss: -183.6734]\n",
      "1903 (5, 1) [D loss: (-48.5734)(R -217.5130, F 168.8193, G 0.0120)] [G loss: -225.4582]\n",
      "1904 (5, 1) [D loss: (24.5159)(R -239.3901, F 263.7174, G 0.0189)] [G loss: -181.9577]\n",
      "1905 (5, 1) [D loss: (45.9476)(R -197.9821, F 243.6749, G 0.0255)] [G loss: -243.3714]\n",
      "1906 (5, 1) [D loss: (-35.9859)(R -269.5266, F 230.9856, G 0.2555)] [G loss: -224.9862]\n",
      "1907 (5, 1) [D loss: (-80.5538)(R -354.8589, F 273.7220, G 0.0583)] [G loss: -341.8478]\n",
      "1908 (5, 1) [D loss: (-72.5261)(R -399.9459, F 327.3104, G 0.0109)] [G loss: -333.8452]\n",
      "1909 (5, 1) [D loss: (1.8373)(R -322.7137, F 324.2437, G 0.0307)] [G loss: -368.0693]\n",
      "1910 (5, 1) [D loss: (15.0673)(R -321.2706, F 336.2422, G 0.0096)] [G loss: -316.4645]\n",
      "1911 (5, 1) [D loss: (-36.8945)(R -298.9266, F 261.9211, G 0.0111)] [G loss: -237.8177]\n",
      "1912 (5, 1) [D loss: (-21.6043)(R -351.9635, F 330.2932, G 0.0066)] [G loss: -299.8546]\n",
      "1913 (5, 1) [D loss: (-77.7230)(R -426.4513, F 348.5819, G 0.0146)] [G loss: -384.0858]\n",
      "1914 (5, 1) [D loss: (-120.7456)(R -441.0552, F 319.6308, G 0.0679)] [G loss: -347.8397]\n",
      "1915 (5, 1) [D loss: (79.3297)(R -334.5896, F 413.7209, G 0.0198)] [G loss: -334.0771]\n",
      "1916 (5, 1) [D loss: (34.6019)(R -274.5589, F 303.5170, G 0.5644)] [G loss: -285.2167]\n",
      "1917 (5, 1) [D loss: (4.4841)(R -277.2973, F 281.6072, G 0.0174)] [G loss: -304.9843]\n",
      "1918 (5, 1) [D loss: (18.4153)(R -281.2081, F 299.5745, G 0.0049)] [G loss: -267.7872]\n",
      "1919 (5, 1) [D loss: (-64.9035)(R -325.2833, F 260.3038, G 0.0076)] [G loss: -273.4013]\n",
      "1920 (5, 1) [D loss: (114.3805)(R -315.9042, F 429.8335, G 0.0451)] [G loss: -301.4816]\n",
      "1921 (5, 1) [D loss: (-27.6673)(R -328.5418, F 300.8223, G 0.0052)] [G loss: -279.7587]\n",
      "1922 (5, 1) [D loss: (20.1190)(R -264.7697, F 284.7861, G 0.0103)] [G loss: -294.3022]\n",
      "1923 (5, 1) [D loss: (-19.1207)(R -277.7637, F 258.4736, G 0.0169)] [G loss: -226.1954]\n",
      "1924 (5, 1) [D loss: (-21.5904)(R -296.3663, F 274.4033, G 0.0373)] [G loss: -326.9025]\n",
      "1925 (5, 1) [D loss: (-23.9052)(R -359.4279, F 334.6929, G 0.0830)] [G loss: -392.7542]\n",
      "1926 (5, 1) [D loss: (-46.7335)(R -419.6779, F 372.8473, G 0.0097)] [G loss: -363.2109]\n",
      "1927 (5, 1) [D loss: (-68.1885)(R -309.9391, F 238.1161, G 0.3634)] [G loss: -342.1204]\n",
      "1928 (5, 1) [D loss: (-31.5932)(R -325.5445, F 293.4756, G 0.0476)] [G loss: -313.6533]\n",
      "1929 (5, 1) [D loss: (-25.3481)(R -358.8192, F 333.4105, G 0.0061)] [G loss: -346.4579]\n",
      "1930 (5, 1) [D loss: (-79.8521)(R -335.3358, F 254.8237, G 0.0660)] [G loss: -325.7590]\n",
      "1931 (5, 1) [D loss: (9.7307)(R -355.7293, F 365.4003, G 0.0060)] [G loss: -313.9112]\n",
      "1932 (5, 1) [D loss: (-41.4069)(R -269.0875, F 226.4265, G 0.1254)] [G loss: -232.0427]\n",
      "1933 (5, 1) [D loss: (1.2403)(R -314.2781, F 315.4181, G 0.0100)] [G loss: -320.5233]\n",
      "1934 (5, 1) [D loss: (-40.3963)(R -340.2256, F 299.6154, G 0.0214)] [G loss: -289.5879]\n",
      "1935 (5, 1) [D loss: (2.3226)(R -309.3640, F 311.5915, G 0.0095)] [G loss: -276.6207]\n",
      "1936 (5, 1) [D loss: (73.6905)(R -252.6163, F 326.1396, G 0.0167)] [G loss: -199.2296]\n",
      "1937 (5, 1) [D loss: (-8.1647)(R -280.6121, F 272.3896, G 0.0058)] [G loss: -276.6385]\n",
      "1938 (5, 1) [D loss: (-33.1445)(R -255.9990, F 222.6548, G 0.0200)] [G loss: -251.5954]\n",
      "1939 (5, 1) [D loss: (-7.6034)(R -263.2061, F 255.3074, G 0.0295)] [G loss: -215.4265]\n",
      "1940 (5, 1) [D loss: (52.4925)(R -203.7064, F 256.0034, G 0.0195)] [G loss: -227.8257]\n",
      "1941 (5, 1) [D loss: (-32.4565)(R -209.7722, F 177.0652, G 0.0251)] [G loss: -215.7755]\n",
      "1942 (5, 1) [D loss: (35.9944)(R -138.0448, F 173.5388, G 0.0500)] [G loss: -166.1599]\n",
      "1943 (5, 1) [D loss: (23.5680)(R -129.8635, F 153.3996, G 0.0032)] [G loss: -162.7485]\n",
      "1944 (5, 1) [D loss: (2.5419)(R -149.8939, F 152.0688, G 0.0367)] [G loss: -139.1825]\n",
      "1945 (5, 1) [D loss: (40.4791)(R -71.2641, F 111.6529, G 0.0090)] [G loss: -127.3768]\n",
      "1946 (5, 1) [D loss: (-20.4341)(R -131.4881, F 110.9723, G 0.0082)] [G loss: -120.6504]\n",
      "1947 (5, 1) [D loss: (39.5964)(R -94.6808, F 133.4341, G 0.0843)] [G loss: -66.4378]\n",
      "1948 (5, 1) [D loss: (-3.9633)(R -80.9746, F 76.8957, G 0.0116)] [G loss: -84.8818]\n",
      "1949 (5, 1) [D loss: (-25.8998)(R -123.6583, F 97.6461, G 0.0112)] [G loss: -134.0932]\n",
      "1950 (5, 1) [D loss: (9.9016)(R -102.3492, F 112.1508, G 0.0100)] [G loss: -118.8387]\n",
      "1951 (5, 1) [D loss: (-2.0482)(R -116.6396, F 114.5399, G 0.0051)] [G loss: -125.1280]\n",
      "1952 (5, 1) [D loss: (17.8738)(R -82.1897, F 100.0213, G 0.0042)] [G loss: -80.8741]\n",
      "1953 (5, 1) [D loss: (-12.4632)(R -136.0721, F 123.5660, G 0.0043)] [G loss: -136.8948]\n",
      "1954 (5, 1) [D loss: (6.2660)(R -132.4161, F 138.5547, G 0.0127)] [G loss: -172.3202]\n",
      "1955 (5, 1) [D loss: (-4.1052)(R -123.5694, F 119.4051, G 0.0059)] [G loss: -62.6907]\n",
      "1956 (5, 1) [D loss: (-39.7055)(R -158.3717, F 118.4336, G 0.0233)] [G loss: -118.0086]\n",
      "1957 (5, 1) [D loss: (-9.8476)(R -115.4128, F 105.5198, G 0.0045)] [G loss: -123.9949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958 (5, 1) [D loss: (-1.0521)(R -140.5334, F 139.4060, G 0.0075)] [G loss: -98.7682]\n",
      "1959 (5, 1) [D loss: (-14.9257)(R -93.4802, F 78.4449, G 0.0110)] [G loss: -87.9324]\n",
      "1960 (5, 1) [D loss: (46.4900)(R -105.2288, F 151.4534, G 0.0265)] [G loss: -119.8292]\n",
      "1961 (5, 1) [D loss: (-43.6538)(R -106.6746, F 62.8179, G 0.0203)] [G loss: -96.8296]\n",
      "1962 (5, 1) [D loss: (-8.1550)(R -118.1629, F 109.8730, G 0.0135)] [G loss: -92.5625]\n",
      "1963 (5, 1) [D loss: (-29.3717)(R -90.3856, F 60.9318, G 0.0082)] [G loss: -117.9338]\n",
      "1964 (5, 1) [D loss: (-9.6263)(R -148.3184, F 138.5521, G 0.0140)] [G loss: -125.8469]\n",
      "1965 (5, 1) [D loss: (4.5673)(R -125.3464, F 129.8684, G 0.0045)] [G loss: -110.3634]\n",
      "1966 (5, 1) [D loss: (71.5710)(R -36.3555, F 107.8818, G 0.0045)] [G loss: -84.7157]\n",
      "1967 (5, 1) [D loss: (7.4624)(R -97.0905, F 104.4581, G 0.0095)] [G loss: -97.7451]\n",
      "1968 (5, 1) [D loss: (43.1528)(R -74.3880, F 117.4995, G 0.0041)] [G loss: -85.2715]\n",
      "1969 (5, 1) [D loss: (4.7480)(R -89.7798, F 94.5002, G 0.0028)] [G loss: -84.8008]\n",
      "1970 (5, 1) [D loss: (27.3312)(R -113.5328, F 140.7501, G 0.0114)] [G loss: -94.8854]\n",
      "1971 (5, 1) [D loss: (-19.3008)(R -127.1362, F 107.7793, G 0.0056)] [G loss: -133.7464]\n",
      "1972 (5, 1) [D loss: (-18.8575)(R -166.2099, F 147.2957, G 0.0057)] [G loss: -137.4654]\n",
      "1973 (5, 1) [D loss: (16.9295)(R -88.7966, F 105.5459, G 0.0180)] [G loss: -103.3259]\n",
      "1974 (5, 1) [D loss: (1.2834)(R -92.3808, F 93.5423, G 0.0122)] [G loss: -114.8307]\n",
      "1975 (5, 1) [D loss: (10.6039)(R -86.3585, F 96.9201, G 0.0042)] [G loss: -50.7369]\n",
      "1976 (5, 1) [D loss: (-25.6556)(R -145.8363, F 120.1062, G 0.0075)] [G loss: -151.7322]\n",
      "1977 (5, 1) [D loss: (-10.6011)(R -135.6760, F 125.0258, G 0.0049)] [G loss: -118.4178]\n",
      "1978 (5, 1) [D loss: (-25.9775)(R -142.5820, F 116.5513, G 0.0053)] [G loss: -93.8908]\n",
      "1979 (5, 1) [D loss: (3.3292)(R -178.5505, F 181.7930, G 0.0087)] [G loss: -125.8926]\n",
      "1980 (5, 1) [D loss: (5.9753)(R -111.7650, F 116.4712, G 0.1269)] [G loss: -88.6517]\n",
      "1981 (5, 1) [D loss: (26.6458)(R -76.7545, F 103.3382, G 0.0062)] [G loss: -105.6453]\n",
      "1982 (5, 1) [D loss: (8.7510)(R -73.9539, F 82.5462, G 0.0159)] [G loss: -120.7965]\n",
      "1983 (5, 1) [D loss: (2.9655)(R -112.3246, F 115.0788, G 0.0211)] [G loss: -81.0762]\n",
      "1984 (5, 1) [D loss: (-56.9066)(R -112.4181, F 55.2758, G 0.0236)] [G loss: -82.8804]\n",
      "1985 (5, 1) [D loss: (12.1240)(R -84.2506, F 96.3011, G 0.0073)] [G loss: -39.6745]\n",
      "1986 (5, 1) [D loss: (-4.9113)(R -67.6018, F 62.6524, G 0.0038)] [G loss: -49.4499]\n",
      "1987 (5, 1) [D loss: (24.9405)(R -59.4663, F 84.2816, G 0.0125)] [G loss: -78.0717]\n",
      "1988 (5, 1) [D loss: (19.1666)(R -41.2984, F 60.4261, G 0.0039)] [G loss: -49.7309]\n",
      "1989 (5, 1) [D loss: (14.9726)(R -55.4224, F 70.3483, G 0.0047)] [G loss: -53.3325]\n",
      "1990 (5, 1) [D loss: (4.9946)(R -62.0635, F 67.0133, G 0.0045)] [G loss: -50.6811]\n",
      "1991 (5, 1) [D loss: (7.4493)(R -41.1102, F 48.5001, G 0.0059)] [G loss: -48.8175]\n",
      "1992 (5, 1) [D loss: (2.9409)(R -29.2304, F 31.8942, G 0.0277)] [G loss: -23.5569]\n",
      "1993 (5, 1) [D loss: (-10.7586)(R -15.4054, F 4.2307, G 0.0416)] [G loss: -6.3760]\n",
      "1994 (5, 1) [D loss: (-4.4937)(R -13.8100, F 9.0076, G 0.0309)] [G loss: -12.0839]\n",
      "1995 (5, 1) [D loss: (-0.8508)(R -27.3298, F 26.2310, G 0.0248)] [G loss: -18.2089]\n",
      "1996 (5, 1) [D loss: (1.7509)(R -12.2802, F 13.7238, G 0.0307)] [G loss: -14.7934]\n",
      "1997 (5, 1) [D loss: (-8.1472)(R -13.6430, F 5.1996, G 0.0296)] [G loss: -14.1817]\n",
      "1998 (5, 1) [D loss: (-3.1541)(R -19.3290, F 15.9556, G 0.0219)] [G loss: -21.1798]\n",
      "1999 (5, 1) [D loss: (6.3641)(R -19.9738, F 26.0321, G 0.0306)] [G loss: -23.6728]\n",
      "2000 (5, 1) [D loss: (-3.5839)(R -25.6713, F 22.0391, G 0.0048)] [G loss: -22.5380]\n",
      "2001 (5, 1) [D loss: (5.8953)(R -36.3502, F 40.6180, G 0.1627)] [G loss: -35.2832]\n",
      "2002 (5, 1) [D loss: (-14.6226)(R -26.2690, F 11.2974, G 0.0349)] [G loss: -22.0446]\n",
      "2003 (5, 1) [D loss: (-15.2807)(R -24.6894, F 9.3606, G 0.0048)] [G loss: -14.6489]\n",
      "2004 (5, 1) [D loss: (16.2970)(R -10.0144, F 26.1674, G 0.0144)] [G loss: -6.5581]\n",
      "2005 (5, 1) [D loss: (1.2471)(R -16.8821, F 18.0133, G 0.0116)] [G loss: -12.2372]\n",
      "2006 (5, 1) [D loss: (-22.0078)(R -32.5053, F 10.4695, G 0.0028)] [G loss: -2.4975]\n",
      "2007 (5, 1) [D loss: (-2.8829)(R -15.7201, F 12.8071, G 0.0030)] [G loss: -13.7179]\n",
      "2008 (5, 1) [D loss: (-10.4134)(R -16.4976, F 6.0373, G 0.0047)] [G loss: -9.0570]\n",
      "2009 (5, 1) [D loss: (-17.8681)(R -43.9228, F 25.9109, G 0.0144)] [G loss: -35.7444]\n",
      "2010 (5, 1) [D loss: (8.6594)(R -24.4582, F 32.7785, G 0.0339)] [G loss: -33.3932]\n",
      "2011 (5, 1) [D loss: (-7.2347)(R -36.6787, F 29.2572, G 0.0187)] [G loss: -36.0222]\n",
      "2012 (5, 1) [D loss: (38.0512)(R -27.8766, F 65.7612, G 0.0167)] [G loss: -29.1988]\n",
      "2013 (5, 1) [D loss: (16.8941)(R -32.1932, F 49.0239, G 0.0063)] [G loss: -31.4227]\n",
      "2014 (5, 1) [D loss: (-8.4182)(R -36.9141, F 28.3388, G 0.0157)] [G loss: -36.6965]\n",
      "2015 (5, 1) [D loss: (-15.9047)(R -42.9633, F 27.0206, G 0.0038)] [G loss: -27.2809]\n",
      "2016 (5, 1) [D loss: (-5.5223)(R -7.9285, F 2.3727, G 0.0033)] [G loss: -27.5172]\n",
      "2017 (5, 1) [D loss: (36.6882)(R -13.0110, F 49.6764, G 0.0023)] [G loss: -23.6861]\n",
      "2018 (5, 1) [D loss: (2.4005)(R -21.4996, F 23.7147, G 0.0185)] [G loss: -14.0526]\n",
      "2019 (5, 1) [D loss: (0.6698)(R -19.5345, F 19.3308, G 0.0874)] [G loss: -7.3320]\n",
      "2020 (5, 1) [D loss: (-4.4699)(R -11.5362, F 6.8625, G 0.0204)] [G loss: -34.6048]\n",
      "2021 (5, 1) [D loss: (17.3268)(R -49.1911, F 66.1695, G 0.0348)] [G loss: -17.9084]\n",
      "2022 (5, 1) [D loss: (3.9986)(R -12.1617, F 16.0456, G 0.0115)] [G loss: 0.8151]\n",
      "2023 (5, 1) [D loss: (22.3335)(R -26.7715, F 49.0506, G 0.0054)] [G loss: -45.0903]\n",
      "2024 (5, 1) [D loss: (-2.7847)(R -45.7091, F 42.8764, G 0.0048)] [G loss: -44.0484]\n",
      "2025 (5, 1) [D loss: (1.6706)(R -34.8778, F 36.4442, G 0.0104)] [G loss: -41.8363]\n",
      "2026 (5, 1) [D loss: (14.5648)(R -75.0144, F 89.1869, G 0.0392)] [G loss: -77.0579]\n",
      "2027 (5, 1) [D loss: (17.9188)(R -72.4624, F 89.7900, G 0.0591)] [G loss: -63.9630]\n",
      "2028 (5, 1) [D loss: (15.6381)(R -65.8341, F 81.3987, G 0.0074)] [G loss: -120.9702]\n",
      "2029 (5, 1) [D loss: (28.7142)(R -47.6571, F 76.1827, G 0.0189)] [G loss: -90.6500]\n",
      "2030 (5, 1) [D loss: (6.6899)(R -65.8247, F 72.4110, G 0.0104)] [G loss: -51.5415]\n",
      "2031 (5, 1) [D loss: (-13.9634)(R -62.2542, F 48.1544, G 0.0136)] [G loss: -42.3442]\n",
      "2032 (5, 1) [D loss: (-10.1474)(R -81.6142, F 71.3808, G 0.0086)] [G loss: -78.1546]\n",
      "2033 (5, 1) [D loss: (1.5507)(R -52.1680, F 53.5866, G 0.0132)] [G loss: -52.3754]\n",
      "2034 (5, 1) [D loss: (-5.8031)(R -60.1647, F 54.2826, G 0.0079)] [G loss: -58.2606]\n",
      "2035 (5, 1) [D loss: (16.2250)(R -56.6835, F 72.8425, G 0.0066)] [G loss: -61.1875]\n",
      "2036 (5, 1) [D loss: (-24.2515)(R -61.5701, F 37.1779, G 0.0141)] [G loss: -76.8172]\n",
      "2037 (5, 1) [D loss: (-26.6299)(R -71.9181, F 44.9137, G 0.0375)] [G loss: -55.4470]\n",
      "2038 (5, 1) [D loss: (-57.6565)(R -98.2691, F 40.1275, G 0.0485)] [G loss: -74.5018]\n",
      "2039 (5, 1) [D loss: (9.9832)(R -79.1390, F 88.9786, G 0.0144)] [G loss: -80.7095]\n",
      "2040 (5, 1) [D loss: (-25.0504)(R -114.9137, F 89.4425, G 0.0421)] [G loss: -97.8770]\n",
      "2041 (5, 1) [D loss: (-42.9637)(R -103.4202, F 60.4050, G 0.0052)] [G loss: -83.1157]\n",
      "2042 (5, 1) [D loss: (-26.0427)(R -124.3433, F 96.1521, G 0.2148)] [G loss: -96.6722]\n",
      "2043 (5, 1) [D loss: (-56.6636)(R -102.8132, F 46.0926, G 0.0057)] [G loss: -69.5605]\n",
      "2044 (5, 1) [D loss: (46.9659)(R -77.9634, F 124.8398, G 0.0089)] [G loss: -85.2092]\n",
      "2045 (5, 1) [D loss: (-3.8405)(R -82.9741, F 79.0854, G 0.0048)] [G loss: -92.4459]\n",
      "2046 (5, 1) [D loss: (-9.8241)(R -53.8148, F 43.8550, G 0.0136)] [G loss: -34.5503]\n",
      "2047 (5, 1) [D loss: (21.4682)(R -65.2663, F 86.6005, G 0.0134)] [G loss: -21.1422]\n",
      "2048 (5, 1) [D loss: (-26.6469)(R -67.3229, F 40.5359, G 0.0140)] [G loss: -63.9014]\n",
      "2049 (5, 1) [D loss: (20.4710)(R -78.3150, F 98.6111, G 0.0175)] [G loss: -98.0871]\n",
      "2050 (5, 1) [D loss: (49.3039)(R -55.2762, F 104.0769, G 0.0503)] [G loss: -89.0299]\n",
      "2051 (5, 1) [D loss: (51.5119)(R -18.2092, F 69.6258, G 0.0095)] [G loss: -58.2666]\n",
      "2052 (5, 1) [D loss: (-29.7631)(R -111.7252, F 81.3795, G 0.0583)] [G loss: -86.2751]\n",
      "2053 (5, 1) [D loss: (-43.7277)(R -108.8216, F 64.9145, G 0.0179)] [G loss: -94.9481]\n",
      "2054 (5, 1) [D loss: (-8.1584)(R -179.5027, F 171.1026, G 0.0242)] [G loss: -117.0696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055 (5, 1) [D loss: (-24.9929)(R -112.7576, F 87.4997, G 0.0265)] [G loss: -40.2259]\n",
      "2056 (5, 1) [D loss: (23.3284)(R -32.1574, F 55.0663, G 0.0420)] [G loss: -6.7742]\n",
      "2057 (5, 1) [D loss: (20.5997)(R -28.1696, F 48.6650, G 0.0104)] [G loss: -44.2783]\n",
      "2058 (5, 1) [D loss: (2.9718)(R -57.3478, F 60.1294, G 0.0190)] [G loss: -28.4775]\n",
      "2059 (5, 1) [D loss: (-2.2850)(R -38.1810, F 35.7825, G 0.0114)] [G loss: -42.6021]\n",
      "2060 (5, 1) [D loss: (100.5802)(R 58.1291, F 42.4177, G 0.0033)] [G loss: -51.2971]\n",
      "2061 (5, 1) [D loss: (-39.2442)(R -38.2224, F -1.0892, G 0.0067)] [G loss: -25.1509]\n",
      "2062 (5, 1) [D loss: (61.6794)(R -9.9130, F 71.3251, G 0.0267)] [G loss: -42.8668]\n",
      "2063 (5, 1) [D loss: (-25.4741)(R -23.3483, F -2.1761, G 0.0050)] [G loss: -36.8099]\n",
      "2064 (5, 1) [D loss: (0.9797)(R -29.4736, F 30.3796, G 0.0074)] [G loss: -69.7053]\n",
      "2065 (5, 1) [D loss: (18.8994)(R -13.6527, F 32.4867, G 0.0065)] [G loss: -61.5588]\n",
      "2066 (5, 1) [D loss: (25.4305)(R -71.6987, F 97.0752, G 0.0054)] [G loss: -70.1082]\n",
      "2067 (5, 1) [D loss: (10.5028)(R -21.0286, F 31.4888, G 0.0043)] [G loss: -44.4495]\n",
      "2068 (5, 1) [D loss: (-0.5227)(R -43.0653, F 42.2898, G 0.0253)] [G loss: -14.5469]\n",
      "2069 (5, 1) [D loss: (-26.7499)(R -31.7001, F 4.8781, G 0.0072)] [G loss: -26.7726]\n",
      "2070 (5, 1) [D loss: (12.5365)(R -37.6733, F 50.1558, G 0.0054)] [G loss: -23.5528]\n",
      "2071 (5, 1) [D loss: (-14.3982)(R -50.6272, F 36.1200, G 0.0109)] [G loss: -74.9344]\n",
      "2072 (5, 1) [D loss: (38.3823)(R -31.4733, F 69.7411, G 0.0115)] [G loss: 2.6742]\n",
      "2073 (5, 1) [D loss: (-35.1939)(R -39.9942, F 4.7120, G 0.0088)] [G loss: -85.0405]\n",
      "2074 (5, 1) [D loss: (1.4087)(R -55.1933, F 56.5380, G 0.0064)] [G loss: -46.8283]\n",
      "2075 (5, 1) [D loss: (-2.1541)(R -50.2545, F 47.8944, G 0.0206)] [G loss: -40.5602]\n",
      "2076 (5, 1) [D loss: (18.3255)(R -52.1214, F 70.0738, G 0.0373)] [G loss: -34.5506]\n",
      "2077 (5, 1) [D loss: (-30.1855)(R -70.9805, F 40.7489, G 0.0046)] [G loss: -50.5202]\n",
      "2078 (5, 1) [D loss: (-5.8034)(R -62.9604, F 57.1195, G 0.0038)] [G loss: -43.7674]\n",
      "2079 (5, 1) [D loss: (-6.9752)(R -54.0941, F 47.0462, G 0.0073)] [G loss: -56.4323]\n",
      "2080 (5, 1) [D loss: (-12.8617)(R -56.8927, F 43.6563, G 0.0375)] [G loss: -50.1468]\n",
      "2081 (5, 1) [D loss: (-31.5845)(R -69.0179, F 37.2827, G 0.0151)] [G loss: -63.6682]\n",
      "2082 (5, 1) [D loss: (-9.4245)(R -74.5132, F 64.9742, G 0.0114)] [G loss: -76.7750]\n",
      "2083 (5, 1) [D loss: (44.3342)(R -38.6705, F 82.8066, G 0.0198)] [G loss: -54.6598]\n",
      "2084 (5, 1) [D loss: (19.6539)(R -55.9896, F 75.5885, G 0.0055)] [G loss: -75.1820]\n",
      "2085 (5, 1) [D loss: (-12.0844)(R -57.3399, F 45.2052, G 0.0050)] [G loss: -53.1745]\n",
      "2086 (5, 1) [D loss: (-24.7786)(R -89.7432, F 64.8947, G 0.0070)] [G loss: -48.3980]\n",
      "2087 (5, 1) [D loss: (66.4422)(R -51.1776, F 117.4372, G 0.0183)] [G loss: -56.5968]\n",
      "2088 (5, 1) [D loss: (16.2677)(R -40.4066, F 56.3934, G 0.0281)] [G loss: -47.6137]\n",
      "2089 (5, 1) [D loss: (-16.9695)(R -35.2011, F 17.9150, G 0.0317)] [G loss: -41.1733]\n",
      "2090 (5, 1) [D loss: (-5.3688)(R -53.1215, F 47.4158, G 0.0337)] [G loss: -51.0443]\n",
      "2091 (5, 1) [D loss: (23.3084)(R -24.6605, F 47.9383, G 0.0031)] [G loss: -14.5148]\n",
      "2092 (5, 1) [D loss: (6.5068)(R -28.7769, F 35.2258, G 0.0058)] [G loss: -23.5073]\n",
      "2093 (5, 1) [D loss: (5.4423)(R -33.0538, F 38.3868, G 0.0109)] [G loss: -6.9768]\n",
      "2094 (5, 1) [D loss: (-14.2418)(R -39.5190, F 25.1904, G 0.0087)] [G loss: -37.7326]\n",
      "2095 (5, 1) [D loss: (14.8873)(R -11.4860, F 26.2519, G 0.0121)] [G loss: -27.5251]\n",
      "2096 (5, 1) [D loss: (-4.1756)(R -24.8924, F 20.4395, G 0.0277)] [G loss: -35.7572]\n",
      "2097 (5, 1) [D loss: (16.7938)(R -38.2255, F 54.8864, G 0.0133)] [G loss: -35.4893]\n",
      "2098 (5, 1) [D loss: (3.2681)(R -19.1605, F 22.2884, G 0.0140)] [G loss: -23.2535]\n",
      "2099 (5, 1) [D loss: (-2.4091)(R -39.4887, F 36.9724, G 0.0107)] [G loss: -39.5369]\n",
      "2100 (5, 1) [D loss: (-8.3245)(R -39.5110, F 31.0892, G 0.0097)] [G loss: -26.5163]\n",
      "2101 (5, 1) [D loss: (11.9751)(R -34.4302, F 46.1127, G 0.0293)] [G loss: -32.1580]\n",
      "2102 (5, 1) [D loss: (6.8735)(R -23.9252, F 30.7528, G 0.0046)] [G loss: -48.4429]\n",
      "2103 (5, 1) [D loss: (10.6373)(R -33.1784, F 43.7695, G 0.0046)] [G loss: -40.7331]\n",
      "2104 (5, 1) [D loss: (-3.0883)(R -29.0387, F 25.8903, G 0.0060)] [G loss: -29.4389]\n",
      "2105 (5, 1) [D loss: (21.3737)(R -30.8357, F 52.0664, G 0.0143)] [G loss: -40.7460]\n",
      "2106 (5, 1) [D loss: (7.1875)(R -29.6186, F 36.6850, G 0.0121)] [G loss: -30.0153]\n",
      "2107 (5, 1) [D loss: (13.8786)(R -21.7617, F 35.5663, G 0.0074)] [G loss: -27.2824]\n",
      "2108 (5, 1) [D loss: (-19.5884)(R -35.7823, F 16.0228, G 0.0171)] [G loss: -28.8158]\n",
      "2109 (5, 1) [D loss: (-2.0141)(R -25.8720, F 23.6996, G 0.0158)] [G loss: -21.1865]\n",
      "2110 (5, 1) [D loss: (1.5944)(R -33.9186, F 35.3940, G 0.0119)] [G loss: -27.3875]\n",
      "2111 (5, 1) [D loss: (-8.4148)(R -38.6644, F 29.7923, G 0.0457)] [G loss: -30.0560]\n",
      "2112 (5, 1) [D loss: (1.4090)(R -37.1376, F 38.4571, G 0.0090)] [G loss: -28.9340]\n",
      "2113 (5, 1) [D loss: (13.0811)(R -6.8650, F 19.8228, G 0.0123)] [G loss: -14.3708]\n",
      "2114 (5, 1) [D loss: (-3.2172)(R -3.5149, F 0.0446, G 0.0253)] [G loss: 2.2771]\n",
      "2115 (5, 1) [D loss: (-1.6844)(R -9.5246, F 7.4612, G 0.0379)] [G loss: -16.5935]\n",
      "2116 (5, 1) [D loss: (-3.6629)(R -21.2874, F 17.3590, G 0.0266)] [G loss: -22.6070]\n",
      "2117 (5, 1) [D loss: (20.3293)(R -8.8579, F 28.9507, G 0.0236)] [G loss: -14.3419]\n",
      "2118 (5, 1) [D loss: (-6.3802)(R -28.5720, F 21.9313, G 0.0260)] [G loss: -13.5326]\n",
      "2119 (5, 1) [D loss: (-2.5608)(R -27.7257, F 25.0535, G 0.0111)] [G loss: -37.3639]\n",
      "2120 (5, 1) [D loss: (9.6079)(R -39.2780, F 48.7686, G 0.0117)] [G loss: -42.4346]\n",
      "2121 (5, 1) [D loss: (18.9139)(R -14.5524, F 33.2400, G 0.0226)] [G loss: -19.3036]\n",
      "2122 (5, 1) [D loss: (3.0108)(R -18.2154, F 20.8910, G 0.0335)] [G loss: -24.6521]\n",
      "2123 (5, 1) [D loss: (15.8158)(R -43.2680, F 58.1635, G 0.0920)] [G loss: -15.8657]\n",
      "2124 (5, 1) [D loss: (-14.1365)(R -32.7350, F 18.3432, G 0.0255)] [G loss: -28.5111]\n",
      "2125 (5, 1) [D loss: (-24.6898)(R -54.8569, F 29.6846, G 0.0483)] [G loss: -47.3825]\n",
      "2126 (5, 1) [D loss: (-6.1365)(R -46.6216, F 40.3659, G 0.0119)] [G loss: -55.9926]\n",
      "2127 (5, 1) [D loss: (12.1705)(R -35.6161, F 47.7121, G 0.0075)] [G loss: -65.8465]\n",
      "2128 (5, 1) [D loss: (-2.3424)(R -35.6601, F 33.2188, G 0.0099)] [G loss: -37.2248]\n",
      "2129 (5, 1) [D loss: (-15.3328)(R -25.3332, F 9.9084, G 0.0092)] [G loss: -30.7233]\n",
      "2130 (5, 1) [D loss: (-14.1408)(R -14.8109, F 0.6041, G 0.0066)] [G loss: -37.4457]\n",
      "2131 (5, 1) [D loss: (-14.5695)(R -15.0140, F 0.3773, G 0.0067)] [G loss: -6.5811]\n",
      "2132 (5, 1) [D loss: (9.2808)(R -8.5481, F 17.7434, G 0.0086)] [G loss: -20.2459]\n",
      "2133 (5, 1) [D loss: (-9.7827)(R -28.3282, F 18.4557, G 0.0090)] [G loss: -34.0993]\n",
      "2134 (5, 1) [D loss: (-10.3592)(R -14.9390, F 4.4710, G 0.0109)] [G loss: -3.1950]\n",
      "2135 (5, 1) [D loss: (0.5402)(R -8.2705, F 8.7246, G 0.0086)] [G loss: -4.5087]\n",
      "2136 (5, 1) [D loss: (-4.2774)(R -14.5150, F 10.2145, G 0.0023)] [G loss: 17.0291]\n",
      "2137 (5, 1) [D loss: (-1.9611)(R -4.6127, F 2.6036, G 0.0048)] [G loss: 1.2849]\n",
      "2138 (5, 1) [D loss: (-3.2528)(R -3.1899, F -0.2221, G 0.0159)] [G loss: 0.9040]\n",
      "2139 (5, 1) [D loss: (-6.9862)(R 9.6945, F -16.7350, G 0.0054)] [G loss: 8.6140]\n",
      "2140 (5, 1) [D loss: (-1.3699)(R -12.4990, F 10.6098, G 0.0519)] [G loss: -5.4797]\n",
      "2141 (5, 1) [D loss: (31.9761)(R 9.4863, F 21.7470, G 0.0743)] [G loss: 2.0113]\n",
      "2142 (5, 1) [D loss: (11.2273)(R -4.8468, F 16.0282, G 0.0046)] [G loss: -0.9738]\n",
      "2143 (5, 1) [D loss: (11.5671)(R 12.1533, F -0.6759, G 0.0090)] [G loss: -2.9960]\n",
      "2144 (5, 1) [D loss: (-7.8233)(R 7.6110, F -15.4832, G 0.0049)] [G loss: 17.1784]\n",
      "2145 (5, 1) [D loss: (-2.1275)(R 30.3839, F -33.0880, G 0.0577)] [G loss: 30.1532]\n",
      "2146 (5, 1) [D loss: (-12.6165)(R 7.1007, F -19.8528, G 0.0136)] [G loss: 13.5341]\n",
      "2147 (5, 1) [D loss: (-18.1637)(R 15.2279, F -34.0555, G 0.0664)] [G loss: 26.6414]\n",
      "2148 (5, 1) [D loss: (-5.2612)(R 5.7083, F -11.1462, G 0.0177)] [G loss: 21.6319]\n",
      "2149 (5, 1) [D loss: (-4.1863)(R 0.3816, F -4.6518, G 0.0084)] [G loss: -5.8203]\n",
      "2150 (5, 1) [D loss: (-9.3143)(R -14.4501, F 5.0559, G 0.0080)] [G loss: 7.8106]\n",
      "2151 (5, 1) [D loss: (-8.8464)(R -14.9921, F 6.0526, G 0.0093)] [G loss: 15.6629]\n",
      "2152 (5, 1) [D loss: (-3.5401)(R -11.8067, F 8.1491, G 0.0117)] [G loss: -6.7571]\n",
      "2153 (5, 1) [D loss: (-3.1591)(R -8.0096, F 4.2048, G 0.0646)] [G loss: -2.1286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2154 (5, 1) [D loss: (-1.3838)(R -8.1563, F 6.6027, G 0.0170)] [G loss: 11.1147]\n",
      "2155 (5, 1) [D loss: (15.7643)(R -0.6752, F 16.2263, G 0.0213)] [G loss: 4.5802]\n",
      "2156 (5, 1) [D loss: (-17.4201)(R -12.0025, F -5.4719, G 0.0054)] [G loss: 1.9102]\n",
      "2157 (5, 1) [D loss: (8.5093)(R 0.2657, F 8.2151, G 0.0028)] [G loss: 6.9255]\n",
      "2158 (5, 1) [D loss: (12.5570)(R 17.1094, F -4.5835, G 0.0031)] [G loss: -13.5022]\n",
      "2159 (5, 1) [D loss: (15.3158)(R -0.5415, F 15.7570, G 0.0100)] [G loss: -24.6337]\n",
      "2160 (5, 1) [D loss: (26.1352)(R 8.2520, F 17.7539, G 0.0129)] [G loss: -5.5940]\n",
      "2161 (5, 1) [D loss: (-1.8335)(R -13.0185, F 11.0658, G 0.0119)] [G loss: -13.3768]\n",
      "2162 (5, 1) [D loss: (11.7016)(R 10.9372, F 0.6752, G 0.0089)] [G loss: 0.7692]\n",
      "2163 (5, 1) [D loss: (-6.3308)(R -14.3191, F 7.8010, G 0.0187)] [G loss: -9.2976]\n",
      "2164 (5, 1) [D loss: (-13.6795)(R -15.5717, F 1.8315, G 0.0061)] [G loss: -6.9941]\n",
      "2165 (5, 1) [D loss: (8.8841)(R -12.9845, F 21.8312, G 0.0037)] [G loss: 5.4316]\n",
      "2166 (5, 1) [D loss: (-14.2113)(R -8.9388, F -5.3055, G 0.0033)] [G loss: -15.5380]\n",
      "2167 (5, 1) [D loss: (29.8994)(R 12.3928, F 17.4556, G 0.0051)] [G loss: -7.7155]\n",
      "2168 (5, 1) [D loss: (-11.8295)(R 9.1735, F -21.0563, G 0.0053)] [G loss: 9.5926]\n",
      "2169 (5, 1) [D loss: (10.4072)(R 36.3821, F -26.0056, G 0.0031)] [G loss: 23.5678]\n",
      "2170 (5, 1) [D loss: (-13.7905)(R 10.1786, F -24.0038, G 0.0035)] [G loss: 13.6827]\n",
      "2171 (5, 1) [D loss: (24.2244)(R 35.4181, F -11.2264, G 0.0033)] [G loss: 39.0631]\n",
      "2172 (5, 1) [D loss: (18.5434)(R 34.1089, F -15.5984, G 0.0033)] [G loss: 32.0931]\n",
      "2173 (5, 1) [D loss: (-4.7655)(R 6.6681, F -11.5775, G 0.0144)] [G loss: -1.4240]\n",
      "2174 (5, 1) [D loss: (10.2679)(R 29.5308, F -19.3492, G 0.0086)] [G loss: -9.9793]\n",
      "2175 (5, 1) [D loss: (0.8030)(R 4.1747, F -3.4071, G 0.0035)] [G loss: 5.5344]\n",
      "2176 (5, 1) [D loss: (-5.6913)(R 12.2600, F -17.9968, G 0.0046)] [G loss: 11.5068]\n",
      "2177 (5, 1) [D loss: (-14.3743)(R 21.4567, F -35.8592, G 0.0028)] [G loss: 32.1092]\n",
      "2178 (5, 1) [D loss: (-20.5713)(R 14.4312, F -35.3703, G 0.0368)] [G loss: 14.0071]\n",
      "2179 (5, 1) [D loss: (-11.9992)(R 31.2264, F -43.4793, G 0.0254)] [G loss: 43.3481]\n",
      "2180 (5, 1) [D loss: (12.0411)(R 34.7081, F -22.7322, G 0.0065)] [G loss: -14.1395]\n",
      "2181 (5, 1) [D loss: (-4.5411)(R 37.4008, F -41.9767, G 0.0035)] [G loss: 17.0063]\n",
      "2182 (5, 1) [D loss: (-5.1822)(R 17.5560, F -22.7898, G 0.0052)] [G loss: 28.9624]\n",
      "2183 (5, 1) [D loss: (-6.8735)(R 12.9684, F -20.1199, G 0.0278)] [G loss: 36.4251]\n",
      "2184 (5, 1) [D loss: (18.7207)(R 42.4300, F -23.9341, G 0.0225)] [G loss: 11.6060]\n",
      "2185 (5, 1) [D loss: (-29.1209)(R 11.9538, F -41.2097, G 0.0135)] [G loss: 12.6313]\n",
      "2186 (5, 1) [D loss: (-15.2320)(R 1.2702, F -16.5324, G 0.0030)] [G loss: 26.9114]\n",
      "2187 (5, 1) [D loss: (-42.0755)(R 3.1744, F -45.3542, G 0.0104)] [G loss: 31.1810]\n",
      "2188 (5, 1) [D loss: (-15.5432)(R 12.1395, F -27.9391, G 0.0256)] [G loss: 33.7209]\n",
      "2189 (5, 1) [D loss: (-10.5216)(R 16.7110, F -27.4573, G 0.0225)] [G loss: 21.2483]\n",
      "2190 (5, 1) [D loss: (-19.2770)(R 18.6242, F -38.0985, G 0.0197)] [G loss: 40.9966]\n",
      "2191 (5, 1) [D loss: (48.2760)(R 66.4540, F -18.2594, G 0.0081)] [G loss: 21.1195]\n",
      "2192 (5, 1) [D loss: (5.0262)(R 19.6306, F -14.7169, G 0.0113)] [G loss: 8.5290]\n",
      "2193 (5, 1) [D loss: (-46.0694)(R -4.6814, F -41.4902, G 0.0102)] [G loss: -1.2412]\n",
      "2194 (5, 1) [D loss: (3.9246)(R 21.2453, F -18.2522, G 0.0931)] [G loss: 5.2991]\n",
      "2195 (5, 1) [D loss: (-3.0689)(R 31.3944, F -35.2341, G 0.0771)] [G loss: 25.6534]\n",
      "2196 (5, 1) [D loss: (-22.3779)(R 18.0867, F -41.1197, G 0.0655)] [G loss: 18.0239]\n",
      "2197 (5, 1) [D loss: (0.0541)(R 29.7615, F -30.0223, G 0.0315)] [G loss: 29.5453]\n",
      "2198 (5, 1) [D loss: (7.8084)(R 20.0208, F -12.3431, G 0.0131)] [G loss: 35.7647]\n",
      "2199 (5, 1) [D loss: (28.7337)(R 23.3231, F 5.3209, G 0.0090)] [G loss: 7.9363]\n",
      "2200 (5, 1) [D loss: (28.0150)(R 38.3825, F -10.3991, G 0.0032)] [G loss: 15.7110]\n",
      "2201 (5, 1) [D loss: (8.0163)(R 12.0671, F -4.1567, G 0.0106)] [G loss: 36.1486]\n",
      "2202 (5, 1) [D loss: (-2.2532)(R 14.3948, F -16.7116, G 0.0064)] [G loss: 17.0700]\n",
      "2203 (5, 1) [D loss: (17.6012)(R 39.4105, F -22.1850, G 0.0376)] [G loss: 40.6487]\n",
      "2204 (5, 1) [D loss: (-28.4691)(R 26.5346, F -55.0872, G 0.0084)] [G loss: 49.6557]\n",
      "2205 (5, 1) [D loss: (-24.7284)(R 30.7327, F -56.9052, G 0.1444)] [G loss: 49.3268]\n",
      "2206 (5, 1) [D loss: (2.8760)(R 52.7429, F -50.1579, G 0.0291)] [G loss: 51.0566]\n",
      "2207 (5, 1) [D loss: (-0.3890)(R 44.3921, F -45.0889, G 0.0308)] [G loss: 28.6859]\n",
      "2208 (5, 1) [D loss: (5.5768)(R 37.1011, F -31.7415, G 0.0217)] [G loss: 28.5496]\n",
      "2209 (5, 1) [D loss: (12.2334)(R 34.9440, F -22.8859, G 0.0175)] [G loss: 34.7215]\n",
      "2210 (5, 1) [D loss: (8.8288)(R 47.5739, F -38.7788, G 0.0034)] [G loss: 28.7229]\n",
      "2211 (5, 1) [D loss: (-2.1067)(R 30.0487, F -32.2366, G 0.0081)] [G loss: 32.0942]\n",
      "2212 (5, 1) [D loss: (5.7293)(R 32.3327, F -26.7764, G 0.0173)] [G loss: -3.9040]\n",
      "2213 (5, 1) [D loss: (-23.4571)(R -8.6875, F -15.1130, G 0.0343)] [G loss: 6.2295]\n",
      "2214 (5, 1) [D loss: (-7.7703)(R 0.3250, F -8.2109, G 0.0116)] [G loss: 13.6448]\n",
      "2215 (5, 1) [D loss: (-16.7360)(R -5.6329, F -11.1536, G 0.0050)] [G loss: 7.2222]\n",
      "2216 (5, 1) [D loss: (1.3219)(R 11.8989, F -10.7262, G 0.0149)] [G loss: 12.7940]\n",
      "2217 (5, 1) [D loss: (-23.1283)(R -13.0636, F -10.1424, G 0.0078)] [G loss: 4.7835]\n",
      "2218 (5, 1) [D loss: (-18.3267)(R 31.3927, F -49.9314, G 0.0212)] [G loss: 42.4762]\n",
      "2219 (5, 1) [D loss: (-19.0849)(R 15.9628, F -35.4002, G 0.0352)] [G loss: 48.1685]\n",
      "2220 (5, 1) [D loss: (-26.8622)(R 8.7422, F -35.9197, G 0.0315)] [G loss: 34.0518]\n",
      "2221 (5, 1) [D loss: (-12.8191)(R 11.3343, F -24.2044, G 0.0051)] [G loss: 25.0255]\n",
      "2222 (5, 1) [D loss: (-3.5016)(R 18.7335, F -22.2721, G 0.0037)] [G loss: 35.0335]\n",
      "2223 (5, 1) [D loss: (-2.9523)(R 18.8939, F -21.9398, G 0.0094)] [G loss: 41.9710]\n",
      "2224 (5, 1) [D loss: (8.7384)(R 25.5333, F -16.9160, G 0.0121)] [G loss: 32.2516]\n",
      "2225 (5, 1) [D loss: (3.0022)(R 2.2972, F 0.5862, G 0.0119)] [G loss: 10.6529]\n",
      "2226 (5, 1) [D loss: (-28.4314)(R -24.2956, F -4.8572, G 0.0721)] [G loss: 14.1435]\n",
      "2227 (5, 1) [D loss: (13.1213)(R -14.4832, F 26.8136, G 0.0791)] [G loss: -13.8155]\n",
      "2228 (5, 1) [D loss: (-30.6501)(R -23.7356, F -7.7771, G 0.0863)] [G loss: -22.4988]\n",
      "2229 (5, 1) [D loss: (-16.1432)(R -21.3919, F 5.2029, G 0.0046)] [G loss: -0.4110]\n",
      "2230 (5, 1) [D loss: (33.3145)(R -14.8308, F 48.0727, G 0.0073)] [G loss: -3.1298]\n",
      "2231 (5, 1) [D loss: (40.8671)(R -14.5752, F 55.3630, G 0.0079)] [G loss: -17.0068]\n",
      "2232 (5, 1) [D loss: (-7.1295)(R -41.7259, F 34.4866, G 0.0110)] [G loss: -28.2354]\n",
      "2233 (5, 1) [D loss: (-11.0612)(R -52.4389, F 41.2624, G 0.0115)] [G loss: -20.2669]\n",
      "2234 (5, 1) [D loss: (6.7661)(R -24.5927, F 31.2409, G 0.0118)] [G loss: -50.9296]\n",
      "2235 (5, 1) [D loss: (-27.0893)(R -51.2426, F 23.9726, G 0.0181)] [G loss: -42.7252]\n",
      "2236 (5, 1) [D loss: (43.5176)(R -7.0271, F 50.4563, G 0.0088)] [G loss: -19.7070]\n",
      "2237 (5, 1) [D loss: (3.4077)(R -23.8797, F 27.2065, G 0.0081)] [G loss: -18.3771]\n",
      "2238 (5, 1) [D loss: (13.8700)(R -17.2514, F 30.8189, G 0.0303)] [G loss: -37.0791]\n",
      "2239 (5, 1) [D loss: (-3.1252)(R -35.1919, F 31.9505, G 0.0116)] [G loss: -50.8995]\n",
      "2240 (5, 1) [D loss: (-23.9902)(R -43.6196, F 19.3801, G 0.0249)] [G loss: 0.5905]\n",
      "2241 (5, 1) [D loss: (2.2832)(R -10.4589, F 12.6024, G 0.0140)] [G loss: 13.3224]\n",
      "2242 (5, 1) [D loss: (30.2363)(R 26.8223, F 3.3658, G 0.0048)] [G loss: -9.8515]\n",
      "2243 (5, 1) [D loss: (-8.5379)(R 14.0560, F -22.6410, G 0.0047)] [G loss: 1.8011]\n",
      "2244 (5, 1) [D loss: (43.4519)(R 1.8414, F 41.5417, G 0.0069)] [G loss: -2.6413]\n",
      "2245 (5, 1) [D loss: (10.5025)(R 34.0368, F -23.8470, G 0.0313)] [G loss: 39.4207]\n",
      "2246 (5, 1) [D loss: (-7.7153)(R 29.8810, F -37.9556, G 0.0359)] [G loss: 38.3254]\n",
      "2247 (5, 1) [D loss: (1.7531)(R 26.2403, F -24.5462, G 0.0059)] [G loss: 34.1100]\n",
      "2248 (5, 1) [D loss: (31.9086)(R 38.9303, F -7.0505, G 0.0029)] [G loss: 16.4328]\n",
      "2249 (5, 1) [D loss: (-36.8614)(R 15.2357, F -52.1769, G 0.0080)] [G loss: 36.9741]\n",
      "2250 (5, 1) [D loss: (-9.9182)(R 35.5500, F -45.7757, G 0.0308)] [G loss: 2.8900]\n",
      "2251 (5, 1) [D loss: (-2.2640)(R 21.9213, F -24.4541, G 0.0269)] [G loss: 8.4595]\n",
      "2252 (5, 1) [D loss: (-3.0407)(R 16.6670, F -20.0288, G 0.0321)] [G loss: 39.0925]\n",
      "2253 (5, 1) [D loss: (-16.4766)(R 6.7243, F -23.3897, G 0.0189)] [G loss: 9.6373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2254 (5, 1) [D loss: (-18.3124)(R 8.9712, F -27.3789, G 0.0095)] [G loss: -20.8742]\n",
      "2255 (5, 1) [D loss: (19.9292)(R 10.8634, F 9.0106, G 0.0055)] [G loss: 5.0101]\n",
      "2256 (5, 1) [D loss: (12.7864)(R 26.3044, F -13.5881, G 0.0070)] [G loss: -0.7149]\n",
      "2257 (5, 1) [D loss: (-13.9807)(R 10.4271, F -24.4613, G 0.0054)] [G loss: 45.6245]\n",
      "2258 (5, 1) [D loss: (-31.5654)(R 13.6877, F -45.3992, G 0.0146)] [G loss: 35.6792]\n",
      "2259 (5, 1) [D loss: (36.8616)(R 58.7531, F -22.2366, G 0.0345)] [G loss: 30.6534]\n",
      "2260 (5, 1) [D loss: (-27.2053)(R 32.1001, F -59.4063, G 0.0101)] [G loss: 53.2751]\n",
      "2261 (5, 1) [D loss: (-48.3689)(R 30.0921, F -78.5919, G 0.0131)] [G loss: 61.9003]\n",
      "2262 (5, 1) [D loss: (-3.1410)(R 60.9424, F -64.1258, G 0.0042)] [G loss: 43.7050]\n",
      "2263 (5, 1) [D loss: (14.2351)(R 47.1604, F -33.1817, G 0.0256)] [G loss: 29.2875]\n",
      "2264 (5, 1) [D loss: (-5.6099)(R 65.4258, F -71.1616, G 0.0126)] [G loss: 72.9074]\n",
      "2265 (5, 1) [D loss: (41.2490)(R 79.2271, F -38.1488, G 0.0171)] [G loss: 80.6316]\n",
      "2266 (5, 1) [D loss: (-11.3572)(R 64.2873, F -75.8387, G 0.0194)] [G loss: 74.2604]\n",
      "2267 (5, 1) [D loss: (-7.6048)(R 105.0731, F -115.4401, G 0.2762)] [G loss: 86.6546]\n",
      "2268 (5, 1) [D loss: (20.5605)(R 66.0669, F -45.8459, G 0.0339)] [G loss: 85.2466]\n",
      "2269 (5, 1) [D loss: (-16.1430)(R 58.8224, F -75.0147, G 0.0049)] [G loss: 61.5095]\n",
      "2270 (5, 1) [D loss: (81.9731)(R 130.6347, F -48.7391, G 0.0077)] [G loss: 53.8044]\n",
      "2271 (5, 1) [D loss: (13.2573)(R 53.3885, F -40.1881, G 0.0057)] [G loss: 46.2400]\n",
      "2272 (5, 1) [D loss: (13.4927)(R 87.0862, F -73.8179, G 0.0224)] [G loss: 132.3268]\n",
      "2273 (5, 1) [D loss: (-43.3679)(R 35.1355, F -78.5821, G 0.0079)] [G loss: 52.4716]\n",
      "2274 (5, 1) [D loss: (65.4624)(R 108.0774, F -42.8441, G 0.0229)] [G loss: 106.1865]\n",
      "2275 (5, 1) [D loss: (7.7535)(R 69.2757, F -61.5950, G 0.0073)] [G loss: 89.2491]\n",
      "2276 (5, 1) [D loss: (8.7919)(R 66.6583, F -58.0484, G 0.0182)] [G loss: 85.0655]\n",
      "2277 (5, 1) [D loss: (45.2741)(R 102.3820, F -57.2540, G 0.0146)] [G loss: 79.7552]\n",
      "2278 (5, 1) [D loss: (-0.4296)(R 80.8862, F -81.4120, G 0.0096)] [G loss: 59.5720]\n",
      "2279 (5, 1) [D loss: (-20.7759)(R 46.2412, F -67.1302, G 0.0113)] [G loss: 68.3650]\n",
      "2280 (5, 1) [D loss: (3.3849)(R 46.6368, F -43.4053, G 0.0153)] [G loss: 60.9127]\n",
      "2281 (5, 1) [D loss: (27.2922)(R 73.6214, F -46.3635, G 0.0034)] [G loss: 40.9987]\n",
      "2282 (5, 1) [D loss: (14.7860)(R 60.4428, F -45.7090, G 0.0052)] [G loss: 26.1085]\n",
      "2283 (5, 1) [D loss: (26.1152)(R 51.0402, F -25.0895, G 0.0165)] [G loss: 69.4454]\n",
      "2284 (5, 1) [D loss: (-19.1929)(R 45.0788, F -64.4528, G 0.0181)] [G loss: 56.1249]\n",
      "2285 (5, 1) [D loss: (16.8793)(R 100.4078, F -84.5784, G 0.1050)] [G loss: 83.4961]\n",
      "2286 (5, 1) [D loss: (-26.4872)(R 50.1201, F -76.6562, G 0.0049)] [G loss: 84.5636]\n",
      "2287 (5, 1) [D loss: (16.1952)(R 74.7651, F -58.8647, G 0.0295)] [G loss: 72.9941]\n",
      "2288 (5, 1) [D loss: (9.8486)(R 69.6460, F -59.8590, G 0.0062)] [G loss: 47.4751]\n",
      "2289 (5, 1) [D loss: (33.8958)(R 51.9357, F -18.2276, G 0.0188)] [G loss: 47.5129]\n",
      "2290 (5, 1) [D loss: (-16.3568)(R 23.1010, F -39.6375, G 0.0180)] [G loss: 17.2174]\n",
      "2291 (5, 1) [D loss: (-6.0346)(R 31.3202, F -37.6077, G 0.0253)] [G loss: 33.0079]\n",
      "2292 (5, 1) [D loss: (-9.6206)(R 47.8495, F -57.5555, G 0.0085)] [G loss: 44.7447]\n",
      "2293 (5, 1) [D loss: (-2.8023)(R 33.4738, F -36.7048, G 0.0429)] [G loss: 19.4479]\n",
      "2294 (5, 1) [D loss: (-9.4657)(R 28.9967, F -38.8443, G 0.0382)] [G loss: 57.0343]\n",
      "2295 (5, 1) [D loss: (-28.0455)(R 35.6368, F -63.8726, G 0.0190)] [G loss: 40.3724]\n",
      "2296 (5, 1) [D loss: (18.4232)(R 58.3675, F -40.0270, G 0.0083)] [G loss: 52.8038]\n",
      "2297 (5, 1) [D loss: (-4.9435)(R 47.5689, F -52.7235, G 0.0211)] [G loss: 72.1391]\n",
      "2298 (5, 1) [D loss: (-17.1265)(R 73.1036, F -90.2874, G 0.0057)] [G loss: 64.2280]\n",
      "2299 (5, 1) [D loss: (-19.7001)(R 61.2975, F -81.0259, G 0.0028)] [G loss: 67.2923]\n",
      "2300 (5, 1) [D loss: (56.4554)(R 101.9014, F -45.5465, G 0.0101)] [G loss: 74.0974]\n",
      "2301 (5, 1) [D loss: (-8.8307)(R 55.0501, F -63.9771, G 0.0096)] [G loss: 62.6441]\n",
      "2302 (5, 1) [D loss: (-15.2500)(R 73.2511, F -88.5752, G 0.0074)] [G loss: 81.9334]\n",
      "2303 (5, 1) [D loss: (25.1870)(R 105.0829, F -79.9882, G 0.0092)] [G loss: 120.3448]\n",
      "2304 (5, 1) [D loss: (-34.9373)(R 76.8359, F -111.8039, G 0.0031)] [G loss: 92.5939]\n",
      "2305 (5, 1) [D loss: (-40.7885)(R 79.2513, F -120.0917, G 0.0052)] [G loss: 62.1109]\n",
      "2306 (5, 1) [D loss: (10.9280)(R 90.8801, F -80.0333, G 0.0081)] [G loss: 67.2157]\n",
      "2307 (5, 1) [D loss: (-12.2326)(R 64.9507, F -77.2959, G 0.0113)] [G loss: 95.4911]\n",
      "2308 (5, 1) [D loss: (10.1867)(R 89.7016, F -79.7591, G 0.0244)] [G loss: 54.5702]\n",
      "2309 (5, 1) [D loss: (-4.9251)(R 69.8287, F -74.8727, G 0.0119)] [G loss: 76.3365]\n",
      "2310 (5, 1) [D loss: (-38.9324)(R 72.4330, F -111.4019, G 0.0036)] [G loss: 83.1159]\n",
      "2311 (5, 1) [D loss: (-61.6367)(R 54.8498, F -116.5362, G 0.0050)] [G loss: 28.1991]\n",
      "2312 (5, 1) [D loss: (-36.2958)(R 55.6659, F -92.0350, G 0.0073)] [G loss: 91.6205]\n",
      "2313 (5, 1) [D loss: (-12.8075)(R 90.5356, F -103.4147, G 0.0072)] [G loss: 87.3542]\n",
      "2314 (5, 1) [D loss: (-10.9531)(R 83.7757, F -95.0125, G 0.0284)] [G loss: 96.3146]\n",
      "2315 (5, 1) [D loss: (-74.7182)(R 62.3131, F -137.1052, G 0.0074)] [G loss: 161.6074]\n",
      "2316 (5, 1) [D loss: (-14.9415)(R 93.5101, F -108.6834, G 0.0232)] [G loss: 43.4106]\n",
      "2317 (5, 1) [D loss: (-15.8428)(R 53.3219, F -69.7712, G 0.0607)] [G loss: 40.7264]\n",
      "2318 (5, 1) [D loss: (4.1871)(R 68.9468, F -65.0025, G 0.0243)] [G loss: 92.0971]\n",
      "2319 (5, 1) [D loss: (27.0726)(R 51.9956, F -25.0707, G 0.0148)] [G loss: 55.1371]\n",
      "2320 (5, 1) [D loss: (5.1581)(R 62.4843, F -57.4366, G 0.0110)] [G loss: 35.5232]\n",
      "2321 (5, 1) [D loss: (-32.1312)(R 32.9339, F -65.1535, G 0.0088)] [G loss: 29.7225]\n",
      "2322 (5, 1) [D loss: (3.7332)(R 48.5373, F -45.0795, G 0.0275)] [G loss: 53.2831]\n",
      "2323 (5, 1) [D loss: (-12.9422)(R 33.8627, F -47.0472, G 0.0242)] [G loss: 41.3361]\n",
      "2324 (5, 1) [D loss: (11.9842)(R 51.4119, F -39.5027, G 0.0075)] [G loss: 43.3830]\n",
      "2325 (5, 1) [D loss: (-0.6827)(R 47.6261, F -48.4148, G 0.0106)] [G loss: 24.2011]\n",
      "2326 (5, 1) [D loss: (-18.1681)(R 13.8237, F -32.0628, G 0.0071)] [G loss: 29.7593]\n",
      "2327 (5, 1) [D loss: (-22.4975)(R 33.8834, F -56.4810, G 0.0100)] [G loss: 27.7222]\n",
      "2328 (5, 1) [D loss: (-1.5024)(R 55.4875, F -57.1418, G 0.0152)] [G loss: 122.7312]\n",
      "2329 (5, 1) [D loss: (-8.8695)(R 52.3119, F -61.2319, G 0.0051)] [G loss: 40.8567]\n",
      "2330 (5, 1) [D loss: (-38.1345)(R 37.7905, F -75.9818, G 0.0057)] [G loss: 47.6906]\n",
      "2331 (5, 1) [D loss: (-40.7606)(R 47.1274, F -87.9391, G 0.0051)] [G loss: 64.4833]\n",
      "2332 (5, 1) [D loss: (-16.4759)(R 18.7584, F -35.2590, G 0.0025)] [G loss: 70.5583]\n",
      "2333 (5, 1) [D loss: (-5.7743)(R 47.1562, F -52.9846, G 0.0054)] [G loss: 100.7079]\n",
      "2334 (5, 1) [D loss: (-20.3097)(R 39.8894, F -60.3071, G 0.0108)] [G loss: 53.9415]\n",
      "2335 (5, 1) [D loss: (-13.7389)(R 51.3615, F -65.2247, G 0.0124)] [G loss: 77.1976]\n",
      "2336 (5, 1) [D loss: (-95.5237)(R 3.5796, F -99.5508, G 0.0447)] [G loss: 69.1848]\n",
      "2337 (5, 1) [D loss: (58.3860)(R 79.9736, F -23.7184, G 0.2131)] [G loss: 74.9873]\n",
      "2338 (5, 1) [D loss: (-44.8961)(R 99.4921, F -144.5264, G 0.0138)] [G loss: 92.5296]\n",
      "2339 (5, 1) [D loss: (11.6649)(R 81.6269, F -69.9976, G 0.0036)] [G loss: 56.4892]\n",
      "2340 (5, 1) [D loss: (-62.1625)(R -2.2297, F -59.9662, G 0.0033)] [G loss: 20.4911]\n",
      "2341 (5, 1) [D loss: (-86.5535)(R 33.5466, F -120.4166, G 0.0317)] [G loss: 43.4476]\n",
      "2342 (5, 1) [D loss: (46.7212)(R 11.1825, F 34.8719, G 0.0667)] [G loss: -13.7833]\n",
      "2343 (5, 1) [D loss: (3.6985)(R 35.8325, F -32.3619, G 0.0228)] [G loss: 14.6639]\n",
      "2344 (5, 1) [D loss: (1.1932)(R 13.3297, F -12.3909, G 0.0254)] [G loss: -18.3201]\n",
      "2345 (5, 1) [D loss: (-110.6374)(R -33.7079, F -77.2800, G 0.0350)] [G loss: -62.8544]\n",
      "2346 (5, 1) [D loss: (3.9181)(R 49.7663, F -46.3974, G 0.0549)] [G loss: 96.3875]\n",
      "2347 (5, 1) [D loss: (15.9911)(R 68.9853, F -54.0109, G 0.1017)] [G loss: 49.8030]\n",
      "2348 (5, 1) [D loss: (53.6390)(R 49.7499, F 3.7775, G 0.0112)] [G loss: -57.5896]\n",
      "2349 (5, 1) [D loss: (39.2715)(R -19.9183, F 58.9964, G 0.0193)] [G loss: -10.8164]\n",
      "2350 (5, 1) [D loss: (108.5689)(R -22.2988, F 130.7944, G 0.0073)] [G loss: -44.3906]\n",
      "2351 (5, 1) [D loss: (-22.5544)(R -50.3994, F 27.8093, G 0.0036)] [G loss: -84.0150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352 (5, 1) [D loss: (-47.5925)(R -99.7478, F 51.7008, G 0.0455)] [G loss: -23.7056]\n",
      "2353 (5, 1) [D loss: (53.5927)(R -59.3514, F 112.8924, G 0.0052)] [G loss: -106.8745]\n",
      "2354 (5, 1) [D loss: (30.0572)(R -110.4145, F 140.1290, G 0.0343)] [G loss: -108.4723]\n",
      "2355 (5, 1) [D loss: (-94.4698)(R -129.7885, F 35.2872, G 0.0031)] [G loss: -180.4149]\n",
      "2356 (5, 1) [D loss: (14.3338)(R -65.5283, F 79.6171, G 0.0245)] [G loss: -55.7334]\n",
      "2357 (5, 1) [D loss: (-15.3036)(R -183.2134, F 167.7038, G 0.0206)] [G loss: -157.6625]\n",
      "2358 (5, 1) [D loss: (-49.7352)(R -203.0125, F 152.9695, G 0.0308)] [G loss: -168.9541]\n",
      "2359 (5, 1) [D loss: (-127.4376)(R -178.6559, F 51.0143, G 0.0204)] [G loss: -217.5585]\n",
      "2360 (5, 1) [D loss: (50.6686)(R -149.4813, F 199.6375, G 0.0512)] [G loss: -122.0072]\n",
      "2361 (5, 1) [D loss: (-100.8141)(R -147.7209, F 46.8247, G 0.0082)] [G loss: -125.4177]\n",
      "2362 (5, 1) [D loss: (-12.0373)(R -156.5208, F 144.1843, G 0.0299)] [G loss: -42.8918]\n",
      "2363 (5, 1) [D loss: (-26.5831)(R -121.9330, F 95.2778, G 0.0072)] [G loss: -75.7944]\n",
      "2364 (5, 1) [D loss: (0.5975)(R -154.8864, F 155.2971, G 0.0187)] [G loss: -92.6494]\n",
      "2365 (5, 1) [D loss: (71.3173)(R -91.1907, F 162.1878, G 0.0320)] [G loss: -155.1458]\n",
      "2366 (5, 1) [D loss: (55.0062)(R -71.3736, F 126.0515, G 0.0328)] [G loss: -156.7872]\n",
      "2367 (5, 1) [D loss: (-95.5306)(R -142.7273, F 47.0279, G 0.0169)] [G loss: -116.3515]\n",
      "2368 (5, 1) [D loss: (-78.9199)(R -180.7652, F 101.6425, G 0.0203)] [G loss: -46.6697]\n",
      "2369 (5, 1) [D loss: (-7.9895)(R -78.5218, F 70.2665, G 0.0266)] [G loss: -84.1398]\n",
      "2370 (5, 1) [D loss: (-2.9465)(R -59.3541, F 56.3328, G 0.0075)] [G loss: -109.7151]\n",
      "2371 (5, 1) [D loss: (16.3826)(R -108.3979, F 124.6460, G 0.0135)] [G loss: -159.0083]\n",
      "2372 (5, 1) [D loss: (46.6393)(R -76.7601, F 123.2721, G 0.0127)] [G loss: -100.4404]\n",
      "2373 (5, 1) [D loss: (2.7673)(R -77.8316, F 80.4913, G 0.0108)] [G loss: -83.7346]\n",
      "2374 (5, 1) [D loss: (-48.2021)(R -80.9030, F 32.3658, G 0.0335)] [G loss: -114.0303]\n",
      "2375 (5, 1) [D loss: (6.0592)(R 10.0256, F -4.3125, G 0.0346)] [G loss: -11.5876]\n",
      "2376 (5, 1) [D loss: (26.0873)(R 26.9604, F -1.0598, G 0.0187)] [G loss: -33.1420]\n",
      "2377 (5, 1) [D loss: (62.7181)(R -12.5858, F 75.2188, G 0.0085)] [G loss: 5.2855]\n",
      "2378 (5, 1) [D loss: (39.7428)(R -30.5957, F 70.2721, G 0.0066)] [G loss: 2.3766]\n",
      "2379 (5, 1) [D loss: (-1.1031)(R 1.9467, F -3.2285, G 0.0179)] [G loss: -37.8234]\n",
      "2380 (5, 1) [D loss: (-60.0151)(R -85.7721, F 25.4379, G 0.0319)] [G loss: 33.3600]\n",
      "2381 (5, 1) [D loss: (-26.2160)(R -112.0013, F 85.5719, G 0.0213)] [G loss: -7.8792]\n",
      "2382 (5, 1) [D loss: (-63.2540)(R -70.1911, F 6.6356, G 0.0302)] [G loss: -4.8731]\n",
      "2383 (5, 1) [D loss: (-51.8767)(R -102.6765, F 50.4132, G 0.0387)] [G loss: -109.6644]\n",
      "2384 (5, 1) [D loss: (37.5476)(R 9.1256, F 28.0130, G 0.0409)] [G loss: -36.5233]\n",
      "2385 (5, 1) [D loss: (-29.6366)(R -67.2150, F 37.5157, G 0.0063)] [G loss: -19.6231]\n",
      "2386 (5, 1) [D loss: (-5.9577)(R 3.9010, F -10.0438, G 0.0185)] [G loss: -37.1130]\n",
      "2387 (5, 1) [D loss: (49.5084)(R 5.8042, F 43.5677, G 0.0136)] [G loss: -35.6957]\n",
      "2388 (5, 1) [D loss: (31.3522)(R -18.3567, F 49.4838, G 0.0225)] [G loss: 23.7585]\n",
      "2389 (5, 1) [D loss: (18.2918)(R -11.5916, F 29.5823, G 0.0301)] [G loss: 1.5556]\n",
      "2390 (5, 1) [D loss: (-16.5985)(R 10.8624, F -27.6533, G 0.0192)] [G loss: 18.9109]\n",
      "2391 (5, 1) [D loss: (-78.6634)(R -37.7084, F -41.0354, G 0.0080)] [G loss: 6.2662]\n",
      "2392 (5, 1) [D loss: (-8.1228)(R -43.3106, F 35.0760, G 0.0112)] [G loss: -4.9239]\n",
      "2393 (5, 1) [D loss: (-33.6458)(R -81.3268, F 46.1783, G 0.1503)] [G loss: -8.5691]\n",
      "2394 (5, 1) [D loss: (-31.0838)(R -92.5996, F 61.3998, G 0.0116)] [G loss: -131.0466]\n",
      "2395 (5, 1) [D loss: (115.7069)(R -51.1847, F 166.3072, G 0.0584)] [G loss: -45.9841]\n",
      "2396 (5, 1) [D loss: (-31.8695)(R -65.9692, F 33.9949, G 0.0105)] [G loss: -15.1191]\n",
      "2397 (5, 1) [D loss: (-0.5844)(R -57.2868, F 56.6549, G 0.0047)] [G loss: -113.4854]\n",
      "2398 (5, 1) [D loss: (13.9484)(R -78.5706, F 91.7609, G 0.0758)] [G loss: -91.9146]\n",
      "2399 (5, 1) [D loss: (59.7743)(R -110.2348, F 169.2687, G 0.0740)] [G loss: -5.4645]\n",
      "2400 (5, 1) [D loss: (7.2928)(R -78.3096, F 85.4252, G 0.0177)] [G loss: -95.4093]\n",
      "2401 (5, 1) [D loss: (-4.3712)(R -20.3551, F 15.7399, G 0.0244)] [G loss: -47.3062]\n",
      "2402 (5, 1) [D loss: (-3.9908)(R -16.0961, F 12.0275, G 0.0078)] [G loss: -79.3720]\n",
      "2403 (5, 1) [D loss: (34.7719)(R -10.3145, F 41.7052, G 0.3381)] [G loss: -119.1760]\n",
      "2404 (5, 1) [D loss: (-57.3893)(R -46.4426, F -11.0642, G 0.0118)] [G loss: -110.0751]\n",
      "2405 (5, 1) [D loss: (96.5518)(R 5.9171, F 90.5640, G 0.0071)] [G loss: -16.8625]\n",
      "2406 (5, 1) [D loss: (112.3471)(R 35.3120, F 76.9213, G 0.0114)] [G loss: -116.3893]\n",
      "2407 (5, 1) [D loss: (63.7505)(R -1.2460, F 64.2242, G 0.0772)] [G loss: -53.0367]\n",
      "2408 (5, 1) [D loss: (-67.9505)(R -79.4398, F 11.3347, G 0.0155)] [G loss: -59.3041]\n",
      "2409 (5, 1) [D loss: (-69.5028)(R -65.9192, F -4.3666, G 0.0783)] [G loss: -41.9167]\n",
      "2410 (5, 1) [D loss: (48.3847)(R -24.4603, F 72.6624, G 0.0183)] [G loss: -204.9403]\n",
      "2411 (5, 1) [D loss: (28.8115)(R -45.4816, F 74.1625, G 0.0131)] [G loss: -89.6835]\n",
      "2412 (5, 1) [D loss: (68.0445)(R -23.7127, F 91.7328, G 0.0024)] [G loss: -103.9483]\n",
      "2413 (5, 1) [D loss: (97.6814)(R 9.5920, F 87.5203, G 0.0569)] [G loss: -123.6395]\n",
      "2414 (5, 1) [D loss: (-29.8380)(R -49.2166, F 19.3255, G 0.0053)] [G loss: -80.2012]\n",
      "2415 (5, 1) [D loss: (40.7597)(R -33.0190, F 73.6924, G 0.0086)] [G loss: -14.1275]\n",
      "2416 (5, 1) [D loss: (-6.5805)(R -58.0413, F 51.4178, G 0.0043)] [G loss: -23.7761]\n",
      "2417 (5, 1) [D loss: (27.3284)(R -11.6126, F 38.9194, G 0.0022)] [G loss: -111.5998]\n",
      "2418 (5, 1) [D loss: (63.6436)(R -24.2905, F 87.8715, G 0.0063)] [G loss: -17.6314]\n",
      "2419 (5, 1) [D loss: (4.7372)(R -43.2604, F 47.6653, G 0.0332)] [G loss: -67.2593]\n",
      "2420 (5, 1) [D loss: (-40.5295)(R -32.5099, F -8.2218, G 0.0202)] [G loss: -11.4079]\n",
      "2421 (5, 1) [D loss: (19.5212)(R -17.2511, F 36.7316, G 0.0041)] [G loss: -45.4889]\n",
      "2422 (5, 1) [D loss: (-17.4803)(R -44.9665, F 27.4245, G 0.0062)] [G loss: -30.8835]\n",
      "2423 (5, 1) [D loss: (20.0850)(R -7.4346, F 27.3619, G 0.0158)] [G loss: -24.9206]\n",
      "2424 (5, 1) [D loss: (-15.1105)(R 12.4102, F -27.6452, G 0.0124)] [G loss: -8.1679]\n",
      "2425 (5, 1) [D loss: (25.5279)(R -14.0753, F 39.5128, G 0.0090)] [G loss: 13.2625]\n",
      "2426 (5, 1) [D loss: (-50.4127)(R -13.8550, F -36.6411, G 0.0083)] [G loss: -19.3465]\n",
      "2427 (5, 1) [D loss: (-22.8977)(R -3.0874, F -19.8580, G 0.0048)] [G loss: -28.0320]\n",
      "2428 (5, 1) [D loss: (80.3010)(R 54.1546, F 26.1187, G 0.0028)] [G loss: -14.1630]\n",
      "2429 (5, 1) [D loss: (6.9055)(R 11.3807, F -4.5820, G 0.0107)] [G loss: 1.4965]\n",
      "2430 (5, 1) [D loss: (3.9929)(R -1.8497, F 5.6717, G 0.0171)] [G loss: 3.9789]\n",
      "2431 (5, 1) [D loss: (-17.1936)(R -13.5136, F -3.8078, G 0.0128)] [G loss: 1.7644]\n",
      "2432 (5, 1) [D loss: (39.1198)(R 31.8227, F 7.1907, G 0.0106)] [G loss: 34.5195]\n",
      "2433 (5, 1) [D loss: (5.0856)(R 10.1880, F -5.1669, G 0.0065)] [G loss: 18.3382]\n",
      "2434 (5, 1) [D loss: (3.7513)(R -4.1809, F 7.8876, G 0.0045)] [G loss: 22.7721]\n",
      "2435 (5, 1) [D loss: (-8.3093)(R 7.3734, F -15.7663, G 0.0084)] [G loss: 11.1928]\n",
      "2436 (5, 1) [D loss: (12.8070)(R 28.0633, F -15.3036, G 0.0047)] [G loss: 14.3439]\n",
      "2437 (5, 1) [D loss: (13.2446)(R 25.9477, F -12.7535, G 0.0050)] [G loss: 31.4862]\n",
      "2438 (5, 1) [D loss: (-2.1707)(R 25.1737, F -27.4150, G 0.0071)] [G loss: 13.5159]\n",
      "2439 (5, 1) [D loss: (10.4358)(R 18.1327, F -7.7268, G 0.0030)] [G loss: 32.7137]\n",
      "2440 (5, 1) [D loss: (-21.7496)(R 2.4407, F -24.2216, G 0.0031)] [G loss: 21.0882]\n",
      "2441 (5, 1) [D loss: (2.7468)(R 10.1891, F -7.7224, G 0.0280)] [G loss: 23.1751]\n",
      "2442 (5, 1) [D loss: (21.0254)(R 36.3676, F -15.5319, G 0.0190)] [G loss: 21.5923]\n",
      "2443 (5, 1) [D loss: (-0.9473)(R 23.8931, F -24.8797, G 0.0039)] [G loss: 39.5611]\n",
      "2444 (5, 1) [D loss: (8.0188)(R 23.5566, F -15.5860, G 0.0048)] [G loss: 28.0647]\n",
      "2445 (5, 1) [D loss: (-21.4916)(R 17.9153, F -39.4661, G 0.0059)] [G loss: 21.2148]\n",
      "2446 (5, 1) [D loss: (16.1073)(R 37.8221, F -21.7491, G 0.0034)] [G loss: 24.6339]\n",
      "2447 (5, 1) [D loss: (3.8756)(R 38.2652, F -34.5516, G 0.0162)] [G loss: 27.6605]\n",
      "2448 (5, 1) [D loss: (-38.1190)(R 18.1977, F -56.5850, G 0.0268)] [G loss: 26.5310]\n",
      "2449 (5, 1) [D loss: (-11.3399)(R 24.8655, F -36.3117, G 0.0106)] [G loss: 18.5858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450 (5, 1) [D loss: (-22.2597)(R 49.4267, F -71.7457, G 0.0059)] [G loss: 41.4154]\n",
      "2451 (5, 1) [D loss: (12.4038)(R 41.3939, F -29.0361, G 0.0046)] [G loss: 27.4685]\n",
      "2452 (5, 1) [D loss: (-19.3856)(R 29.2554, F -48.7182, G 0.0077)] [G loss: 12.2462]\n",
      "2453 (5, 1) [D loss: (0.3207)(R 25.8548, F -25.5854, G 0.0051)] [G loss: 64.0540]\n",
      "2454 (5, 1) [D loss: (-27.5783)(R 4.5463, F -32.2313, G 0.0107)] [G loss: 11.0654]\n",
      "2455 (5, 1) [D loss: (8.4426)(R 25.3378, F -17.0485, G 0.0153)] [G loss: -6.4166]\n",
      "2456 (5, 1) [D loss: (-13.6313)(R 6.4752, F -20.1793, G 0.0073)] [G loss: -7.7221]\n",
      "2457 (5, 1) [D loss: (-11.0492)(R 18.7545, F -29.9514, G 0.0148)] [G loss: 17.0810]\n",
      "2458 (5, 1) [D loss: (-1.4029)(R 4.5910, F -6.0580, G 0.0064)] [G loss: -14.8739]\n",
      "2459 (5, 1) [D loss: (5.1323)(R 3.8762, F 1.1985, G 0.0058)] [G loss: 10.0348]\n",
      "2460 (5, 1) [D loss: (-13.6055)(R 8.2411, F -21.9232, G 0.0077)] [G loss: 12.8135]\n",
      "2461 (5, 1) [D loss: (-23.2843)(R 33.6953, F -57.0748, G 0.0095)] [G loss: 27.9909]\n",
      "2462 (5, 1) [D loss: (-17.6388)(R 22.0082, F -39.6877, G 0.0041)] [G loss: 40.1418]\n",
      "2463 (5, 1) [D loss: (-49.2167)(R 14.8371, F -64.6321, G 0.0578)] [G loss: 56.7254]\n",
      "2464 (5, 1) [D loss: (-12.9890)(R 27.0965, F -40.1419, G 0.0056)] [G loss: 28.4574]\n",
      "2465 (5, 1) [D loss: (37.3769)(R 84.2291, F -46.9306, G 0.0078)] [G loss: 31.4774]\n",
      "2466 (5, 1) [D loss: (79.6257)(R 54.0680, F 25.4862, G 0.0071)] [G loss: 23.3130]\n",
      "2467 (5, 1) [D loss: (4.5380)(R 19.3462, F -14.9012, G 0.0093)] [G loss: 14.7577]\n",
      "2468 (5, 1) [D loss: (25.7580)(R 31.4899, F -5.7888, G 0.0057)] [G loss: 12.6232]\n",
      "2469 (5, 1) [D loss: (-9.9618)(R 5.8910, F -15.9758, G 0.0123)] [G loss: 11.0195]\n",
      "2470 (5, 1) [D loss: (0.7075)(R 12.5094, F -11.9374, G 0.0136)] [G loss: 18.8406]\n",
      "2471 (5, 1) [D loss: (-11.4649)(R 5.5161, F -17.0484, G 0.0067)] [G loss: 14.2727]\n",
      "2472 (5, 1) [D loss: (-8.7413)(R 4.3172, F -13.1751, G 0.0117)] [G loss: 3.2446]\n",
      "2473 (5, 1) [D loss: (-0.7458)(R 17.7027, F -18.5341, G 0.0086)] [G loss: 16.1657]\n",
      "2474 (5, 1) [D loss: (1.7943)(R 25.3492, F -23.6432, G 0.0088)] [G loss: 26.5134]\n",
      "2475 (5, 1) [D loss: (-2.8733)(R 32.3256, F -35.3016, G 0.0103)] [G loss: 29.4462]\n",
      "2476 (5, 1) [D loss: (8.1067)(R 43.4067, F -35.5562, G 0.0256)] [G loss: 27.9856]\n",
      "2477 (5, 1) [D loss: (-15.7058)(R 26.7846, F -43.2385, G 0.0748)] [G loss: 36.8916]\n",
      "2478 (5, 1) [D loss: (-12.5268)(R 48.6818, F -61.4054, G 0.0197)] [G loss: 27.6228]\n",
      "2479 (5, 1) [D loss: (-21.2864)(R 45.4015, F -66.8456, G 0.0158)] [G loss: 87.7258]\n",
      "2480 (5, 1) [D loss: (11.3701)(R 70.1355, F -59.0848, G 0.0319)] [G loss: 80.4926]\n",
      "2481 (5, 1) [D loss: (-52.0310)(R 10.1647, F -62.2503, G 0.0055)] [G loss: 56.7593]\n",
      "2482 (5, 1) [D loss: (10.6664)(R 57.1527, F -46.5140, G 0.0028)] [G loss: 10.5289]\n",
      "2483 (5, 1) [D loss: (37.9356)(R 65.9370, F -28.0504, G 0.0049)] [G loss: 20.4354]\n",
      "2484 (5, 1) [D loss: (-16.7068)(R 6.8054, F -23.5707, G 0.0058)] [G loss: 14.8348]\n",
      "2485 (5, 1) [D loss: (-21.6571)(R 23.4828, F -45.2919, G 0.0152)] [G loss: 43.5805]\n",
      "2486 (5, 1) [D loss: (-14.8168)(R 61.1642, F -76.1914, G 0.0210)] [G loss: 42.2541]\n",
      "2487 (5, 1) [D loss: (-11.0440)(R 41.6929, F -52.9418, G 0.0205)] [G loss: 68.3070]\n",
      "2488 (5, 1) [D loss: (1.1761)(R 53.4972, F -52.5271, G 0.0206)] [G loss: 61.5791]\n",
      "2489 (5, 1) [D loss: (20.0012)(R 49.8554, F -29.9356, G 0.0081)] [G loss: 44.7164]\n",
      "2490 (5, 1) [D loss: (1.0968)(R 28.8676, F -27.8175, G 0.0047)] [G loss: 26.7229]\n",
      "2491 (5, 1) [D loss: (-26.4218)(R 18.2782, F -44.7456, G 0.0046)] [G loss: 45.2931]\n",
      "2492 (5, 1) [D loss: (48.0748)(R 72.4884, F -24.6078, G 0.0194)] [G loss: 83.9225]\n",
      "2493 (5, 1) [D loss: (4.4210)(R 59.3650, F -55.0222, G 0.0078)] [G loss: 53.8535]\n",
      "2494 (5, 1) [D loss: (-0.1285)(R 33.7957, F -34.3311, G 0.0407)] [G loss: 36.7449]\n",
      "2495 (5, 1) [D loss: (0.0878)(R 45.1399, F -45.1253, G 0.0073)] [G loss: 61.8040]\n",
      "2496 (5, 1) [D loss: (15.2994)(R 65.1875, F -49.9302, G 0.0042)] [G loss: 43.6628]\n",
      "2497 (5, 1) [D loss: (6.3280)(R 50.0435, F -43.7730, G 0.0057)] [G loss: 39.0052]\n",
      "2498 (5, 1) [D loss: (40.0631)(R 71.9355, F -31.9653, G 0.0093)] [G loss: 40.0778]\n",
      "2499 (5, 1) [D loss: (-20.5490)(R 37.7662, F -58.4116, G 0.0096)] [G loss: 49.7714]\n",
      "2500 (5, 1) [D loss: (-9.8685)(R 35.6840, F -45.6777, G 0.0125)] [G loss: 52.3115]\n",
      "2501 (5, 1) [D loss: (23.7349)(R 42.9724, F -19.3712, G 0.0134)] [G loss: 36.6675]\n",
      "2502 (5, 1) [D loss: (1.0417)(R 35.8103, F -34.8557, G 0.0087)] [G loss: 29.2198]\n",
      "2503 (5, 1) [D loss: (1.9111)(R 39.9342, F -38.0535, G 0.0030)] [G loss: 38.5437]\n",
      "2504 (5, 1) [D loss: (-4.8656)(R 39.2285, F -44.1779, G 0.0084)] [G loss: 17.3655]\n",
      "2505 (5, 1) [D loss: (16.0317)(R 36.1962, F -20.2295, G 0.0065)] [G loss: 29.4857]\n",
      "2506 (5, 1) [D loss: (-7.5601)(R 21.4642, F -29.3322, G 0.0308)] [G loss: 23.9291]\n",
      "2507 (5, 1) [D loss: (4.5915)(R 27.4122, F -22.8847, G 0.0064)] [G loss: 31.9582]\n",
      "2508 (5, 1) [D loss: (-5.5733)(R 24.6100, F -30.6343, G 0.0451)] [G loss: 40.3713]\n",
      "2509 (5, 1) [D loss: (6.2026)(R 35.3191, F -29.1537, G 0.0037)] [G loss: 30.6417]\n",
      "2510 (5, 1) [D loss: (3.4228)(R 39.3670, F -36.0181, G 0.0074)] [G loss: 27.6598]\n",
      "2511 (5, 1) [D loss: (8.5207)(R 41.0911, F -32.7662, G 0.0196)] [G loss: 40.9328]\n",
      "2512 (5, 1) [D loss: (-4.6492)(R 36.2169, F -41.0241, G 0.0158)] [G loss: 32.2569]\n",
      "2513 (5, 1) [D loss: (3.6335)(R 29.4722, F -26.1117, G 0.0273)] [G loss: 25.3663]\n",
      "2514 (5, 1) [D loss: (-1.9875)(R 27.5538, F -29.7013, G 0.0160)] [G loss: 37.6637]\n",
      "2515 (5, 1) [D loss: (-2.0193)(R 39.0011, F -41.1614, G 0.0141)] [G loss: 39.5477]\n",
      "2516 (5, 1) [D loss: (-12.9679)(R 29.0007, F -42.0677, G 0.0099)] [G loss: 42.6882]\n",
      "2517 (5, 1) [D loss: (7.3524)(R 50.1661, F -42.9223, G 0.0109)] [G loss: 49.3992]\n",
      "2518 (5, 1) [D loss: (2.1021)(R 41.3024, F -39.2376, G 0.0037)] [G loss: 63.1614]\n",
      "2519 (5, 1) [D loss: (-9.6459)(R 29.0103, F -38.6924, G 0.0036)] [G loss: 36.5951]\n",
      "2520 (5, 1) [D loss: (-5.4818)(R 41.3069, F -46.8322, G 0.0044)] [G loss: 47.3595]\n",
      "2521 (5, 1) [D loss: (-14.6416)(R 48.9468, F -63.6460, G 0.0058)] [G loss: 61.1757]\n",
      "2522 (5, 1) [D loss: (6.2316)(R 54.4687, F -48.2646, G 0.0028)] [G loss: 53.5586]\n",
      "2523 (5, 1) [D loss: (-1.1771)(R 56.4864, F -57.7080, G 0.0044)] [G loss: 42.6195]\n",
      "2524 (5, 1) [D loss: (11.5440)(R 47.6443, F -36.1634, G 0.0063)] [G loss: 45.8098]\n",
      "2525 (5, 1) [D loss: (-13.4349)(R 28.9389, F -42.4265, G 0.0053)] [G loss: 53.2496]\n",
      "2526 (5, 1) [D loss: (-15.6817)(R 37.0843, F -52.8366, G 0.0071)] [G loss: 57.9295]\n",
      "2527 (5, 1) [D loss: (-13.8743)(R 40.9663, F -54.8770, G 0.0036)] [G loss: 52.1918]\n",
      "2528 (5, 1) [D loss: (-0.3461)(R 56.3336, F -56.8895, G 0.0210)] [G loss: 51.9760]\n",
      "2529 (5, 1) [D loss: (-7.5503)(R 42.6264, F -50.2324, G 0.0056)] [G loss: 31.8676]\n",
      "2530 (5, 1) [D loss: (0.1870)(R 43.7636, F -43.6348, G 0.0058)] [G loss: 40.4100]\n",
      "2531 (5, 1) [D loss: (8.5460)(R 47.3058, F -38.8135, G 0.0054)] [G loss: 65.1513]\n",
      "2532 (5, 1) [D loss: (-1.3966)(R 41.0801, F -42.5155, G 0.0039)] [G loss: 32.5884]\n",
      "2533 (5, 1) [D loss: (-5.8526)(R 32.2820, F -38.1783, G 0.0044)] [G loss: 30.4274]\n",
      "2534 (5, 1) [D loss: (12.8070)(R 39.6992, F -27.2329, G 0.0341)] [G loss: 30.9672]\n",
      "2535 (5, 1) [D loss: (-1.9537)(R 35.3588, F -37.3554, G 0.0043)] [G loss: 38.9947]\n",
      "2536 (5, 1) [D loss: (10.6481)(R 38.5996, F -27.9933, G 0.0042)] [G loss: 36.5198]\n",
      "2537 (5, 1) [D loss: (0.9819)(R 23.3949, F -22.5384, G 0.0125)] [G loss: 16.6262]\n",
      "2538 (5, 1) [D loss: (5.2179)(R 33.1315, F -27.9785, G 0.0065)] [G loss: 29.3613]\n",
      "2539 (5, 1) [D loss: (-2.6960)(R 22.0875, F -24.8752, G 0.0092)] [G loss: 22.4063]\n",
      "2540 (5, 1) [D loss: (-3.9039)(R 19.5730, F -23.6009, G 0.0124)] [G loss: 25.7785]\n",
      "2541 (5, 1) [D loss: (7.9739)(R 34.2357, F -26.3656, G 0.0104)] [G loss: 26.4788]\n",
      "2542 (5, 1) [D loss: (-0.6405)(R 27.7564, F -28.5024, G 0.0106)] [G loss: 24.0930]\n",
      "2543 (5, 1) [D loss: (-8.9153)(R 32.2865, F -41.2654, G 0.0064)] [G loss: 31.3374]\n",
      "2544 (5, 1) [D loss: (0.3948)(R 32.8680, F -32.5573, G 0.0084)] [G loss: 32.7886]\n",
      "2545 (5, 1) [D loss: (4.2280)(R 47.0391, F -43.9264, G 0.1115)] [G loss: 43.6381]\n",
      "2546 (5, 1) [D loss: (0.5298)(R 47.6099, F -47.2092, G 0.0129)] [G loss: 43.9728]\n",
      "2547 (5, 1) [D loss: (0.7718)(R 65.0496, F -64.5332, G 0.0255)] [G loss: 45.5777]\n",
      "2548 (5, 1) [D loss: (3.7879)(R 61.7917, F -58.4374, G 0.0434)] [G loss: 71.8813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2549 (5, 1) [D loss: (-1.2280)(R 61.6948, F -63.0197, G 0.0097)] [G loss: 53.6674]\n",
      "2550 (5, 1) [D loss: (9.9603)(R 60.5082, F -50.8600, G 0.0312)] [G loss: 56.1418]\n",
      "2551 (5, 1) [D loss: (8.6332)(R 58.1890, F -49.6719, G 0.0116)] [G loss: 50.9876]\n",
      "2552 (5, 1) [D loss: (9.3190)(R 52.6488, F -43.3766, G 0.0047)] [G loss: 31.6377]\n",
      "2553 (5, 1) [D loss: (-11.8367)(R 39.3482, F -51.2125, G 0.0028)] [G loss: 53.9623]\n",
      "2554 (5, 1) [D loss: (5.1040)(R 55.5051, F -50.4351, G 0.0034)] [G loss: 45.5716]\n",
      "2555 (5, 1) [D loss: (-1.7772)(R 35.0015, F -36.8618, G 0.0083)] [G loss: 28.7356]\n",
      "2556 (5, 1) [D loss: (6.8152)(R 33.0045, F -26.9007, G 0.0711)] [G loss: 36.2647]\n",
      "2557 (5, 1) [D loss: (4.7790)(R 37.6738, F -33.5741, G 0.0679)] [G loss: 39.2101]\n",
      "2558 (5, 1) [D loss: (-1.9314)(R 28.6095, F -30.6244, G 0.0083)] [G loss: 28.6111]\n",
      "2559 (5, 1) [D loss: (-19.6114)(R 30.3630, F -50.1423, G 0.0168)] [G loss: 46.0064]\n",
      "2560 (5, 1) [D loss: (-27.9493)(R 25.9033, F -53.8930, G 0.0040)] [G loss: 40.6290]\n",
      "2561 (5, 1) [D loss: (-0.8276)(R 62.1206, F -63.0071, G 0.0059)] [G loss: 68.5221]\n",
      "2562 (5, 1) [D loss: (-6.4383)(R 69.7225, F -76.2611, G 0.0100)] [G loss: 93.3818]\n",
      "2563 (5, 1) [D loss: (-6.2037)(R 82.0944, F -88.3550, G 0.0057)] [G loss: 95.7220]\n",
      "2564 (5, 1) [D loss: (2.9301)(R 113.7200, F -110.9457, G 0.0156)] [G loss: 98.9071]\n",
      "2565 (5, 1) [D loss: (-37.8091)(R 96.5324, F -134.4216, G 0.0080)] [G loss: 109.2154]\n",
      "2566 (5, 1) [D loss: (-1.9878)(R 121.8711, F -123.9111, G 0.0052)] [G loss: 110.6789]\n",
      "2567 (5, 1) [D loss: (23.0422)(R 130.2301, F -107.2411, G 0.0053)] [G loss: 143.3555]\n",
      "2568 (5, 1) [D loss: (11.0530)(R 115.9961, F -104.9653, G 0.0022)] [G loss: 128.1216]\n",
      "2569 (5, 1) [D loss: (-34.3089)(R 115.0053, F -149.3676, G 0.0053)] [G loss: 136.4451]\n",
      "2570 (5, 1) [D loss: (25.4761)(R 128.4880, F -103.0530, G 0.0041)] [G loss: 123.3748]\n",
      "2571 (5, 1) [D loss: (-13.4430)(R 129.3476, F -142.8856, G 0.0095)] [G loss: 126.2121]\n",
      "2572 (5, 1) [D loss: (-44.8793)(R 145.5909, F -190.5453, G 0.0075)] [G loss: 148.0127]\n",
      "2573 (5, 1) [D loss: (9.8730)(R 182.3968, F -172.5857, G 0.0062)] [G loss: 147.2617]\n",
      "2574 (5, 1) [D loss: (-5.8561)(R 133.4348, F -139.3882, G 0.0097)] [G loss: 98.9911]\n",
      "2575 (5, 1) [D loss: (5.9078)(R 100.1316, F -94.2749, G 0.0051)] [G loss: 101.9855]\n",
      "2576 (5, 1) [D loss: (-14.9198)(R 99.8919, F -114.8457, G 0.0034)] [G loss: 81.3854]\n",
      "2577 (5, 1) [D loss: (30.1774)(R 144.8725, F -114.8373, G 0.0142)] [G loss: 66.7624]\n",
      "2578 (5, 1) [D loss: (-20.7131)(R 92.5223, F -113.4011, G 0.0166)] [G loss: 113.7865]\n",
      "2579 (5, 1) [D loss: (34.5975)(R 106.1878, F -71.6225, G 0.0032)] [G loss: 91.0024]\n",
      "2580 (5, 1) [D loss: (-25.9360)(R 48.5845, F -74.5431, G 0.0023)] [G loss: 72.7371]\n",
      "2581 (5, 1) [D loss: (-26.7211)(R 67.2069, F -93.9859, G 0.0058)] [G loss: 67.3044]\n",
      "2582 (5, 1) [D loss: (-11.9044)(R 55.8326, F -67.7852, G 0.0048)] [G loss: 81.5043]\n",
      "2583 (5, 1) [D loss: (1.5648)(R 57.1733, F -55.6584, G 0.0050)] [G loss: 51.2360]\n",
      "2584 (5, 1) [D loss: (1.1646)(R 69.9613, F -68.8484, G 0.0052)] [G loss: 66.9385]\n",
      "2585 (5, 1) [D loss: (-12.8341)(R 59.2675, F -72.1475, G 0.0046)] [G loss: 73.3887]\n",
      "2586 (5, 1) [D loss: (1.8436)(R 62.5495, F -60.7498, G 0.0044)] [G loss: 61.2304]\n",
      "2587 (5, 1) [D loss: (-0.7009)(R 77.1623, F -77.9025, G 0.0039)] [G loss: 54.8018]\n",
      "2588 (5, 1) [D loss: (-2.8784)(R 86.6382, F -89.5891, G 0.0073)] [G loss: 62.1446]\n",
      "2589 (5, 1) [D loss: (-18.1371)(R 58.4992, F -76.7186, G 0.0082)] [G loss: 58.4093]\n",
      "2590 (5, 1) [D loss: (0.4565)(R 61.3263, F -60.9236, G 0.0054)] [G loss: 58.4878]\n",
      "2591 (5, 1) [D loss: (-6.5611)(R 45.9741, F -52.6651, G 0.0130)] [G loss: 45.8867]\n",
      "2592 (5, 1) [D loss: (18.6576)(R 63.1580, F -44.6968, G 0.0196)] [G loss: 49.9261]\n",
      "2593 (5, 1) [D loss: (2.4556)(R 66.5298, F -64.3033, G 0.0229)] [G loss: 66.4024]\n",
      "2594 (5, 1) [D loss: (-0.0264)(R 61.5903, F -61.8202, G 0.0203)] [G loss: 58.5662]\n",
      "2595 (5, 1) [D loss: (3.9231)(R 75.5710, F -71.7852, G 0.0137)] [G loss: 63.8166]\n",
      "2596 (5, 1) [D loss: (-1.5961)(R 71.9843, F -73.6201, G 0.0040)] [G loss: 65.9580]\n",
      "2597 (5, 1) [D loss: (7.7181)(R 72.4176, F -65.0999, G 0.0400)] [G loss: 87.4625]\n",
      "2598 (5, 1) [D loss: (2.4704)(R 65.0771, F -62.8187, G 0.0212)] [G loss: 73.6304]\n",
      "2599 (5, 1) [D loss: (-13.3343)(R 61.6718, F -75.0992, G 0.0093)] [G loss: 82.5051]\n",
      "2600 (5, 1) [D loss: (-22.5518)(R 66.1350, F -88.8064, G 0.0120)] [G loss: 86.4947]\n",
      "2601 (5, 1) [D loss: (-33.8875)(R 82.0939, F -116.0811, G 0.0100)] [G loss: 102.6245]\n",
      "2602 (5, 1) [D loss: (-32.4047)(R 103.7155, F -136.3018, G 0.0182)] [G loss: 114.6359]\n",
      "2603 (5, 1) [D loss: (4.0493)(R 108.9676, F -104.9857, G 0.0067)] [G loss: 96.9541]\n",
      "2604 (5, 1) [D loss: (-8.3044)(R 139.7394, F -148.1750, G 0.0131)] [G loss: 129.1016]\n",
      "2605 (5, 1) [D loss: (19.0571)(R 128.7086, F -109.7379, G 0.0086)] [G loss: 111.2540]\n",
      "2606 (5, 1) [D loss: (-5.1052)(R 91.4629, F -96.6576, G 0.0089)] [G loss: 111.3602]\n",
      "2607 (5, 1) [D loss: (7.6062)(R 107.9845, F -100.5510, G 0.0173)] [G loss: 99.0330]\n",
      "2608 (5, 1) [D loss: (-22.2843)(R 90.0411, F -112.4002, G 0.0075)] [G loss: 104.2710]\n",
      "2609 (5, 1) [D loss: (13.1267)(R 116.1477, F -103.0950, G 0.0074)] [G loss: 103.3627]\n",
      "2610 (5, 1) [D loss: (-13.7071)(R 76.3020, F -90.0766, G 0.0068)] [G loss: 85.0942]\n",
      "2611 (5, 1) [D loss: (3.0724)(R 81.9299, F -78.9601, G 0.0103)] [G loss: 74.6290]\n",
      "2612 (5, 1) [D loss: (11.1168)(R 97.3299, F -86.6419, G 0.0429)] [G loss: 83.3615]\n",
      "2613 (5, 1) [D loss: (2.4415)(R 88.4566, F -86.2352, G 0.0220)] [G loss: 79.5802]\n",
      "2614 (5, 1) [D loss: (-14.1907)(R 64.1233, F -78.4205, G 0.0106)] [G loss: 73.4037]\n",
      "2615 (5, 1) [D loss: (-27.7233)(R 64.8788, F -92.6642, G 0.0062)] [G loss: 77.5160]\n",
      "2616 (5, 1) [D loss: (4.5629)(R 93.1373, F -88.6533, G 0.0079)] [G loss: 85.1041]\n",
      "2617 (5, 1) [D loss: (-8.9446)(R 74.7574, F -83.7593, G 0.0057)] [G loss: 78.5088]\n",
      "2618 (5, 1) [D loss: (10.1129)(R 57.7265, F -47.8107, G 0.0197)] [G loss: 44.2395]\n",
      "2619 (5, 1) [D loss: (4.4895)(R 50.6914, F -46.2997, G 0.0098)] [G loss: 38.5164]\n",
      "2620 (5, 1) [D loss: (1.9165)(R 20.5111, F -18.7557, G 0.0161)] [G loss: 24.6402]\n",
      "2621 (5, 1) [D loss: (-4.8298)(R 21.8173, F -26.7982, G 0.0151)] [G loss: 30.4091]\n",
      "2622 (5, 1) [D loss: (2.9761)(R 22.7895, F -19.9143, G 0.0101)] [G loss: 28.8027]\n",
      "2623 (5, 1) [D loss: (5.8247)(R 28.4566, F -22.8011, G 0.0169)] [G loss: 20.1012]\n",
      "2624 (5, 1) [D loss: (-7.4103)(R 21.5851, F -29.1144, G 0.0119)] [G loss: 34.2758]\n",
      "2625 (5, 1) [D loss: (13.3428)(R 45.5117, F -32.2394, G 0.0071)] [G loss: 40.6498]\n",
      "2626 (5, 1) [D loss: (-1.9225)(R 45.4933, F -47.4550, G 0.0039)] [G loss: 44.2154]\n",
      "2627 (5, 1) [D loss: (-0.9504)(R 38.3443, F -39.3255, G 0.0031)] [G loss: 40.5823]\n",
      "2628 (5, 1) [D loss: (-23.7894)(R 28.3809, F -52.2152, G 0.0045)] [G loss: 38.3910]\n",
      "2629 (5, 1) [D loss: (-11.4304)(R 61.2012, F -72.7528, G 0.0121)] [G loss: 67.5668]\n",
      "2630 (5, 1) [D loss: (-3.9399)(R 78.6834, F -82.6772, G 0.0054)] [G loss: 58.2210]\n",
      "2631 (5, 1) [D loss: (-12.8915)(R 57.7145, F -70.8013, G 0.0195)] [G loss: 77.9213]\n",
      "2632 (5, 1) [D loss: (-9.7867)(R 63.3479, F -73.1871, G 0.0052)] [G loss: 61.7776]\n",
      "2633 (5, 1) [D loss: (-0.1660)(R 68.1564, F -68.3661, G 0.0044)] [G loss: 82.7176]\n",
      "2634 (5, 1) [D loss: (-0.7553)(R 68.2210, F -69.0681, G 0.0092)] [G loss: 78.8878]\n",
      "2635 (5, 1) [D loss: (10.5207)(R 71.0450, F -60.5634, G 0.0039)] [G loss: 61.4320]\n",
      "2636 (5, 1) [D loss: (-6.6760)(R 72.1278, F -78.9030, G 0.0099)] [G loss: 77.8889]\n",
      "2637 (5, 1) [D loss: (-17.9154)(R 77.7756, F -95.7790, G 0.0088)] [G loss: 93.7885]\n",
      "2638 (5, 1) [D loss: (2.1414)(R 106.6866, F -104.6723, G 0.0127)] [G loss: 100.2826]\n",
      "2639 (5, 1) [D loss: (-8.2880)(R 86.7957, F -95.1436, G 0.0060)] [G loss: 85.4315]\n",
      "2640 (5, 1) [D loss: (-6.8439)(R 104.9667, F -111.9212, G 0.0111)] [G loss: 123.9278]\n",
      "2641 (5, 1) [D loss: (-3.3301)(R 109.6656, F -113.0396, G 0.0044)] [G loss: 108.6256]\n",
      "2642 (5, 1) [D loss: (-7.2860)(R 79.8989, F -87.2678, G 0.0083)] [G loss: 84.5457]\n",
      "2643 (5, 1) [D loss: (-13.7343)(R 115.4980, F -129.3692, G 0.0137)] [G loss: 106.9827]\n",
      "2644 (5, 1) [D loss: (-0.5397)(R 87.9909, F -88.6725, G 0.0142)] [G loss: 99.5380]\n",
      "2645 (5, 1) [D loss: (6.1068)(R 106.9900, F -100.9905, G 0.0107)] [G loss: 93.6510]\n",
      "2646 (5, 1) [D loss: (21.1609)(R 109.1526, F -88.0412, G 0.0049)] [G loss: 88.0674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2647 (5, 1) [D loss: (4.2806)(R 111.6397, F -107.4043, G 0.0045)] [G loss: 121.6014]\n",
      "2648 (5, 1) [D loss: (5.7120)(R 100.1681, F -94.4907, G 0.0035)] [G loss: 123.1108]\n",
      "2649 (5, 1) [D loss: (-12.8608)(R 104.7849, F -117.7488, G 0.0103)] [G loss: 97.4626]\n",
      "2650 (5, 1) [D loss: (-5.0831)(R 126.8499, F -132.0464, G 0.0113)] [G loss: 160.1690]\n",
      "2651 (5, 1) [D loss: (-15.1399)(R 129.8818, F -145.0960, G 0.0074)] [G loss: 132.7214]\n",
      "2652 (5, 1) [D loss: (-7.3100)(R 139.3403, F -146.7240, G 0.0074)] [G loss: 152.6888]\n",
      "2653 (5, 1) [D loss: (-2.2356)(R 144.8052, F -147.0915, G 0.0051)] [G loss: 130.5517]\n",
      "2654 (5, 1) [D loss: (-1.2375)(R 115.2229, F -116.5185, G 0.0058)] [G loss: 142.4915]\n",
      "2655 (5, 1) [D loss: (51.7635)(R 152.5187, F -100.9153, G 0.0160)] [G loss: 108.2980]\n",
      "2656 (5, 1) [D loss: (22.1480)(R 125.5691, F -103.5333, G 0.0112)] [G loss: 120.0132]\n",
      "2657 (5, 1) [D loss: (26.6419)(R 145.9284, F -119.3946, G 0.0108)] [G loss: 119.0991]\n",
      "2658 (5, 1) [D loss: (14.0374)(R 136.9714, F -123.0378, G 0.0104)] [G loss: 127.7809]\n",
      "2659 (5, 1) [D loss: (17.5815)(R 140.8747, F -123.3725, G 0.0079)] [G loss: 99.4869]\n",
      "2660 (5, 1) [D loss: (28.8508)(R 146.5749, F -117.8771, G 0.0153)] [G loss: 119.4873]\n",
      "2661 (5, 1) [D loss: (-12.8269)(R 111.0430, F -123.9265, G 0.0057)] [G loss: 114.4658]\n",
      "2662 (5, 1) [D loss: (-30.5590)(R 90.9400, F -121.5873, G 0.0088)] [G loss: 126.4828]\n",
      "2663 (5, 1) [D loss: (-20.3382)(R 117.5209, F -138.1489, G 0.0290)] [G loss: 131.2545]\n",
      "2664 (5, 1) [D loss: (-20.0071)(R 109.3209, F -129.4152, G 0.0087)] [G loss: 139.8058]\n",
      "2665 (5, 1) [D loss: (6.9037)(R 129.0967, F -122.3385, G 0.0145)] [G loss: 117.9364]\n",
      "2666 (5, 1) [D loss: (-4.8318)(R 126.9337, F -131.8509, G 0.0085)] [G loss: 110.1123]\n",
      "2667 (5, 1) [D loss: (12.0016)(R 126.8708, F -114.9387, G 0.0070)] [G loss: 88.4622]\n",
      "2668 (5, 1) [D loss: (-5.9177)(R 96.8093, F -102.9360, G 0.0209)] [G loss: 108.2199]\n",
      "2669 (5, 1) [D loss: (1.2383)(R 109.7005, F -108.7528, G 0.0291)] [G loss: 74.8001]\n",
      "2670 (5, 1) [D loss: (5.7394)(R 110.0462, F -104.3527, G 0.0046)] [G loss: 82.8659]\n",
      "2671 (5, 1) [D loss: (-22.3584)(R 96.0158, F -118.4397, G 0.0065)] [G loss: 106.4604]\n",
      "2672 (5, 1) [D loss: (8.2836)(R 107.9030, F -99.6648, G 0.0045)] [G loss: 106.3968]\n",
      "2673 (5, 1) [D loss: (4.5325)(R 108.5596, F -104.0730, G 0.0046)] [G loss: 97.5246]\n",
      "2674 (5, 1) [D loss: (19.9522)(R 96.5940, F -76.6952, G 0.0053)] [G loss: 89.2978]\n",
      "2675 (5, 1) [D loss: (-10.8021)(R 64.5452, F -75.4063, G 0.0059)] [G loss: 87.1493]\n",
      "2676 (5, 1) [D loss: (15.2049)(R 79.5781, F -64.4622, G 0.0089)] [G loss: 79.7978]\n",
      "2677 (5, 1) [D loss: (2.3090)(R 101.0915, F -98.8861, G 0.0104)] [G loss: 103.2509]\n",
      "2678 (5, 1) [D loss: (0.0421)(R 106.6556, F -106.6976, G 0.0084)] [G loss: 107.3302]\n",
      "2679 (5, 1) [D loss: (-9.8809)(R 90.8182, F -100.9367, G 0.0238)] [G loss: 103.5409]\n",
      "2680 (5, 1) [D loss: (10.0039)(R 90.9112, F -81.0834, G 0.0176)] [G loss: 110.4641]\n",
      "2681 (5, 1) [D loss: (-17.2425)(R 87.0357, F -104.4324, G 0.0154)] [G loss: 87.4788]\n",
      "2682 (5, 1) [D loss: (-5.3744)(R 97.8824, F -103.4004, G 0.0144)] [G loss: 95.5115]\n",
      "2683 (5, 1) [D loss: (-10.3246)(R 93.4083, F -103.8420, G 0.0109)] [G loss: 126.1494]\n",
      "2684 (5, 1) [D loss: (-25.0833)(R 93.4458, F -118.6124, G 0.0083)] [G loss: 113.1258]\n",
      "2685 (5, 1) [D loss: (-1.6815)(R 115.1517, F -117.1212, G 0.0288)] [G loss: 112.4194]\n",
      "2686 (5, 1) [D loss: (19.9938)(R 132.5898, F -112.6959, G 0.0100)] [G loss: 104.8741]\n",
      "2687 (5, 1) [D loss: (-5.1364)(R 114.7217, F -119.8838, G 0.0026)] [G loss: 72.1080]\n",
      "2688 (5, 1) [D loss: (-11.1957)(R 88.9334, F -100.1764, G 0.0047)] [G loss: 39.8361]\n",
      "2689 (5, 1) [D loss: (1.9453)(R 81.2836, F -79.4360, G 0.0098)] [G loss: 63.8526]\n",
      "2690 (5, 1) [D loss: (1.0575)(R 73.5868, F -72.8200, G 0.0291)] [G loss: 65.0240]\n",
      "2691 (5, 1) [D loss: (5.8107)(R 74.3605, F -68.9137, G 0.0364)] [G loss: 58.6438]\n",
      "2692 (5, 1) [D loss: (11.4628)(R 71.1980, F -60.0480, G 0.0313)] [G loss: 51.5080]\n",
      "2693 (5, 1) [D loss: (-7.6816)(R 63.7566, F -71.5290, G 0.0091)] [G loss: 72.7957]\n",
      "2694 (5, 1) [D loss: (-4.6047)(R 81.1672, F -85.8125, G 0.0041)] [G loss: 98.0091]\n",
      "2695 (5, 1) [D loss: (2.8269)(R 82.4047, F -79.6823, G 0.0104)] [G loss: 73.5640]\n",
      "2696 (5, 1) [D loss: (2.0380)(R 90.1599, F -88.1680, G 0.0046)] [G loss: 74.3594]\n",
      "2697 (5, 1) [D loss: (-5.9777)(R 72.0863, F -78.1109, G 0.0047)] [G loss: 84.7354]\n",
      "2698 (5, 1) [D loss: (-3.9483)(R 66.8687, F -70.8923, G 0.0075)] [G loss: 69.5969]\n",
      "2699 (5, 1) [D loss: (-3.8923)(R 64.3466, F -68.3440, G 0.0105)] [G loss: 64.5475]\n",
      "2700 (5, 1) [D loss: (-1.0288)(R 64.5145, F -65.6818, G 0.0138)] [G loss: 67.3505]\n",
      "2701 (5, 1) [D loss: (2.4147)(R 57.8739, F -55.6205, G 0.0161)] [G loss: 59.2509]\n",
      "2702 (5, 1) [D loss: (1.5667)(R 57.3000, F -55.7770, G 0.0044)] [G loss: 47.5894]\n",
      "2703 (5, 1) [D loss: (9.5193)(R 66.2073, F -56.7539, G 0.0066)] [G loss: 52.5392]\n",
      "2704 (5, 1) [D loss: (9.2271)(R 60.9121, F -51.8617, G 0.0177)] [G loss: 52.0427]\n",
      "2705 (5, 1) [D loss: (11.3629)(R 51.7917, F -40.5805, G 0.0152)] [G loss: 53.1751]\n",
      "2706 (5, 1) [D loss: (16.1193)(R 86.6618, F -70.5925, G 0.0050)] [G loss: 58.7717]\n",
      "2707 (5, 1) [D loss: (-8.4632)(R 47.3609, F -55.8721, G 0.0048)] [G loss: 62.8862]\n",
      "2708 (5, 1) [D loss: (3.2472)(R 70.0023, F -66.8091, G 0.0054)] [G loss: 58.1685]\n",
      "2709 (5, 1) [D loss: (6.9613)(R 53.4614, F -46.5926, G 0.0092)] [G loss: 54.8857]\n",
      "2710 (5, 1) [D loss: (-12.1407)(R 37.6330, F -49.8926, G 0.0119)] [G loss: 39.9790]\n",
      "2711 (5, 1) [D loss: (1.2081)(R 30.0393, F -28.9077, G 0.0077)] [G loss: 45.0159]\n",
      "2712 (5, 1) [D loss: (-17.6492)(R 40.8512, F -59.0985, G 0.0598)] [G loss: 54.9870]\n",
      "2713 (5, 1) [D loss: (-7.1418)(R 57.0634, F -64.2418, G 0.0037)] [G loss: 63.9382]\n",
      "2714 (5, 1) [D loss: (-15.1696)(R 38.9649, F -54.3098, G 0.0175)] [G loss: 59.2247]\n",
      "2715 (5, 1) [D loss: (6.5819)(R 39.9459, F -33.4742, G 0.0110)] [G loss: 31.6663]\n",
      "2716 (5, 1) [D loss: (-2.3430)(R 39.2678, F -41.6998, G 0.0089)] [G loss: 41.7340]\n",
      "2717 (5, 1) [D loss: (-4.2988)(R 37.9438, F -42.2850, G 0.0042)] [G loss: 54.6353]\n",
      "2718 (5, 1) [D loss: (13.1642)(R 50.1645, F -37.0465, G 0.0046)] [G loss: 43.6135]\n",
      "2719 (5, 1) [D loss: (-2.2361)(R 34.5503, F -37.0925, G 0.0306)] [G loss: 37.1459]\n",
      "2720 (5, 1) [D loss: (4.0550)(R 51.1913, F -47.2894, G 0.0153)] [G loss: 50.8539]\n",
      "2721 (5, 1) [D loss: (-0.4284)(R 59.1110, F -59.6085, G 0.0069)] [G loss: 65.9863]\n",
      "2722 (5, 1) [D loss: (4.3191)(R 63.2739, F -59.0625, G 0.0108)] [G loss: 63.7506]\n",
      "2723 (5, 1) [D loss: (3.2817)(R 102.7019, F -99.4383, G 0.0018)] [G loss: 85.0686]\n",
      "2724 (5, 1) [D loss: (-15.5200)(R 87.3436, F -102.9904, G 0.0127)] [G loss: 102.1295]\n",
      "2725 (5, 1) [D loss: (-4.6820)(R 89.4783, F -94.3451, G 0.0185)] [G loss: 110.9471]\n",
      "2726 (5, 1) [D loss: (-31.3869)(R 98.5164, F -130.1430, G 0.0240)] [G loss: 132.3261]\n",
      "2727 (5, 1) [D loss: (44.4941)(R 125.2419, F -80.8139, G 0.0066)] [G loss: 93.0219]\n",
      "2728 (5, 1) [D loss: (10.6358)(R 111.6235, F -101.0774, G 0.0090)] [G loss: 91.5851]\n",
      "2729 (5, 1) [D loss: (-4.0070)(R 84.1220, F -88.1676, G 0.0039)] [G loss: 84.3074]\n",
      "2730 (5, 1) [D loss: (-16.1545)(R 79.3695, F -95.5737, G 0.0050)] [G loss: 82.9372]\n",
      "2731 (5, 1) [D loss: (5.7305)(R 99.3755, F -93.7619, G 0.0117)] [G loss: 103.1562]\n",
      "2732 (5, 1) [D loss: (-16.6725)(R 86.1020, F -102.8733, G 0.0099)] [G loss: 89.7936]\n",
      "2733 (5, 1) [D loss: (-0.5883)(R 95.8288, F -96.5188, G 0.0102)] [G loss: 99.0376]\n",
      "2734 (5, 1) [D loss: (-25.9183)(R 94.6409, F -120.6463, G 0.0087)] [G loss: 90.2402]\n",
      "2735 (5, 1) [D loss: (10.6820)(R 127.2596, F -116.6654, G 0.0088)] [G loss: 125.5636]\n",
      "2736 (5, 1) [D loss: (-13.6671)(R 127.5639, F -141.2838, G 0.0053)] [G loss: 107.7591]\n",
      "2737 (5, 1) [D loss: (11.1740)(R 145.2785, F -134.4555, G 0.0351)] [G loss: 151.2472]\n",
      "2738 (5, 1) [D loss: (-16.0426)(R 148.7678, F -165.4195, G 0.0609)] [G loss: 175.9241]\n",
      "2739 (5, 1) [D loss: (-3.0237)(R 189.0099, F -192.1622, G 0.0129)] [G loss: 181.9602]\n",
      "2740 (5, 1) [D loss: (23.1180)(R 149.7479, F -126.6621, G 0.0032)] [G loss: 143.9242]\n",
      "2741 (5, 1) [D loss: (14.3547)(R 134.8210, F -120.5415, G 0.0075)] [G loss: 115.9300]\n",
      "2742 (5, 1) [D loss: (28.9089)(R 122.9323, F -94.1479, G 0.0125)] [G loss: 127.3769]\n",
      "2743 (5, 1) [D loss: (1.7948)(R 87.3610, F -85.7230, G 0.0157)] [G loss: 94.5209]\n",
      "2744 (5, 1) [D loss: (3.7155)(R 75.1286, F -71.4835, G 0.0070)] [G loss: 75.9823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2745 (5, 1) [D loss: (-14.3834)(R 71.6740, F -86.1177, G 0.0060)] [G loss: 64.2389]\n",
      "2746 (5, 1) [D loss: (7.8628)(R 83.8552, F -76.0859, G 0.0094)] [G loss: 91.2568]\n",
      "2747 (5, 1) [D loss: (8.5701)(R 77.6406, F -69.1512, G 0.0081)] [G loss: 73.4533]\n",
      "2748 (5, 1) [D loss: (12.6287)(R 68.5778, F -55.9720, G 0.0023)] [G loss: 66.7245]\n",
      "2749 (5, 1) [D loss: (-10.6345)(R 48.4397, F -59.1127, G 0.0039)] [G loss: 65.8803]\n",
      "2750 (5, 1) [D loss: (-15.1498)(R 40.0361, F -55.2289, G 0.0043)] [G loss: 57.2597]\n",
      "2751 (5, 1) [D loss: (5.9319)(R 42.7052, F -36.8253, G 0.0052)] [G loss: 55.5605]\n",
      "2752 (5, 1) [D loss: (-7.2573)(R 65.6049, F -72.9339, G 0.0072)] [G loss: 67.6018]\n",
      "2753 (5, 1) [D loss: (-16.6165)(R 67.9079, F -84.5832, G 0.0059)] [G loss: 97.1876]\n",
      "2754 (5, 1) [D loss: (-1.6910)(R 101.0150, F -102.8068, G 0.0101)] [G loss: 88.1406]\n",
      "2755 (5, 1) [D loss: (-0.1521)(R 115.0305, F -115.2573, G 0.0075)] [G loss: 110.8335]\n",
      "2756 (5, 1) [D loss: (4.2120)(R 102.5103, F -98.4783, G 0.0180)] [G loss: 80.5126]\n",
      "2757 (5, 1) [D loss: (-15.5893)(R 98.4465, F -114.1894, G 0.0154)] [G loss: 127.1365]\n",
      "2758 (5, 1) [D loss: (-5.0818)(R 112.7923, F -118.0372, G 0.0163)] [G loss: 126.3400]\n",
      "2759 (5, 1) [D loss: (-36.3047)(R 94.6577, F -131.0303, G 0.0068)] [G loss: 127.4975]\n",
      "2760 (5, 1) [D loss: (19.1232)(R 141.2616, F -122.2017, G 0.0063)] [G loss: 110.3838]\n",
      "2761 (5, 1) [D loss: (2.7595)(R 157.9668, F -155.2997, G 0.0092)] [G loss: 142.7751]\n",
      "2762 (5, 1) [D loss: (38.0167)(R 147.6900, F -109.7742, G 0.0101)] [G loss: 130.3894]\n",
      "2763 (5, 1) [D loss: (1.3189)(R 122.6061, F -121.8298, G 0.0543)] [G loss: 77.9443]\n",
      "2764 (5, 1) [D loss: (-3.9121)(R 144.6631, F -148.6358, G 0.0061)] [G loss: 114.5143]\n",
      "2765 (5, 1) [D loss: (-13.8850)(R 117.7668, F -131.9553, G 0.0303)] [G loss: 116.2695]\n",
      "2766 (5, 1) [D loss: (-36.6259)(R 93.7034, F -130.3909, G 0.0062)] [G loss: 111.8996]\n",
      "2767 (5, 1) [D loss: (25.4561)(R 139.8413, F -114.4416, G 0.0056)] [G loss: 118.8550]\n",
      "2768 (5, 1) [D loss: (-0.9964)(R 112.6032, F -113.6464, G 0.0047)] [G loss: 106.3511]\n",
      "2769 (5, 1) [D loss: (15.6582)(R 115.3422, F -99.7589, G 0.0075)] [G loss: 89.5095]\n",
      "2770 (5, 1) [D loss: (2.4112)(R 79.4435, F -77.0892, G 0.0057)] [G loss: 69.2299]\n",
      "2771 (5, 1) [D loss: (11.9137)(R 108.2249, F -96.3733, G 0.0062)] [G loss: 106.9045]\n",
      "2772 (5, 1) [D loss: (7.7288)(R 118.8764, F -111.2301, G 0.0083)] [G loss: 89.9243]\n",
      "2773 (5, 1) [D loss: (-11.3270)(R 78.8735, F -90.2592, G 0.0059)] [G loss: 119.4996]\n",
      "2774 (5, 1) [D loss: (-21.8678)(R 79.5575, F -101.5439, G 0.0119)] [G loss: 86.5246]\n",
      "2775 (5, 1) [D loss: (5.7152)(R 95.2537, F -89.6331, G 0.0095)] [G loss: 98.7799]\n",
      "2776 (5, 1) [D loss: (-43.5335)(R 108.6195, F -152.2688, G 0.0116)] [G loss: 112.7180]\n",
      "2777 (5, 1) [D loss: (-37.9543)(R 120.5191, F -158.6123, G 0.0139)] [G loss: 134.3667]\n",
      "2778 (5, 1) [D loss: (-4.5188)(R 121.6500, F -126.2487, G 0.0080)] [G loss: 132.4035]\n",
      "2779 (5, 1) [D loss: (31.5171)(R 144.5149, F -113.2211, G 0.0223)] [G loss: 132.9939]\n",
      "2780 (5, 1) [D loss: (-25.1479)(R 161.4560, F -187.1578, G 0.0554)] [G loss: 134.3130]\n",
      "2781 (5, 1) [D loss: (-8.3760)(R 146.6225, F -155.2232, G 0.0225)] [G loss: 159.2498]\n",
      "2782 (5, 1) [D loss: (-3.5974)(R 154.2517, F -158.0353, G 0.0186)] [G loss: 136.2296]\n",
      "2783 (5, 1) [D loss: (32.4599)(R 174.8659, F -142.5409, G 0.0135)] [G loss: 154.4937]\n",
      "2784 (5, 1) [D loss: (-43.0757)(R 172.1659, F -215.7017, G 0.0460)] [G loss: 217.0449]\n",
      "2785 (5, 1) [D loss: (38.0288)(R 207.5087, F -169.7164, G 0.0237)] [G loss: 121.2928]\n",
      "2786 (5, 1) [D loss: (-26.0601)(R 143.2032, F -169.5187, G 0.0255)] [G loss: 191.4482]\n",
      "2787 (5, 1) [D loss: (-17.5909)(R 129.8727, F -147.5992, G 0.0136)] [G loss: 147.7953]\n",
      "2788 (5, 1) [D loss: (12.9088)(R 137.9102, F -125.0858, G 0.0084)] [G loss: 144.3176]\n",
      "2789 (5, 1) [D loss: (-24.0376)(R 143.2058, F -167.2972, G 0.0054)] [G loss: 111.8868]\n",
      "2790 (5, 1) [D loss: (-27.6759)(R 104.8682, F -132.6131, G 0.0069)] [G loss: 105.9914]\n",
      "2791 (5, 1) [D loss: (30.5339)(R 143.6576, F -113.3817, G 0.0258)] [G loss: 99.8799]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/JKP/Generative_Model_Drill/models/WGANGP.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, n_critic, using_generator)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/JKP/Generative_Model_Drill/models/WGANGP.py\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(self, x_train, batch_size, using_generator)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jktest3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1061\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jktest3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.conda/envs/jktest3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.5, label = 'D_Loss')\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.75, label = 'D_Loss_Real')\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.5, label = 'D_Loss_Fake')\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.5, label = \"G_Loss\")\n",
    "\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=18)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "plt.ylim(-100, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "0 (5, 1) [D loss: (8.9632)(R -0.0996, F -0.0005, G 0.9063)] [G loss: -0.0136]\n",
      "1 (5, 1) [D loss: (8.7713)(R -0.2295, F -0.0021, G 0.9003)] [G loss: -0.0328]\n",
      "2 (5, 1) [D loss: (8.4407)(R -0.4510, F -0.0032, G 0.8895)] [G loss: -0.0573]\n",
      "3 (5, 1) [D loss: (7.8783)(R -0.8313, F -0.0032, G 0.8713)] [G loss: -0.1148]\n",
      "4 (5, 1) [D loss: (6.8045)(R -1.5560, F -0.0025, G 0.8363)] [G loss: -0.2238]\n",
      "5 (5, 1) [D loss: (4.7131)(R -2.9330, F 0.0053, G 0.7641)] [G loss: -0.4357]\n",
      "6 (5, 1) [D loss: (1.2587)(R -5.2087, F 0.0187, G 0.6449)] [G loss: -0.8880]\n",
      "7 (5, 1) [D loss: (-4.6702)(R -9.3259, F 0.0194, G 0.4636)] [G loss: -1.7742]\n",
      "8 (5, 1) [D loss: (-12.9915)(R -15.4043, F 0.0184, G 0.2394)] [G loss: -3.3896]\n",
      "9 (5, 1) [D loss: (-22.5948)(R -23.1334, F -0.0845, G 0.0623)] [G loss: -5.8812]\n",
      "10 (5, 1) [D loss: (-33.7989)(R -33.5714, F -0.4201, G 0.0193)] [G loss: -9.4881]\n",
      "11 (5, 1) [D loss: (-45.1765)(R -47.3153, F -0.6548, G 0.2794)] [G loss: -13.9784]\n",
      "12 (5, 1) [D loss: (-54.1901)(R -60.8503, F -1.3805, G 0.8041)] [G loss: -18.8100]\n",
      "13 (5, 1) [D loss: (-58.6189)(R -70.9242, F -2.8226, G 1.5128)] [G loss: -24.0798]\n",
      "14 (5, 1) [D loss: (-63.5250)(R -80.8163, F -4.7414, G 2.2033)] [G loss: -27.6213]\n",
      "15 (5, 1) [D loss: (-67.0113)(R -86.6143, F -6.2111, G 2.5814)] [G loss: -29.8375]\n",
      "16 (5, 1) [D loss: (-73.8820)(R -90.9978, F -10.9900, G 2.8106)] [G loss: -31.0027]\n",
      "17 (5, 1) [D loss: (-77.9035)(R -95.1678, F -16.1098, G 3.3374)] [G loss: -31.3529]\n",
      "18 (5, 1) [D loss: (-82.9127)(R -98.4699, F -22.1729, G 3.7730)] [G loss: -32.0775]\n",
      "19 (5, 1) [D loss: (-89.3586)(R -100.1438, F -28.9823, G 3.9768)] [G loss: -31.0672]\n",
      "20 (5, 1) [D loss: (-92.9873)(R -102.0742, F -36.7085, G 4.5795)] [G loss: -32.0286]\n",
      "21 (5, 1) [D loss: (-98.4782)(R -104.5933, F -41.6490, G 4.7764)] [G loss: -31.8538]\n",
      "22 (5, 1) [D loss: (-104.1221)(R -105.7858, F -47.1390, G 4.8803)] [G loss: -32.3295]\n",
      "23 (5, 1) [D loss: (-104.2454)(R -106.2641, F -50.0663, G 5.2085)] [G loss: -34.6767]\n",
      "24 (5, 1) [D loss: (-107.4297)(R -107.4084, F -60.3612, G 6.0340)] [G loss: -33.5402]\n",
      "25 (5, 1) [D loss: (-109.0148)(R -104.4862, F -58.4525, G 5.3924)] [G loss: -32.2944]\n",
      "26 (5, 1) [D loss: (-118.9869)(R -106.1703, F -66.2066, G 5.3390)] [G loss: -32.3735]\n",
      "27 (5, 1) [D loss: (-122.6541)(R -106.8368, F -71.2169, G 5.5400)] [G loss: -31.0299]\n",
      "28 (5, 1) [D loss: (-118.8493)(R -106.1793, F -69.3154, G 5.6645)] [G loss: -32.8344]\n",
      "29 (5, 1) [D loss: (-118.4996)(R -106.1186, F -72.0812, G 5.9700)] [G loss: -31.7901]\n",
      "30 (5, 1) [D loss: (-119.4217)(R -104.6133, F -68.3452, G 5.3537)] [G loss: -31.1270]\n",
      "31 (5, 1) [D loss: (-123.9528)(R -106.2339, F -69.1411, G 5.1422)] [G loss: -30.2345]\n",
      "32 (5, 1) [D loss: (-118.0471)(R -107.7184, F -67.8643, G 5.7536)] [G loss: -33.1557]\n",
      "33 (5, 1) [D loss: (-115.8120)(R -106.6084, F -64.8839, G 5.5680)] [G loss: -33.0460]\n",
      "34 (5, 1) [D loss: (-111.6181)(R -102.6252, F -65.1086, G 5.6116)] [G loss: -29.6313]\n",
      "35 (5, 1) [D loss: (-108.7096)(R -103.6428, F -59.0191, G 5.3952)] [G loss: -32.7284]\n",
      "36 (5, 1) [D loss: (-109.4418)(R -103.5028, F -60.0077, G 5.4069)] [G loss: -29.6006]\n",
      "37 (5, 1) [D loss: (-109.2375)(R -104.5339, F -55.6557, G 5.0952)] [G loss: -30.8311]\n",
      "38 (5, 1) [D loss: (-103.2539)(R -100.1706, F -52.3761, G 4.9293)] [G loss: -28.7431]\n",
      "39 (5, 1) [D loss: (-103.9150)(R -98.9436, F -53.1534, G 4.8182)] [G loss: -26.3992]\n",
      "40 (5, 1) [D loss: (-95.0618)(R -94.4431, F -49.5644, G 4.8946)] [G loss: -23.9054]\n",
      "41 (5, 1) [D loss: (-97.1296)(R -93.3749, F -50.5238, G 4.6769)] [G loss: -23.8386]\n",
      "42 (5, 1) [D loss: (-90.9481)(R -93.3440, F -42.0492, G 4.4445)] [G loss: -23.3534]\n",
      "43 (5, 1) [D loss: (-87.0244)(R -90.2148, F -38.9097, G 4.2100)] [G loss: -22.1478]\n",
      "44 (5, 1) [D loss: (-82.5223)(R -87.6550, F -37.0543, G 4.2187)] [G loss: -19.4718]\n",
      "45 (5, 1) [D loss: (-85.9428)(R -85.8525, F -37.4882, G 3.7398)] [G loss: -20.1745]\n",
      "46 (5, 1) [D loss: (-82.6662)(R -82.9256, F -33.3155, G 3.3575)] [G loss: -17.1188]\n",
      "47 (5, 1) [D loss: (-76.5679)(R -81.3902, F -29.1216, G 3.3944)] [G loss: -16.6321]\n",
      "48 (5, 1) [D loss: (-72.3880)(R -81.2549, F -26.2534, G 3.5120)] [G loss: -17.0513]\n",
      "49 (5, 1) [D loss: (-75.0547)(R -81.6219, F -27.1848, G 3.3752)] [G loss: -16.9345]\n",
      "50 (5, 1) [D loss: (-72.2141)(R -79.0278, F -26.0422, G 3.2856)] [G loss: -15.1205]\n",
      "51 (5, 1) [D loss: (-67.6915)(R -75.1742, F -21.2222, G 2.8705)] [G loss: -14.2603]\n",
      "52 (5, 1) [D loss: (-65.9318)(R -75.4844, F -19.2679, G 2.8820)] [G loss: -15.9327]\n",
      "53 (5, 1) [D loss: (-61.0578)(R -73.3152, F -15.7867, G 2.8044)] [G loss: -14.5452]\n",
      "54 (5, 1) [D loss: (-60.9287)(R -72.7859, F -14.6214, G 2.6479)] [G loss: -14.5694]\n",
      "55 (5, 1) [D loss: (-60.8573)(R -72.0384, F -14.6723, G 2.5853)] [G loss: -14.6254]\n",
      "56 (5, 1) [D loss: (-58.7998)(R -70.2523, F -11.2411, G 2.2694)] [G loss: -13.6326]\n",
      "57 (5, 1) [D loss: (-57.3135)(R -71.1607, F -9.6942, G 2.3541)] [G loss: -13.5108]\n",
      "58 (5, 1) [D loss: (-55.8459)(R -68.7330, F -9.2689, G 2.2156)] [G loss: -13.3282]\n",
      "59 (5, 1) [D loss: (-50.1381)(R -66.5313, F -6.2742, G 2.2667)] [G loss: -13.5265]\n",
      "60 (5, 1) [D loss: (-49.5703)(R -67.7272, F -3.0605, G 2.1217)] [G loss: -13.8907]\n",
      "61 (5, 1) [D loss: (-50.3972)(R -65.9389, F -3.8220, G 1.9364)] [G loss: -13.3675]\n",
      "62 (5, 1) [D loss: (-49.2503)(R -66.6356, F -3.0096, G 2.0395)] [G loss: -14.9138]\n",
      "63 (5, 1) [D loss: (-46.1533)(R -66.5638, F 0.9883, G 1.9422)] [G loss: -15.4584]\n",
      "64 (5, 1) [D loss: (-44.6859)(R -63.4640, F 1.2932, G 1.7485)] [G loss: -14.7795]\n",
      "65 (5, 1) [D loss: (-45.1520)(R -65.6768, F 2.9177, G 1.7607)] [G loss: -15.3264]\n",
      "66 (5, 1) [D loss: (-43.6130)(R -65.2249, F 4.6277, G 1.6984)] [G loss: -15.6859]\n",
      "67 (5, 1) [D loss: (-44.2833)(R -62.9580, F 3.2428, G 1.5432)] [G loss: -15.6037]\n",
      "68 (5, 1) [D loss: (-39.0933)(R -64.1642, F 8.5384, G 1.6532)] [G loss: -16.5617]\n",
      "69 (5, 1) [D loss: (-39.3289)(R -61.6064, F 7.6302, G 1.4647)] [G loss: -15.7566]\n",
      "70 (5, 1) [D loss: (-35.8799)(R -59.3028, F 9.2821, G 1.4141)] [G loss: -15.1176]\n",
      "71 (5, 1) [D loss: (-38.0717)(R -60.7681, F 9.2879, G 1.3409)] [G loss: -15.7511]\n",
      "72 (5, 1) [D loss: (-38.0609)(R -60.5026, F 8.3808, G 1.4061)] [G loss: -15.7459]\n",
      "73 (5, 1) [D loss: (-36.9375)(R -58.8649, F 9.3102, G 1.2617)] [G loss: -15.6753]\n",
      "74 (5, 1) [D loss: (-37.4154)(R -59.8900, F 9.5123, G 1.2962)] [G loss: -16.6536]\n",
      "75 (5, 1) [D loss: (-36.5057)(R -58.3078, F 9.5241, G 1.2278)] [G loss: -15.5814]\n",
      "76 (5, 1) [D loss: (-35.0634)(R -59.1068, F 10.9632, G 1.3080)] [G loss: -15.9976]\n",
      "77 (5, 1) [D loss: (-37.8023)(R -58.4774, F 8.6000, G 1.2075)] [G loss: -15.2837]\n",
      "78 (5, 1) [D loss: (-35.4443)(R -57.6421, F 9.8651, G 1.2333)] [G loss: -15.1754]\n",
      "79 (5, 1) [D loss: (-35.0367)(R -56.5736, F 9.4197, G 1.2117)] [G loss: -15.2777]\n",
      "80 (5, 1) [D loss: (-32.4813)(R -55.1636, F 10.8755, G 1.1807)] [G loss: -14.9724]\n",
      "81 (5, 1) [D loss: (-35.0882)(R -55.5016, F 9.1792, G 1.1234)] [G loss: -14.5457]\n",
      "82 (5, 1) [D loss: (-34.2661)(R -56.3796, F 11.2850, G 1.0828)] [G loss: -15.4265]\n",
      "83 (5, 1) [D loss: (-33.1300)(R -54.6660, F 10.9085, G 1.0627)] [G loss: -14.9120]\n",
      "84 (5, 1) [D loss: (-33.2640)(R -54.8872, F 10.9798, G 1.0644)] [G loss: -15.1907]\n",
      "85 (5, 1) [D loss: (-33.3780)(R -55.4025, F 11.2614, G 1.0763)] [G loss: -15.7380]\n",
      "86 (5, 1) [D loss: (-33.6090)(R -55.2696, F 11.4810, G 1.0180)] [G loss: -15.7108]\n",
      "87 (5, 1) [D loss: (-31.7052)(R -54.7341, F 12.3712, G 1.0658)] [G loss: -14.9216]\n",
      "88 (5, 1) [D loss: (-29.9178)(R -52.3155, F 12.1584, G 1.0239)] [G loss: -14.7954]\n",
      "89 (5, 1) [D loss: (-29.5148)(R -53.5630, F 13.2366, G 1.0811)] [G loss: -14.9998]\n",
      "90 (5, 1) [D loss: (-30.8773)(R -53.9855, F 12.7953, G 1.0313)] [G loss: -15.7593]\n",
      "91 (5, 1) [D loss: (-31.2709)(R -55.0957, F 13.4522, G 1.0373)] [G loss: -15.5438]\n",
      "92 (5, 1) [D loss: (-30.2310)(R -54.0881, F 14.0837, G 0.9773)] [G loss: -16.2440]\n",
      "93 (5, 1) [D loss: (-30.2855)(R -54.0469, F 14.4399, G 0.9321)] [G loss: -16.7170]\n",
      "94 (5, 1) [D loss: (-28.9782)(R -53.9896, F 15.8697, G 0.9142)] [G loss: -17.0552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 (5, 1) [D loss: (-29.1491)(R -53.0315, F 14.8320, G 0.9050)] [G loss: -17.4698]\n",
      "96 (5, 1) [D loss: (-29.0652)(R -54.4606, F 16.0239, G 0.9371)] [G loss: -17.0825]\n",
      "97 (5, 1) [D loss: (-26.0105)(R -52.6922, F 17.1303, G 0.9551)] [G loss: -18.2838]\n",
      "98 (5, 1) [D loss: (-28.9561)(R -54.7934, F 17.0441, G 0.8793)] [G loss: -18.6498]\n",
      "99 (5, 1) [D loss: (-27.5328)(R -53.1274, F 16.9952, G 0.8599)] [G loss: -17.5598]\n",
      "100 (5, 1) [D loss: (-27.9242)(R -54.3859, F 17.6867, G 0.8775)] [G loss: -19.6048]\n",
      "101 (5, 1) [D loss: (-28.2887)(R -55.6549, F 18.2539, G 0.9112)] [G loss: -19.7689]\n",
      "102 (5, 1) [D loss: (-27.8270)(R -54.5382, F 18.1889, G 0.8522)] [G loss: -19.6700]\n",
      "103 (5, 1) [D loss: (-27.6683)(R -54.3544, F 18.3931, G 0.8293)] [G loss: -19.6868]\n",
      "104 (5, 1) [D loss: (-26.6069)(R -54.5423, F 19.3938, G 0.8542)] [G loss: -20.1937]\n",
      "105 (5, 1) [D loss: (-26.4088)(R -55.2456, F 20.0867, G 0.8750)] [G loss: -21.2689]\n",
      "106 (5, 1) [D loss: (-26.4194)(R -54.3740, F 19.7851, G 0.8170)] [G loss: -21.1159]\n",
      "107 (5, 1) [D loss: (-27.8246)(R -54.9482, F 18.6950, G 0.8429)] [G loss: -21.6666]\n",
      "108 (5, 1) [D loss: (-25.5644)(R -53.4474, F 19.8324, G 0.8051)] [G loss: -20.3482]\n",
      "109 (5, 1) [D loss: (-26.8791)(R -54.2057, F 19.3692, G 0.7957)] [G loss: -20.4596]\n",
      "110 (5, 1) [D loss: (-26.4927)(R -56.4076, F 21.5806, G 0.8334)] [G loss: -21.7148]\n",
      "111 (5, 1) [D loss: (-26.6020)(R -54.2458, F 19.8290, G 0.7815)] [G loss: -21.3920]\n",
      "112 (5, 1) [D loss: (-26.1279)(R -53.7377, F 19.7704, G 0.7839)] [G loss: -21.1665]\n",
      "113 (5, 1) [D loss: (-24.4620)(R -52.3067, F 20.1368, G 0.7708)] [G loss: -20.8361]\n",
      "114 (5, 1) [D loss: (-24.8264)(R -53.9111, F 20.8651, G 0.8220)] [G loss: -20.9091]\n",
      "115 (5, 1) [D loss: (-25.9539)(R -52.7131, F 19.4253, G 0.7334)] [G loss: -20.6095]\n",
      "116 (5, 1) [D loss: (-25.0352)(R -55.0910, F 21.8748, G 0.8181)] [G loss: -22.1212]\n",
      "117 (5, 1) [D loss: (-24.4490)(R -52.0631, F 20.4847, G 0.7129)] [G loss: -21.3366]\n",
      "118 (5, 1) [D loss: (-24.9424)(R -52.8658, F 20.7416, G 0.7182)] [G loss: -21.5148]\n",
      "119 (5, 1) [D loss: (-24.1730)(R -53.6539, F 22.3487, G 0.7132)] [G loss: -21.8557]\n",
      "120 (5, 1) [D loss: (-23.4271)(R -52.2723, F 21.6171, G 0.7228)] [G loss: -21.7790]\n",
      "121 (5, 1) [D loss: (-24.6412)(R -53.4111, F 22.0671, G 0.6703)] [G loss: -21.8556]\n",
      "122 (5, 1) [D loss: (-21.9450)(R -52.0904, F 23.3432, G 0.6802)] [G loss: -22.3112]\n",
      "123 (5, 1) [D loss: (-22.6194)(R -53.2592, F 23.9136, G 0.6726)] [G loss: -23.5256]\n",
      "124 (5, 1) [D loss: (-22.7166)(R -52.9005, F 23.7614, G 0.6422)] [G loss: -24.1332]\n",
      "125 (5, 1) [D loss: (-20.6739)(R -53.1047, F 25.7838, G 0.6647)] [G loss: -24.4774]\n",
      "126 (5, 1) [D loss: (-22.8133)(R -56.7378, F 27.3271, G 0.6597)] [G loss: -26.8135]\n",
      "127 (5, 1) [D loss: (-20.5326)(R -53.8740, F 26.7847, G 0.6557)] [G loss: -26.0353]\n",
      "128 (5, 1) [D loss: (-20.2397)(R -54.2007, F 27.7434, G 0.6218)] [G loss: -26.0809]\n",
      "129 (5, 1) [D loss: (-20.1281)(R -54.1625, F 28.1455, G 0.5889)] [G loss: -27.1505]\n",
      "130 (5, 1) [D loss: (-21.6899)(R -56.9304, F 28.8477, G 0.6393)] [G loss: -28.4756]\n",
      "131 (5, 1) [D loss: (-19.8913)(R -56.2887, F 30.0111, G 0.6386)] [G loss: -28.3956]\n",
      "132 (5, 1) [D loss: (-21.5155)(R -56.4422, F 28.7578, G 0.6169)] [G loss: -28.4649]\n",
      "133 (5, 1) [D loss: (-20.4959)(R -55.7944, F 29.5109, G 0.5788)] [G loss: -27.9937]\n",
      "134 (5, 1) [D loss: (-20.4156)(R -54.8398, F 28.8678, G 0.5556)] [G loss: -28.4007]\n",
      "135 (5, 1) [D loss: (-19.7780)(R -54.8512, F 29.3596, G 0.5714)] [G loss: -28.7853]\n",
      "136 (5, 1) [D loss: (-18.4877)(R -54.5630, F 30.3357, G 0.5740)] [G loss: -29.1292]\n",
      "137 (5, 1) [D loss: (-19.9711)(R -55.2518, F 29.9586, G 0.5322)] [G loss: -29.1107]\n",
      "138 (5, 1) [D loss: (-18.6272)(R -54.5018, F 30.4386, G 0.5436)] [G loss: -28.8946]\n",
      "139 (5, 1) [D loss: (-18.7836)(R -55.4823, F 30.9623, G 0.5736)] [G loss: -30.0943]\n",
      "140 (5, 1) [D loss: (-18.8373)(R -54.4087, F 30.5623, G 0.5009)] [G loss: -29.1584]\n",
      "141 (5, 1) [D loss: (-18.7381)(R -54.8098, F 30.6108, G 0.5461)] [G loss: -29.7405]\n",
      "142 (5, 1) [D loss: (-17.5719)(R -53.1912, F 30.5445, G 0.5075)] [G loss: -28.8460]\n",
      "143 (5, 1) [D loss: (-19.1350)(R -54.0645, F 30.1904, G 0.4739)] [G loss: -29.8733]\n",
      "144 (5, 1) [D loss: (-18.8526)(R -54.4569, F 30.6467, G 0.4958)] [G loss: -30.2049]\n",
      "145 (5, 1) [D loss: (-17.2706)(R -54.9167, F 32.2728, G 0.5373)] [G loss: -30.6035]\n",
      "146 (5, 1) [D loss: (-18.7952)(R -54.0726, F 30.6126, G 0.4665)] [G loss: -30.9168]\n",
      "147 (5, 1) [D loss: (-17.0674)(R -53.6571, F 31.5813, G 0.5008)] [G loss: -29.7796]\n",
      "148 (5, 1) [D loss: (-16.9189)(R -53.4222, F 31.6442, G 0.4859)] [G loss: -30.3289]\n",
      "149 (5, 1) [D loss: (-17.3949)(R -54.4290, F 32.0927, G 0.4941)] [G loss: -31.3887]\n",
      "150 (5, 1) [D loss: (-17.5413)(R -53.2432, F 31.1423, G 0.4560)] [G loss: -30.6431]\n",
      "151 (5, 1) [D loss: (-17.1692)(R -53.2339, F 31.5306, G 0.4534)] [G loss: -31.1995]\n",
      "152 (5, 1) [D loss: (-16.7608)(R -54.2381, F 32.5895, G 0.4888)] [G loss: -31.4683]\n",
      "153 (5, 1) [D loss: (-18.3960)(R -55.0546, F 32.1684, G 0.4490)] [G loss: -32.5746]\n",
      "154 (5, 1) [D loss: (-16.8931)(R -54.6637, F 32.9940, G 0.4777)] [G loss: -33.1035]\n",
      "155 (5, 1) [D loss: (-14.5275)(R -53.0651, F 33.7124, G 0.4825)] [G loss: -32.8012]\n",
      "156 (5, 1) [D loss: (-17.0517)(R -55.3091, F 33.6618, G 0.4596)] [G loss: -33.1890]\n",
      "157 (5, 1) [D loss: (-15.9037)(R -55.8478, F 35.0258, G 0.4918)] [G loss: -33.7383]\n",
      "158 (5, 1) [D loss: (-16.3546)(R -54.5242, F 33.6462, G 0.4523)] [G loss: -34.1034]\n",
      "159 (5, 1) [D loss: (-15.6061)(R -54.0103, F 34.0089, G 0.4395)] [G loss: -34.4041]\n",
      "160 (5, 1) [D loss: (-16.3270)(R -55.6782, F 34.9355, G 0.4416)] [G loss: -35.2592]\n",
      "161 (5, 1) [D loss: (-15.5320)(R -54.1888, F 34.4886, G 0.4168)] [G loss: -34.7200]\n",
      "162 (5, 1) [D loss: (-15.7320)(R -56.3643, F 36.0458, G 0.4586)] [G loss: -36.2739]\n",
      "163 (5, 1) [D loss: (-15.6353)(R -55.5351, F 35.5206, G 0.4379)] [G loss: -35.7430]\n",
      "164 (5, 1) [D loss: (-15.3578)(R -55.5887, F 35.9831, G 0.4248)] [G loss: -37.0631]\n",
      "165 (5, 1) [D loss: (-14.8511)(R -55.1985, F 36.2782, G 0.4069)] [G loss: -36.2053]\n",
      "166 (5, 1) [D loss: (-14.0152)(R -54.7819, F 36.8275, G 0.3939)] [G loss: -36.4896]\n",
      "167 (5, 1) [D loss: (-16.0324)(R -57.0088, F 36.8347, G 0.4142)] [G loss: -37.3650]\n",
      "168 (5, 1) [D loss: (-14.8422)(R -57.0794, F 38.0592, G 0.4178)] [G loss: -37.5680]\n",
      "169 (5, 1) [D loss: (-14.4595)(R -55.1181, F 36.8353, G 0.3823)] [G loss: -36.8139]\n",
      "170 (5, 1) [D loss: (-12.9631)(R -55.1947, F 38.2358, G 0.3996)] [G loss: -37.0426]\n",
      "171 (5, 1) [D loss: (-13.7401)(R -54.4071, F 37.1376, G 0.3529)] [G loss: -36.8422]\n",
      "172 (5, 1) [D loss: (-13.4207)(R -54.8035, F 37.6681, G 0.3715)] [G loss: -37.7666]\n",
      "173 (5, 1) [D loss: (-14.0722)(R -55.7450, F 37.9933, G 0.3680)] [G loss: -37.3434]\n",
      "174 (5, 1) [D loss: (-13.2250)(R -55.8447, F 38.9239, G 0.3696)] [G loss: -38.7329]\n",
      "175 (5, 1) [D loss: (-14.1113)(R -55.5368, F 38.0062, G 0.3419)] [G loss: -38.2677]\n",
      "176 (5, 1) [D loss: (-12.2190)(R -54.4886, F 38.7721, G 0.3497)] [G loss: -37.4464]\n",
      "177 (5, 1) [D loss: (-12.4195)(R -52.6736, F 37.2587, G 0.2995)] [G loss: -37.2160]\n",
      "178 (5, 1) [D loss: (-12.4233)(R -54.9734, F 39.1939, G 0.3356)] [G loss: -38.7030]\n",
      "179 (5, 1) [D loss: (-13.0814)(R -55.7501, F 39.2992, G 0.3369)] [G loss: -38.7204]\n",
      "180 (5, 1) [D loss: (-13.5603)(R -54.8245, F 38.1576, G 0.3107)] [G loss: -38.5113]\n",
      "181 (5, 1) [D loss: (-11.4542)(R -53.9463, F 39.2321, G 0.3260)] [G loss: -39.2711]\n",
      "182 (5, 1) [D loss: (-12.4802)(R -54.1026, F 38.5564, G 0.3066)] [G loss: -38.6543]\n",
      "183 (5, 1) [D loss: (-12.8779)(R -54.7135, F 38.8025, G 0.3033)] [G loss: -39.3684]\n",
      "184 (5, 1) [D loss: (-12.5413)(R -54.0929, F 38.6372, G 0.2914)] [G loss: -38.6378]\n",
      "185 (5, 1) [D loss: (-13.0463)(R -54.5843, F 38.7568, G 0.2781)] [G loss: -39.4128]\n",
      "186 (5, 1) [D loss: (-10.9720)(R -54.2622, F 40.2730, G 0.3017)] [G loss: -39.3438]\n",
      "187 (5, 1) [D loss: (-10.8174)(R -53.2761, F 39.5404, G 0.2918)] [G loss: -39.6200]\n",
      "188 (5, 1) [D loss: (-11.8762)(R -54.6293, F 39.8375, G 0.2916)] [G loss: -39.9643]\n",
      "189 (5, 1) [D loss: (-10.9057)(R -53.1962, F 39.5708, G 0.2720)] [G loss: -38.7951]\n",
      "190 (5, 1) [D loss: (-11.4480)(R -54.1024, F 39.9008, G 0.2754)] [G loss: -39.8711]\n",
      "191 (5, 1) [D loss: (-11.7931)(R -54.0637, F 39.5153, G 0.2755)] [G loss: -40.6947]\n",
      "192 (5, 1) [D loss: (-12.3648)(R -55.2536, F 40.2664, G 0.2622)] [G loss: -40.5180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 (5, 1) [D loss: (-11.4569)(R -52.7712, F 38.8948, G 0.2419)] [G loss: -39.3556]\n",
      "194 (5, 1) [D loss: (-10.4568)(R -53.1873, F 40.3375, G 0.2393)] [G loss: -40.6165]\n",
      "195 (5, 1) [D loss: (-10.4141)(R -53.8537, F 40.7826, G 0.2657)] [G loss: -40.5048]\n",
      "196 (5, 1) [D loss: (-11.0105)(R -54.2171, F 40.6567, G 0.2550)] [G loss: -40.8638]\n",
      "197 (5, 1) [D loss: (-10.4895)(R -52.8650, F 40.0061, G 0.2369)] [G loss: -40.3108]\n",
      "198 (5, 1) [D loss: (-11.1665)(R -53.5883, F 39.9649, G 0.2457)] [G loss: -40.3668]\n",
      "199 (5, 1) [D loss: (-11.1453)(R -53.2062, F 39.7702, G 0.2291)] [G loss: -40.2369]\n",
      "200 (5, 1) [D loss: (-10.5713)(R -54.2127, F 41.1311, G 0.2510)] [G loss: -41.2212]\n",
      "201 (5, 1) [D loss: (-10.2684)(R -53.1248, F 40.6477, G 0.2209)] [G loss: -39.8872]\n",
      "202 (5, 1) [D loss: (-10.0204)(R -54.0569, F 41.6004, G 0.2436)] [G loss: -40.6033]\n",
      "203 (5, 1) [D loss: (-11.0335)(R -53.2343, F 40.0428, G 0.2158)] [G loss: -40.5436]\n",
      "204 (5, 1) [D loss: (-11.2109)(R -53.1680, F 39.9824, G 0.1975)] [G loss: -40.7202]\n",
      "205 (5, 1) [D loss: (-10.2453)(R -53.2281, F 40.7445, G 0.2238)] [G loss: -41.4114]\n",
      "206 (5, 1) [D loss: (-10.3884)(R -53.9201, F 41.3128, G 0.2219)] [G loss: -41.6664]\n",
      "207 (5, 1) [D loss: (-10.7700)(R -53.8308, F 40.8779, G 0.2183)] [G loss: -41.3201]\n",
      "208 (5, 1) [D loss: (-10.1767)(R -52.5280, F 40.2634, G 0.2088)] [G loss: -40.4324]\n",
      "209 (5, 1) [D loss: (-10.0492)(R -52.9093, F 40.8387, G 0.2021)] [G loss: -40.7577]\n",
      "210 (5, 1) [D loss: (-9.9813)(R -52.8120, F 40.9149, G 0.1916)] [G loss: -41.0817]\n",
      "211 (5, 1) [D loss: (-9.0158)(R -52.8318, F 41.8599, G 0.1956)] [G loss: -40.8180]\n",
      "212 (5, 1) [D loss: (-9.8713)(R -52.1837, F 40.5090, G 0.1803)] [G loss: -41.1301]\n",
      "213 (5, 1) [D loss: (-10.3654)(R -53.0052, F 40.8871, G 0.1753)] [G loss: -42.0564]\n",
      "214 (5, 1) [D loss: (-9.4895)(R -52.4598, F 41.1483, G 0.1822)] [G loss: -41.7291]\n",
      "215 (5, 1) [D loss: (-9.7922)(R -53.0408, F 41.3459, G 0.1903)] [G loss: -42.3164]\n",
      "216 (5, 1) [D loss: (-8.9751)(R -53.1131, F 42.1976, G 0.1940)] [G loss: -42.0452]\n",
      "217 (5, 1) [D loss: (-9.1154)(R -51.8377, F 40.8220, G 0.1900)] [G loss: -41.3884]\n",
      "218 (5, 1) [D loss: (-10.2983)(R -52.7549, F 40.6447, G 0.1812)] [G loss: -41.6394]\n",
      "219 (5, 1) [D loss: (-9.8005)(R -52.5684, F 41.0985, G 0.1669)] [G loss: -41.1872]\n",
      "220 (5, 1) [D loss: (-10.9403)(R -52.4397, F 39.8753, G 0.1624)] [G loss: -41.3373]\n",
      "221 (5, 1) [D loss: (-8.8918)(R -51.9319, F 41.3147, G 0.1725)] [G loss: -41.8649]\n",
      "222 (5, 1) [D loss: (-9.7216)(R -52.2065, F 40.9051, G 0.1580)] [G loss: -42.3803]\n",
      "223 (5, 1) [D loss: (-8.0753)(R -51.5943, F 41.7435, G 0.1776)] [G loss: -41.5816]\n",
      "224 (5, 1) [D loss: (-9.3528)(R -51.4938, F 40.6715, G 0.1470)] [G loss: -41.6171]\n",
      "225 (5, 1) [D loss: (-7.5384)(R -49.8585, F 40.8653, G 0.1455)] [G loss: -40.2820]\n",
      "226 (5, 1) [D loss: (-8.9884)(R -49.6759, F 39.3426, G 0.1345)] [G loss: -40.8808]\n",
      "227 (5, 1) [D loss: (-9.4836)(R -51.9056, F 40.8217, G 0.1600)] [G loss: -41.6528]\n",
      "228 (5, 1) [D loss: (-8.0687)(R -50.8221, F 41.3097, G 0.1444)] [G loss: -41.5347]\n",
      "229 (5, 1) [D loss: (-7.3582)(R -49.9390, F 40.9905, G 0.1590)] [G loss: -41.4959]\n",
      "230 (5, 1) [D loss: (-7.3188)(R -50.3354, F 41.5190, G 0.1498)] [G loss: -41.0943]\n",
      "231 (5, 1) [D loss: (-8.7597)(R -51.2231, F 41.0234, G 0.1440)] [G loss: -42.2152]\n",
      "232 (5, 1) [D loss: (-8.1612)(R -50.2137, F 40.7094, G 0.1343)] [G loss: -41.0034]\n",
      "233 (5, 1) [D loss: (-6.6093)(R -49.3874, F 41.4132, G 0.1365)] [G loss: -40.8899]\n",
      "234 (5, 1) [D loss: (-8.1499)(R -51.1364, F 41.6044, G 0.1382)] [G loss: -41.6731]\n",
      "235 (5, 1) [D loss: (-7.8942)(R -49.1009, F 40.0009, G 0.1206)] [G loss: -40.4214]\n",
      "236 (5, 1) [D loss: (-6.9531)(R -49.3399, F 41.0881, G 0.1299)] [G loss: -40.7243]\n",
      "237 (5, 1) [D loss: (-8.2594)(R -50.2590, F 40.7693, G 0.1230)] [G loss: -41.1823]\n",
      "238 (5, 1) [D loss: (-8.2963)(R -49.9815, F 40.4494, G 0.1236)] [G loss: -41.4421]\n",
      "239 (5, 1) [D loss: (-6.6440)(R -48.6031, F 40.7982, G 0.1161)] [G loss: -41.1089]\n",
      "240 (5, 1) [D loss: (-8.2236)(R -50.3352, F 40.9272, G 0.1184)] [G loss: -41.0825]\n",
      "241 (5, 1) [D loss: (-6.5766)(R -48.9907, F 41.2942, G 0.1120)] [G loss: -41.2422]\n",
      "242 (5, 1) [D loss: (-6.9514)(R -48.3379, F 40.2799, G 0.1107)] [G loss: -40.6499]\n",
      "243 (5, 1) [D loss: (-7.6723)(R -49.5976, F 40.8301, G 0.1095)] [G loss: -41.4230]\n",
      "244 (5, 1) [D loss: (-6.8956)(R -48.9138, F 40.8985, G 0.1120)] [G loss: -41.7357]\n",
      "245 (5, 1) [D loss: (-7.2173)(R -49.7848, F 41.5082, G 0.1059)] [G loss: -41.3016]\n",
      "246 (5, 1) [D loss: (-6.6218)(R -48.6360, F 40.9616, G 0.1053)] [G loss: -41.0102]\n",
      "247 (5, 1) [D loss: (-6.9486)(R -48.2576, F 40.4134, G 0.0896)] [G loss: -41.1058]\n",
      "248 (5, 1) [D loss: (-7.2950)(R -48.7467, F 40.4760, G 0.0976)] [G loss: -41.3940]\n",
      "249 (5, 1) [D loss: (-6.4068)(R -48.7767, F 41.2161, G 0.1154)] [G loss: -41.1809]\n",
      "250 (5, 1) [D loss: (-7.1540)(R -48.0749, F 39.9219, G 0.0999)] [G loss: -40.2432]\n",
      "251 (5, 1) [D loss: (-6.2065)(R -48.3758, F 41.1071, G 0.1062)] [G loss: -41.3842]\n",
      "252 (5, 1) [D loss: (-7.0113)(R -48.2745, F 40.3553, G 0.0908)] [G loss: -40.9494]\n",
      "253 (5, 1) [D loss: (-6.0641)(R -47.8640, F 40.8331, G 0.0967)] [G loss: -40.8011]\n",
      "254 (5, 1) [D loss: (-5.5863)(R -47.6465, F 41.1428, G 0.0917)] [G loss: -41.5216]\n",
      "255 (5, 1) [D loss: (-6.2972)(R -46.9978, F 39.8685, G 0.0832)] [G loss: -40.4447]\n",
      "256 (5, 1) [D loss: (-6.5217)(R -47.8425, F 40.4153, G 0.0905)] [G loss: -41.2896]\n",
      "257 (5, 1) [D loss: (-6.4745)(R -47.6327, F 40.2630, G 0.0895)] [G loss: -40.3341]\n",
      "258 (5, 1) [D loss: (-6.6150)(R -47.8349, F 40.3650, G 0.0855)] [G loss: -41.0137]\n",
      "259 (5, 1) [D loss: (-6.3386)(R -47.2427, F 40.0614, G 0.0843)] [G loss: -41.3615]\n",
      "260 (5, 1) [D loss: (-5.5065)(R -46.3312, F 39.9973, G 0.0827)] [G loss: -40.2140]\n",
      "261 (5, 1) [D loss: (-5.9290)(R -46.9471, F 40.2910, G 0.0727)] [G loss: -40.2287]\n",
      "262 (5, 1) [D loss: (-5.6644)(R -46.9243, F 40.3775, G 0.0882)] [G loss: -40.5001]\n",
      "263 (5, 1) [D loss: (-5.2770)(R -46.8747, F 40.7855, G 0.0812)] [G loss: -41.1377]\n",
      "264 (5, 1) [D loss: (-6.0269)(R -46.3592, F 39.6594, G 0.0673)] [G loss: -40.5380]\n",
      "265 (5, 1) [D loss: (-6.9996)(R -48.1975, F 40.3519, G 0.0846)] [G loss: -41.1879]\n",
      "266 (5, 1) [D loss: (-5.7480)(R -47.3524, F 40.7934, G 0.0811)] [G loss: -40.5735]\n",
      "267 (5, 1) [D loss: (-6.3306)(R -46.7215, F 39.6821, G 0.0709)] [G loss: -40.5814]\n",
      "268 (5, 1) [D loss: (-4.3276)(R -44.9811, F 39.9277, G 0.0726)] [G loss: -39.8128]\n",
      "269 (5, 1) [D loss: (-4.8392)(R -45.2134, F 39.7203, G 0.0654)] [G loss: -39.9619]\n",
      "270 (5, 1) [D loss: (-6.0764)(R -46.6357, F 39.8582, G 0.0701)] [G loss: -40.1621]\n",
      "271 (5, 1) [D loss: (-5.2201)(R -46.3453, F 40.4689, G 0.0656)] [G loss: -40.2432]\n",
      "272 (5, 1) [D loss: (-5.1405)(R -45.9898, F 40.2135, G 0.0636)] [G loss: -40.2528]\n",
      "273 (5, 1) [D loss: (-4.4610)(R -44.7997, F 39.7341, G 0.0605)] [G loss: -40.0124]\n",
      "274 (5, 1) [D loss: (-5.1109)(R -44.9019, F 39.2193, G 0.0572)] [G loss: -39.5280]\n",
      "275 (5, 1) [D loss: (-4.7776)(R -45.8121, F 40.3862, G 0.0648)] [G loss: -40.6821]\n",
      "276 (5, 1) [D loss: (-5.8381)(R -45.3269, F 38.9210, G 0.0568)] [G loss: -39.1299]\n",
      "277 (5, 1) [D loss: (-4.9818)(R -44.8920, F 39.3456, G 0.0565)] [G loss: -39.7899]\n",
      "278 (5, 1) [D loss: (-4.7285)(R -44.4693, F 39.1735, G 0.0567)] [G loss: -39.5333]\n",
      "279 (5, 1) [D loss: (-4.8006)(R -43.4678, F 38.2271, G 0.0440)] [G loss: -38.6590]\n",
      "280 (5, 1) [D loss: (-4.8203)(R -44.3009, F 38.9678, G 0.0513)] [G loss: -38.9892]\n",
      "281 (5, 1) [D loss: (-5.1296)(R -45.0491, F 39.3766, G 0.0543)] [G loss: -39.6879]\n",
      "282 (5, 1) [D loss: (-4.7805)(R -44.7067, F 39.3702, G 0.0556)] [G loss: -39.0080]\n",
      "283 (5, 1) [D loss: (-4.5041)(R -44.7795, F 39.7067, G 0.0569)] [G loss: -40.1305]\n",
      "284 (5, 1) [D loss: (-5.3637)(R -44.7621, F 38.8841, G 0.0514)] [G loss: -39.4496]\n",
      "285 (5, 1) [D loss: (-5.7030)(R -45.9543, F 39.6930, G 0.0558)] [G loss: -40.2414]\n",
      "286 (5, 1) [D loss: (-4.7866)(R -45.1691, F 39.8092, G 0.0573)] [G loss: -39.8690]\n",
      "287 (5, 1) [D loss: (-4.8146)(R -44.7469, F 39.4254, G 0.0507)] [G loss: -39.6834]\n",
      "288 (5, 1) [D loss: (-4.3789)(R -43.8504, F 38.9895, G 0.0482)] [G loss: -39.7667]\n",
      "289 (5, 1) [D loss: (-4.4767)(R -43.6280, F 38.7218, G 0.0430)] [G loss: -39.0233]\n",
      "290 (5, 1) [D loss: (-3.0740)(R -42.9933, F 39.4598, G 0.0460)] [G loss: -38.9178]\n",
      "291 (5, 1) [D loss: (-4.4606)(R -44.2975, F 39.3716, G 0.0465)] [G loss: -39.1763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 (5, 1) [D loss: (-4.1585)(R -43.6314, F 39.0475, G 0.0425)] [G loss: -39.3300]\n",
      "293 (5, 1) [D loss: (-5.1413)(R -42.8898, F 37.3902, G 0.0358)] [G loss: -38.4410]\n",
      "294 (5, 1) [D loss: (-4.2963)(R -43.6642, F 38.9214, G 0.0447)] [G loss: -38.7658]\n",
      "295 (5, 1) [D loss: (-3.7902)(R -42.7035, F 38.4943, G 0.0419)] [G loss: -38.5418]\n",
      "296 (5, 1) [D loss: (-3.5076)(R -42.3441, F 38.4443, G 0.0392)] [G loss: -38.1353]\n",
      "297 (5, 1) [D loss: (-4.2432)(R -41.7409, F 37.1840, G 0.0314)] [G loss: -38.1802]\n",
      "298 (5, 1) [D loss: (-3.9847)(R -42.2939, F 37.9977, G 0.0312)] [G loss: -37.7545]\n",
      "299 (5, 1) [D loss: (-4.2212)(R -42.4586, F 37.8777, G 0.0360)] [G loss: -37.9625]\n",
      "300 (5, 1) [D loss: (-3.8107)(R -42.1822, F 38.0241, G 0.0347)] [G loss: -37.9111]\n",
      "301 (5, 1) [D loss: (-4.2034)(R -42.4974, F 37.9498, G 0.0344)] [G loss: -37.9442]\n",
      "302 (5, 1) [D loss: (-3.8268)(R -41.9426, F 37.7843, G 0.0332)] [G loss: -38.0220]\n",
      "303 (5, 1) [D loss: (-4.5548)(R -43.2245, F 38.2759, G 0.0394)] [G loss: -38.8637]\n",
      "304 (5, 1) [D loss: (-4.3751)(R -43.3763, F 38.6045, G 0.0397)] [G loss: -38.7476]\n",
      "305 (5, 1) [D loss: (-4.0524)(R -42.4212, F 37.9988, G 0.0370)] [G loss: -38.2893]\n",
      "306 (5, 1) [D loss: (-3.7895)(R -42.0435, F 37.9234, G 0.0331)] [G loss: -37.8890]\n",
      "307 (5, 1) [D loss: (-3.3252)(R -41.3375, F 37.6976, G 0.0315)] [G loss: -37.7534]\n",
      "308 (5, 1) [D loss: (-3.3168)(R -41.3573, F 37.7538, G 0.0287)] [G loss: -37.7778]\n",
      "309 (5, 1) [D loss: (-3.5428)(R -41.3994, F 37.5472, G 0.0309)] [G loss: -37.8125]\n",
      "310 (5, 1) [D loss: (-2.8795)(R -40.1807, F 37.0048, G 0.0296)] [G loss: -36.9294]\n",
      "311 (5, 1) [D loss: (-3.0408)(R -40.7105, F 37.3951, G 0.0275)] [G loss: -37.5057]\n",
      "312 (5, 1) [D loss: (-2.7669)(R -40.4360, F 37.4092, G 0.0260)] [G loss: -37.3226]\n",
      "313 (5, 1) [D loss: (-3.7508)(R -41.6978, F 37.6425, G 0.0304)] [G loss: -38.5704]\n",
      "314 (5, 1) [D loss: (-3.6736)(R -40.2368, F 36.3176, G 0.0246)] [G loss: -36.9967]\n",
      "315 (5, 1) [D loss: (-4.1438)(R -40.7146, F 36.3439, G 0.0227)] [G loss: -36.8267]\n",
      "316 (5, 1) [D loss: (-2.5222)(R -39.3314, F 36.5739, G 0.0235)] [G loss: -36.4913]\n",
      "317 (5, 1) [D loss: (-3.7482)(R -39.5427, F 35.5895, G 0.0205)] [G loss: -36.7134]\n",
      "318 (5, 1) [D loss: (-3.3046)(R -40.1716, F 36.5997, G 0.0267)] [G loss: -37.3995]\n",
      "319 (5, 1) [D loss: (-3.4445)(R -39.7729, F 36.1255, G 0.0203)] [G loss: -36.2426]\n",
      "320 (5, 1) [D loss: (-2.4651)(R -39.2401, F 36.5687, G 0.0206)] [G loss: -36.5455]\n",
      "321 (5, 1) [D loss: (-3.4362)(R -39.9390, F 36.2711, G 0.0232)] [G loss: -36.2828]\n",
      "322 (5, 1) [D loss: (-3.1710)(R -39.0656, F 35.6690, G 0.0226)] [G loss: -35.9602]\n",
      "323 (5, 1) [D loss: (-2.7990)(R -38.1386, F 35.1363, G 0.0203)] [G loss: -35.4368]\n",
      "324 (5, 1) [D loss: (-2.4522)(R -38.2367, F 35.5976, G 0.0187)] [G loss: -35.6204]\n",
      "325 (5, 1) [D loss: (-2.3960)(R -39.3597, F 36.7021, G 0.0262)] [G loss: -36.4563]\n",
      "326 (5, 1) [D loss: (-3.2223)(R -38.8383, F 35.4104, G 0.0206)] [G loss: -36.2679]\n",
      "327 (5, 1) [D loss: (-3.2062)(R -38.9831, F 35.5788, G 0.0198)] [G loss: -36.1925]\n",
      "328 (5, 1) [D loss: (-2.2309)(R -38.3116, F 35.9011, G 0.0180)] [G loss: -35.4221]\n",
      "329 (5, 1) [D loss: (-2.8027)(R -38.5969, F 35.6401, G 0.0154)] [G loss: -35.3106]\n",
      "330 (5, 1) [D loss: (-3.5720)(R -39.6114, F 35.8348, G 0.0205)] [G loss: -36.7724]\n",
      "331 (5, 1) [D loss: (-2.8728)(R -38.3812, F 35.3544, G 0.0154)] [G loss: -35.7721]\n",
      "332 (5, 1) [D loss: (-2.5630)(R -37.4256, F 34.7282, G 0.0134)] [G loss: -35.1480]\n",
      "333 (5, 1) [D loss: (-1.7300)(R -36.9650, F 35.0525, G 0.0182)] [G loss: -35.1418]\n",
      "334 (5, 1) [D loss: (-3.4302)(R -37.2470, F 33.6883, G 0.0128)] [G loss: -34.1525]\n",
      "335 (5, 1) [D loss: (-3.5402)(R -37.7423, F 34.0705, G 0.0132)] [G loss: -34.9560]\n",
      "336 (5, 1) [D loss: (-2.8456)(R -37.5589, F 34.5561, G 0.0157)] [G loss: -34.9505]\n",
      "337 (5, 1) [D loss: (-2.6035)(R -36.8220, F 34.1046, G 0.0114)] [G loss: -34.6034]\n",
      "338 (5, 1) [D loss: (-2.5366)(R -36.0397, F 33.3828, G 0.0120)] [G loss: -33.8703]\n",
      "339 (5, 1) [D loss: (-1.7984)(R -35.4116, F 33.5010, G 0.0112)] [G loss: -33.7915]\n",
      "340 (5, 1) [D loss: (-1.8337)(R -35.4953, F 33.5456, G 0.0116)] [G loss: -33.4368]\n",
      "341 (5, 1) [D loss: (-1.5826)(R -35.0710, F 33.3967, G 0.0092)] [G loss: -33.2549]\n",
      "342 (5, 1) [D loss: (-2.1381)(R -34.8511, F 32.6280, G 0.0085)] [G loss: -33.0960]\n",
      "343 (5, 1) [D loss: (-1.4780)(R -34.7190, F 33.1580, G 0.0083)] [G loss: -32.2050]\n",
      "344 (5, 1) [D loss: (-1.9559)(R -34.1543, F 32.1042, G 0.0094)] [G loss: -32.3836]\n",
      "345 (5, 1) [D loss: (-1.7208)(R -34.3488, F 32.5296, G 0.0098)] [G loss: -32.2480]\n",
      "346 (5, 1) [D loss: (-1.3512)(R -33.1523, F 31.7481, G 0.0053)] [G loss: -31.3236]\n",
      "347 (5, 1) [D loss: (-2.3119)(R -33.3258, F 30.9420, G 0.0072)] [G loss: -31.5284]\n",
      "348 (5, 1) [D loss: (-1.3829)(R -32.7165, F 31.2373, G 0.0096)] [G loss: -31.0131]\n",
      "349 (5, 1) [D loss: (-1.8212)(R -33.9390, F 32.0170, G 0.0101)] [G loss: -31.3702]\n",
      "350 (5, 1) [D loss: (-1.5971)(R -33.4817, F 31.7855, G 0.0099)] [G loss: -31.8162]\n",
      "351 (5, 1) [D loss: (-2.4313)(R -33.0150, F 30.4976, G 0.0086)] [G loss: -30.8392]\n",
      "352 (5, 1) [D loss: (-2.1157)(R -33.0748, F 30.8662, G 0.0093)] [G loss: -31.2575]\n",
      "353 (5, 1) [D loss: (-1.7949)(R -32.5176, F 30.6487, G 0.0074)] [G loss: -30.5821]\n",
      "354 (5, 1) [D loss: (-1.3559)(R -33.2442, F 31.7860, G 0.0102)] [G loss: -31.6224]\n",
      "355 (5, 1) [D loss: (-1.6307)(R -32.3379, F 30.6199, G 0.0087)] [G loss: -30.8007]\n",
      "356 (5, 1) [D loss: (-1.2375)(R -31.8205, F 30.5076, G 0.0075)] [G loss: -30.4872]\n",
      "357 (5, 1) [D loss: (-1.0689)(R -31.3313, F 30.1784, G 0.0084)] [G loss: -29.5294]\n",
      "358 (5, 1) [D loss: (-1.2676)(R -31.3775, F 30.0575, G 0.0052)] [G loss: -29.5087]\n",
      "359 (5, 1) [D loss: (-1.2640)(R -29.3475, F 28.0477, G 0.0036)] [G loss: -28.2673]\n",
      "360 (5, 1) [D loss: (-1.9677)(R -30.8220, F 28.8060, G 0.0048)] [G loss: -29.4736]\n",
      "361 (5, 1) [D loss: (-1.4885)(R -29.8296, F 28.2815, G 0.0060)] [G loss: -29.1869]\n",
      "362 (5, 1) [D loss: (-1.5465)(R -30.2575, F 28.6612, G 0.0050)] [G loss: -28.0659]\n",
      "363 (5, 1) [D loss: (-0.8839)(R -28.5887, F 27.6672, G 0.0038)] [G loss: -27.3557]\n",
      "364 (5, 1) [D loss: (-1.4433)(R -29.1132, F 27.6302, G 0.0040)] [G loss: -27.4543]\n",
      "365 (5, 1) [D loss: (-1.5656)(R -30.0442, F 28.4223, G 0.0056)] [G loss: -28.5279]\n",
      "366 (5, 1) [D loss: (-2.1603)(R -30.0489, F 27.8370, G 0.0052)] [G loss: -27.9011]\n",
      "367 (5, 1) [D loss: (-1.2247)(R -27.9945, F 26.7197, G 0.0050)] [G loss: -26.7429]\n",
      "368 (5, 1) [D loss: (-2.3364)(R -28.0070, F 25.6242, G 0.0046)] [G loss: -25.9765]\n",
      "369 (5, 1) [D loss: (-0.8244)(R -27.7297, F 26.8607, G 0.0045)] [G loss: -26.8546]\n",
      "370 (5, 1) [D loss: (-1.6427)(R -27.9557, F 26.2758, G 0.0037)] [G loss: -25.6684]\n",
      "371 (5, 1) [D loss: (-2.1575)(R -27.3805, F 25.1798, G 0.0043)] [G loss: -24.9474]\n",
      "372 (5, 1) [D loss: (-1.5121)(R -27.1467, F 25.5871, G 0.0047)] [G loss: -25.6933]\n",
      "373 (5, 1) [D loss: (-1.3726)(R -26.3576, F 24.9569, G 0.0028)] [G loss: -23.7891]\n",
      "374 (5, 1) [D loss: (-1.9850)(R -24.7236, F 22.7129, G 0.0026)] [G loss: -23.3392]\n",
      "375 (5, 1) [D loss: (-1.5567)(R -24.6142, F 23.0258, G 0.0032)] [G loss: -23.6916]\n",
      "376 (5, 1) [D loss: (-0.4096)(R -23.3729, F 22.9351, G 0.0028)] [G loss: -21.8953]\n",
      "377 (5, 1) [D loss: (-0.5312)(R -22.1705, F 21.6135, G 0.0026)] [G loss: -20.8371]\n",
      "378 (5, 1) [D loss: (-1.1936)(R -21.3347, F 20.1189, G 0.0022)] [G loss: -19.2596]\n",
      "379 (5, 1) [D loss: (-0.8055)(R -20.7297, F 19.9041, G 0.0020)] [G loss: -18.5730]\n",
      "380 (5, 1) [D loss: (-1.4332)(R -20.6830, F 19.2309, G 0.0019)] [G loss: -19.2194]\n",
      "381 (5, 1) [D loss: (-0.6249)(R -21.2869, F 20.6332, G 0.0029)] [G loss: -20.4292]\n",
      "382 (5, 1) [D loss: (-0.3736)(R -21.6716, F 21.2597, G 0.0038)] [G loss: -21.0055]\n",
      "383 (5, 1) [D loss: (-0.7672)(R -20.6547, F 19.8584, G 0.0029)] [G loss: -18.9756]\n",
      "384 (5, 1) [D loss: (-0.5445)(R -19.0486, F 18.4838, G 0.0020)] [G loss: -16.9378]\n",
      "385 (5, 1) [D loss: (-0.2801)(R -17.2920, F 16.9895, G 0.0022)] [G loss: -16.5621]\n",
      "386 (5, 1) [D loss: (-0.5755)(R -17.4444, F 16.8502, G 0.0019)] [G loss: -16.5583]\n",
      "387 (5, 1) [D loss: (-1.1713)(R -17.1308, F 15.9419, G 0.0018)] [G loss: -16.0178]\n",
      "388 (5, 1) [D loss: (-1.4010)(R -18.3932, F 16.9603, G 0.0032)] [G loss: -17.1495]\n",
      "389 (5, 1) [D loss: (-1.7765)(R -19.6173, F 17.7939, G 0.0047)] [G loss: -18.4923]\n",
      "390 (5, 1) [D loss: (-1.2047)(R -20.5402, F 19.2738, G 0.0062)] [G loss: -19.8193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 (5, 1) [D loss: (-1.3636)(R -21.6932, F 20.2728, G 0.0057)] [G loss: -20.3466]\n",
      "392 (5, 1) [D loss: (-1.5521)(R -21.4803, F 19.8930, G 0.0035)] [G loss: -20.1585]\n",
      "393 (5, 1) [D loss: (-1.4750)(R -21.8011, F 20.2896, G 0.0036)] [G loss: -19.9815]\n",
      "394 (5, 1) [D loss: (-1.5255)(R -18.9690, F 17.4165, G 0.0027)] [G loss: -17.0470]\n",
      "395 (5, 1) [D loss: (-0.9844)(R -16.8675, F 15.8670, G 0.0016)] [G loss: -15.1087]\n",
      "396 (5, 1) [D loss: (-0.8752)(R -11.5867, F 10.6994, G 0.0012)] [G loss: -9.3285]\n",
      "397 (5, 1) [D loss: (-0.7661)(R -6.2107, F 5.4360, G 0.0009)] [G loss: -3.9203]\n",
      "398 (5, 1) [D loss: (-2.0876)(R -2.0964, F 0.0019, G 0.0007)] [G loss: 0.6106]\n",
      "399 (5, 1) [D loss: (-2.3150)(R 1.1044, F -3.4430, G 0.0024)] [G loss: 3.7264]\n",
      "400 (5, 1) [D loss: (-1.5569)(R 1.5503, F -3.1713, G 0.0064)] [G loss: 2.9985]\n",
      "401 (5, 1) [D loss: (-1.7310)(R -3.1911, F 1.3713, G 0.0089)] [G loss: -3.8759]\n",
      "402 (5, 1) [D loss: (-2.7487)(R -14.2130, F 11.3240, G 0.0140)] [G loss: -13.3201]\n",
      "403 (5, 1) [D loss: (-1.9823)(R -22.6250, F 20.3809, G 0.0262)] [G loss: -22.4797]\n",
      "404 (5, 1) [D loss: (-1.7505)(R -25.6233, F 23.6757, G 0.0197)] [G loss: -23.6629]\n",
      "405 (5, 1) [D loss: (-1.0092)(R -23.4812, F 22.3988, G 0.0073)] [G loss: -19.8962]\n",
      "406 (5, 1) [D loss: (-1.3728)(R -21.0250, F 19.6067, G 0.0046)] [G loss: -17.7524]\n",
      "407 (5, 1) [D loss: (-3.2226)(R -16.6217, F 13.3606, G 0.0039)] [G loss: -12.4073]\n",
      "408 (5, 1) [D loss: (-4.1004)(R -8.1736, F 3.9795, G 0.0094)] [G loss: -3.1707]\n",
      "409 (5, 1) [D loss: (-3.5499)(R 0.1850, F -3.9537, G 0.0219)] [G loss: 4.6178]\n",
      "410 (5, 1) [D loss: (-2.2323)(R 6.3371, F -8.8399, G 0.0270)] [G loss: 9.0948]\n",
      "411 (5, 1) [D loss: (-0.8839)(R 7.8545, F -8.8417, G 0.0103)] [G loss: 8.4297]\n",
      "412 (5, 1) [D loss: (-0.1785)(R 4.9095, F -5.1010, G 0.0013)] [G loss: 4.2290]\n",
      "413 (5, 1) [D loss: (-0.5525)(R -3.5088, F 2.9319, G 0.0024)] [G loss: -3.8543]\n",
      "414 (5, 1) [D loss: (-2.8926)(R -14.8727, F 11.9589, G 0.0021)] [G loss: -13.4370]\n",
      "415 (5, 1) [D loss: (-9.2613)(R -29.5397, F 19.6590, G 0.0619)] [G loss: -22.5821]\n",
      "416 (5, 1) [D loss: (-9.5603)(R -31.5532, F 20.5217, G 0.1471)] [G loss: -20.8360]\n",
      "417 (5, 1) [D loss: (-4.4064)(R -19.5488, F 14.4110, G 0.0731)] [G loss: -13.8474]\n",
      "418 (5, 1) [D loss: (-0.6129)(R -12.1403, F 11.3559, G 0.0172)] [G loss: -9.2477]\n",
      "419 (5, 1) [D loss: (2.5529)(R -6.4110, F 8.9530, G 0.0011)] [G loss: -5.6360]\n",
      "420 (5, 1) [D loss: (2.7411)(R -2.6782, F 5.2900, G 0.0129)] [G loss: -3.2862]\n",
      "421 (5, 1) [D loss: (1.7302)(R -0.7040, F 2.1886, G 0.0245)] [G loss: -0.5630]\n",
      "422 (5, 1) [D loss: (-0.4199)(R 0.6261, F -1.2993, G 0.0253)] [G loss: 1.1661]\n",
      "423 (5, 1) [D loss: (-1.2738)(R 1.0175, F -2.4111, G 0.0120)] [G loss: 2.5945]\n",
      "424 (5, 1) [D loss: (-4.1214)(R -0.2867, F -3.8502, G 0.0015)] [G loss: 2.7681]\n",
      "425 (5, 1) [D loss: (-5.1320)(R -1.2245, F -3.9582, G 0.0051)] [G loss: 2.9506]\n",
      "426 (5, 1) [D loss: (-6.5154)(R -3.3789, F -3.4540, G 0.0317)] [G loss: 2.8115]\n",
      "427 (5, 1) [D loss: (-6.4643)(R -3.8978, F -3.2157, G 0.0649)] [G loss: 1.9425]\n",
      "428 (5, 1) [D loss: (-4.6588)(R -3.0857, F -2.3260, G 0.0753)] [G loss: 2.4548]\n",
      "429 (5, 1) [D loss: (-2.7421)(R -1.8931, F -1.4029, G 0.0554)] [G loss: 0.9878]\n",
      "430 (5, 1) [D loss: (-1.2199)(R -3.8386, F 2.3355, G 0.0283)] [G loss: -2.7607]\n",
      "431 (5, 1) [D loss: (-0.2504)(R -7.7376, F 7.3834, G 0.0104)] [G loss: -7.3791]\n",
      "432 (5, 1) [D loss: (0.3266)(R -12.0599, F 12.3497, G 0.0037)] [G loss: -12.2293]\n",
      "433 (5, 1) [D loss: (0.2845)(R -18.2250, F 18.4833, G 0.0026)] [G loss: -18.8480]\n",
      "434 (5, 1) [D loss: (-0.8551)(R -25.6038, F 24.6935, G 0.0055)] [G loss: -25.7269]\n",
      "435 (5, 1) [D loss: (-1.0887)(R -32.4710, F 31.2204, G 0.0162)] [G loss: -31.9046]\n",
      "436 (5, 1) [D loss: (-2.6242)(R -37.4513, F 34.5437, G 0.0283)] [G loss: -35.4606]\n",
      "437 (5, 1) [D loss: (-2.3930)(R -38.7894, F 36.1232, G 0.0273)] [G loss: -36.7713]\n",
      "438 (5, 1) [D loss: (-2.1852)(R -38.3767, F 35.9109, G 0.0281)] [G loss: -36.3293]\n",
      "439 (5, 1) [D loss: (-3.1729)(R -38.7244, F 35.3681, G 0.0183)] [G loss: -36.1110]\n",
      "440 (5, 1) [D loss: (-2.6191)(R -37.6442, F 34.8648, G 0.0160)] [G loss: -34.8794]\n",
      "441 (5, 1) [D loss: (-1.9429)(R -34.9441, F 32.9098, G 0.0091)] [G loss: -32.8380]\n",
      "442 (5, 1) [D loss: (-1.4146)(R -32.9674, F 31.4979, G 0.0055)] [G loss: -31.1043]\n",
      "443 (5, 1) [D loss: (-1.1429)(R -30.1792, F 29.0177, G 0.0019)] [G loss: -27.8352]\n",
      "444 (5, 1) [D loss: (-0.5461)(R -26.6768, F 26.1139, G 0.0017)] [G loss: -24.8837]\n",
      "445 (5, 1) [D loss: (-0.9474)(R -24.1978, F 23.2183, G 0.0032)] [G loss: -23.0101]\n",
      "446 (5, 1) [D loss: (-0.5887)(R -22.2630, F 21.6419, G 0.0032)] [G loss: -21.4576]\n",
      "447 (5, 1) [D loss: (-0.3003)(R -20.5173, F 20.1682, G 0.0049)] [G loss: -19.4018]\n",
      "448 (5, 1) [D loss: (-0.0088)(R -18.2910, F 18.2275, G 0.0055)] [G loss: -17.6739]\n",
      "449 (5, 1) [D loss: (-0.6508)(R -17.5493, F 16.8368, G 0.0062)] [G loss: -16.6594]\n",
      "450 (5, 1) [D loss: (-0.4466)(R -16.3890, F 15.8965, G 0.0046)] [G loss: -15.7866]\n",
      "451 (5, 1) [D loss: (-0.9707)(R -15.9805, F 14.9675, G 0.0042)] [G loss: -14.7397]\n",
      "452 (5, 1) [D loss: (-0.7734)(R -15.9249, F 15.1230, G 0.0029)] [G loss: -15.2068]\n",
      "453 (5, 1) [D loss: (-1.4871)(R -16.5617, F 15.0598, G 0.0015)] [G loss: -15.8073]\n",
      "454 (5, 1) [D loss: (-1.2314)(R -16.7918, F 15.5506, G 0.0010)] [G loss: -15.8278]\n",
      "455 (5, 1) [D loss: (-1.7881)(R -18.7584, F 16.9567, G 0.0014)] [G loss: -17.6224]\n",
      "456 (5, 1) [D loss: (-1.6062)(R -19.6146, F 17.9917, G 0.0017)] [G loss: -18.5369]\n",
      "457 (5, 1) [D loss: (-1.8258)(R -20.8056, F 18.9552, G 0.0025)] [G loss: -20.1463]\n",
      "458 (5, 1) [D loss: (-2.0265)(R -22.5849, F 20.5169, G 0.0041)] [G loss: -20.9264]\n",
      "459 (5, 1) [D loss: (-2.2796)(R -23.6594, F 21.3277, G 0.0052)] [G loss: -22.4209]\n",
      "460 (5, 1) [D loss: (-1.8638)(R -23.5784, F 21.6577, G 0.0057)] [G loss: -22.6111]\n",
      "461 (5, 1) [D loss: (-1.5847)(R -24.1957, F 22.5543, G 0.0057)] [G loss: -22.9922]\n",
      "462 (5, 1) [D loss: (-1.8485)(R -24.5721, F 22.6585, G 0.0065)] [G loss: -23.7672]\n",
      "463 (5, 1) [D loss: (-1.4032)(R -25.2570, F 23.7910, G 0.0063)] [G loss: -24.1119]\n",
      "464 (5, 1) [D loss: (-1.6853)(R -25.7970, F 24.0609, G 0.0051)] [G loss: -24.7068]\n",
      "465 (5, 1) [D loss: (-1.4765)(R -26.5457, F 25.0102, G 0.0059)] [G loss: -25.3129]\n",
      "466 (5, 1) [D loss: (-1.1372)(R -26.6648, F 25.4767, G 0.0051)] [G loss: -26.3037]\n",
      "467 (5, 1) [D loss: (-1.7684)(R -28.1557, F 26.3309, G 0.0056)] [G loss: -26.8946]\n",
      "468 (5, 1) [D loss: (-1.1293)(R -27.9836, F 26.7940, G 0.0060)] [G loss: -27.3074]\n",
      "469 (5, 1) [D loss: (-1.0465)(R -28.7048, F 27.5978, G 0.0060)] [G loss: -28.2701]\n",
      "470 (5, 1) [D loss: (-1.1858)(R -30.0585, F 28.7953, G 0.0077)] [G loss: -29.7241]\n",
      "471 (5, 1) [D loss: (-1.1199)(R -30.9430, F 29.7329, G 0.0090)] [G loss: -30.0318]\n",
      "472 (5, 1) [D loss: (-1.5940)(R -31.1612, F 29.4981, G 0.0069)] [G loss: -30.2536]\n",
      "473 (5, 1) [D loss: (-1.4938)(R -30.0183, F 28.4769, G 0.0048)] [G loss: -28.8339]\n",
      "474 (5, 1) [D loss: (-1.6338)(R -29.7609, F 28.0726, G 0.0054)] [G loss: -28.4406]\n",
      "475 (5, 1) [D loss: (-1.7406)(R -30.2476, F 28.4484, G 0.0059)] [G loss: -28.8850]\n",
      "476 (5, 1) [D loss: (-1.4375)(R -28.9932, F 27.5061, G 0.0050)] [G loss: -27.5618]\n",
      "477 (5, 1) [D loss: (-1.7334)(R -27.6371, F 25.8674, G 0.0036)] [G loss: -26.3901]\n",
      "478 (5, 1) [D loss: (-1.3134)(R -26.2797, F 24.9339, G 0.0032)] [G loss: -24.7344]\n",
      "479 (5, 1) [D loss: (-1.1440)(R -24.2133, F 23.0502, G 0.0019)] [G loss: -22.8329]\n",
      "480 (5, 1) [D loss: (-1.0146)(R -22.0142, F 20.9810, G 0.0019)] [G loss: -20.9726]\n",
      "481 (5, 1) [D loss: (-1.1697)(R -20.3754, F 19.1920, G 0.0014)] [G loss: -19.2252]\n",
      "482 (5, 1) [D loss: (-0.8550)(R -18.6603, F 17.7905, G 0.0015)] [G loss: -17.8228]\n",
      "483 (5, 1) [D loss: (-0.7713)(R -16.2274, F 15.4406, G 0.0015)] [G loss: -15.1564]\n",
      "484 (5, 1) [D loss: (-1.0864)(R -14.5679, F 13.4681, G 0.0013)] [G loss: -13.2252]\n",
      "485 (5, 1) [D loss: (-1.0691)(R -13.3030, F 12.2208, G 0.0013)] [G loss: -12.3093]\n",
      "486 (5, 1) [D loss: (-1.1797)(R -11.1878, F 9.9951, G 0.0013)] [G loss: -9.8828]\n",
      "487 (5, 1) [D loss: (-1.2173)(R -9.8121, F 8.5838, G 0.0011)] [G loss: -7.9430]\n",
      "488 (5, 1) [D loss: (-1.4473)(R -8.0589, F 6.6003, G 0.0011)] [G loss: -6.5291]\n",
      "489 (5, 1) [D loss: (-1.0263)(R -6.8308, F 5.7951, G 0.0009)] [G loss: -5.2797]\n",
      "490 (5, 1) [D loss: (-1.7331)(R -7.2998, F 5.5571, G 0.0010)] [G loss: -5.8558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 (5, 1) [D loss: (-1.5186)(R -7.4935, F 5.9621, G 0.0013)] [G loss: -5.9668]\n",
      "492 (5, 1) [D loss: (-1.5432)(R -7.8915, F 6.3326, G 0.0016)] [G loss: -6.6357]\n",
      "493 (5, 1) [D loss: (-0.9612)(R -7.5052, F 6.5269, G 0.0017)] [G loss: -6.8038]\n",
      "494 (5, 1) [D loss: (-1.4640)(R -8.7757, F 7.2904, G 0.0021)] [G loss: -8.1562]\n",
      "495 (5, 1) [D loss: (-1.2065)(R -11.7240, F 10.4758, G 0.0042)] [G loss: -11.2538]\n",
      "496 (5, 1) [D loss: (-1.3244)(R -14.8958, F 13.5228, G 0.0049)] [G loss: -14.5916]\n",
      "497 (5, 1) [D loss: (-1.3260)(R -19.1063, F 17.6984, G 0.0082)] [G loss: -18.7833]\n",
      "498 (5, 1) [D loss: (-1.2576)(R -22.8751, F 21.4922, G 0.0125)] [G loss: -22.3107]\n",
      "499 (5, 1) [D loss: (-1.4791)(R -25.1015, F 23.4804, G 0.0142)] [G loss: -24.8974]\n",
      "500 (5, 1) [D loss: (-1.5734)(R -26.6097, F 24.8932, G 0.0143)] [G loss: -26.0194]\n",
      "501 (5, 1) [D loss: (-2.0336)(R -28.0622, F 25.8785, G 0.0150)] [G loss: -27.4923]\n",
      "502 (5, 1) [D loss: (-1.7729)(R -28.5864, F 26.6350, G 0.0179)] [G loss: -27.4455]\n",
      "503 (5, 1) [D loss: (-1.6606)(R -28.5861, F 26.7863, G 0.0139)] [G loss: -27.7485]\n",
      "504 (5, 1) [D loss: (-1.7306)(R -27.7391, F 25.8893, G 0.0119)] [G loss: -26.7100]\n",
      "505 (5, 1) [D loss: (-1.8931)(R -27.6674, F 25.6586, G 0.0116)] [G loss: -25.8678]\n",
      "506 (5, 1) [D loss: (-1.7495)(R -26.0011, F 24.1827, G 0.0069)] [G loss: -24.3926]\n",
      "507 (5, 1) [D loss: (-1.4219)(R -24.0561, F 22.5792, G 0.0055)] [G loss: -22.6733]\n",
      "508 (5, 1) [D loss: (-1.5506)(R -22.8779, F 21.2875, G 0.0040)] [G loss: -22.0029]\n",
      "509 (5, 1) [D loss: (-0.9447)(R -20.8784, F 19.9045, G 0.0029)] [G loss: -19.3455]\n",
      "510 (5, 1) [D loss: (-0.9124)(R -19.7561, F 18.8166, G 0.0027)] [G loss: -18.8137]\n",
      "511 (5, 1) [D loss: (-0.2887)(R -19.2877, F 18.9732, G 0.0026)] [G loss: -19.1848]\n",
      "512 (5, 1) [D loss: (-0.8988)(R -19.6445, F 18.7258, G 0.0020)] [G loss: -18.9443]\n",
      "513 (5, 1) [D loss: (-0.6348)(R -20.3331, F 19.6743, G 0.0024)] [G loss: -19.9411]\n",
      "514 (5, 1) [D loss: (-1.2813)(R -21.4841, F 20.1796, G 0.0023)] [G loss: -20.8719]\n",
      "515 (5, 1) [D loss: (-0.7424)(R -21.6068, F 20.8366, G 0.0028)] [G loss: -21.0026]\n",
      "516 (5, 1) [D loss: (-1.4893)(R -21.9950, F 20.4776, G 0.0028)] [G loss: -21.0511]\n",
      "517 (5, 1) [D loss: (-1.2872)(R -22.2822, F 20.9613, G 0.0034)] [G loss: -21.2598]\n",
      "518 (5, 1) [D loss: (-1.2723)(R -21.9857, F 20.6649, G 0.0049)] [G loss: -19.8990]\n",
      "519 (5, 1) [D loss: (-1.6565)(R -19.5163, F 17.8253, G 0.0034)] [G loss: -17.2441]\n",
      "520 (5, 1) [D loss: (-1.5793)(R -17.3974, F 15.7879, G 0.0030)] [G loss: -15.0159]\n",
      "521 (5, 1) [D loss: (-1.1290)(R -14.3204, F 13.1662, G 0.0025)] [G loss: -12.4497]\n",
      "522 (5, 1) [D loss: (-1.5151)(R -11.4557, F 9.9246, G 0.0016)] [G loss: -9.4950]\n",
      "523 (5, 1) [D loss: (-1.6025)(R -9.5699, F 7.9489, G 0.0019)] [G loss: -7.7584]\n",
      "524 (5, 1) [D loss: (-1.2975)(R -7.6930, F 6.3691, G 0.0026)] [G loss: -6.0100]\n",
      "525 (5, 1) [D loss: (-0.6642)(R -6.1725, F 5.4824, G 0.0026)] [G loss: -5.4752]\n",
      "526 (5, 1) [D loss: (-0.8287)(R -7.8683, F 7.0059, G 0.0034)] [G loss: -7.7582]\n",
      "527 (5, 1) [D loss: (-1.4194)(R -11.7674, F 10.2936, G 0.0054)] [G loss: -11.0071]\n",
      "528 (5, 1) [D loss: (-1.6311)(R -13.9338, F 12.2475, G 0.0055)] [G loss: -12.8009]\n",
      "529 (5, 1) [D loss: (-1.3154)(R -15.5633, F 14.1589, G 0.0089)] [G loss: -14.6233]\n",
      "530 (5, 1) [D loss: (-2.0956)(R -15.3588, F 13.1830, G 0.0080)] [G loss: -13.2255]\n",
      "531 (5, 1) [D loss: (-1.8775)(R -12.2264, F 10.2906, G 0.0058)] [G loss: -9.6186]\n",
      "532 (5, 1) [D loss: (-2.0283)(R -7.1828, F 5.0863, G 0.0068)] [G loss: -4.3222]\n",
      "533 (5, 1) [D loss: (-2.7611)(R -2.4827, F -0.3528, G 0.0074)] [G loss: 0.9418]\n",
      "534 (5, 1) [D loss: (-2.1279)(R 4.7458, F -7.0050, G 0.0131)] [G loss: 7.8577]\n",
      "535 (5, 1) [D loss: (-2.7639)(R 7.6448, F -10.5747, G 0.0166)] [G loss: 10.1062]\n",
      "536 (5, 1) [D loss: (-2.5064)(R 9.6663, F -12.3446, G 0.0172)] [G loss: 11.8333]\n",
      "537 (5, 1) [D loss: (-1.8164)(R 9.2660, F -11.2386, G 0.0156)] [G loss: 10.8609]\n",
      "538 (5, 1) [D loss: (-2.4374)(R 6.7619, F -9.3213, G 0.0122)] [G loss: 9.0182]\n",
      "539 (5, 1) [D loss: (-2.3606)(R 4.0523, F -6.4884, G 0.0075)] [G loss: 5.6579]\n",
      "540 (5, 1) [D loss: (-3.0687)(R -2.2019, F -0.9392, G 0.0072)] [G loss: -0.6461]\n",
      "541 (5, 1) [D loss: (-3.3333)(R -8.7883, F 5.3367, G 0.0118)] [G loss: -6.7099]\n",
      "542 (5, 1) [D loss: (-3.3958)(R -16.3733, F 12.7016, G 0.0276)] [G loss: -14.1013]\n",
      "543 (5, 1) [D loss: (-2.1982)(R -18.8642, F 16.3174, G 0.0349)] [G loss: -16.0746]\n",
      "544 (5, 1) [D loss: (-1.4771)(R -19.5411, F 17.8092, G 0.0255)] [G loss: -18.0945]\n",
      "545 (5, 1) [D loss: (-0.5046)(R -19.8174, F 19.1606, G 0.0152)] [G loss: -20.2214]\n",
      "546 (5, 1) [D loss: (-1.0283)(R -23.9605, F 22.8178, G 0.0114)] [G loss: -24.1880]\n",
      "547 (5, 1) [D loss: (-1.0882)(R -26.8799, F 25.6627, G 0.0129)] [G loss: -26.9583]\n",
      "548 (5, 1) [D loss: (-1.8795)(R -30.7195, F 28.6319, G 0.0208)] [G loss: -30.2057]\n",
      "549 (5, 1) [D loss: (-2.8223)(R -31.5107, F 28.4555, G 0.0233)] [G loss: -29.6039]\n",
      "550 (5, 1) [D loss: (-2.7612)(R -31.0057, F 27.9860, G 0.0258)] [G loss: -28.2627]\n",
      "551 (5, 1) [D loss: (-2.9466)(R -26.2342, F 23.1512, G 0.0136)] [G loss: -23.0102]\n",
      "552 (5, 1) [D loss: (-1.3397)(R -19.5393, F 18.1446, G 0.0055)] [G loss: -16.9175]\n",
      "553 (5, 1) [D loss: (-1.6241)(R -14.0560, F 12.4098, G 0.0022)] [G loss: -12.0356]\n",
      "554 (5, 1) [D loss: (-1.0544)(R -8.8539, F 7.7889, G 0.0011)] [G loss: -7.2903]\n",
      "555 (5, 1) [D loss: (-0.8021)(R -6.1003, F 5.2911, G 0.0007)] [G loss: -4.5363]\n",
      "556 (5, 1) [D loss: (-0.5229)(R -3.1663, F 2.6339, G 0.0010)] [G loss: -2.6153]\n",
      "557 (5, 1) [D loss: (-0.1805)(R -3.5171, F 3.3239, G 0.0013)] [G loss: -3.4090]\n",
      "558 (5, 1) [D loss: (0.1135)(R -5.4047, F 5.5018, G 0.0016)] [G loss: -5.6335]\n",
      "559 (5, 1) [D loss: (0.3959)(R -9.4647, F 9.8460, G 0.0015)] [G loss: -10.3969]\n",
      "560 (5, 1) [D loss: (-0.7732)(R -15.7018, F 14.9212, G 0.0007)] [G loss: -16.1325]\n",
      "561 (5, 1) [D loss: (-1.6739)(R -21.0037, F 19.3112, G 0.0019)] [G loss: -20.8436]\n",
      "562 (5, 1) [D loss: (-1.9694)(R -24.5291, F 22.5142, G 0.0046)] [G loss: -22.8655]\n",
      "563 (5, 1) [D loss: (-1.2980)(R -22.1153, F 20.7874, G 0.0030)] [G loss: -19.7573]\n",
      "564 (5, 1) [D loss: (-1.4857)(R -17.8005, F 16.3038, G 0.0011)] [G loss: -15.3160]\n",
      "565 (5, 1) [D loss: (-1.8649)(R -11.7732, F 9.8968, G 0.0012)] [G loss: -7.8540]\n",
      "566 (5, 1) [D loss: (-2.5179)(R -4.4981, F 1.9663, G 0.0014)] [G loss: -0.4295]\n",
      "567 (5, 1) [D loss: (-2.9734)(R 3.4598, F -6.4732, G 0.0040)] [G loss: 7.1944]\n",
      "568 (5, 1) [D loss: (-3.3034)(R 8.3587, F -11.7917, G 0.0130)] [G loss: 12.0138]\n",
      "569 (5, 1) [D loss: (-2.7983)(R 11.0790, F -14.1182, G 0.0241)] [G loss: 13.8852]\n",
      "570 (5, 1) [D loss: (-2.5985)(R 10.4775, F -13.3388, G 0.0263)] [G loss: 12.8200]\n",
      "571 (5, 1) [D loss: (-2.8602)(R 7.7762, F -10.8640, G 0.0228)] [G loss: 9.8575]\n",
      "572 (5, 1) [D loss: (-2.1954)(R 3.6988, F -6.0611, G 0.0167)] [G loss: 5.6049]\n",
      "573 (5, 1) [D loss: (-2.6198)(R -0.4750, F -2.3089, G 0.0164)] [G loss: 1.1752]\n",
      "574 (5, 1) [D loss: (-3.2986)(R -4.3627, F 0.8705, G 0.0194)] [G loss: -1.6019]\n",
      "575 (5, 1) [D loss: (-2.8550)(R -3.8777, F 0.7928, G 0.0230)] [G loss: -0.1973]\n",
      "576 (5, 1) [D loss: (-2.8720)(R 0.3439, F -3.4891, G 0.0273)] [G loss: 4.6195]\n",
      "577 (5, 1) [D loss: (-4.0201)(R 5.3005, F -9.6704, G 0.0350)] [G loss: 10.7446]\n",
      "578 (5, 1) [D loss: (-3.7596)(R 12.8948, F -17.1568, G 0.0502)] [G loss: 16.8092]\n",
      "579 (5, 1) [D loss: (-3.9335)(R 18.8427, F -23.4690, G 0.0693)] [G loss: 22.8556]\n",
      "580 (5, 1) [D loss: (-3.5214)(R 21.1987, F -25.3640, G 0.0644)] [G loss: 23.4574]\n",
      "581 (5, 1) [D loss: (-3.0703)(R 21.8380, F -25.4103, G 0.0502)] [G loss: 23.9329]\n",
      "582 (5, 1) [D loss: (-2.4390)(R 22.5969, F -25.4291, G 0.0393)] [G loss: 23.5450]\n",
      "583 (5, 1) [D loss: (-1.1843)(R 22.4488, F -23.8450, G 0.0212)] [G loss: 21.9238]\n",
      "584 (5, 1) [D loss: (-1.0515)(R 19.0123, F -20.1461, G 0.0082)] [G loss: 19.0576]\n",
      "585 (5, 1) [D loss: (-0.8165)(R 18.2726, F -19.1330, G 0.0044)] [G loss: 17.8730]\n",
      "586 (5, 1) [D loss: (-0.8082)(R 15.3399, F -16.1649, G 0.0017)] [G loss: 15.1392]\n",
      "587 (5, 1) [D loss: (-2.9939)(R 9.0200, F -12.0247, G 0.0011)] [G loss: 11.2580]\n",
      "588 (5, 1) [D loss: (-4.9715)(R 0.7443, F -5.7849, G 0.0069)] [G loss: 3.9820]\n",
      "589 (5, 1) [D loss: (-8.2565)(R -11.2383, F 2.3678, G 0.0614)] [G loss: -3.0440]\n",
      "590 (5, 1) [D loss: (-8.4635)(R -14.8871, F 5.0977, G 0.1326)] [G loss: -4.7450]\n",
      "591 (5, 1) [D loss: (-7.2185)(R -9.3023, F 0.8927, G 0.1191)] [G loss: 0.1860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592 (5, 1) [D loss: (-5.6786)(R -3.4491, F -2.9841, G 0.0755)] [G loss: 3.4222]\n",
      "593 (5, 1) [D loss: (-3.7035)(R -5.1391, F 1.0087, G 0.0427)] [G loss: -1.7856]\n",
      "594 (5, 1) [D loss: (-2.3457)(R -8.2205, F 5.6511, G 0.0224)] [G loss: -7.3253]\n",
      "595 (5, 1) [D loss: (-2.0083)(R -16.2289, F 14.0175, G 0.0203)] [G loss: -16.0155]\n",
      "596 (5, 1) [D loss: (-2.5024)(R -23.5166, F 20.6954, G 0.0319)] [G loss: -22.8011]\n",
      "597 (5, 1) [D loss: (-3.0984)(R -27.2946, F 23.8727, G 0.0323)] [G loss: -26.3258]\n",
      "598 (5, 1) [D loss: (-2.2370)(R -29.2836, F 26.7211, G 0.0326)] [G loss: -27.3693]\n",
      "599 (5, 1) [D loss: (-1.6485)(R -27.9405, F 26.1341, G 0.0158)] [G loss: -26.7825]\n",
      "600 (5, 1) [D loss: (-1.3684)(R -25.9917, F 24.5542, G 0.0069)] [G loss: -24.5000]\n",
      "601 (5, 1) [D loss: (-0.8853)(R -22.7038, F 21.7966, G 0.0022)] [G loss: -22.0312]\n",
      "602 (5, 1) [D loss: (-0.7558)(R -20.4123, F 19.6447, G 0.0012)] [G loss: -19.8732]\n",
      "603 (5, 1) [D loss: (-0.7626)(R -18.5611, F 17.7861, G 0.0012)] [G loss: -17.6442]\n",
      "604 (5, 1) [D loss: (-1.1083)(R -15.1973, F 14.0686, G 0.0020)] [G loss: -13.6396]\n",
      "605 (5, 1) [D loss: (-1.0688)(R -12.1012, F 11.0043, G 0.0028)] [G loss: -11.0975]\n",
      "606 (5, 1) [D loss: (-0.8868)(R -9.2936, F 8.3841, G 0.0023)] [G loss: -7.6992]\n",
      "607 (5, 1) [D loss: (-1.1855)(R -6.2035, F 4.9950, G 0.0023)] [G loss: -4.4637]\n",
      "608 (5, 1) [D loss: (-0.8317)(R -2.3072, F 1.4569, G 0.0019)] [G loss: -0.9592]\n",
      "609 (5, 1) [D loss: (-0.8918)(R -0.5895, F -0.3160, G 0.0014)] [G loss: 1.4466]\n",
      "610 (5, 1) [D loss: (-1.1036)(R 2.0452, F -3.1571, G 0.0008)] [G loss: 4.0937]\n",
      "611 (5, 1) [D loss: (-0.7034)(R 1.8953, F -2.6064, G 0.0008)] [G loss: 3.3754]\n",
      "612 (5, 1) [D loss: (-1.1591)(R 0.7085, F -1.8756, G 0.0008)] [G loss: 1.6864]\n",
      "613 (5, 1) [D loss: (-1.9781)(R -2.1377, F 0.1475, G 0.0012)] [G loss: -0.6595]\n",
      "614 (5, 1) [D loss: (-2.6333)(R -6.0660, F 3.4029, G 0.0030)] [G loss: -4.3293]\n",
      "615 (5, 1) [D loss: (-2.6892)(R -8.3472, F 5.5816, G 0.0076)] [G loss: -5.7615]\n",
      "616 (5, 1) [D loss: (-2.6506)(R -8.0102, F 5.2522, G 0.0107)] [G loss: -5.6367]\n",
      "617 (5, 1) [D loss: (-2.3934)(R -7.2353, F 4.7281, G 0.0114)] [G loss: -4.2845]\n",
      "618 (5, 1) [D loss: (-2.1233)(R -3.8787, F 1.6329, G 0.0123)] [G loss: -0.4037]\n",
      "619 (5, 1) [D loss: (-2.2337)(R -1.0563, F -1.2761, G 0.0099)] [G loss: 2.4759]\n",
      "620 (5, 1) [D loss: (-1.6654)(R 1.7984, F -3.5577, G 0.0094)] [G loss: 4.1567]\n",
      "621 (5, 1) [D loss: (-2.1553)(R 1.8771, F -4.1089, G 0.0077)] [G loss: 4.8045]\n",
      "622 (5, 1) [D loss: (-2.0284)(R 2.2492, F -4.3590, G 0.0081)] [G loss: 4.6389]\n",
      "623 (5, 1) [D loss: (-2.0331)(R 1.5635, F -3.6682, G 0.0072)] [G loss: 4.0149]\n",
      "624 (5, 1) [D loss: (-2.2943)(R -0.2087, F -2.1470, G 0.0061)] [G loss: 1.7260]\n",
      "625 (5, 1) [D loss: (-1.7868)(R -3.1677, F 1.3373, G 0.0044)] [G loss: -2.1089]\n",
      "626 (5, 1) [D loss: (-2.6060)(R -9.9557, F 7.3115, G 0.0038)] [G loss: -8.6431]\n",
      "627 (5, 1) [D loss: (-1.6966)(R -15.3723, F 13.6149, G 0.0061)] [G loss: -14.3860]\n",
      "628 (5, 1) [D loss: (-1.5781)(R -20.5632, F 18.8845, G 0.0101)] [G loss: -19.7131]\n",
      "629 (5, 1) [D loss: (-2.0315)(R -24.6127, F 22.4436, G 0.0138)] [G loss: -23.1434]\n",
      "630 (5, 1) [D loss: (-2.9974)(R -27.6214, F 24.4688, G 0.0155)] [G loss: -25.5205]\n",
      "631 (5, 1) [D loss: (-2.8674)(R -29.3424, F 26.2668, G 0.0208)] [G loss: -26.9227]\n",
      "632 (5, 1) [D loss: (-2.9181)(R -29.3062, F 26.1870, G 0.0201)] [G loss: -26.7577]\n",
      "633 (5, 1) [D loss: (-2.8349)(R -27.6928, F 24.6980, G 0.0160)] [G loss: -25.1084]\n",
      "634 (5, 1) [D loss: (-2.5274)(R -26.1499, F 23.4606, G 0.0162)] [G loss: -22.7933]\n",
      "635 (5, 1) [D loss: (-3.1339)(R -23.6167, F 20.3571, G 0.0126)] [G loss: -19.7644]\n",
      "636 (5, 1) [D loss: (-2.5085)(R -18.8823, F 16.2865, G 0.0087)] [G loss: -14.9401]\n",
      "637 (5, 1) [D loss: (-2.8220)(R -13.3515, F 10.4732, G 0.0056)] [G loss: -9.5041]\n",
      "638 (5, 1) [D loss: (-2.7938)(R -7.1326, F 4.2790, G 0.0060)] [G loss: -3.6515]\n",
      "639 (5, 1) [D loss: (-2.3046)(R -1.5634, F -0.8307, G 0.0090)] [G loss: 2.7575]\n",
      "640 (5, 1) [D loss: (-2.6005)(R 3.4228, F -6.1352, G 0.0112)] [G loss: 7.0692]\n",
      "641 (5, 1) [D loss: (-2.4266)(R 8.0481, F -10.6217, G 0.0147)] [G loss: 12.0679]\n",
      "642 (5, 1) [D loss: (-2.1143)(R 12.1792, F -14.4980, G 0.0204)] [G loss: 15.7286]\n",
      "643 (5, 1) [D loss: (-1.8131)(R 14.4841, F -16.4558, G 0.0159)] [G loss: 17.3077]\n",
      "644 (5, 1) [D loss: (-2.2733)(R 14.4685, F -16.8676, G 0.0126)] [G loss: 17.3672]\n",
      "645 (5, 1) [D loss: (-1.2618)(R 14.9641, F -16.3123, G 0.0086)] [G loss: 17.2869]\n",
      "646 (5, 1) [D loss: (-0.9791)(R 14.6838, F -15.7026, G 0.0040)] [G loss: 15.9584]\n",
      "647 (5, 1) [D loss: (-0.8652)(R 12.8072, F -13.6840, G 0.0012)] [G loss: 13.8976]\n",
      "648 (5, 1) [D loss: (-0.3475)(R 11.2040, F -11.5609, G 0.0009)] [G loss: 11.4719]\n",
      "649 (5, 1) [D loss: (-0.2916)(R 8.0313, F -8.3454, G 0.0022)] [G loss: 7.9345]\n",
      "650 (5, 1) [D loss: (-0.8804)(R 4.7551, F -5.6741, G 0.0039)] [G loss: 5.2254]\n",
      "651 (5, 1) [D loss: (-0.4242)(R 2.2906, F -2.7580, G 0.0043)] [G loss: 2.0718]\n",
      "652 (5, 1) [D loss: (-0.5149)(R -1.8487, F 1.2965, G 0.0037)] [G loss: -2.9165]\n",
      "653 (5, 1) [D loss: (-1.0005)(R -6.9719, F 5.9470, G 0.0024)] [G loss: -7.5329]\n",
      "654 (5, 1) [D loss: (-1.4571)(R -11.5414, F 10.0759, G 0.0008)] [G loss: -11.6565]\n",
      "655 (5, 1) [D loss: (-0.8691)(R -14.1972, F 13.3169, G 0.0011)] [G loss: -13.5179]\n",
      "656 (5, 1) [D loss: (-2.0157)(R -16.7696, F 14.7381, G 0.0016)] [G loss: -15.5706]\n",
      "657 (5, 1) [D loss: (-1.7343)(R -16.5986, F 14.8471, G 0.0017)] [G loss: -15.0767]\n",
      "658 (5, 1) [D loss: (-2.2284)(R -15.6400, F 13.3976, G 0.0014)] [G loss: -13.1137]\n",
      "659 (5, 1) [D loss: (-1.4878)(R -12.6593, F 11.1538, G 0.0018)] [G loss: -10.1904]\n",
      "660 (5, 1) [D loss: (-2.5459)(R -9.3561, F 6.7927, G 0.0018)] [G loss: -6.3018]\n",
      "661 (5, 1) [D loss: (-2.3100)(R -6.2636, F 3.9192, G 0.0034)] [G loss: -3.1416]\n",
      "662 (5, 1) [D loss: (-2.8664)(R -3.1576, F 0.2374, G 0.0054)] [G loss: -0.1897]\n",
      "663 (5, 1) [D loss: (-2.0599)(R -1.8109, F -0.3401, G 0.0091)] [G loss: 0.4498]\n",
      "664 (5, 1) [D loss: (-1.5026)(R -1.1089, F -0.4884, G 0.0095)] [G loss: 0.8890]\n",
      "665 (5, 1) [D loss: (-1.5874)(R -2.7541, F 1.0957, G 0.0071)] [G loss: -1.7667]\n",
      "666 (5, 1) [D loss: (-1.1914)(R -5.9053, F 4.6494, G 0.0065)] [G loss: -5.4489]\n",
      "667 (5, 1) [D loss: (-0.5547)(R -10.2048, F 9.5883, G 0.0062)] [G loss: -10.3476]\n",
      "668 (5, 1) [D loss: (-1.2059)(R -16.6597, F 15.3769, G 0.0077)] [G loss: -16.8917]\n",
      "669 (5, 1) [D loss: (-2.3369)(R -24.0086, F 21.5098, G 0.0162)] [G loss: -23.4263]\n",
      "670 (5, 1) [D loss: (-2.8975)(R -30.0100, F 26.7662, G 0.0346)] [G loss: -27.9366]\n",
      "671 (5, 1) [D loss: (-2.0641)(R -27.9534, F 25.6700, G 0.0219)] [G loss: -24.6600]\n",
      "672 (5, 1) [D loss: (-2.2583)(R -22.8986, F 20.5521, G 0.0088)] [G loss: -19.7175]\n",
      "673 (5, 1) [D loss: (-2.5439)(R -16.3693, F 13.7972, G 0.0028)] [G loss: -11.9573]\n",
      "674 (5, 1) [D loss: (-1.9910)(R -8.1284, F 6.1195, G 0.0018)] [G loss: -3.9364]\n",
      "675 (5, 1) [D loss: (-2.5063)(R 0.0955, F -2.6409, G 0.0039)] [G loss: 3.8707]\n",
      "676 (5, 1) [D loss: (-2.0760)(R 6.1405, F -8.2998, G 0.0083)] [G loss: 8.4570]\n",
      "677 (5, 1) [D loss: (-1.6796)(R 7.7224, F -9.4992, G 0.0097)] [G loss: 9.5415]\n",
      "678 (5, 1) [D loss: (-1.6332)(R 5.3170, F -7.0113, G 0.0061)] [G loss: 6.5949]\n",
      "679 (5, 1) [D loss: (-1.3890)(R 1.6169, F -3.0529, G 0.0047)] [G loss: 2.3794]\n",
      "680 (5, 1) [D loss: (-1.9815)(R -4.9715, F 2.9311, G 0.0059)] [G loss: -4.3978]\n",
      "681 (5, 1) [D loss: (-1.6538)(R -12.1797, F 10.3947, G 0.0131)] [G loss: -11.9251]\n",
      "682 (5, 1) [D loss: (-2.3798)(R -18.7332, F 16.0889, G 0.0265)] [G loss: -17.9771]\n",
      "683 (5, 1) [D loss: (-2.4831)(R -20.6177, F 17.8438, G 0.0291)] [G loss: -18.4007]\n",
      "684 (5, 1) [D loss: (-1.6115)(R -18.8322, F 17.0203, G 0.0200)] [G loss: -16.3068]\n",
      "685 (5, 1) [D loss: (-2.0603)(R -16.4422, F 14.2617, G 0.0120)] [G loss: -14.0201]\n",
      "686 (5, 1) [D loss: (-1.4354)(R -13.8028, F 12.2849, G 0.0083)] [G loss: -12.1569]\n",
      "687 (5, 1) [D loss: (-1.1517)(R -10.9400, F 9.7381, G 0.0050)] [G loss: -9.3908]\n",
      "688 (5, 1) [D loss: (-1.4274)(R -7.9056, F 6.4470, G 0.0031)] [G loss: -6.7213]\n",
      "689 (5, 1) [D loss: (-1.2206)(R -5.6648, F 4.4244, G 0.0020)] [G loss: -4.1290]\n",
      "690 (5, 1) [D loss: (-0.8348)(R -3.0138, F 2.1580, G 0.0021)] [G loss: -1.8831]\n",
      "691 (5, 1) [D loss: (-1.0048)(R -2.5864, F 1.5654, G 0.0016)] [G loss: -1.0256]\n",
      "692 (5, 1) [D loss: (-1.0620)(R -1.7965, F 0.7190, G 0.0015)] [G loss: -1.4774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 (5, 1) [D loss: (-1.0274)(R -3.3497, F 2.3046, G 0.0018)] [G loss: -2.7606]\n",
      "694 (5, 1) [D loss: (-1.2780)(R -6.2731, F 4.9705, G 0.0025)] [G loss: -5.9205]\n",
      "695 (5, 1) [D loss: (-1.6835)(R -9.7730, F 8.0661, G 0.0023)] [G loss: -9.5195]\n",
      "696 (5, 1) [D loss: (-1.3802)(R -12.1302, F 10.7144, G 0.0036)] [G loss: -11.8612]\n",
      "697 (5, 1) [D loss: (-1.3679)(R -13.0231, F 11.6126, G 0.0043)] [G loss: -11.1950]\n",
      "698 (5, 1) [D loss: (-1.9757)(R -12.7748, F 10.7601, G 0.0039)] [G loss: -10.8575]\n",
      "699 (5, 1) [D loss: (-2.5454)(R -10.7719, F 8.1889, G 0.0038)] [G loss: -7.5024]\n",
      "700 (5, 1) [D loss: (-3.1079)(R -7.1246, F 3.9662, G 0.0051)] [G loss: -3.5903]\n",
      "701 (5, 1) [D loss: (-3.6950)(R -3.6840, F -0.1078, G 0.0097)] [G loss: 0.2085]\n",
      "702 (5, 1) [D loss: (-3.8417)(R -0.1992, F -3.8172, G 0.0175)] [G loss: 4.2912]\n",
      "703 (5, 1) [D loss: (-3.8145)(R 2.9354, F -7.0150, G 0.0265)] [G loss: 7.2513]\n",
      "704 (5, 1) [D loss: (-2.8272)(R 4.3395, F -7.4686, G 0.0302)] [G loss: 7.9898]\n",
      "705 (5, 1) [D loss: (-3.1497)(R 4.3966, F -7.8133, G 0.0267)] [G loss: 8.2243]\n",
      "706 (5, 1) [D loss: (-1.3971)(R 3.9982, F -5.5614, G 0.0166)] [G loss: 5.5915]\n",
      "707 (5, 1) [D loss: (-1.0994)(R 1.8168, F -3.0184, G 0.0102)] [G loss: 3.4657]\n",
      "708 (5, 1) [D loss: (-0.9334)(R -1.4361, F 0.4341, G 0.0069)] [G loss: -0.7028]\n",
      "709 (5, 1) [D loss: (-0.3532)(R -6.2121, F 5.8243, G 0.0035)] [G loss: -6.3719]\n",
      "710 (5, 1) [D loss: (-0.9435)(R -12.1436, F 11.1586, G 0.0041)] [G loss: -11.9852]\n",
      "711 (5, 1) [D loss: (-1.4892)(R -16.4147, F 14.8615, G 0.0064)] [G loss: -15.4625]\n",
      "712 (5, 1) [D loss: (-1.5150)(R -18.7923, F 17.1830, G 0.0094)] [G loss: -17.3446]\n",
      "713 (5, 1) [D loss: (-1.7880)(R -17.0711, F 15.2119, G 0.0071)] [G loss: -14.1853]\n",
      "714 (5, 1) [D loss: (-2.1623)(R -10.6984, F 8.4920, G 0.0044)] [G loss: -7.7630]\n",
      "715 (5, 1) [D loss: (-2.2137)(R -3.1828, F 0.9311, G 0.0038)] [G loss: 0.7243]\n",
      "716 (5, 1) [D loss: (-3.6038)(R 8.0197, F -11.7516, G 0.0128)] [G loss: 12.5415]\n",
      "717 (5, 1) [D loss: (-3.5859)(R 17.6687, F -21.5948, G 0.0340)] [G loss: 21.2806]\n",
      "718 (5, 1) [D loss: (-3.7589)(R 21.7889, F -26.0362, G 0.0488)] [G loss: 24.5445]\n",
      "719 (5, 1) [D loss: (-3.5934)(R 22.9074, F -27.0053, G 0.0505)] [G loss: 25.6362]\n",
      "720 (5, 1) [D loss: (-2.6446)(R 23.3879, F -26.4923, G 0.0460)] [G loss: 24.8046]\n",
      "721 (5, 1) [D loss: (-3.0193)(R 20.4960, F -23.7822, G 0.0267)] [G loss: 22.2154]\n",
      "722 (5, 1) [D loss: (-2.1392)(R 17.7462, F -20.0294, G 0.0144)] [G loss: 18.7918]\n",
      "723 (5, 1) [D loss: (-1.8391)(R 14.7579, F -16.6805, G 0.0083)] [G loss: 15.2869]\n",
      "724 (5, 1) [D loss: (-1.3968)(R 9.9672, F -11.4074, G 0.0043)] [G loss: 9.9833]\n",
      "725 (5, 1) [D loss: (-2.0553)(R 1.4140, F -3.5046, G 0.0035)] [G loss: 2.0181]\n",
      "726 (5, 1) [D loss: (-4.0573)(R -11.6211, F 7.4007, G 0.0163)] [G loss: -10.7850]\n",
      "727 (5, 1) [D loss: (-3.9338)(R -19.5982, F 15.1640, G 0.0500)] [G loss: -15.9112]\n",
      "728 (5, 1) [D loss: (-4.3365)(R -18.1300, F 13.2808, G 0.0513)] [G loss: -11.8212]\n",
      "729 (5, 1) [D loss: (-3.6281)(R -8.0143, F 4.1323, G 0.0254)] [G loss: -2.2904]\n",
      "730 (5, 1) [D loss: (-3.1926)(R 0.9039, F -4.3164, G 0.0220)] [G loss: 6.9737]\n",
      "731 (5, 1) [D loss: (-3.0427)(R 8.3447, F -11.6182, G 0.0231)] [G loss: 12.7962]\n",
      "732 (5, 1) [D loss: (-2.0042)(R 10.4328, F -12.5809, G 0.0144)] [G loss: 13.2080]\n",
      "733 (5, 1) [D loss: (-1.0946)(R 9.0041, F -10.1663, G 0.0068)] [G loss: 10.0911]\n",
      "734 (5, 1) [D loss: (-1.0997)(R 2.1748, F -3.2871, G 0.0013)] [G loss: 2.6840]\n",
      "735 (5, 1) [D loss: (-0.7264)(R -5.6450, F 4.9087, G 0.0010)] [G loss: -6.7934]\n",
      "736 (5, 1) [D loss: (-1.8249)(R -16.8546, F 14.9740, G 0.0056)] [G loss: -17.8752]\n",
      "737 (5, 1) [D loss: (-2.1127)(R -26.0615, F 23.7398, G 0.0209)] [G loss: -25.6771]\n",
      "738 (5, 1) [D loss: (-1.0821)(R -27.1825, F 25.8917, G 0.0209)] [G loss: -26.0026]\n",
      "739 (5, 1) [D loss: (-0.5788)(R -25.5987, F 24.9182, G 0.0102)] [G loss: -24.2474]\n",
      "740 (5, 1) [D loss: (-1.3991)(R -22.2510, F 20.8264, G 0.0026)] [G loss: -20.6053]\n",
      "741 (5, 1) [D loss: (-0.9504)(R -18.6959, F 17.7277, G 0.0018)] [G loss: -16.1398]\n",
      "742 (5, 1) [D loss: (-1.3299)(R -15.5141, F 14.1674, G 0.0017)] [G loss: -13.2191]\n",
      "743 (5, 1) [D loss: (-1.3155)(R -11.6000, F 10.2632, G 0.0021)] [G loss: -9.3789]\n",
      "744 (5, 1) [D loss: (-1.8619)(R -8.1236, F 6.2418, G 0.0020)] [G loss: -5.1532]\n",
      "745 (5, 1) [D loss: (-2.2901)(R -5.1020, F 2.8002, G 0.0012)] [G loss: -2.9033]\n",
      "746 (5, 1) [D loss: (-2.0344)(R -3.1581, F 1.1077, G 0.0016)] [G loss: -0.8223]\n",
      "747 (5, 1) [D loss: (-1.5835)(R -3.1603, F 1.5550, G 0.0022)] [G loss: -1.1357]\n",
      "748 (5, 1) [D loss: (-1.5496)(R -4.6067, F 3.0251, G 0.0032)] [G loss: -3.2487]\n",
      "749 (5, 1) [D loss: (-1.1629)(R -7.6903, F 6.4907, G 0.0037)] [G loss: -6.5436]\n",
      "750 (5, 1) [D loss: (-1.9725)(R -12.9531, F 10.9028, G 0.0078)] [G loss: -11.2716]\n",
      "751 (5, 1) [D loss: (-2.9705)(R -18.8882, F 15.7690, G 0.0149)] [G loss: -17.5324]\n",
      "752 (5, 1) [D loss: (-3.1752)(R -23.8611, F 20.4182, G 0.0268)] [G loss: -21.9002]\n",
      "753 (5, 1) [D loss: (-3.3007)(R -25.1737, F 21.5763, G 0.0297)] [G loss: -22.2020]\n",
      "754 (5, 1) [D loss: (-2.3794)(R -22.9532, F 20.3712, G 0.0203)] [G loss: -19.6882]\n",
      "755 (5, 1) [D loss: (-2.3508)(R -18.9720, F 16.4898, G 0.0131)] [G loss: -15.7450]\n",
      "756 (5, 1) [D loss: (-1.8061)(R -14.1018, F 12.1927, G 0.0103)] [G loss: -10.3287]\n",
      "757 (5, 1) [D loss: (-1.9149)(R -7.8899, F 5.9360, G 0.0039)] [G loss: -4.7004]\n",
      "758 (5, 1) [D loss: (-1.5395)(R -1.5750, F 0.0011, G 0.0034)] [G loss: 0.5872]\n",
      "759 (5, 1) [D loss: (-0.9272)(R 2.3694, F -3.3358, G 0.0039)] [G loss: 4.6297]\n",
      "760 (5, 1) [D loss: (-0.1812)(R 6.0306, F -6.2464, G 0.0034)] [G loss: 6.5381]\n",
      "761 (5, 1) [D loss: (-0.1464)(R 5.7470, F -5.9100, G 0.0017)] [G loss: 5.9677]\n",
      "762 (5, 1) [D loss: (0.0048)(R 4.5902, F -4.5986, G 0.0013)] [G loss: 3.8687]\n",
      "763 (5, 1) [D loss: (0.5392)(R 1.0849, F -0.5732, G 0.0027)] [G loss: 0.1726]\n",
      "764 (5, 1) [D loss: (0.2212)(R -4.5179, F 4.7029, G 0.0036)] [G loss: -5.6447]\n",
      "765 (5, 1) [D loss: (-0.5941)(R -11.6581, F 11.0391, G 0.0025)] [G loss: -12.4606]\n",
      "766 (5, 1) [D loss: (-1.7418)(R -20.2229, F 18.4498, G 0.0031)] [G loss: -20.7156]\n",
      "767 (5, 1) [D loss: (-3.2330)(R -29.2188, F 25.7936, G 0.0192)] [G loss: -28.2390]\n",
      "768 (5, 1) [D loss: (-2.6955)(R -32.0365, F 29.0144, G 0.0327)] [G loss: -29.4881]\n",
      "769 (5, 1) [D loss: (-2.8895)(R -29.7160, F 26.6251, G 0.0201)] [G loss: -26.3071]\n",
      "770 (5, 1) [D loss: (-2.1841)(R -25.6016, F 23.3165, G 0.0101)] [G loss: -22.0410]\n",
      "771 (5, 1) [D loss: (-2.8427)(R -20.3631, F 17.4710, G 0.0050)] [G loss: -16.8068]\n",
      "772 (5, 1) [D loss: (-2.4492)(R -16.1129, F 13.6085, G 0.0055)] [G loss: -11.9618]\n",
      "773 (5, 1) [D loss: (-3.0310)(R -11.7766, F 8.6960, G 0.0050)] [G loss: -7.6990]\n",
      "774 (5, 1) [D loss: (-3.2911)(R -5.9820, F 2.6136, G 0.0077)] [G loss: -1.9122]\n",
      "775 (5, 1) [D loss: (-3.0793)(R -1.7480, F -1.4440, G 0.0113)] [G loss: 2.2705]\n",
      "776 (5, 1) [D loss: (-2.7821)(R 1.1239, F -4.0530, G 0.0147)] [G loss: 4.1638]\n",
      "777 (5, 1) [D loss: (-2.3743)(R 2.8951, F -5.4678, G 0.0198)] [G loss: 5.6631]\n",
      "778 (5, 1) [D loss: (-1.9858)(R 1.4204, F -3.5700, G 0.0164)] [G loss: 3.1425]\n",
      "779 (5, 1) [D loss: (-1.6502)(R -1.3956, F -0.3755, G 0.0121)] [G loss: 0.1972]\n",
      "780 (5, 1) [D loss: (-1.5933)(R -6.3136, F 4.6134, G 0.0107)] [G loss: -5.4290]\n",
      "781 (5, 1) [D loss: (-1.7920)(R -11.0833, F 9.1561, G 0.0135)] [G loss: -10.7681]\n",
      "782 (5, 1) [D loss: (-1.2354)(R -16.0163, F 14.6146, G 0.0166)] [G loss: -15.2555]\n",
      "783 (5, 1) [D loss: (-1.6963)(R -19.0882, F 17.1892, G 0.0203)] [G loss: -17.7747]\n",
      "784 (5, 1) [D loss: (-0.7414)(R -15.3578, F 14.5326, G 0.0084)] [G loss: -13.2185]\n",
      "785 (5, 1) [D loss: (-1.1883)(R -10.8266, F 9.5976, G 0.0041)] [G loss: -8.8723]\n",
      "786 (5, 1) [D loss: (-1.5576)(R -6.1207, F 4.5270, G 0.0036)] [G loss: -3.2176]\n",
      "787 (5, 1) [D loss: (-1.7512)(R 1.4361, F -3.2134, G 0.0026)] [G loss: 4.5393]\n",
      "788 (5, 1) [D loss: (-3.0347)(R 9.0574, F -12.1606, G 0.0069)] [G loss: 12.9223]\n",
      "789 (5, 1) [D loss: (-2.9146)(R 16.1613, F -19.2174, G 0.0142)] [G loss: 19.0433]\n",
      "790 (5, 1) [D loss: (-3.0276)(R 19.6347, F -22.9232, G 0.0261)] [G loss: 22.4976]\n",
      "791 (5, 1) [D loss: (-2.3089)(R 20.0406, F -22.6034, G 0.0254)] [G loss: 21.7812]\n",
      "792 (5, 1) [D loss: (-2.3827)(R 16.2487, F -18.7874, G 0.0156)] [G loss: 18.3882]\n",
      "793 (5, 1) [D loss: (-2.6025)(R 12.0861, F -14.8111, G 0.0122)] [G loss: 14.0922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 (5, 1) [D loss: (-1.9151)(R 7.9759, F -9.9953, G 0.0104)] [G loss: 8.4327]\n",
      "795 (5, 1) [D loss: (-2.3706)(R 1.1502, F -3.6205, G 0.0100)] [G loss: 2.2768]\n",
      "796 (5, 1) [D loss: (-2.3702)(R -2.0684, F -0.4193, G 0.0117)] [G loss: -0.0363]\n",
      "797 (5, 1) [D loss: (-2.4103)(R -3.9630, F 1.4121, G 0.0141)] [G loss: -1.2968]\n",
      "798 (5, 1) [D loss: (-1.5944)(R -2.4348, F 0.7232, G 0.0117)] [G loss: -0.3828]\n",
      "799 (5, 1) [D loss: (-2.1544)(R 0.0921, F -2.3512, G 0.0105)] [G loss: 2.3170]\n",
      "800 (5, 1) [D loss: (-2.4043)(R 2.6931, F -5.1883, G 0.0091)] [G loss: 4.7490]\n",
      "801 (5, 1) [D loss: (-2.3230)(R 5.3770, F -7.7925, G 0.0093)] [G loss: 7.9341]\n",
      "802 (5, 1) [D loss: (-1.6062)(R 7.3518, F -9.0502, G 0.0092)] [G loss: 9.1275]\n",
      "803 (5, 1) [D loss: (-1.4252)(R 7.6945, F -9.1999, G 0.0080)] [G loss: 9.0344]\n",
      "804 (5, 1) [D loss: (-1.6736)(R 5.7860, F -7.5187, G 0.0059)] [G loss: 7.1625]\n",
      "805 (5, 1) [D loss: (-0.9417)(R 3.4704, F -4.4512, G 0.0039)] [G loss: 3.9513]\n",
      "806 (5, 1) [D loss: (-0.9476)(R -1.0435, F 0.0727, G 0.0023)] [G loss: -1.0561]\n",
      "807 (5, 1) [D loss: (-1.3337)(R -7.3523, F 5.9937, G 0.0025)] [G loss: -6.8000]\n",
      "808 (5, 1) [D loss: (-1.6523)(R -13.9939, F 12.2910, G 0.0051)] [G loss: -13.8336]\n",
      "809 (5, 1) [D loss: (-1.6677)(R -19.2574, F 17.5101, G 0.0080)] [G loss: -18.2866]\n",
      "810 (5, 1) [D loss: (-0.6762)(R -21.4818, F 20.6889, G 0.0117)] [G loss: -20.3472]\n",
      "811 (5, 1) [D loss: (-0.4043)(R -20.6647, F 20.1685, G 0.0092)] [G loss: -19.4529]\n",
      "812 (5, 1) [D loss: (-0.5613)(R -19.4615, F 18.8608, G 0.0040)] [G loss: -18.1959]\n",
      "813 (5, 1) [D loss: (-0.7924)(R -18.5117, F 17.6959, G 0.0023)] [G loss: -17.2599]\n",
      "814 (5, 1) [D loss: (-0.7078)(R -18.6952, F 17.9600, G 0.0027)] [G loss: -16.9086]\n",
      "815 (5, 1) [D loss: (-1.0466)(R -18.3999, F 17.3172, G 0.0036)] [G loss: -17.3471]\n",
      "816 (5, 1) [D loss: (-2.2024)(R -20.0653, F 17.8038, G 0.0059)] [G loss: -18.0807]\n",
      "817 (5, 1) [D loss: (-2.4396)(R -21.0802, F 18.5589, G 0.0082)] [G loss: -18.5577]\n",
      "818 (5, 1) [D loss: (-2.5368)(R -20.8319, F 18.1765, G 0.0119)] [G loss: -18.3158]\n",
      "819 (5, 1) [D loss: (-2.8026)(R -20.9169, F 17.9466, G 0.0168)] [G loss: -18.2112]\n",
      "820 (5, 1) [D loss: (-2.6472)(R -20.1526, F 17.2851, G 0.0220)] [G loss: -17.0722]\n",
      "821 (5, 1) [D loss: (-3.4565)(R -18.8994, F 15.2161, G 0.0227)] [G loss: -15.8043]\n",
      "822 (5, 1) [D loss: (-2.8164)(R -15.8542, F 12.8570, G 0.0181)] [G loss: -13.0995]\n",
      "823 (5, 1) [D loss: (-2.2027)(R -14.0316, F 11.6401, G 0.0189)] [G loss: -11.8392]\n",
      "824 (5, 1) [D loss: (-2.3196)(R -13.9067, F 11.4184, G 0.0169)] [G loss: -11.9554]\n",
      "825 (5, 1) [D loss: (-2.4860)(R -14.8154, F 12.1442, G 0.0185)] [G loss: -12.8365]\n",
      "826 (5, 1) [D loss: (-1.8103)(R -14.7732, F 12.8091, G 0.0154)] [G loss: -12.5510]\n",
      "827 (5, 1) [D loss: (-1.6387)(R -14.1622, F 12.4077, G 0.0116)] [G loss: -12.5261]\n",
      "828 (5, 1) [D loss: (-0.8761)(R -12.9831, F 12.0311, G 0.0076)] [G loss: -11.2077]\n",
      "829 (5, 1) [D loss: (-1.9629)(R -11.8762, F 9.8738, G 0.0040)] [G loss: -10.7214]\n",
      "830 (5, 1) [D loss: (-1.3915)(R -10.3091, F 8.8804, G 0.0037)] [G loss: -9.5124]\n",
      "831 (5, 1) [D loss: (-0.8835)(R -9.5481, F 8.6397, G 0.0025)] [G loss: -8.6265]\n",
      "832 (5, 1) [D loss: (-0.8148)(R -7.5781, F 6.7422, G 0.0021)] [G loss: -6.9027]\n",
      "833 (5, 1) [D loss: (-0.8922)(R -7.2027, F 6.2922, G 0.0018)] [G loss: -6.3005]\n",
      "834 (5, 1) [D loss: (-1.0446)(R -7.4129, F 6.3445, G 0.0024)] [G loss: -6.4861]\n",
      "835 (5, 1) [D loss: (-0.7938)(R -6.8325, F 6.0115, G 0.0027)] [G loss: -5.7505]\n",
      "836 (5, 1) [D loss: (-1.2431)(R -5.7465, F 4.4836, G 0.0020)] [G loss: -4.5057]\n",
      "837 (5, 1) [D loss: (-1.1086)(R -4.7464, F 3.6142, G 0.0024)] [G loss: -2.7038]\n",
      "838 (5, 1) [D loss: (-1.5149)(R -2.6506, F 1.1085, G 0.0027)] [G loss: -0.5479]\n",
      "839 (5, 1) [D loss: (-1.5147)(R -1.3224, F -0.2365, G 0.0044)] [G loss: 1.1001]\n",
      "840 (5, 1) [D loss: (-1.2767)(R -0.0416, F -1.2821, G 0.0047)] [G loss: 1.8800]\n",
      "841 (5, 1) [D loss: (-1.7448)(R 0.8086, F -2.6076, G 0.0054)] [G loss: 2.9815]\n",
      "842 (5, 1) [D loss: (-2.0193)(R 2.6155, F -4.7011, G 0.0066)] [G loss: 4.9445]\n",
      "843 (5, 1) [D loss: (-1.8414)(R 3.6765, F -5.6032, G 0.0085)] [G loss: 5.7392]\n",
      "844 (5, 1) [D loss: (-2.4263)(R 4.5330, F -7.0673, G 0.0108)] [G loss: 7.1331]\n",
      "845 (5, 1) [D loss: (-2.8944)(R 4.8562, F -7.8953, G 0.0145)] [G loss: 7.7657]\n",
      "846 (5, 1) [D loss: (-2.2823)(R 6.1414, F -8.5781, G 0.0154)] [G loss: 9.2675]\n",
      "847 (5, 1) [D loss: (-2.7941)(R 8.2409, F -11.2581, G 0.0223)] [G loss: 11.8002]\n",
      "848 (5, 1) [D loss: (-4.0124)(R 10.6178, F -14.9471, G 0.0317)] [G loss: 14.3823]\n",
      "849 (5, 1) [D loss: (-3.9020)(R 13.0698, F -17.3753, G 0.0403)] [G loss: 17.3072]\n",
      "850 (5, 1) [D loss: (-3.8248)(R 14.5505, F -18.8422, G 0.0467)] [G loss: 18.5753]\n",
      "851 (5, 1) [D loss: (-3.2938)(R 14.6125, F -18.3565, G 0.0450)] [G loss: 17.9014]\n",
      "852 (5, 1) [D loss: (-2.9533)(R 11.8406, F -15.2066, G 0.0413)] [G loss: 14.7036]\n",
      "853 (5, 1) [D loss: (-2.7315)(R 10.1995, F -13.2560, G 0.0325)] [G loss: 13.0913]\n",
      "854 (5, 1) [D loss: (-2.2765)(R 9.4232, F -11.9202, G 0.0220)] [G loss: 11.2252]\n",
      "855 (5, 1) [D loss: (-1.5331)(R 7.9134, F -9.6079, G 0.0161)] [G loss: 9.6229]\n",
      "856 (5, 1) [D loss: (-0.6567)(R 5.6250, F -6.3844, G 0.0103)] [G loss: 5.5232]\n",
      "857 (5, 1) [D loss: (-1.2685)(R -0.4369, F -0.8854, G 0.0054)] [G loss: 0.4025]\n",
      "858 (5, 1) [D loss: (-0.8290)(R -6.2826, F 5.4108, G 0.0043)] [G loss: -6.6197]\n",
      "859 (5, 1) [D loss: (-1.4611)(R -13.7530, F 12.2392, G 0.0053)] [G loss: -13.9206]\n",
      "860 (5, 1) [D loss: (-1.8013)(R -20.1976, F 18.3070, G 0.0089)] [G loss: -19.5063]\n",
      "861 (5, 1) [D loss: (-1.4826)(R -21.7015, F 20.1290, G 0.0090)] [G loss: -20.1736]\n",
      "862 (5, 1) [D loss: (-1.5366)(R -20.7969, F 19.2036, G 0.0057)] [G loss: -18.7711]\n",
      "863 (5, 1) [D loss: (-1.1292)(R -19.1379, F 17.9502, G 0.0059)] [G loss: -16.8637]\n",
      "864 (5, 1) [D loss: (-1.6187)(R -16.9173, F 15.2592, G 0.0039)] [G loss: -14.3073]\n",
      "865 (5, 1) [D loss: (-2.1223)(R -14.2309, F 12.0723, G 0.0036)] [G loss: -11.3878]\n",
      "866 (5, 1) [D loss: (-2.0058)(R -12.1705, F 10.1309, G 0.0034)] [G loss: -9.9909]\n",
      "867 (5, 1) [D loss: (-2.5368)(R -12.3951, F 9.8024, G 0.0056)] [G loss: -10.4602]\n",
      "868 (5, 1) [D loss: (-1.2204)(R -13.8446, F 12.5519, G 0.0072)] [G loss: -13.1925]\n",
      "869 (5, 1) [D loss: (-2.1151)(R -18.9791, F 16.7297, G 0.0134)] [G loss: -18.1846]\n",
      "870 (5, 1) [D loss: (-2.0149)(R -22.7927, F 20.5247, G 0.0253)] [G loss: -21.5983]\n",
      "871 (5, 1) [D loss: (-1.6755)(R -23.0867, F 21.2007, G 0.0211)] [G loss: -21.2099]\n",
      "872 (5, 1) [D loss: (-1.8719)(R -21.6832, F 19.6686, G 0.0143)] [G loss: -19.5936]\n",
      "873 (5, 1) [D loss: (-1.4082)(R -19.9309, F 18.4158, G 0.0107)] [G loss: -17.7424]\n",
      "874 (5, 1) [D loss: (-1.6774)(R -16.0558, F 14.3335, G 0.0045)] [G loss: -13.6532]\n",
      "875 (5, 1) [D loss: (-1.2159)(R -10.3880, F 9.1474, G 0.0025)] [G loss: -7.2195]\n",
      "876 (5, 1) [D loss: (-1.5677)(R -3.4810, F 1.8930, G 0.0020)] [G loss: -0.3944]\n",
      "877 (5, 1) [D loss: (-1.8612)(R 4.8807, F -6.7599, G 0.0018)] [G loss: 7.7537]\n",
      "878 (5, 1) [D loss: (-0.9859)(R 13.3065, F -14.3391, G 0.0047)] [G loss: 15.2287]\n",
      "879 (5, 1) [D loss: (-1.5933)(R 15.9949, F -17.6612, G 0.0073)] [G loss: 18.5137]\n",
      "880 (5, 1) [D loss: (-1.4541)(R 15.6913, F -17.2006, G 0.0055)] [G loss: 16.8638]\n",
      "881 (5, 1) [D loss: (-1.7514)(R 12.0449, F -13.8327, G 0.0036)] [G loss: 13.6120]\n",
      "882 (5, 1) [D loss: (-1.1769)(R 9.8037, F -11.0215, G 0.0041)] [G loss: 10.8546]\n",
      "883 (5, 1) [D loss: (-1.9443)(R 7.2003, F -9.1803, G 0.0036)] [G loss: 8.5413]\n",
      "884 (5, 1) [D loss: (-1.7280)(R 8.0095, F -9.7833, G 0.0046)] [G loss: 10.6522]\n",
      "885 (5, 1) [D loss: (-1.7109)(R 13.3972, F -15.1679, G 0.0060)] [G loss: 15.7241]\n",
      "886 (5, 1) [D loss: (-2.6964)(R 19.4088, F -22.2063, G 0.0101)] [G loss: 23.2023]\n",
      "887 (5, 1) [D loss: (-3.3218)(R 26.0530, F -29.5903, G 0.0215)] [G loss: 28.9258]\n",
      "888 (5, 1) [D loss: (-4.0078)(R 29.1798, F -33.4653, G 0.0278)] [G loss: 31.5479]\n",
      "889 (5, 1) [D loss: (-3.2410)(R 28.6183, F -32.1353, G 0.0276)] [G loss: 30.1859]\n",
      "890 (5, 1) [D loss: (-3.2729)(R 24.2962, F -27.7411, G 0.0172)] [G loss: 26.5251]\n",
      "891 (5, 1) [D loss: (-2.1508)(R 19.0082, F -21.2383, G 0.0079)] [G loss: 19.7074]\n",
      "892 (5, 1) [D loss: (-2.7777)(R 11.3002, F -14.1157, G 0.0038)] [G loss: 13.3962]\n",
      "893 (5, 1) [D loss: (-2.4823)(R 5.4135, F -7.9440, G 0.0048)] [G loss: 7.2724]\n",
      "894 (5, 1) [D loss: (-2.6868)(R 1.1683, F -3.9357, G 0.0081)] [G loss: 2.7643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895 (5, 1) [D loss: (-1.9031)(R -2.0942, F 0.0922, G 0.0099)] [G loss: 0.1079]\n",
      "896 (5, 1) [D loss: (-2.0384)(R -2.0190, F -0.1178, G 0.0098)] [G loss: 0.3311]\n",
      "897 (5, 1) [D loss: (-1.8979)(R 2.0018, F -3.9895, G 0.0090)] [G loss: 3.7706]\n",
      "898 (5, 1) [D loss: (-1.0764)(R 3.4815, F -4.6413, G 0.0083)] [G loss: 4.6846]\n",
      "899 (5, 1) [D loss: (-1.1604)(R 1.8237, F -3.0427, G 0.0059)] [G loss: 2.9552]\n",
      "900 (5, 1) [D loss: (-1.6171)(R -0.9962, F -0.6681, G 0.0047)] [G loss: 0.1553]\n",
      "901 (5, 1) [D loss: (-1.6812)(R -7.2395, F 5.5068, G 0.0051)] [G loss: -7.3852]\n",
      "902 (5, 1) [D loss: (-2.7850)(R -16.7393, F 13.7959, G 0.0158)] [G loss: -15.7304]\n",
      "903 (5, 1) [D loss: (-3.7646)(R -21.7767, F 17.7280, G 0.0284)] [G loss: -18.6725]\n",
      "904 (5, 1) [D loss: (-3.3061)(R -20.7928, F 17.2391, G 0.0248)] [G loss: -16.6028]\n",
      "905 (5, 1) [D loss: (-2.1646)(R -15.1300, F 12.8161, G 0.0149)] [G loss: -12.0316]\n",
      "906 (5, 1) [D loss: (-2.3214)(R -11.4453, F 9.0043, G 0.0120)] [G loss: -8.5765]\n",
      "907 (5, 1) [D loss: (-2.2098)(R -10.7672, F 8.4532, G 0.0104)] [G loss: -8.6605]\n",
      "908 (5, 1) [D loss: (-1.1067)(R -14.4837, F 13.2365, G 0.0140)] [G loss: -14.4418]\n",
      "909 (5, 1) [D loss: (-1.7758)(R -20.5602, F 18.6008, G 0.0184)] [G loss: -19.9038]\n",
      "910 (5, 1) [D loss: (-1.7436)(R -25.2759, F 23.2725, G 0.0260)] [G loss: -24.6317]\n",
      "911 (5, 1) [D loss: (-1.3685)(R -26.2886, F 24.6671, G 0.0253)] [G loss: -24.6093]\n",
      "912 (5, 1) [D loss: (-1.3139)(R -25.1490, F 23.6907, G 0.0144)] [G loss: -23.6373]\n",
      "913 (5, 1) [D loss: (-0.9344)(R -22.4364, F 21.4269, G 0.0075)] [G loss: -21.0851]\n",
      "914 (5, 1) [D loss: (-0.6623)(R -19.8828, F 19.1703, G 0.0050)] [G loss: -18.6689]\n",
      "915 (5, 1) [D loss: (-0.9785)(R -17.2874, F 16.2808, G 0.0028)] [G loss: -15.6052]\n",
      "916 (5, 1) [D loss: (-1.4418)(R -13.8312, F 12.3575, G 0.0032)] [G loss: -11.7206]\n",
      "917 (5, 1) [D loss: (-1.7922)(R -10.5790, F 8.7612, G 0.0026)] [G loss: -8.4810]\n",
      "918 (5, 1) [D loss: (-1.7896)(R -7.4941, F 5.6796, G 0.0025)] [G loss: -4.8784]\n",
      "919 (5, 1) [D loss: (-1.4188)(R -5.3143, F 3.8603, G 0.0035)] [G loss: -3.6169]\n",
      "920 (5, 1) [D loss: (-1.3300)(R -6.0232, F 4.6514, G 0.0042)] [G loss: -5.1303]\n",
      "921 (5, 1) [D loss: (-1.5089)(R -9.6027, F 8.0272, G 0.0067)] [G loss: -9.0523]\n",
      "922 (5, 1) [D loss: (-1.4758)(R -13.6475, F 12.0610, G 0.0111)] [G loss: -12.8241]\n",
      "923 (5, 1) [D loss: (-1.7415)(R -15.2920, F 13.4422, G 0.0108)] [G loss: -13.7370]\n",
      "924 (5, 1) [D loss: (-1.1515)(R -11.4909, F 10.2757, G 0.0064)] [G loss: -9.5833]\n",
      "925 (5, 1) [D loss: (-1.5950)(R -7.6108, F 5.9797, G 0.0036)] [G loss: -5.2477]\n",
      "926 (5, 1) [D loss: (-1.8472)(R 0.3704, F -2.2526, G 0.0035)] [G loss: 3.9762]\n",
      "927 (5, 1) [D loss: (-2.2714)(R 9.8031, F -12.1511, G 0.0077)] [G loss: 13.7298]\n",
      "928 (5, 1) [D loss: (-2.9380)(R 18.7768, F -21.9462, G 0.0231)] [G loss: 22.5331]\n",
      "929 (5, 1) [D loss: (-2.6015)(R 21.5490, F -24.4368, G 0.0286)] [G loss: 23.7623]\n",
      "930 (5, 1) [D loss: (-1.5085)(R 18.8267, F -20.5206, G 0.0185)] [G loss: 20.2337]\n",
      "931 (5, 1) [D loss: (-2.1931)(R 13.6474, F -15.9435, G 0.0103)] [G loss: 15.1707]\n",
      "932 (5, 1) [D loss: (-1.4657)(R 8.8907, F -10.4367, G 0.0080)] [G loss: 9.2959]\n",
      "933 (5, 1) [D loss: (-2.7846)(R 5.2741, F -8.1663, G 0.0108)] [G loss: 7.5758]\n",
      "934 (5, 1) [D loss: (-2.6303)(R 6.9906, F -9.7577, G 0.0137)] [G loss: 9.9914]\n",
      "935 (5, 1) [D loss: (-2.4471)(R 13.1022, F -15.7144, G 0.0165)] [G loss: 16.6163]\n",
      "936 (5, 1) [D loss: (-2.7279)(R 19.8533, F -22.9070, G 0.0326)] [G loss: 23.2661]\n",
      "937 (5, 1) [D loss: (-2.7552)(R 21.4779, F -24.5051, G 0.0272)] [G loss: 23.7121]\n",
      "938 (5, 1) [D loss: (-2.3477)(R 21.6720, F -24.2386, G 0.0219)] [G loss: 23.3554]\n",
      "939 (5, 1) [D loss: (-1.7130)(R 19.7383, F -21.6171, G 0.0166)] [G loss: 21.1860]\n",
      "940 (5, 1) [D loss: (-1.3591)(R 13.9469, F -15.3651, G 0.0059)] [G loss: 14.6683]\n",
      "941 (5, 1) [D loss: (-1.5549)(R 7.6877, F -9.2864, G 0.0044)] [G loss: 7.8557]\n",
      "942 (5, 1) [D loss: (-2.1208)(R -0.0325, F -2.1385, G 0.0050)] [G loss: 0.6995]\n",
      "943 (5, 1) [D loss: (-2.1493)(R -4.0895, F 1.8664, G 0.0074)] [G loss: -1.8974]\n",
      "944 (5, 1) [D loss: (-2.2913)(R -2.2929, F -0.0751, G 0.0077)] [G loss: 0.5348]\n",
      "945 (5, 1) [D loss: (-2.4164)(R 2.2205, F -4.7134, G 0.0076)] [G loss: 5.7607]\n",
      "946 (5, 1) [D loss: (-2.8290)(R 9.5171, F -12.4771, G 0.0131)] [G loss: 13.1864]\n",
      "947 (5, 1) [D loss: (-2.3974)(R 14.8535, F -17.4965, G 0.0246)] [G loss: 17.3747]\n",
      "948 (5, 1) [D loss: (-2.1500)(R 15.1436, F -17.4785, G 0.0185)] [G loss: 16.6800]\n",
      "949 (5, 1) [D loss: (-1.8987)(R 12.3295, F -14.3402, G 0.0112)] [G loss: 13.5080]\n",
      "950 (5, 1) [D loss: (-1.3118)(R 7.1033, F -8.4666, G 0.0052)] [G loss: 7.4040]\n",
      "951 (5, 1) [D loss: (-1.5817)(R -0.4545, F -1.1718, G 0.0045)] [G loss: -0.2031]\n",
      "952 (5, 1) [D loss: (-1.5231)(R -5.7408, F 4.1427, G 0.0075)] [G loss: -4.9894]\n",
      "953 (5, 1) [D loss: (-1.7414)(R -7.8379, F 6.0118, G 0.0085)] [G loss: -6.6296]\n",
      "954 (5, 1) [D loss: (-1.2798)(R -3.9436, F 2.6064, G 0.0057)] [G loss: -1.8609]\n",
      "955 (5, 1) [D loss: (-1.8400)(R 2.6379, F -4.5329, G 0.0055)] [G loss: 5.9089]\n",
      "956 (5, 1) [D loss: (-1.0816)(R 9.5245, F -10.6785, G 0.0072)] [G loss: 12.0536]\n",
      "957 (5, 1) [D loss: (-1.5437)(R 12.7717, F -14.4451, G 0.0130)] [G loss: 14.3627]\n",
      "958 (5, 1) [D loss: (-1.8149)(R 10.6403, F -12.5638, G 0.0109)] [G loss: 11.7284]\n",
      "959 (5, 1) [D loss: (-2.3402)(R 3.4707, F -5.8751, G 0.0064)] [G loss: 4.5363]\n",
      "960 (5, 1) [D loss: (-2.4850)(R -6.4522, F 3.8383, G 0.0129)] [G loss: -6.4010]\n",
      "961 (5, 1) [D loss: (-1.9059)(R -11.8956, F 9.7740, G 0.0216)] [G loss: -9.8351]\n",
      "962 (5, 1) [D loss: (-2.2495)(R -10.6569, F 8.2928, G 0.0115)] [G loss: -7.8158]\n",
      "963 (5, 1) [D loss: (-1.8637)(R -5.6248, F 3.6994, G 0.0062)] [G loss: -1.7159]\n",
      "964 (5, 1) [D loss: (-1.1990)(R 1.7643, F -3.0016, G 0.0038)] [G loss: 5.0098]\n",
      "965 (5, 1) [D loss: (-2.1931)(R 5.3982, F -7.6343, G 0.0043)] [G loss: 7.7805]\n",
      "966 (5, 1) [D loss: (-1.7218)(R 3.0183, F -4.7859, G 0.0046)] [G loss: 4.2003]\n",
      "967 (5, 1) [D loss: (-1.5018)(R -3.7999, F 2.2409, G 0.0057)] [G loss: -3.6156]\n",
      "968 (5, 1) [D loss: (-2.4525)(R -13.1746, F 10.6044, G 0.0118)] [G loss: -12.6818]\n",
      "969 (5, 1) [D loss: (-2.5535)(R -17.3270, F 14.5310, G 0.0242)] [G loss: -15.1218]\n",
      "970 (5, 1) [D loss: (-1.6702)(R -15.2309, F 13.3834, G 0.0177)] [G loss: -13.4821]\n",
      "971 (5, 1) [D loss: (-2.0614)(R -11.4230, F 9.2754, G 0.0086)] [G loss: -8.3121]\n",
      "972 (5, 1) [D loss: (-2.1229)(R -7.5804, F 5.3763, G 0.0081)] [G loss: -4.2085]\n",
      "973 (5, 1) [D loss: (-2.2741)(R -3.5474, F 1.1860, G 0.0087)] [G loss: -0.0650]\n",
      "974 (5, 1) [D loss: (-3.2621)(R -0.6104, F -2.7623, G 0.0111)] [G loss: 2.5492]\n",
      "975 (5, 1) [D loss: (-2.3208)(R -1.1383, F -1.3262, G 0.0144)] [G loss: 1.2079]\n",
      "976 (5, 1) [D loss: (-2.0967)(R -4.1698, F 1.9153, G 0.0158)] [G loss: -2.6200]\n",
      "977 (5, 1) [D loss: (-2.1420)(R -8.2802, F 5.9453, G 0.0193)] [G loss: -7.0277]\n",
      "978 (5, 1) [D loss: (-1.9789)(R -12.6700, F 10.5004, G 0.0191)] [G loss: -10.7022]\n",
      "979 (5, 1) [D loss: (-1.7328)(R -11.0460, F 9.1593, G 0.0154)] [G loss: -8.6172]\n",
      "980 (5, 1) [D loss: (-1.7284)(R -6.8605, F 5.0470, G 0.0085)] [G loss: -4.5847]\n",
      "981 (5, 1) [D loss: (-1.1760)(R -2.5105, F 1.2643, G 0.0070)] [G loss: 0.2515]\n",
      "982 (5, 1) [D loss: (-1.8674)(R 3.6262, F -5.5444, G 0.0051)] [G loss: 6.3477]\n",
      "983 (5, 1) [D loss: (-1.3803)(R 9.4593, F -10.9210, G 0.0081)] [G loss: 10.8229]\n",
      "984 (5, 1) [D loss: (-1.7833)(R 8.5330, F -10.4004, G 0.0084)] [G loss: 10.2199]\n",
      "985 (5, 1) [D loss: (-1.3019)(R 6.9182, F -8.2961, G 0.0076)] [G loss: 7.5993]\n",
      "986 (5, 1) [D loss: (-2.1122)(R 0.3684, F -2.5569, G 0.0076)] [G loss: 1.1143]\n",
      "987 (5, 1) [D loss: (-1.6451)(R -4.6415, F 2.8845, G 0.0112)] [G loss: -3.8391]\n",
      "988 (5, 1) [D loss: (-1.8255)(R -6.4943, F 4.5234, G 0.0145)] [G loss: -4.9476]\n",
      "989 (5, 1) [D loss: (-1.5265)(R -3.1628, F 1.5142, G 0.0122)] [G loss: -0.9179]\n",
      "990 (5, 1) [D loss: (-1.1287)(R 1.7562, F -2.9573, G 0.0072)] [G loss: 4.1405]\n",
      "991 (5, 1) [D loss: (-1.6886)(R 6.7214, F -8.4929, G 0.0083)] [G loss: 9.4364]\n",
      "992 (5, 1) [D loss: (-1.3710)(R 10.3857, F -11.8623, G 0.0106)] [G loss: 12.0789]\n",
      "993 (5, 1) [D loss: (-1.5600)(R 8.9788, F -10.6231, G 0.0084)] [G loss: 10.0731]\n",
      "994 (5, 1) [D loss: (-1.1969)(R 6.1396, F -7.4009, G 0.0064)] [G loss: 6.5678]\n",
      "995 (5, 1) [D loss: (-1.6522)(R -0.5693, F -1.1594, G 0.0077)] [G loss: -0.7368]\n",
      "996 (5, 1) [D loss: (-2.1302)(R -8.3845, F 6.0988, G 0.0155)] [G loss: -7.4822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997 (5, 1) [D loss: (-2.0913)(R -13.2726, F 10.9866, G 0.0195)] [G loss: -11.7274]\n",
      "998 (5, 1) [D loss: (-2.1751)(R -11.7254, F 9.3817, G 0.0169)] [G loss: -8.6178]\n",
      "999 (5, 1) [D loss: (-2.3480)(R -7.5142, F 5.0754, G 0.0091)] [G loss: -4.0103]\n",
      "1000 (5, 1) [D loss: (-2.0241)(R -1.5318, F -0.5578, G 0.0066)] [G loss: 1.5703]\n",
      "1001 (5, 1) [D loss: (-2.4161)(R 4.2771, F -6.7852, G 0.0092)] [G loss: 7.6424]\n",
      "1002 (5, 1) [D loss: (-2.5426)(R 8.1556, F -10.8388, G 0.0141)] [G loss: 11.2760]\n",
      "1003 (5, 1) [D loss: (-1.4261)(R 7.7660, F -9.3316, G 0.0140)] [G loss: 9.2929]\n",
      "1004 (5, 1) [D loss: (-2.0338)(R -0.4470, F -1.6778, G 0.0091)] [G loss: 0.1949]\n",
      "1005 (5, 1) [D loss: (-2.5899)(R -9.5765, F 6.8155, G 0.0171)] [G loss: -9.4933]\n",
      "1006 (5, 1) [D loss: (-2.1403)(R -15.2446, F 12.8163, G 0.0288)] [G loss: -13.0656]\n",
      "1007 (5, 1) [D loss: (-1.6202)(R -10.3464, F 8.5875, G 0.0139)] [G loss: -7.8858]\n",
      "1008 (5, 1) [D loss: (-1.8637)(R -3.7939, F 1.8721, G 0.0058)] [G loss: -0.6272]\n",
      "1009 (5, 1) [D loss: (-2.6514)(R 6.2130, F -8.9327, G 0.0068)] [G loss: 10.4814]\n",
      "1010 (5, 1) [D loss: (-3.3044)(R 16.6789, F -20.1654, G 0.0182)] [G loss: 20.7828]\n",
      "1011 (5, 1) [D loss: (-1.6528)(R 20.1735, F -22.1321, G 0.0306)] [G loss: 22.2712]\n",
      "1012 (5, 1) [D loss: (-1.6420)(R 15.7126, F -17.4987, G 0.0144)] [G loss: 16.2032]\n",
      "1013 (5, 1) [D loss: (-2.1694)(R 7.0033, F -9.2521, G 0.0079)] [G loss: 7.4588]\n",
      "1014 (5, 1) [D loss: (-2.3146)(R -2.9795, F 0.5310, G 0.0134)] [G loss: -2.0989]\n",
      "1015 (5, 1) [D loss: (-2.3786)(R -6.5440, F 3.9739, G 0.0192)] [G loss: -4.0086]\n",
      "1016 (5, 1) [D loss: (-1.9819)(R -0.7162, F -1.3645, G 0.0099)] [G loss: 2.7010]\n",
      "1017 (5, 1) [D loss: (-2.8157)(R 9.8515, F -12.7800, G 0.0113)] [G loss: 14.1801]\n",
      "1018 (5, 1) [D loss: (-2.3746)(R 20.1556, F -22.7773, G 0.0247)] [G loss: 23.4658]\n",
      "1019 (5, 1) [D loss: (-3.2686)(R 23.1946, F -26.7660, G 0.0303)] [G loss: 26.3236]\n",
      "1020 (5, 1) [D loss: (-1.1329)(R 21.1079, F -22.4023, G 0.0161)] [G loss: 20.9636]\n",
      "1021 (5, 1) [D loss: (-0.9840)(R 13.2612, F -14.2965, G 0.0051)] [G loss: 13.6202]\n",
      "1022 (5, 1) [D loss: (-1.4628)(R 5.0792, F -6.5794, G 0.0037)] [G loss: 4.6803]\n",
      "1023 (5, 1) [D loss: (-2.5099)(R -5.7240, F 3.1454, G 0.0069)] [G loss: -5.4677]\n",
      "1024 (5, 1) [D loss: (-2.0196)(R -8.5708, F 6.4277, G 0.0123)] [G loss: -6.3020]\n",
      "1025 (5, 1) [D loss: (-1.3672)(R -1.7475, F 0.3014, G 0.0079)] [G loss: 1.4976]\n",
      "1026 (5, 1) [D loss: (-2.3554)(R 10.7908, F -13.2377, G 0.0092)] [G loss: 14.5756]\n",
      "1027 (5, 1) [D loss: (-3.5606)(R 22.7821, F -26.6657, G 0.0323)] [G loss: 26.5079]\n",
      "1028 (5, 1) [D loss: (-2.1567)(R 27.3504, F -29.9746, G 0.0467)] [G loss: 28.8403]\n",
      "1029 (5, 1) [D loss: (-1.0760)(R 22.6078, F -23.8702, G 0.0186)] [G loss: 22.2631]\n",
      "1030 (5, 1) [D loss: (-0.8654)(R 14.7697, F -15.6845, G 0.0049)] [G loss: 14.2938]\n",
      "1031 (5, 1) [D loss: (-1.7068)(R 4.8295, F -6.5685, G 0.0032)] [G loss: 4.2736]\n",
      "1032 (5, 1) [D loss: (-2.2470)(R -4.7664, F 2.4568, G 0.0063)] [G loss: -4.2663]\n",
      "1033 (5, 1) [D loss: (-1.8273)(R -7.4330, F 5.4595, G 0.0146)] [G loss: -5.4308]\n",
      "1034 (5, 1) [D loss: (-1.3970)(R -3.0885, F 1.6051, G 0.0087)] [G loss: 0.6640]\n",
      "1035 (5, 1) [D loss: (-2.0593)(R 7.3967, F -9.5326, G 0.0077)] [G loss: 11.7056]\n",
      "1036 (5, 1) [D loss: (-3.3101)(R 18.5614, F -22.0759, G 0.0204)] [G loss: 22.7681]\n",
      "1037 (5, 1) [D loss: (-2.6923)(R 23.1699, F -26.2350, G 0.0373)] [G loss: 24.8507]\n",
      "1038 (5, 1) [D loss: (-2.0128)(R 17.9581, F -20.1304, G 0.0160)] [G loss: 19.0873]\n",
      "1039 (5, 1) [D loss: (-2.2756)(R 8.4330, F -10.7654, G 0.0057)] [G loss: 8.5954]\n",
      "1040 (5, 1) [D loss: (-2.2684)(R -4.2541, F 1.8966, G 0.0089)] [G loss: -5.2121]\n",
      "1041 (5, 1) [D loss: (-2.6041)(R -16.2346, F 13.2890, G 0.0342)] [G loss: -14.8620]\n",
      "1042 (5, 1) [D loss: (-2.1269)(R -14.5518, F 12.1882, G 0.0237)] [G loss: -11.6608]\n",
      "1043 (5, 1) [D loss: (-1.8442)(R -7.8553, F 5.9160, G 0.0095)] [G loss: -4.7019]\n",
      "1044 (5, 1) [D loss: (-1.7427)(R -1.4202, F -0.3828, G 0.0060)] [G loss: 1.9960]\n",
      "1045 (5, 1) [D loss: (-2.2356)(R 2.5219, F -4.8309, G 0.0073)] [G loss: 5.7435]\n",
      "1046 (5, 1) [D loss: (-1.4052)(R 0.7515, F -2.2530, G 0.0096)] [G loss: 1.1834]\n",
      "1047 (5, 1) [D loss: (-2.3414)(R -7.6856, F 5.2218, G 0.0122)] [G loss: -6.7994]\n",
      "1048 (5, 1) [D loss: (-2.1335)(R -14.8875, F 12.5079, G 0.0246)] [G loss: -13.4649]\n",
      "1049 (5, 1) [D loss: (-2.9879)(R -18.8679, F 15.5579, G 0.0322)] [G loss: -17.1120]\n",
      "1050 (5, 1) [D loss: (-1.9554)(R -18.2612, F 15.9328, G 0.0373)] [G loss: -16.1634]\n",
      "1051 (5, 1) [D loss: (-1.6050)(R -13.1125, F 11.3178, G 0.0190)] [G loss: -10.0267]\n",
      "1052 (5, 1) [D loss: (-1.4949)(R -7.9007, F 6.3388, G 0.0067)] [G loss: -5.1389]\n",
      "1053 (5, 1) [D loss: (-1.3837)(R -3.4054, F 1.9735, G 0.0048)] [G loss: -1.1393]\n",
      "1054 (5, 1) [D loss: (-1.5219)(R -1.2443, F -0.3290, G 0.0051)] [G loss: 0.9812]\n",
      "1055 (5, 1) [D loss: (-1.1968)(R 1.2493, F -2.5237, G 0.0078)] [G loss: 2.9346]\n",
      "1056 (5, 1) [D loss: (-1.2853)(R -0.2062, F -1.1571, G 0.0078)] [G loss: 0.5509]\n",
      "1057 (5, 1) [D loss: (-1.6640)(R -4.5031, F 2.7200, G 0.0119)] [G loss: -3.1797]\n",
      "1058 (5, 1) [D loss: (-1.7181)(R -7.2077, F 5.3390, G 0.0151)] [G loss: -6.0221]\n",
      "1059 (5, 1) [D loss: (-2.3173)(R -8.4202, F 5.9722, G 0.0131)] [G loss: -6.4970]\n",
      "1060 (5, 1) [D loss: (-1.7512)(R -5.4020, F 3.5703, G 0.0081)] [G loss: -2.8907]\n",
      "1061 (5, 1) [D loss: (-1.3179)(R -2.4183, F 1.0110, G 0.0089)] [G loss: -0.0342]\n",
      "1062 (5, 1) [D loss: (-2.2709)(R 2.1735, F -4.5146, G 0.0070)] [G loss: 5.4411]\n",
      "1063 (5, 1) [D loss: (-2.1967)(R 8.1760, F -10.4608, G 0.0088)] [G loss: 11.6703]\n",
      "1064 (5, 1) [D loss: (-1.9291)(R 12.1720, F -14.2211, G 0.0120)] [G loss: 14.7549]\n",
      "1065 (5, 1) [D loss: (-1.8940)(R 11.5151, F -13.5439, G 0.0135)] [G loss: 13.3684]\n",
      "1066 (5, 1) [D loss: (-2.0225)(R 9.4398, F -11.5895, G 0.0127)] [G loss: 10.6127]\n",
      "1067 (5, 1) [D loss: (-2.0038)(R 5.7500, F -7.8865, G 0.0133)] [G loss: 7.1881]\n",
      "1068 (5, 1) [D loss: (-1.9480)(R 4.0797, F -6.1756, G 0.0148)] [G loss: 6.5340]\n",
      "1069 (5, 1) [D loss: (-2.0039)(R 5.1837, F -7.3305, G 0.0143)] [G loss: 7.8992]\n",
      "1070 (5, 1) [D loss: (-2.0952)(R 7.1202, F -9.3381, G 0.0123)] [G loss: 10.3876]\n",
      "1071 (5, 1) [D loss: (-1.4159)(R 11.4383, F -12.9819, G 0.0128)] [G loss: 13.8567]\n",
      "1072 (5, 1) [D loss: (-1.5098)(R 14.8493, F -16.4884, G 0.0129)] [G loss: 17.0895]\n",
      "1073 (5, 1) [D loss: (-1.8384)(R 16.1451, F -18.1301, G 0.0147)] [G loss: 17.7366]\n",
      "1074 (5, 1) [D loss: (-2.2240)(R 14.1677, F -16.5267, G 0.0135)] [G loss: 16.0804]\n",
      "1075 (5, 1) [D loss: (-2.0348)(R 13.4788, F -15.6336, G 0.0120)] [G loss: 15.9022]\n",
      "1076 (5, 1) [D loss: (-2.4687)(R 12.0691, F -14.6597, G 0.0122)] [G loss: 14.5416]\n",
      "1077 (5, 1) [D loss: (-2.7220)(R 9.4111, F -12.2647, G 0.0132)] [G loss: 11.9273]\n",
      "1078 (5, 1) [D loss: (-2.3668)(R 7.9454, F -10.4386, G 0.0126)] [G loss: 10.0575]\n",
      "1079 (5, 1) [D loss: (-2.4300)(R 7.1454, F -9.7054, G 0.0130)] [G loss: 9.7089]\n",
      "1080 (5, 1) [D loss: (-2.2559)(R 9.1129, F -11.5174, G 0.0149)] [G loss: 12.1826]\n",
      "1081 (5, 1) [D loss: (-1.7709)(R 14.7187, F -16.6602, G 0.0171)] [G loss: 17.5913]\n",
      "1082 (5, 1) [D loss: (-2.2188)(R 19.1392, F -21.5478, G 0.0190)] [G loss: 22.3536]\n",
      "1083 (5, 1) [D loss: (-1.4908)(R 20.3233, F -22.0090, G 0.0195)] [G loss: 21.3849]\n",
      "1084 (5, 1) [D loss: (-1.5327)(R 15.8192, F -17.4414, G 0.0089)] [G loss: 16.6327]\n",
      "1085 (5, 1) [D loss: (-1.4403)(R 11.6199, F -13.1345, G 0.0074)] [G loss: 12.1631]\n",
      "1086 (5, 1) [D loss: (-2.1964)(R 5.8407, F -8.1304, G 0.0093)] [G loss: 6.6575]\n",
      "1087 (5, 1) [D loss: (-2.1374)(R 1.7358, F -3.9707, G 0.0097)] [G loss: 3.3063]\n",
      "1088 (5, 1) [D loss: (-2.4769)(R 3.6260, F -6.2254, G 0.0122)] [G loss: 7.0086]\n",
      "1089 (5, 1) [D loss: (-3.2192)(R 7.3554, F -10.7120, G 0.0137)] [G loss: 11.3940]\n",
      "1090 (5, 1) [D loss: (-2.2338)(R 13.6780, F -16.1421, G 0.0230)] [G loss: 16.2754]\n",
      "1091 (5, 1) [D loss: (-2.1113)(R 13.3832, F -15.6718, G 0.0177)] [G loss: 15.5485]\n",
      "1092 (5, 1) [D loss: (-1.2582)(R 10.3514, F -11.6998, G 0.0090)] [G loss: 11.2116]\n",
      "1093 (5, 1) [D loss: (-1.8456)(R 2.8521, F -4.8044, G 0.0107)] [G loss: 2.7889]\n",
      "1094 (5, 1) [D loss: (-1.9154)(R -7.4892, F 5.4229, G 0.0151)] [G loss: -7.1076]\n",
      "1095 (5, 1) [D loss: (-1.8009)(R -12.7060, F 10.6864, G 0.0219)] [G loss: -11.6980]\n",
      "1096 (5, 1) [D loss: (-1.3571)(R -10.6430, F 9.1495, G 0.0136)] [G loss: -8.0508]\n",
      "1097 (5, 1) [D loss: (-1.8325)(R -5.6888, F 3.7808, G 0.0075)] [G loss: -2.5746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098 (5, 1) [D loss: (-1.8742)(R 2.1250, F -4.0732, G 0.0074)] [G loss: 5.7741]\n",
      "1099 (5, 1) [D loss: (-2.4105)(R 9.0259, F -11.5709, G 0.0134)] [G loss: 12.5544]\n",
      "1100 (5, 1) [D loss: (-2.1798)(R 12.8784, F -15.2379, G 0.0180)] [G loss: 14.7836]\n",
      "1101 (5, 1) [D loss: (-1.6009)(R 7.7633, F -9.5084, G 0.0144)] [G loss: 8.8267]\n",
      "1102 (5, 1) [D loss: (-1.6486)(R -0.4310, F -1.3235, G 0.0106)] [G loss: 0.3944]\n",
      "1103 (5, 1) [D loss: (-2.1159)(R -8.4504, F 6.1656, G 0.0169)] [G loss: -7.6899]\n",
      "1104 (5, 1) [D loss: (-1.9531)(R -11.9022, F 9.7366, G 0.0213)] [G loss: -8.9547]\n",
      "1105 (5, 1) [D loss: (-1.2550)(R -5.2373, F 3.8916, G 0.0091)] [G loss: -2.6400]\n",
      "1106 (5, 1) [D loss: (-1.4437)(R 2.9511, F -4.4551, G 0.0060)] [G loss: 6.3112]\n",
      "1107 (5, 1) [D loss: (-2.1436)(R 12.9127, F -15.1468, G 0.0091)] [G loss: 15.7960]\n",
      "1108 (5, 1) [D loss: (-1.7063)(R 18.7810, F -20.6501, G 0.0163)] [G loss: 21.0878]\n",
      "1109 (5, 1) [D loss: (-2.2597)(R 18.7782, F -21.1925, G 0.0155)] [G loss: 20.3051]\n",
      "1110 (5, 1) [D loss: (-1.7900)(R 14.1281, F -16.0003, G 0.0082)] [G loss: 14.4247]\n",
      "1111 (5, 1) [D loss: (-2.6949)(R 4.4923, F -7.2418, G 0.0055)] [G loss: 4.2600]\n",
      "1112 (5, 1) [D loss: (-2.6426)(R -7.3170, F 4.4777, G 0.0197)] [G loss: -5.9774]\n",
      "1113 (5, 1) [D loss: (-2.2856)(R -10.0283, F 7.4695, G 0.0273)] [G loss: -6.7788]\n",
      "1114 (5, 1) [D loss: (-2.0727)(R -2.2846, F 0.0611, G 0.0151)] [G loss: 1.8226]\n",
      "1115 (5, 1) [D loss: (-2.0652)(R 6.3549, F -8.5375, G 0.0117)] [G loss: 10.1463]\n",
      "1116 (5, 1) [D loss: (-1.9745)(R 13.3255, F -15.4454, G 0.0145)] [G loss: 15.7136]\n",
      "1117 (5, 1) [D loss: (-2.5034)(R 11.9554, F -14.5909, G 0.0132)] [G loss: 14.0758]\n",
      "1118 (5, 1) [D loss: (-1.0039)(R 6.5222, F -7.6035, G 0.0077)] [G loss: 6.1209]\n",
      "1119 (5, 1) [D loss: (-1.9412)(R -6.5347, F 4.4692, G 0.0124)] [G loss: -7.5131]\n",
      "1120 (5, 1) [D loss: (-2.7551)(R -17.5320, F 14.3867, G 0.0390)] [G loss: -16.1672]\n",
      "1121 (5, 1) [D loss: (-2.2759)(R -16.0837, F 13.5435, G 0.0264)] [G loss: -13.3481]\n",
      "1122 (5, 1) [D loss: (-2.2673)(R -12.6540, F 10.2050, G 0.0182)] [G loss: -9.7566]\n",
      "1123 (5, 1) [D loss: (-2.3547)(R -6.6231, F 4.1906, G 0.0078)] [G loss: -3.1383]\n",
      "1124 (5, 1) [D loss: (-2.7084)(R 2.9052, F -5.7019, G 0.0088)] [G loss: 7.7708]\n",
      "1125 (5, 1) [D loss: (-2.3790)(R 13.8673, F -16.4300, G 0.0184)] [G loss: 17.0669]\n",
      "1126 (5, 1) [D loss: (-2.0494)(R 13.6725, F -15.9087, G 0.0187)] [G loss: 14.8933]\n",
      "1127 (5, 1) [D loss: (-0.6220)(R 5.5099, F -6.2120, G 0.0080)] [G loss: 5.1826]\n",
      "1128 (5, 1) [D loss: (-0.9749)(R -2.4283, F 1.3936, G 0.0060)] [G loss: -2.8595]\n",
      "1129 (5, 1) [D loss: (-1.8147)(R -9.3957, F 7.4584, G 0.0123)] [G loss: -8.7730]\n",
      "1130 (5, 1) [D loss: (-1.7000)(R -9.6626, F 7.8404, G 0.0122)] [G loss: -7.0105]\n",
      "1131 (5, 1) [D loss: (-1.7454)(R -1.8395, F 0.0229, G 0.0071)] [G loss: 1.4243]\n",
      "1132 (5, 1) [D loss: (-1.6117)(R 6.7268, F -8.4078, G 0.0069)] [G loss: 11.0984]\n",
      "1133 (5, 1) [D loss: (-2.5920)(R 16.8648, F -19.6638, G 0.0207)] [G loss: 21.2786]\n",
      "1134 (5, 1) [D loss: (-2.8636)(R 20.4489, F -23.6353, G 0.0323)] [G loss: 22.4341]\n",
      "1135 (5, 1) [D loss: (-3.5200)(R 15.6657, F -19.3806, G 0.0195)] [G loss: 18.9463]\n",
      "1136 (5, 1) [D loss: (-2.6006)(R 10.7667, F -13.5044, G 0.0137)] [G loss: 12.0566]\n",
      "1137 (5, 1) [D loss: (-1.8917)(R 1.3343, F -3.3733, G 0.0147)] [G loss: 1.1206]\n",
      "1138 (5, 1) [D loss: (-2.3403)(R -5.3392, F 2.7961, G 0.0203)] [G loss: -3.6557]\n",
      "1139 (5, 1) [D loss: (-1.8702)(R -6.8892, F 4.7978, G 0.0221)] [G loss: -3.7760]\n",
      "1140 (5, 1) [D loss: (-1.6982)(R -2.6651, F 0.8523, G 0.0115)] [G loss: 0.1267]\n",
      "1141 (5, 1) [D loss: (-2.0548)(R 1.6756, F -3.8239, G 0.0093)] [G loss: 4.2873]\n",
      "1142 (5, 1) [D loss: (-1.9181)(R 6.1839, F -8.1803, G 0.0078)] [G loss: 9.0061]\n",
      "1143 (5, 1) [D loss: (-2.4198)(R 7.2800, F -9.7958, G 0.0096)] [G loss: 9.8943]\n",
      "1144 (5, 1) [D loss: (-2.0788)(R 6.1037, F -8.2867, G 0.0104)] [G loss: 8.3898]\n",
      "1145 (5, 1) [D loss: (-1.7709)(R 2.8438, F -4.7098, G 0.0095)] [G loss: 4.0074]\n",
      "1146 (5, 1) [D loss: (-2.0894)(R -3.4064, F 1.1740, G 0.0143)] [G loss: -1.6708]\n",
      "1147 (5, 1) [D loss: (-3.2480)(R -8.3231, F 4.8750, G 0.0200)] [G loss: -6.2546]\n",
      "1148 (5, 1) [D loss: (-2.2064)(R -8.4680, F 6.0180, G 0.0244)] [G loss: -4.9316]\n",
      "1149 (5, 1) [D loss: (-1.8411)(R -2.4584, F 0.4669, G 0.0150)] [G loss: 1.0694]\n",
      "1150 (5, 1) [D loss: (-2.1050)(R 4.4939, F -6.7338, G 0.0135)] [G loss: 8.2845]\n",
      "1151 (5, 1) [D loss: (-1.8767)(R 10.8147, F -12.8808, G 0.0190)] [G loss: 13.5376]\n",
      "1152 (5, 1) [D loss: (-1.6384)(R 13.3391, F -15.1556, G 0.0178)] [G loss: 14.9752]\n",
      "1153 (5, 1) [D loss: (-1.4175)(R 10.8157, F -12.3741, G 0.0141)] [G loss: 12.3139]\n",
      "1154 (5, 1) [D loss: (-1.5196)(R 6.1000, F -7.6855, G 0.0066)] [G loss: 6.3012]\n",
      "1155 (5, 1) [D loss: (-1.4709)(R 0.7693, F -2.3206, G 0.0081)] [G loss: 0.6732]\n",
      "1156 (5, 1) [D loss: (-1.7348)(R -4.5033, F 2.6723, G 0.0096)] [G loss: -4.0398]\n",
      "1157 (5, 1) [D loss: (-1.8972)(R -8.5248, F 6.4461, G 0.0181)] [G loss: -7.4656]\n",
      "1158 (5, 1) [D loss: (-2.2480)(R -7.4009, F 4.9815, G 0.0171)] [G loss: -3.9432]\n",
      "1159 (5, 1) [D loss: (-1.8840)(R -1.1513, F -0.8373, G 0.0105)] [G loss: 2.4202]\n",
      "1160 (5, 1) [D loss: (-2.5921)(R 7.1029, F -9.8525, G 0.0157)] [G loss: 11.0932]\n",
      "1161 (5, 1) [D loss: (-2.5082)(R 9.6022, F -12.2875, G 0.0177)] [G loss: 13.2215]\n",
      "1162 (5, 1) [D loss: (-1.9993)(R 8.7687, F -10.9240, G 0.0156)] [G loss: 10.3810]\n",
      "1163 (5, 1) [D loss: (-2.4469)(R 0.3517, F -2.8957, G 0.0097)] [G loss: 0.9094]\n",
      "1164 (5, 1) [D loss: (-1.7252)(R -10.6382, F 8.6916, G 0.0221)] [G loss: -10.9411]\n",
      "1165 (5, 1) [D loss: (-2.1375)(R -17.5043, F 15.0476, G 0.0319)] [G loss: -16.6074]\n",
      "1166 (5, 1) [D loss: (-2.3129)(R -18.9352, F 16.3419, G 0.0280)] [G loss: -16.7870]\n",
      "1167 (5, 1) [D loss: (-1.5310)(R -15.3195, F 13.6237, G 0.0165)] [G loss: -12.8364]\n",
      "1168 (5, 1) [D loss: (-2.8121)(R -10.6957, F 7.7947, G 0.0089)] [G loss: -7.3420]\n",
      "1169 (5, 1) [D loss: (-2.7103)(R -7.0322, F 4.2444, G 0.0078)] [G loss: -4.1413]\n",
      "1170 (5, 1) [D loss: (-2.8061)(R -3.5437, F 0.6608, G 0.0077)] [G loss: -0.4230]\n",
      "1171 (5, 1) [D loss: (-2.9956)(R 0.3428, F -3.4566, G 0.0118)] [G loss: 4.0269]\n",
      "1172 (5, 1) [D loss: (-2.4950)(R 2.1388, F -4.7686, G 0.0135)] [G loss: 5.0289]\n",
      "1173 (5, 1) [D loss: (-1.7191)(R 1.4369, F -3.3170, G 0.0161)] [G loss: 2.7025]\n",
      "1174 (5, 1) [D loss: (-1.5502)(R -2.6638, F 0.9804, G 0.0133)] [G loss: -1.0851]\n",
      "1175 (5, 1) [D loss: (-2.1808)(R -5.3913, F 3.0611, G 0.0149)] [G loss: -3.9223]\n",
      "1176 (5, 1) [D loss: (-1.6435)(R -6.8200, F 5.0462, G 0.0130)] [G loss: -4.7648]\n",
      "1177 (5, 1) [D loss: (-1.4642)(R -4.4673, F 2.8856, G 0.0117)] [G loss: -2.4274]\n",
      "1178 (5, 1) [D loss: (-1.4896)(R -1.5445, F -0.0290, G 0.0084)] [G loss: 1.3339]\n",
      "1179 (5, 1) [D loss: (-1.6799)(R 5.0735, F -6.8463, G 0.0093)] [G loss: 8.0557]\n",
      "1180 (5, 1) [D loss: (-2.5894)(R 10.7780, F -13.5154, G 0.0148)] [G loss: 13.5619]\n",
      "1181 (5, 1) [D loss: (-2.0522)(R 12.0911, F -14.2873, G 0.0144)] [G loss: 14.3548]\n",
      "1182 (5, 1) [D loss: (-2.0150)(R 9.7665, F -11.9474, G 0.0166)] [G loss: 11.8143]\n",
      "1183 (5, 1) [D loss: (-2.2053)(R 5.3937, F -7.7366, G 0.0138)] [G loss: 6.2156]\n",
      "1184 (5, 1) [D loss: (-1.8115)(R -0.9319, F -1.0336, G 0.0154)] [G loss: -0.0013]\n",
      "1185 (5, 1) [D loss: (-2.3555)(R -4.5580, F 2.0186, G 0.0184)] [G loss: -3.3691]\n",
      "1186 (5, 1) [D loss: (-1.6485)(R -6.2932, F 4.4321, G 0.0213)] [G loss: -4.3425]\n",
      "1187 (5, 1) [D loss: (-1.9726)(R -6.6476, F 4.5406, G 0.0134)] [G loss: -4.8593]\n",
      "1188 (5, 1) [D loss: (-2.0489)(R -5.2969, F 3.1301, G 0.0118)] [G loss: -2.6892]\n",
      "1189 (5, 1) [D loss: (-1.9880)(R -3.5155, F 1.4155, G 0.0112)] [G loss: -0.6822]\n",
      "1190 (5, 1) [D loss: (-2.2989)(R -2.7054, F 0.2790, G 0.0127)] [G loss: -0.5520]\n",
      "1191 (5, 1) [D loss: (-1.0931)(R -1.9079, F 0.7001, G 0.0115)] [G loss: -0.1464]\n",
      "1192 (5, 1) [D loss: (-1.5432)(R -2.3858, F 0.7060, G 0.0137)] [G loss: -0.5894]\n",
      "1193 (5, 1) [D loss: (-2.0371)(R -2.8851, F 0.7031, G 0.0145)] [G loss: -1.1204]\n",
      "1194 (5, 1) [D loss: (-2.9769)(R -4.9172, F 1.7778, G 0.0162)] [G loss: -2.1660]\n",
      "1195 (5, 1) [D loss: (-2.9660)(R -5.9659, F 2.8249, G 0.0175)] [G loss: -2.8143]\n",
      "1196 (5, 1) [D loss: (-1.8511)(R -2.7698, F 0.7718, G 0.0147)] [G loss: -0.1146]\n",
      "1197 (5, 1) [D loss: (-2.4266)(R -0.8777, F -1.6933, G 0.0144)] [G loss: 2.0558]\n",
      "1198 (5, 1) [D loss: (-1.7906)(R 4.5013, F -6.4432, G 0.0151)] [G loss: 6.9577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199 (5, 1) [D loss: (-2.3080)(R 7.2883, F -9.7619, G 0.0166)] [G loss: 10.4066]\n",
      "1200 (5, 1) [D loss: (-1.4240)(R 10.9573, F -12.5538, G 0.0172)] [G loss: 13.2955]\n",
      "1201 (5, 1) [D loss: (-2.2130)(R 11.6076, F -13.9503, G 0.0130)] [G loss: 14.1805]\n",
      "1202 (5, 1) [D loss: (-1.2677)(R 12.3612, F -13.7548, G 0.0126)] [G loss: 13.8245]\n",
      "1203 (5, 1) [D loss: (-2.1898)(R 9.8975, F -12.1929, G 0.0106)] [G loss: 11.3384]\n",
      "1204 (5, 1) [D loss: (-1.5459)(R 7.7040, F -9.3471, G 0.0097)] [G loss: 9.8981]\n",
      "1205 (5, 1) [D loss: (-2.3328)(R 4.6983, F -7.1669, G 0.0136)] [G loss: 7.2574]\n",
      "1206 (5, 1) [D loss: (-2.5419)(R 2.0500, F -4.7491, G 0.0157)] [G loss: 3.9480]\n",
      "1207 (5, 1) [D loss: (-1.6990)(R 1.8387, F -3.6852, G 0.0147)] [G loss: 4.2151]\n",
      "1208 (5, 1) [D loss: (-1.7311)(R 2.0269, F -3.9131, G 0.0155)] [G loss: 4.6200]\n",
      "1209 (5, 1) [D loss: (-2.1212)(R 3.6938, F -5.9510, G 0.0136)] [G loss: 6.0724]\n",
      "1210 (5, 1) [D loss: (-1.5369)(R 6.1145, F -7.7899, G 0.0138)] [G loss: 7.9857]\n",
      "1211 (5, 1) [D loss: (-1.1379)(R 4.9154, F -6.1622, G 0.0109)] [G loss: 5.8449]\n",
      "1212 (5, 1) [D loss: (-1.7938)(R 1.6774, F -3.5896, G 0.0118)] [G loss: 2.5770]\n",
      "1213 (5, 1) [D loss: (-1.9573)(R -4.8195, F 2.7074, G 0.0155)] [G loss: -3.2335]\n",
      "1214 (5, 1) [D loss: (-2.1704)(R -10.6396, F 8.2661, G 0.0203)] [G loss: -8.8044]\n",
      "1215 (5, 1) [D loss: (-2.1940)(R -11.8940, F 9.4450, G 0.0255)] [G loss: -9.3878]\n",
      "1216 (5, 1) [D loss: (-2.5056)(R -10.3093, F 7.6569, G 0.0147)] [G loss: -7.4809]\n",
      "1217 (5, 1) [D loss: (-2.2405)(R -8.4630, F 6.0707, G 0.0152)] [G loss: -4.9889]\n",
      "1218 (5, 1) [D loss: (-3.2270)(R -3.9303, F 0.5918, G 0.0112)] [G loss: 0.3138]\n",
      "1219 (5, 1) [D loss: (-2.2949)(R 1.4055, F -3.8149, G 0.0114)] [G loss: 5.5390]\n",
      "1220 (5, 1) [D loss: (-2.2902)(R 5.8427, F -8.2753, G 0.0142)] [G loss: 8.3263]\n",
      "1221 (5, 1) [D loss: (-1.5230)(R 5.4053, F -7.0522, G 0.0124)] [G loss: 6.7862]\n",
      "1222 (5, 1) [D loss: (-1.7443)(R 1.4122, F -3.2587, G 0.0102)] [G loss: 2.6426]\n",
      "1223 (5, 1) [D loss: (-1.5804)(R -3.5582, F 1.8295, G 0.0148)] [G loss: -2.2188]\n",
      "1224 (5, 1) [D loss: (-1.8001)(R -6.3396, F 4.3860, G 0.0153)] [G loss: -4.6652]\n",
      "1225 (5, 1) [D loss: (-1.7441)(R -3.9256, F 2.0441, G 0.0137)] [G loss: -0.1902]\n",
      "1226 (5, 1) [D loss: (-1.8555)(R 3.3280, F -5.2732, G 0.0090)] [G loss: 6.6474]\n",
      "1227 (5, 1) [D loss: (-2.1542)(R 8.8385, F -11.1223, G 0.0130)] [G loss: 12.0307]\n",
      "1228 (5, 1) [D loss: (-1.8375)(R 12.4353, F -14.4399, G 0.0167)] [G loss: 14.7256]\n",
      "1229 (5, 1) [D loss: (-0.9402)(R 10.4736, F -11.5686, G 0.0155)] [G loss: 11.1617]\n",
      "1230 (5, 1) [D loss: (-2.0603)(R 4.5574, F -6.7104, G 0.0093)] [G loss: 6.1097]\n",
      "1231 (5, 1) [D loss: (-1.5171)(R -1.4134, F -0.2410, G 0.0137)] [G loss: -0.5867]\n",
      "1232 (5, 1) [D loss: (-1.9307)(R -6.8886, F 4.7644, G 0.0193)] [G loss: -5.8721]\n",
      "1233 (5, 1) [D loss: (-1.8476)(R -11.5697, F 9.5173, G 0.0205)] [G loss: -10.2183]\n",
      "1234 (5, 1) [D loss: (-1.6677)(R -11.8148, F 9.9649, G 0.0182)] [G loss: -8.2780]\n",
      "1235 (5, 1) [D loss: (-1.9012)(R -9.2740, F 7.2361, G 0.0137)] [G loss: -6.3058]\n",
      "1236 (5, 1) [D loss: (-2.6141)(R -6.2773, F 3.5525, G 0.0111)] [G loss: -3.1376]\n",
      "1237 (5, 1) [D loss: (-1.7773)(R -1.6644, F -0.2211, G 0.0108)] [G loss: 1.0205]\n",
      "1238 (5, 1) [D loss: (-1.4369)(R 2.3219, F -3.8804, G 0.0122)] [G loss: 4.1482]\n",
      "1239 (5, 1) [D loss: (-1.6397)(R 2.5123, F -4.2873, G 0.0135)] [G loss: 3.3413]\n",
      "1240 (5, 1) [D loss: (-2.0947)(R -2.6651, F 0.4197, G 0.0151)] [G loss: -2.0241]\n",
      "1241 (5, 1) [D loss: (-2.8044)(R -7.9355, F 4.9231, G 0.0208)] [G loss: -5.5044]\n",
      "1242 (5, 1) [D loss: (-2.1023)(R -7.8641, F 5.5839, G 0.0178)] [G loss: -5.2320]\n",
      "1243 (5, 1) [D loss: (-1.9117)(R -5.4202, F 3.3627, G 0.0146)] [G loss: -3.1711]\n",
      "1244 (5, 1) [D loss: (-1.2032)(R -1.0387, F -0.2936, G 0.0129)] [G loss: 2.0376]\n",
      "1245 (5, 1) [D loss: (-1.6273)(R 4.8486, F -6.5828, G 0.0107)] [G loss: 8.1648]\n",
      "1246 (5, 1) [D loss: (-2.8564)(R 8.8382, F -11.8974, G 0.0203)] [G loss: 11.9680]\n",
      "1247 (5, 1) [D loss: (-1.8469)(R 11.0514, F -13.0842, G 0.0186)] [G loss: 13.6487]\n",
      "1248 (5, 1) [D loss: (-1.8740)(R 8.8311, F -10.8424, G 0.0137)] [G loss: 11.0487]\n",
      "1249 (5, 1) [D loss: (-2.1102)(R 6.4785, F -8.7183, G 0.0130)] [G loss: 7.6842]\n",
      "1250 (5, 1) [D loss: (-1.4836)(R 0.7224, F -2.3318, G 0.0126)] [G loss: 0.6802]\n",
      "1251 (5, 1) [D loss: (-2.0933)(R -4.8601, F 2.5852, G 0.0182)] [G loss: -3.4557]\n",
      "1252 (5, 1) [D loss: (-2.0854)(R -4.5708, F 2.3526, G 0.0133)] [G loss: -2.2277]\n",
      "1253 (5, 1) [D loss: (-1.7844)(R -4.1273, F 2.2132, G 0.0130)] [G loss: -1.6130]\n",
      "1254 (5, 1) [D loss: (-1.9088)(R -2.2867, F 0.2596, G 0.0118)] [G loss: -0.3833]\n",
      "1255 (5, 1) [D loss: (-2.2343)(R -0.5833, F -1.7842, G 0.0133)] [G loss: 2.0477]\n",
      "1256 (5, 1) [D loss: (-1.3295)(R 1.3607, F -2.8130, G 0.0123)] [G loss: 3.0782]\n",
      "1257 (5, 1) [D loss: (-1.0243)(R -0.1832, F -0.9664, G 0.0125)] [G loss: 1.3706]\n",
      "1258 (5, 1) [D loss: (-1.3481)(R -2.2224, F 0.7464, G 0.0128)] [G loss: -1.7966]\n",
      "1259 (5, 1) [D loss: (-2.2109)(R -7.8701, F 5.5217, G 0.0137)] [G loss: -6.2313]\n",
      "1260 (5, 1) [D loss: (-2.2355)(R -12.1069, F 9.6937, G 0.0178)] [G loss: -10.3264]\n",
      "1261 (5, 1) [D loss: (-2.2295)(R -13.5592, F 11.1373, G 0.0192)] [G loss: -11.3158]\n",
      "1262 (5, 1) [D loss: (-3.0258)(R -13.2295, F 10.0030, G 0.0201)] [G loss: -10.4921]\n",
      "1263 (5, 1) [D loss: (-1.2973)(R -8.9878, F 7.5657, G 0.0125)] [G loss: -7.1891]\n",
      "1264 (5, 1) [D loss: (-1.4716)(R -5.5917, F 4.0301, G 0.0090)] [G loss: -2.4916]\n",
      "1265 (5, 1) [D loss: (-2.0413)(R 1.4342, F -3.5756, G 0.0100)] [G loss: 4.5651]\n",
      "1266 (5, 1) [D loss: (-1.7516)(R 6.8695, F -8.7566, G 0.0135)] [G loss: 10.0073]\n",
      "1267 (5, 1) [D loss: (-1.5069)(R 8.3832, F -10.0542, G 0.0164)] [G loss: 9.8467]\n",
      "1268 (5, 1) [D loss: (-1.9993)(R 6.9744, F -9.1000, G 0.0126)] [G loss: 10.1353]\n",
      "1269 (5, 1) [D loss: (-1.3093)(R 5.8840, F -7.2946, G 0.0101)] [G loss: 6.6533]\n",
      "1270 (5, 1) [D loss: (-2.5061)(R -0.9503, F -1.6784, G 0.0123)] [G loss: 0.6976]\n",
      "1271 (5, 1) [D loss: (-2.4285)(R -2.8174, F 0.2170, G 0.0172)] [G loss: -0.4445]\n",
      "1272 (5, 1) [D loss: (-2.2074)(R -0.3596, F -1.9828, G 0.0135)] [G loss: 2.7148]\n",
      "1273 (5, 1) [D loss: (-2.1431)(R 5.3814, F -7.6727, G 0.0148)] [G loss: 8.3651]\n",
      "1274 (5, 1) [D loss: (-1.4949)(R 13.0665, F -14.7100, G 0.0149)] [G loss: 15.3715]\n",
      "1275 (5, 1) [D loss: (-2.2025)(R 13.6976, F -16.0939, G 0.0194)] [G loss: 16.6539]\n",
      "1276 (5, 1) [D loss: (-1.9043)(R 14.1234, F -16.1418, G 0.0114)] [G loss: 15.6225]\n",
      "1277 (5, 1) [D loss: (-2.4011)(R 8.9931, F -11.4946, G 0.0100)] [G loss: 9.8462]\n",
      "1278 (5, 1) [D loss: (-1.5674)(R 2.8074, F -4.4812, G 0.0106)] [G loss: 3.1459]\n",
      "1279 (5, 1) [D loss: (-2.4221)(R -6.9540, F 4.3700, G 0.0162)] [G loss: -7.0398]\n",
      "1280 (5, 1) [D loss: (-2.3561)(R -11.6782, F 9.1180, G 0.0204)] [G loss: -10.0952]\n",
      "1281 (5, 1) [D loss: (-1.6980)(R -10.9922, F 9.1328, G 0.0161)] [G loss: -8.7437]\n",
      "1282 (5, 1) [D loss: (-1.8178)(R -7.0207, F 5.1149, G 0.0088)] [G loss: -4.5629]\n",
      "1283 (5, 1) [D loss: (-2.2272)(R -0.4056, F -1.9199, G 0.0098)] [G loss: 2.2627]\n",
      "1284 (5, 1) [D loss: (-1.6156)(R 4.6491, F -6.4104, G 0.0146)] [G loss: 7.5378]\n",
      "1285 (5, 1) [D loss: (-1.8127)(R 8.1987, F -10.2026, G 0.0191)] [G loss: 9.9531]\n",
      "1286 (5, 1) [D loss: (-1.6114)(R 4.9464, F -6.6719, G 0.0114)] [G loss: 5.6889]\n",
      "1287 (5, 1) [D loss: (-1.6838)(R -0.4919, F -1.3038, G 0.0112)] [G loss: 1.2428]\n",
      "1288 (5, 1) [D loss: (-2.0270)(R -5.7394, F 3.6092, G 0.0103)] [G loss: -4.8484]\n",
      "1289 (5, 1) [D loss: (-2.2351)(R -10.1466, F 7.7206, G 0.0191)] [G loss: -8.6530]\n",
      "1290 (5, 1) [D loss: (-1.9856)(R -8.7652, F 6.6435, G 0.0136)] [G loss: -6.3647]\n",
      "1291 (5, 1) [D loss: (-1.2422)(R -5.5408, F 4.1833, G 0.0115)] [G loss: -2.6500]\n",
      "1292 (5, 1) [D loss: (-1.6832)(R 1.1091, F -2.8889, G 0.0097)] [G loss: 4.0979]\n",
      "1293 (5, 1) [D loss: (-2.4088)(R 7.0672, F -9.6314, G 0.0155)] [G loss: 11.1196]\n",
      "1294 (5, 1) [D loss: (-2.2008)(R 10.2231, F -12.6025, G 0.0179)] [G loss: 12.8815]\n",
      "1295 (5, 1) [D loss: (-2.3287)(R 7.7733, F -10.2726, G 0.0171)] [G loss: 9.5012]\n",
      "1296 (5, 1) [D loss: (-1.4053)(R 3.3263, F -4.8823, G 0.0151)] [G loss: 3.5433]\n",
      "1297 (5, 1) [D loss: (-2.3352)(R -5.6092, F 3.1479, G 0.0126)] [G loss: -4.7806]\n",
      "1298 (5, 1) [D loss: (-1.9390)(R -11.2293, F 9.1010, G 0.0189)] [G loss: -9.5436]\n",
      "1299 (5, 1) [D loss: (-2.5782)(R -14.4638, F 11.6339, G 0.0252)] [G loss: -12.5308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 (5, 1) [D loss: (-1.1414)(R -12.0283, F 10.7454, G 0.0142)] [G loss: -10.5196]\n",
      "1301 (5, 1) [D loss: (-1.6805)(R -8.9634, F 7.1769, G 0.0106)] [G loss: -6.5269]\n",
      "1302 (5, 1) [D loss: (-1.6803)(R -4.9275, F 3.1633, G 0.0084)] [G loss: -2.9148]\n",
      "1303 (5, 1) [D loss: (-1.3263)(R -0.4412, F -0.9900, G 0.0105)] [G loss: 1.7154]\n",
      "1304 (5, 1) [D loss: (-1.9953)(R 0.1682, F -2.2948, G 0.0131)] [G loss: 1.7419]\n",
      "1305 (5, 1) [D loss: (-1.6583)(R -1.7882, F 0.0196, G 0.0110)] [G loss: -0.0628]\n",
      "1306 (5, 1) [D loss: (-2.5613)(R -6.0291, F 3.3423, G 0.0125)] [G loss: -4.6769]\n",
      "1307 (5, 1) [D loss: (-1.9333)(R -12.2700, F 10.1233, G 0.0213)] [G loss: -11.2947]\n",
      "1308 (5, 1) [D loss: (-1.1373)(R -14.7007, F 13.3352, G 0.0228)] [G loss: -13.0517]\n",
      "1309 (5, 1) [D loss: (-1.4742)(R -12.8144, F 11.1773, G 0.0163)] [G loss: -10.7679]\n",
      "1310 (5, 1) [D loss: (-1.3839)(R -9.0703, F 7.5861, G 0.0100)] [G loss: -6.7468]\n",
      "1311 (5, 1) [D loss: (-2.0236)(R -2.8486, F 0.7411, G 0.0084)] [G loss: 0.4453]\n",
      "1312 (5, 1) [D loss: (-2.1136)(R 5.7573, F -7.9898, G 0.0119)] [G loss: 9.0643]\n",
      "1313 (5, 1) [D loss: (-2.7018)(R 11.0899, F -13.9577, G 0.0166)] [G loss: 14.6801]\n",
      "1314 (5, 1) [D loss: (-2.2107)(R 12.6761, F -15.0704, G 0.0184)] [G loss: 13.7827]\n",
      "1315 (5, 1) [D loss: (-2.1225)(R 9.2738, F -11.5462, G 0.0150)] [G loss: 10.9880]\n",
      "1316 (5, 1) [D loss: (-1.8494)(R 5.0844, F -7.0378, G 0.0104)] [G loss: 5.8153]\n",
      "1317 (5, 1) [D loss: (-1.6956)(R 0.4553, F -2.2944, G 0.0143)] [G loss: 1.2436]\n",
      "1318 (5, 1) [D loss: (-1.8797)(R -3.9377, F 1.9045, G 0.0154)] [G loss: -2.4705]\n",
      "1319 (5, 1) [D loss: (-2.3595)(R -3.7788, F 1.2728, G 0.0147)] [G loss: -1.3749]\n",
      "1320 (5, 1) [D loss: (-1.0206)(R 2.8697, F -3.9966, G 0.0106)] [G loss: 6.5949]\n",
      "1321 (5, 1) [D loss: (-1.8039)(R 11.5837, F -13.5314, G 0.0144)] [G loss: 14.0532]\n",
      "1322 (5, 1) [D loss: (-2.2801)(R 15.1968, F -17.6445, G 0.0168)] [G loss: 17.9090]\n",
      "1323 (5, 1) [D loss: (-1.8531)(R 16.0209, F -18.0977, G 0.0224)] [G loss: 17.4917]\n",
      "1324 (5, 1) [D loss: (-2.2074)(R 11.5305, F -13.8601, G 0.0122)] [G loss: 13.0876]\n",
      "1325 (5, 1) [D loss: (-1.3470)(R 6.8221, F -8.2540, G 0.0085)] [G loss: 7.5379]\n",
      "1326 (5, 1) [D loss: (-1.3501)(R 0.1611, F -1.6254, G 0.0114)] [G loss: 0.7103]\n",
      "1327 (5, 1) [D loss: (-2.1294)(R -5.7554, F 3.4754, G 0.0151)] [G loss: -3.9386]\n",
      "1328 (5, 1) [D loss: (-2.3977)(R -7.3853, F 4.8444, G 0.0143)] [G loss: -4.9477]\n",
      "1329 (5, 1) [D loss: (-2.6525)(R -6.0574, F 3.2916, G 0.0113)] [G loss: -3.7785]\n",
      "1330 (5, 1) [D loss: (-1.9171)(R -3.6412, F 1.6194, G 0.0105)] [G loss: -0.9144]\n",
      "1331 (5, 1) [D loss: (-1.7564)(R -0.1382, F -1.7094, G 0.0091)] [G loss: 2.6505]\n",
      "1332 (5, 1) [D loss: (-1.9660)(R 3.9370, F -6.0395, G 0.0136)] [G loss: 6.7144]\n",
      "1333 (5, 1) [D loss: (-1.6910)(R 6.4225, F -8.2456, G 0.0132)] [G loss: 7.8468]\n",
      "1334 (5, 1) [D loss: (-2.1366)(R 5.7169, F -8.0034, G 0.0150)] [G loss: 7.2402]\n",
      "1335 (5, 1) [D loss: (-1.9129)(R 0.7672, F -2.7849, G 0.0105)] [G loss: 1.9938]\n",
      "1336 (5, 1) [D loss: (-1.6303)(R -3.2667, F 1.4744, G 0.0162)] [G loss: -2.2259]\n",
      "1337 (5, 1) [D loss: (-1.8443)(R -7.9724, F 5.9085, G 0.0220)] [G loss: -7.1755]\n",
      "1338 (5, 1) [D loss: (-1.9342)(R -10.0355, F 7.9441, G 0.0157)] [G loss: -8.0224]\n",
      "1339 (5, 1) [D loss: (-1.6640)(R -7.5399, F 5.7514, G 0.0125)] [G loss: -4.7339]\n",
      "1340 (5, 1) [D loss: (-1.6251)(R -4.4385, F 2.7076, G 0.0106)] [G loss: -1.7811]\n",
      "1341 (5, 1) [D loss: (-1.9353)(R -2.5639, F 0.5088, G 0.0120)] [G loss: 0.1588]\n",
      "1342 (5, 1) [D loss: (-2.0321)(R -0.2065, F -1.9427, G 0.0117)] [G loss: 1.5967]\n",
      "1343 (5, 1) [D loss: (-2.1534)(R -1.3387, F -0.9298, G 0.0115)] [G loss: 0.1569]\n",
      "1344 (5, 1) [D loss: (-1.8861)(R -4.7351, F 2.7162, G 0.0133)] [G loss: -3.3549]\n",
      "1345 (5, 1) [D loss: (-2.0634)(R -9.4026, F 7.1524, G 0.0187)] [G loss: -7.4109]\n",
      "1346 (5, 1) [D loss: (-2.1381)(R -12.9154, F 10.5571, G 0.0220)] [G loss: -11.8765]\n",
      "1347 (5, 1) [D loss: (-2.5546)(R -15.1143, F 12.3311, G 0.0229)] [G loss: -12.6424]\n",
      "1348 (5, 1) [D loss: (-2.2477)(R -14.7468, F 12.2628, G 0.0236)] [G loss: -12.2021]\n",
      "1349 (5, 1) [D loss: (-1.7589)(R -11.9181, F 9.9910, G 0.0168)] [G loss: -9.6455]\n",
      "1350 (5, 1) [D loss: (-1.9029)(R -9.0727, F 7.0532, G 0.0117)] [G loss: -6.9312]\n",
      "1351 (5, 1) [D loss: (-1.5880)(R -9.1645, F 7.4631, G 0.0113)] [G loss: -7.9123]\n",
      "1352 (5, 1) [D loss: (-1.9191)(R -9.0341, F 6.9765, G 0.0138)] [G loss: -6.5430]\n",
      "1353 (5, 1) [D loss: (-2.1370)(R -8.3817, F 6.1048, G 0.0140)] [G loss: -6.2110]\n",
      "1354 (5, 1) [D loss: (-1.8312)(R -8.5502, F 6.5737, G 0.0145)] [G loss: -6.5182]\n",
      "1355 (5, 1) [D loss: (-1.7670)(R -8.6835, F 6.7826, G 0.0134)] [G loss: -7.2448]\n",
      "1356 (5, 1) [D loss: (-1.1035)(R -6.3034, F 5.0961, G 0.0104)] [G loss: -5.0997]\n",
      "1357 (5, 1) [D loss: (-1.8912)(R -7.1073, F 5.1064, G 0.0110)] [G loss: -6.0843]\n",
      "1358 (5, 1) [D loss: (-1.7339)(R -7.7982, F 5.9420, G 0.0122)] [G loss: -5.8007]\n",
      "1359 (5, 1) [D loss: (-1.7980)(R -3.8736, F 1.9765, G 0.0099)] [G loss: -1.3853]\n",
      "1360 (5, 1) [D loss: (-2.2061)(R -0.0847, F -2.2432, G 0.0122)] [G loss: 3.1613]\n",
      "1361 (5, 1) [D loss: (-2.2404)(R 3.5894, F -5.9761, G 0.0146)] [G loss: 5.4457]\n",
      "1362 (5, 1) [D loss: (-2.6157)(R 3.8478, F -6.5899, G 0.0126)] [G loss: 5.5585]\n",
      "1363 (5, 1) [D loss: (-0.9265)(R 4.0437, F -5.1041, G 0.0134)] [G loss: 5.3224]\n",
      "1364 (5, 1) [D loss: (-1.8287)(R 3.9112, F -5.8684, G 0.0128)] [G loss: 5.3382]\n",
      "1365 (5, 1) [D loss: (-2.1046)(R 4.2040, F -6.4510, G 0.0142)] [G loss: 6.9255]\n",
      "1366 (5, 1) [D loss: (-1.9826)(R 3.1292, F -5.2423, G 0.0131)] [G loss: 4.9882]\n",
      "1367 (5, 1) [D loss: (-1.8706)(R 1.6301, F -3.6187, G 0.0118)] [G loss: 3.4993]\n",
      "1368 (5, 1) [D loss: (-1.4708)(R 0.9662, F -2.5543, G 0.0117)] [G loss: 3.0797]\n",
      "1369 (5, 1) [D loss: (-2.5059)(R -0.5269, F -2.1259, G 0.0147)] [G loss: 2.2537]\n",
      "1370 (5, 1) [D loss: (-2.0826)(R 0.3952, F -2.6071, G 0.0129)] [G loss: 1.3961]\n",
      "1371 (5, 1) [D loss: (-2.6109)(R -1.0933, F -1.6459, G 0.0128)] [G loss: 1.2904]\n",
      "1372 (5, 1) [D loss: (-1.8904)(R 0.5763, F -2.6068, G 0.0140)] [G loss: 2.8251]\n",
      "1373 (5, 1) [D loss: (-2.2888)(R 1.1023, F -3.5347, G 0.0144)] [G loss: 3.4167]\n",
      "1374 (5, 1) [D loss: (-1.9930)(R 2.7888, F -4.9132, G 0.0131)] [G loss: 4.8805]\n",
      "1375 (5, 1) [D loss: (-1.1565)(R 2.9632, F -4.2191, G 0.0099)] [G loss: 3.8937]\n",
      "1376 (5, 1) [D loss: (-2.0768)(R 2.1541, F -4.3418, G 0.0111)] [G loss: 5.1075]\n",
      "1377 (5, 1) [D loss: (-1.3700)(R 3.6767, F -5.1699, G 0.0123)] [G loss: 4.7552]\n",
      "1378 (5, 1) [D loss: (-2.0969)(R -0.6568, F -1.5665, G 0.0126)] [G loss: 1.1225]\n",
      "1379 (5, 1) [D loss: (-1.7447)(R -2.8327, F 0.9774, G 0.0111)] [G loss: -1.5929]\n",
      "1380 (5, 1) [D loss: (-1.4275)(R -4.0188, F 2.4676, G 0.0124)] [G loss: -2.4856]\n",
      "1381 (5, 1) [D loss: (-1.5873)(R -4.1250, F 2.3882, G 0.0150)] [G loss: -2.0462]\n",
      "1382 (5, 1) [D loss: (-1.6830)(R -2.7981, F 0.9881, G 0.0127)] [G loss: -0.5690]\n",
      "1383 (5, 1) [D loss: (-1.3823)(R -0.5362, F -0.9677, G 0.0122)] [G loss: 1.5378]\n",
      "1384 (5, 1) [D loss: (-1.9325)(R 1.8937, F -3.9532, G 0.0127)] [G loss: 3.8680]\n",
      "1385 (5, 1) [D loss: (-1.6879)(R 2.1656, F -3.9978, G 0.0144)] [G loss: 4.2394]\n",
      "1386 (5, 1) [D loss: (-2.1149)(R -1.5254, F -0.7228, G 0.0133)] [G loss: -0.4885]\n",
      "1387 (5, 1) [D loss: (-2.0141)(R -4.7340, F 2.5784, G 0.0142)] [G loss: -3.2129]\n",
      "1388 (5, 1) [D loss: (-1.4373)(R -7.9049, F 6.3133, G 0.0154)] [G loss: -7.1426]\n",
      "1389 (5, 1) [D loss: (-2.8394)(R -12.0735, F 9.0368, G 0.0197)] [G loss: -10.4013]\n",
      "1390 (5, 1) [D loss: (-2.1383)(R -13.1456, F 10.7948, G 0.0212)] [G loss: -10.3325]\n",
      "1391 (5, 1) [D loss: (-1.9894)(R -10.4242, F 8.3179, G 0.0117)] [G loss: -7.5159]\n",
      "1392 (5, 1) [D loss: (-1.8790)(R -7.1381, F 5.1371, G 0.0122)] [G loss: -5.1611]\n",
      "1393 (5, 1) [D loss: (-2.5263)(R -4.9527, F 2.3067, G 0.0120)] [G loss: -2.3424]\n",
      "1394 (5, 1) [D loss: (-1.5033)(R -1.2864, F -0.3531, G 0.0136)] [G loss: 1.3512]\n",
      "1395 (5, 1) [D loss: (-2.1231)(R -0.5626, F -1.6891, G 0.0129)] [G loss: 1.9322]\n",
      "1396 (5, 1) [D loss: (-2.3581)(R -0.9718, F -1.5266, G 0.0140)] [G loss: 1.0671]\n",
      "1397 (5, 1) [D loss: (-1.7662)(R -1.9448, F 0.0421, G 0.0137)] [G loss: -0.3493]\n",
      "1398 (5, 1) [D loss: (-2.1556)(R -4.8005, F 2.4775, G 0.0167)] [G loss: -3.7486]\n",
      "1399 (5, 1) [D loss: (-2.1929)(R -7.0007, F 4.6420, G 0.0166)] [G loss: -4.5219]\n",
      "1400 (5, 1) [D loss: (-1.9610)(R -4.4007, F 2.3043, G 0.0135)] [G loss: -2.2103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401 (5, 1) [D loss: (-0.9968)(R -0.9952, F -0.1003, G 0.0099)] [G loss: 0.7146]\n",
      "1402 (5, 1) [D loss: (-1.8285)(R 0.7317, F -2.6965, G 0.0136)] [G loss: 2.7664]\n",
      "1403 (5, 1) [D loss: (-2.0892)(R 2.3141, F -4.5326, G 0.0129)] [G loss: 4.6431]\n",
      "1404 (5, 1) [D loss: (-1.5272)(R 4.2862, F -5.9542, G 0.0141)] [G loss: 5.8918]\n",
      "1405 (5, 1) [D loss: (-1.5088)(R 4.6019, F -6.2367, G 0.0126)] [G loss: 6.0384]\n",
      "1406 (5, 1) [D loss: (-1.6395)(R 2.4163, F -4.1916, G 0.0136)] [G loss: 3.1466]\n",
      "1407 (5, 1) [D loss: (-1.0379)(R -1.4383, F 0.2658, G 0.0135)] [G loss: -0.6596]\n",
      "1408 (5, 1) [D loss: (-1.8456)(R -5.5498, F 3.5526, G 0.0152)] [G loss: -4.5310]\n",
      "1409 (5, 1) [D loss: (-2.1087)(R -8.7778, F 6.5211, G 0.0148)] [G loss: -7.4539]\n",
      "1410 (5, 1) [D loss: (-1.5582)(R -9.5124, F 7.8034, G 0.0151)] [G loss: -7.3350]\n",
      "1411 (5, 1) [D loss: (-1.3027)(R -9.2616, F 7.8163, G 0.0143)] [G loss: -7.9963]\n",
      "1412 (5, 1) [D loss: (-2.0279)(R -7.6667, F 5.5191, G 0.0120)] [G loss: -5.4464]\n",
      "1413 (5, 1) [D loss: (-2.0351)(R -4.7933, F 2.6623, G 0.0096)] [G loss: -2.3109]\n",
      "1414 (5, 1) [D loss: (-2.1344)(R -1.6314, F -0.6159, G 0.0113)] [G loss: 1.3520]\n",
      "1415 (5, 1) [D loss: (-1.6799)(R 1.8202, F -3.6247, G 0.0125)] [G loss: 4.2303]\n",
      "1416 (5, 1) [D loss: (-1.8438)(R 2.0158, F -3.9984, G 0.0139)] [G loss: 4.3773]\n",
      "1417 (5, 1) [D loss: (-2.0505)(R 0.2579, F -2.4412, G 0.0133)] [G loss: 2.1363]\n",
      "1418 (5, 1) [D loss: (-1.3454)(R -1.6565, F 0.1883, G 0.0123)] [G loss: 0.3086]\n",
      "1419 (5, 1) [D loss: (-2.2321)(R -2.4878, F 0.1247, G 0.0131)] [G loss: 0.1200]\n",
      "1420 (5, 1) [D loss: (-2.0998)(R -3.0202, F 0.7743, G 0.0146)] [G loss: -0.9299]\n",
      "1421 (5, 1) [D loss: (-1.8216)(R -1.3354, F -0.6386, G 0.0152)] [G loss: 1.1632]\n",
      "1422 (5, 1) [D loss: (-1.7611)(R 0.8047, F -2.6892, G 0.0123)] [G loss: 3.9861]\n",
      "1423 (5, 1) [D loss: (-1.9293)(R 2.9992, F -5.0392, G 0.0111)] [G loss: 5.1222]\n",
      "1424 (5, 1) [D loss: (-1.7531)(R 4.4701, F -6.3452, G 0.0122)] [G loss: 6.3886]\n",
      "1425 (5, 1) [D loss: (-1.5007)(R 4.9611, F -6.5743, G 0.0113)] [G loss: 6.4659]\n",
      "1426 (5, 1) [D loss: (-1.2355)(R 4.3293, F -5.6821, G 0.0117)] [G loss: 5.5436]\n",
      "1427 (5, 1) [D loss: (-1.6811)(R 0.0768, F -1.8767, G 0.0119)] [G loss: 0.9256]\n",
      "1428 (5, 1) [D loss: (-1.0528)(R -2.4006, F 1.2487, G 0.0099)] [G loss: -2.1468]\n",
      "1429 (5, 1) [D loss: (-1.9763)(R -7.1154, F 4.9913, G 0.0148)] [G loss: -6.3127]\n",
      "1430 (5, 1) [D loss: (-2.2561)(R -10.6173, F 8.1850, G 0.0176)] [G loss: -9.1675]\n",
      "1431 (5, 1) [D loss: (-2.0298)(R -9.6062, F 7.4209, G 0.0156)] [G loss: -7.5093]\n",
      "1432 (5, 1) [D loss: (-1.4538)(R -7.6529, F 6.0971, G 0.0102)] [G loss: -5.3795]\n",
      "1433 (5, 1) [D loss: (-1.8457)(R -4.2544, F 2.3056, G 0.0103)] [G loss: -1.2873]\n",
      "1434 (5, 1) [D loss: (-1.6744)(R -0.3012, F -1.4784, G 0.0105)] [G loss: 2.2724]\n",
      "1435 (5, 1) [D loss: (-2.5506)(R 1.9125, F -4.5946, G 0.0132)] [G loss: 4.7411]\n",
      "1436 (5, 1) [D loss: (-2.2179)(R 2.5654, F -4.9106, G 0.0127)] [G loss: 4.7239]\n",
      "1437 (5, 1) [D loss: (-1.7567)(R 2.0591, F -3.9593, G 0.0144)] [G loss: 4.1345]\n",
      "1438 (5, 1) [D loss: (-1.7906)(R 1.3880, F -3.3038, G 0.0125)] [G loss: 2.4539]\n",
      "1439 (5, 1) [D loss: (-1.6253)(R -1.2497, F -0.5246, G 0.0149)] [G loss: 1.1514]\n",
      "1440 (5, 1) [D loss: (-2.1453)(R -2.7558, F 0.4693, G 0.0141)] [G loss: -0.4360]\n",
      "1441 (5, 1) [D loss: (-2.2225)(R -2.3155, F -0.0870, G 0.0180)] [G loss: 0.4371]\n",
      "1442 (5, 1) [D loss: (-2.6574)(R 0.8530, F -3.6505, G 0.0140)] [G loss: 4.0377]\n",
      "1443 (5, 1) [D loss: (-2.0287)(R 5.9238, F -8.1049, G 0.0152)] [G loss: 8.5610]\n",
      "1444 (5, 1) [D loss: (-1.7575)(R 8.8809, F -10.8329, G 0.0194)] [G loss: 10.4802]\n",
      "1445 (5, 1) [D loss: (-2.4089)(R 8.0510, F -10.6206, G 0.0161)] [G loss: 10.3396]\n",
      "1446 (5, 1) [D loss: (-1.8444)(R 7.0047, F -9.0008, G 0.0152)] [G loss: 7.8876]\n",
      "1447 (5, 1) [D loss: (-1.5968)(R 3.4817, F -5.1967, G 0.0118)] [G loss: 4.3599]\n",
      "1448 (5, 1) [D loss: (-0.9447)(R -1.3071, F 0.2724, G 0.0090)] [G loss: -1.2893]\n",
      "1449 (5, 1) [D loss: (-1.6637)(R -6.2297, F 4.4113, G 0.0155)] [G loss: -5.6329]\n",
      "1450 (5, 1) [D loss: (-1.9648)(R -8.8711, F 6.7467, G 0.0160)] [G loss: -7.7234]\n",
      "1451 (5, 1) [D loss: (-1.8183)(R -8.8143, F 6.8485, G 0.0148)] [G loss: -6.8483]\n",
      "1452 (5, 1) [D loss: (-1.5677)(R -5.2074, F 3.5231, G 0.0117)] [G loss: -3.0842]\n",
      "1453 (5, 1) [D loss: (-2.5316)(R -2.0200, F -0.6154, G 0.0104)] [G loss: 1.1592]\n",
      "1454 (5, 1) [D loss: (-1.2287)(R 3.0759, F -4.4301, G 0.0126)] [G loss: 4.8306]\n",
      "1455 (5, 1) [D loss: (-1.5922)(R 5.1010, F -6.8238, G 0.0131)] [G loss: 6.7864]\n",
      "1456 (5, 1) [D loss: (-1.7174)(R 5.1489, F -6.9973, G 0.0131)] [G loss: 6.6466]\n",
      "1457 (5, 1) [D loss: (-1.8481)(R 3.3075, F -5.2781, G 0.0122)] [G loss: 4.7756]\n",
      "1458 (5, 1) [D loss: (-2.1191)(R 1.5867, F -3.8114, G 0.0106)] [G loss: 3.0342]\n",
      "1459 (5, 1) [D loss: (-1.5984)(R -0.4673, F -1.2671, G 0.0136)] [G loss: 0.9525]\n",
      "1460 (5, 1) [D loss: (-1.5951)(R -0.2897, F -1.4193, G 0.0114)] [G loss: 1.5286]\n",
      "1461 (5, 1) [D loss: (-2.7321)(R -1.3606, F -1.5490, G 0.0178)] [G loss: 1.3989]\n",
      "1462 (5, 1) [D loss: (-2.0213)(R 3.8161, F -5.9751, G 0.0138)] [G loss: 7.2376]\n",
      "1463 (5, 1) [D loss: (-2.2994)(R 9.6690, F -12.1445, G 0.0176)] [G loss: 12.2588]\n",
      "1464 (5, 1) [D loss: (-1.9692)(R 11.1428, F -13.2729, G 0.0161)] [G loss: 13.2062]\n",
      "1465 (5, 1) [D loss: (-2.2083)(R 10.4340, F -12.7980, G 0.0156)] [G loss: 12.0854]\n",
      "1466 (5, 1) [D loss: (-1.7700)(R 7.9921, F -9.9072, G 0.0145)] [G loss: 9.9253]\n",
      "1467 (5, 1) [D loss: (-2.2707)(R 5.0320, F -7.4065, G 0.0104)] [G loss: 6.9133]\n",
      "1468 (5, 1) [D loss: (-2.2085)(R -0.0373, F -2.2911, G 0.0120)] [G loss: 1.2527]\n",
      "1469 (5, 1) [D loss: (-2.1892)(R -6.2435, F 3.8880, G 0.0166)] [G loss: -5.6097]\n",
      "1470 (5, 1) [D loss: (-2.2798)(R -8.6301, F 6.1786, G 0.0172)] [G loss: -7.3142]\n",
      "1471 (5, 1) [D loss: (-1.8269)(R -10.3077, F 8.3338, G 0.0147)] [G loss: -8.0425]\n",
      "1472 (5, 1) [D loss: (-2.5437)(R -8.6840, F 5.9807, G 0.0160)] [G loss: -5.7831]\n",
      "1473 (5, 1) [D loss: (-2.3756)(R -6.3797, F 3.8974, G 0.0107)] [G loss: -3.7883]\n",
      "1474 (5, 1) [D loss: (-2.0001)(R -2.6155, F 0.4906, G 0.0125)] [G loss: 0.4570]\n",
      "1475 (5, 1) [D loss: (-1.6607)(R -0.3191, F -1.4501, G 0.0109)] [G loss: 1.1617]\n",
      "1476 (5, 1) [D loss: (-1.2267)(R -2.1320, F 0.7954, G 0.0110)] [G loss: -0.7193]\n",
      "1477 (5, 1) [D loss: (-1.1986)(R -2.4389, F 1.1351, G 0.0105)] [G loss: -0.8356]\n",
      "1478 (5, 1) [D loss: (-1.5434)(R -3.5892, F 1.9388, G 0.0107)] [G loss: -2.1090]\n",
      "1479 (5, 1) [D loss: (-1.2489)(R -3.8355, F 2.4885, G 0.0098)] [G loss: -2.7197]\n",
      "1480 (5, 1) [D loss: (-1.5453)(R -4.4981, F 2.8390, G 0.0114)] [G loss: -2.7727]\n",
      "1481 (5, 1) [D loss: (-1.7758)(R -3.6659, F 1.7711, G 0.0119)] [G loss: -2.2853]\n",
      "1482 (5, 1) [D loss: (-1.8123)(R -1.4177, F -0.5025, G 0.0108)] [G loss: 1.0673]\n",
      "1483 (5, 1) [D loss: (-2.2948)(R 1.8594, F -4.2682, G 0.0114)] [G loss: 5.0769]\n",
      "1484 (5, 1) [D loss: (-1.3543)(R 6.0600, F -7.5484, G 0.0134)] [G loss: 7.6055]\n",
      "1485 (5, 1) [D loss: (-2.5913)(R 6.2908, F -9.0154, G 0.0133)] [G loss: 8.8648]\n",
      "1486 (5, 1) [D loss: (-1.7725)(R 4.8565, F -6.7509, G 0.0122)] [G loss: 6.4813]\n",
      "1487 (5, 1) [D loss: (-2.5089)(R 0.3518, F -2.9912, G 0.0131)] [G loss: 1.7899]\n",
      "1488 (5, 1) [D loss: (-1.6758)(R -4.3811, F 2.5690, G 0.0136)] [G loss: -4.1548]\n",
      "1489 (5, 1) [D loss: (-1.9867)(R -9.4816, F 7.2991, G 0.0196)] [G loss: -8.0413]\n",
      "1490 (5, 1) [D loss: (-2.4261)(R -8.9799, F 6.3934, G 0.0160)] [G loss: -7.1967]\n",
      "1491 (5, 1) [D loss: (-2.1135)(R -7.3513, F 5.1016, G 0.0136)] [G loss: -4.3704]\n",
      "1492 (5, 1) [D loss: (-1.7478)(R -3.2734, F 1.4160, G 0.0110)] [G loss: -1.2317]\n",
      "1493 (5, 1) [D loss: (-1.7565)(R -0.3438, F -1.5680, G 0.0155)] [G loss: 2.3062]\n",
      "1494 (5, 1) [D loss: (-2.0574)(R 2.1815, F -4.4180, G 0.0179)] [G loss: 4.4954]\n",
      "1495 (5, 1) [D loss: (-1.4924)(R 1.9300, F -3.5672, G 0.0145)] [G loss: 4.1142]\n",
      "1496 (5, 1) [D loss: (-1.8379)(R -0.8476, F -1.1239, G 0.0134)] [G loss: 1.0438]\n",
      "1497 (5, 1) [D loss: (-1.5966)(R -2.0143, F 0.3013, G 0.0116)] [G loss: -0.6436]\n",
      "1498 (5, 1) [D loss: (-1.7637)(R -2.5690, F 0.6883, G 0.0117)] [G loss: -0.6661]\n",
      "1499 (5, 1) [D loss: (-1.6929)(R -3.2308, F 1.3966, G 0.0141)] [G loss: -1.6197]\n",
      "1500 (5, 1) [D loss: (-1.6445)(R -1.2583, F -0.4938, G 0.0108)] [G loss: 0.6587]\n",
      "1501 (5, 1) [D loss: (-1.9286)(R 1.1609, F -3.2183, G 0.0129)] [G loss: 3.7846]\n",
      "1502 (5, 1) [D loss: (-1.5982)(R 5.1556, F -6.9039, G 0.0150)] [G loss: 8.4597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503 (5, 1) [D loss: (-1.9227)(R 8.2780, F -10.3294, G 0.0129)] [G loss: 10.5366]\n",
      "1504 (5, 1) [D loss: (-2.0045)(R 10.2419, F -12.4140, G 0.0168)] [G loss: 12.3128]\n",
      "1505 (5, 1) [D loss: (-1.4532)(R 9.8351, F -11.4362, G 0.0148)] [G loss: 11.0624]\n",
      "1506 (5, 1) [D loss: (-1.5706)(R 8.7209, F -10.4517, G 0.0160)] [G loss: 10.1340]\n",
      "1507 (5, 1) [D loss: (-1.8127)(R 5.7921, F -7.6972, G 0.0092)] [G loss: 6.3082]\n",
      "1508 (5, 1) [D loss: (-1.2678)(R 1.4590, F -2.7973, G 0.0071)] [G loss: 2.2439]\n",
      "1509 (5, 1) [D loss: (-1.6906)(R -2.8957, F 1.0923, G 0.0113)] [G loss: -1.4188]\n",
      "1510 (5, 1) [D loss: (-1.7659)(R -4.1641, F 2.2895, G 0.0109)] [G loss: -2.9347]\n",
      "1511 (5, 1) [D loss: (-1.6213)(R -5.1620, F 3.4246, G 0.0116)] [G loss: -2.5521]\n",
      "1512 (5, 1) [D loss: (-1.6433)(R -3.4069, F 1.6354, G 0.0128)] [G loss: -1.4972]\n",
      "1513 (5, 1) [D loss: (-2.1286)(R -0.6524, F -1.5908, G 0.0115)] [G loss: 0.9868]\n",
      "1514 (5, 1) [D loss: (-2.0100)(R -0.6986, F -1.4515, G 0.0140)] [G loss: 1.7393]\n",
      "1515 (5, 1) [D loss: (-1.9356)(R 0.4894, F -2.5715, G 0.0147)] [G loss: 2.4102]\n",
      "1516 (5, 1) [D loss: (-2.3092)(R 0.0221, F -2.4800, G 0.0149)] [G loss: 2.8039]\n",
      "1517 (5, 1) [D loss: (-1.6099)(R -0.2201, F -1.5373, G 0.0147)] [G loss: 1.7248]\n",
      "1518 (5, 1) [D loss: (-1.5723)(R -1.8248, F 0.1207, G 0.0132)] [G loss: -0.4711]\n",
      "1519 (5, 1) [D loss: (-1.6990)(R -4.1193, F 2.2897, G 0.0131)] [G loss: -2.3407]\n",
      "1520 (5, 1) [D loss: (-1.8609)(R -6.3141, F 4.2952, G 0.0158)] [G loss: -5.1271]\n",
      "1521 (5, 1) [D loss: (-2.1526)(R -7.5177, F 5.2087, G 0.0156)] [G loss: -5.2491]\n",
      "1522 (5, 1) [D loss: (-2.1113)(R -6.5084, F 4.2820, G 0.0115)] [G loss: -3.9869]\n",
      "1523 (5, 1) [D loss: (-2.2322)(R -3.8049, F 1.4672, G 0.0105)] [G loss: -0.9656]\n",
      "1524 (5, 1) [D loss: (-1.9972)(R -0.3943, F -1.7117, G 0.0109)] [G loss: 2.3813]\n",
      "1525 (5, 1) [D loss: (-1.5411)(R 3.6101, F -5.2647, G 0.0114)] [G loss: 5.9043]\n",
      "1526 (5, 1) [D loss: (-1.3225)(R 3.2305, F -4.6710, G 0.0118)] [G loss: 3.6347]\n",
      "1527 (5, 1) [D loss: (-1.5630)(R -1.6742, F -0.0397, G 0.0151)] [G loss: -0.9760]\n",
      "1528 (5, 1) [D loss: (-2.0774)(R -10.2591, F 8.0109, G 0.0171)] [G loss: -9.7847]\n",
      "1529 (5, 1) [D loss: (-2.0968)(R -14.9464, F 12.6197, G 0.0230)] [G loss: -13.6732]\n",
      "1530 (5, 1) [D loss: (-2.4233)(R -17.6703, F 15.0003, G 0.0247)] [G loss: -15.9198]\n",
      "1531 (5, 1) [D loss: (-2.5517)(R -18.1385, F 15.4166, G 0.0170)] [G loss: -16.1478]\n",
      "1532 (5, 1) [D loss: (-1.6103)(R -15.3213, F 13.5916, G 0.0119)] [G loss: -12.7238]\n",
      "1533 (5, 1) [D loss: (-1.7217)(R -11.2258, F 9.4096, G 0.0095)] [G loss: -8.2634]\n",
      "1534 (5, 1) [D loss: (-1.3985)(R -7.2844, F 5.7970, G 0.0089)] [G loss: -5.2778]\n",
      "1535 (5, 1) [D loss: (-1.7828)(R -5.3843, F 3.4744, G 0.0127)] [G loss: -3.1246]\n",
      "1536 (5, 1) [D loss: (-1.8920)(R -5.9745, F 3.9655, G 0.0117)] [G loss: -4.2268]\n",
      "1537 (5, 1) [D loss: (-1.6563)(R -6.1078, F 4.3175, G 0.0134)] [G loss: -4.9820]\n",
      "1538 (5, 1) [D loss: (-1.8786)(R -6.9126, F 4.8983, G 0.0136)] [G loss: -4.7328]\n",
      "1539 (5, 1) [D loss: (-2.1732)(R -7.0076, F 4.7056, G 0.0129)] [G loss: -4.5452]\n",
      "1540 (5, 1) [D loss: (-1.7418)(R -7.4517, F 5.5554, G 0.0155)] [G loss: -4.9410]\n",
      "1541 (5, 1) [D loss: (-2.0288)(R -4.8139, F 2.6571, G 0.0128)] [G loss: -2.6349]\n",
      "1542 (5, 1) [D loss: (-1.5070)(R -2.6408, F 0.9813, G 0.0153)] [G loss: -0.0729]\n",
      "1543 (5, 1) [D loss: (-1.9841)(R 0.7310, F -2.8526, G 0.0138)] [G loss: 3.4187]\n",
      "1544 (5, 1) [D loss: (-2.2294)(R 1.8517, F -4.2210, G 0.0140)] [G loss: 4.5235]\n",
      "1545 (5, 1) [D loss: (-1.1202)(R 4.9273, F -6.2171, G 0.0170)] [G loss: 6.0661]\n",
      "1546 (5, 1) [D loss: (-2.0113)(R 4.3445, F -6.5254, G 0.0170)] [G loss: 6.4992]\n",
      "1547 (5, 1) [D loss: (-1.6422)(R 2.7694, F -4.5603, G 0.0149)] [G loss: 4.3798]\n",
      "1548 (5, 1) [D loss: (-1.9496)(R 0.9670, F -3.0446, G 0.0128)] [G loss: 3.7464]\n",
      "1549 (5, 1) [D loss: (-1.9717)(R -0.9558, F -1.2017, G 0.0186)] [G loss: 0.4800]\n",
      "1550 (5, 1) [D loss: (-1.5876)(R -1.5383, F -0.1969, G 0.0148)] [G loss: 0.2840]\n",
      "1551 (5, 1) [D loss: (-1.6739)(R -2.3847, F 0.5622, G 0.0149)] [G loss: -0.6818]\n",
      "1552 (5, 1) [D loss: (-1.9001)(R -2.8305, F 0.7944, G 0.0136)] [G loss: -1.1083]\n",
      "1553 (5, 1) [D loss: (-1.6992)(R -2.3166, F 0.4962, G 0.0121)] [G loss: -0.6146]\n",
      "1554 (5, 1) [D loss: (-1.4572)(R -1.3392, F -0.2340, G 0.0116)] [G loss: 0.4628]\n",
      "1555 (5, 1) [D loss: (-1.6463)(R -0.7035, F -1.0491, G 0.0106)] [G loss: 1.0464]\n",
      "1556 (5, 1) [D loss: (-2.1039)(R -0.9254, F -1.3155, G 0.0137)] [G loss: 1.1139]\n",
      "1557 (5, 1) [D loss: (-1.8309)(R 0.6021, F -2.5712, G 0.0138)] [G loss: 3.0935]\n",
      "1558 (5, 1) [D loss: (-1.7588)(R 3.4585, F -5.3551, G 0.0138)] [G loss: 5.8604]\n",
      "1559 (5, 1) [D loss: (-1.7661)(R 3.5230, F -5.4463, G 0.0157)] [G loss: 4.9873]\n",
      "1560 (5, 1) [D loss: (-1.9797)(R 2.2410, F -4.3590, G 0.0138)] [G loss: 4.4571]\n",
      "1561 (5, 1) [D loss: (-1.7100)(R 1.9359, F -3.8051, G 0.0159)] [G loss: 3.6022]\n",
      "1562 (5, 1) [D loss: (-1.8099)(R 0.2642, F -2.2509, G 0.0177)] [G loss: 2.0054]\n",
      "1563 (5, 1) [D loss: (-1.5350)(R 0.0934, F -1.7871, G 0.0159)] [G loss: 1.5869]\n",
      "1564 (5, 1) [D loss: (-1.3327)(R -0.5618, F -0.9118, G 0.0141)] [G loss: 0.3717]\n",
      "1565 (5, 1) [D loss: (-1.6727)(R -1.7469, F -0.0530, G 0.0127)] [G loss: 0.0547]\n",
      "1566 (5, 1) [D loss: (-1.9819)(R -2.5674, F 0.4653, G 0.0120)] [G loss: -0.5444]\n",
      "1567 (5, 1) [D loss: (-2.1485)(R -2.7597, F 0.4775, G 0.0134)] [G loss: -0.5547]\n",
      "1568 (5, 1) [D loss: (-1.7604)(R -4.5959, F 2.7168, G 0.0119)] [G loss: -2.8636]\n",
      "1569 (5, 1) [D loss: (-1.6761)(R -4.9590, F 3.1592, G 0.0124)] [G loss: -3.1712]\n",
      "1570 (5, 1) [D loss: (-2.2303)(R -6.3459, F 3.9577, G 0.0158)] [G loss: -4.9990]\n",
      "1571 (5, 1) [D loss: (-2.1340)(R -8.4604, F 6.1340, G 0.0192)] [G loss: -6.7872]\n",
      "1572 (5, 1) [D loss: (-1.8042)(R -10.2907, F 8.2824, G 0.0204)] [G loss: -8.3505]\n",
      "1573 (5, 1) [D loss: (-1.7578)(R -10.6898, F 8.7669, G 0.0165)] [G loss: -8.6462]\n",
      "1574 (5, 1) [D loss: (-1.8117)(R -9.4411, F 7.4808, G 0.0149)] [G loss: -7.3798]\n",
      "1575 (5, 1) [D loss: (-2.0358)(R -9.8159, F 7.6515, G 0.0129)] [G loss: -7.5491]\n",
      "1576 (5, 1) [D loss: (-1.8029)(R -10.6990, F 8.7765, G 0.0120)] [G loss: -8.3521]\n",
      "1577 (5, 1) [D loss: (-1.8442)(R -10.4192, F 8.4503, G 0.0125)] [G loss: -8.6955]\n",
      "1578 (5, 1) [D loss: (-2.0877)(R -10.5862, F 8.3616, G 0.0137)] [G loss: -8.1469]\n",
      "1579 (5, 1) [D loss: (-1.6770)(R -9.6585, F 7.8813, G 0.0100)] [G loss: -8.4764]\n",
      "1580 (5, 1) [D loss: (-1.6159)(R -9.3376, F 7.6203, G 0.0101)] [G loss: -6.9992]\n",
      "1581 (5, 1) [D loss: (-1.8562)(R -7.4837, F 5.5284, G 0.0099)] [G loss: -5.3500]\n",
      "1582 (5, 1) [D loss: (-1.7974)(R -5.3019, F 3.3751, G 0.0129)] [G loss: -3.5884]\n",
      "1583 (5, 1) [D loss: (-1.7860)(R -3.8158, F 1.9159, G 0.0114)] [G loss: -1.2790]\n",
      "1584 (5, 1) [D loss: (-2.1557)(R -1.9554, F -0.3305, G 0.0130)] [G loss: 1.0094]\n",
      "1585 (5, 1) [D loss: (-1.8624)(R -0.5601, F -1.4604, G 0.0158)] [G loss: 1.7166]\n",
      "1586 (5, 1) [D loss: (-1.2841)(R -0.1574, F -1.2619, G 0.0135)] [G loss: 1.2983]\n",
      "1587 (5, 1) [D loss: (-1.4525)(R -1.6742, F 0.1006, G 0.0121)] [G loss: -0.3685]\n",
      "1588 (5, 1) [D loss: (-2.1509)(R -4.5709, F 2.2829, G 0.0137)] [G loss: -2.8036]\n",
      "1589 (5, 1) [D loss: (-2.2549)(R -7.5134, F 5.1109, G 0.0148)] [G loss: -5.5877]\n",
      "1590 (5, 1) [D loss: (-1.9963)(R -7.6601, F 5.5395, G 0.0124)] [G loss: -5.1431]\n",
      "1591 (5, 1) [D loss: (-1.7075)(R -6.9306, F 5.1054, G 0.0118)] [G loss: -4.8201]\n",
      "1592 (5, 1) [D loss: (-1.2638)(R -5.8875, F 4.4988, G 0.0125)] [G loss: -3.7981]\n",
      "1593 (5, 1) [D loss: (-1.4616)(R -3.2476, F 1.6685, G 0.0118)] [G loss: -0.7839]\n",
      "1594 (5, 1) [D loss: (-2.2441)(R -0.8323, F -1.5821, G 0.0170)] [G loss: 1.9882]\n",
      "1595 (5, 1) [D loss: (-2.2704)(R 0.9262, F -3.3735, G 0.0177)] [G loss: 3.2244]\n",
      "1596 (5, 1) [D loss: (-2.3747)(R 0.1896, F -2.7452, G 0.0181)] [G loss: 2.7471]\n",
      "1597 (5, 1) [D loss: (-1.9908)(R -0.5912, F -1.5704, G 0.0171)] [G loss: 1.6458]\n",
      "1598 (5, 1) [D loss: (-1.6317)(R -1.9940, F 0.2338, G 0.0128)] [G loss: -0.0883]\n",
      "1599 (5, 1) [D loss: (-1.5767)(R -3.7364, F 2.0290, G 0.0131)] [G loss: -2.0467]\n",
      "1600 (5, 1) [D loss: (-1.8029)(R -4.9250, F 3.0111, G 0.0111)] [G loss: -2.9366]\n",
      "1601 (5, 1) [D loss: (-1.6726)(R -4.6470, F 2.8590, G 0.0115)] [G loss: -2.4678]\n",
      "1602 (5, 1) [D loss: (-2.1393)(R -2.7720, F 0.4976, G 0.0135)] [G loss: 0.0452]\n",
      "1603 (5, 1) [D loss: (-1.7690)(R 1.9160, F -3.8303, G 0.0145)] [G loss: 4.7798]\n",
      "1604 (5, 1) [D loss: (-1.6963)(R 4.2433, F -6.0830, G 0.0143)] [G loss: 6.3901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605 (5, 1) [D loss: (-1.2586)(R 5.7368, F -7.1455, G 0.0150)] [G loss: 7.6264]\n",
      "1606 (5, 1) [D loss: (-2.4812)(R 7.0634, F -9.6836, G 0.0139)] [G loss: 9.6900]\n",
      "1607 (5, 1) [D loss: (-1.9697)(R 7.3368, F -9.4465, G 0.0140)] [G loss: 9.5548]\n",
      "1608 (5, 1) [D loss: (-2.3979)(R 6.6127, F -9.1868, G 0.0176)] [G loss: 8.4467]\n",
      "1609 (5, 1) [D loss: (-1.7574)(R 4.0600, F -5.9834, G 0.0166)] [G loss: 5.4082]\n",
      "1610 (5, 1) [D loss: (-1.7661)(R 2.6855, F -4.5774, G 0.0126)] [G loss: 4.4067]\n",
      "1611 (5, 1) [D loss: (-1.6837)(R 2.5023, F -4.2997, G 0.0114)] [G loss: 3.7947]\n",
      "1612 (5, 1) [D loss: (-1.9285)(R 0.8851, F -2.9245, G 0.0111)] [G loss: 3.5635]\n",
      "1613 (5, 1) [D loss: (-2.2072)(R 1.1111, F -3.4302, G 0.0112)] [G loss: 3.8910]\n",
      "1614 (5, 1) [D loss: (-1.7074)(R 1.3900, F -3.2144, G 0.0117)] [G loss: 3.2637]\n",
      "1615 (5, 1) [D loss: (-2.6054)(R 0.6289, F -3.3700, G 0.0136)] [G loss: 3.4711]\n",
      "1616 (5, 1) [D loss: (-1.8477)(R 1.9903, F -3.9675, G 0.0130)] [G loss: 4.7092]\n",
      "1617 (5, 1) [D loss: (-1.9602)(R 3.4624, F -5.5701, G 0.0148)] [G loss: 6.2114]\n",
      "1618 (5, 1) [D loss: (-1.8264)(R 7.4639, F -9.4459, G 0.0156)] [G loss: 10.7238]\n",
      "1619 (5, 1) [D loss: (-2.0591)(R 8.0235, F -10.2679, G 0.0185)] [G loss: 10.2935]\n",
      "1620 (5, 1) [D loss: (-2.1832)(R 8.6084, F -10.9827, G 0.0191)] [G loss: 10.1399]\n",
      "1621 (5, 1) [D loss: (-2.2550)(R 7.6509, F -10.0680, G 0.0162)] [G loss: 8.8664]\n",
      "1622 (5, 1) [D loss: (-2.0905)(R 5.1788, F -7.4113, G 0.0142)] [G loss: 7.1643]\n",
      "1623 (5, 1) [D loss: (-1.5849)(R 4.4390, F -6.1486, G 0.0125)] [G loss: 6.0486]\n",
      "1624 (5, 1) [D loss: (-2.4996)(R 3.2808, F -5.8856, G 0.0105)] [G loss: 5.2706]\n",
      "1625 (5, 1) [D loss: (-2.1812)(R 2.2904, F -4.5816, G 0.0110)] [G loss: 4.6350]\n",
      "1626 (5, 1) [D loss: (-2.8067)(R 2.4719, F -5.4265, G 0.0148)] [G loss: 5.2403]\n",
      "1627 (5, 1) [D loss: (-2.7725)(R 2.3797, F -5.2890, G 0.0137)] [G loss: 4.3505]\n",
      "1628 (5, 1) [D loss: (-1.5966)(R 3.1965, F -4.9317, G 0.0139)] [G loss: 4.8960]\n",
      "1629 (5, 1) [D loss: (-1.3908)(R 1.1364, F -2.6534, G 0.0126)] [G loss: 2.2671]\n",
      "1630 (5, 1) [D loss: (-2.0659)(R -3.7322, F 1.5314, G 0.0135)] [G loss: -2.8288]\n",
      "1631 (5, 1) [D loss: (-2.4631)(R -6.8547, F 4.2161, G 0.0176)] [G loss: -4.8488]\n",
      "1632 (5, 1) [D loss: (-2.4503)(R -8.5531, F 5.8991, G 0.0204)] [G loss: -5.6320]\n",
      "1633 (5, 1) [D loss: (-1.8301)(R -8.1781, F 6.1964, G 0.0152)] [G loss: -6.6015]\n",
      "1634 (5, 1) [D loss: (-1.7761)(R -8.0065, F 6.1103, G 0.0120)] [G loss: -5.9336]\n",
      "1635 (5, 1) [D loss: (-1.5601)(R -7.2898, F 5.6201, G 0.0110)] [G loss: -4.6964]\n",
      "1636 (5, 1) [D loss: (-1.9102)(R -6.4094, F 4.4001, G 0.0099)] [G loss: -5.5604]\n",
      "1637 (5, 1) [D loss: (-1.6575)(R -7.9479, F 6.1715, G 0.0119)] [G loss: -6.3007]\n",
      "1638 (5, 1) [D loss: (-1.4855)(R -8.4424, F 6.8477, G 0.0109)] [G loss: -7.4221]\n",
      "1639 (5, 1) [D loss: (-2.0524)(R -10.1339, F 7.9883, G 0.0093)] [G loss: -8.4050]\n",
      "1640 (5, 1) [D loss: (-2.0318)(R -10.2436, F 8.0844, G 0.0127)] [G loss: -7.6289]\n",
      "1641 (5, 1) [D loss: (-1.8262)(R -7.9012, F 5.9571, G 0.0118)] [G loss: -5.3419]\n",
      "1642 (5, 1) [D loss: (-1.9448)(R -4.6983, F 2.6198, G 0.0134)] [G loss: -1.6207]\n",
      "1643 (5, 1) [D loss: (-2.1133)(R -0.9021, F -1.3518, G 0.0141)] [G loss: 2.3048]\n",
      "1644 (5, 1) [D loss: (-1.1553)(R 0.1587, F -1.4288, G 0.0115)] [G loss: 2.1193]\n",
      "1645 (5, 1) [D loss: (-1.4624)(R 0.1328, F -1.6877, G 0.0093)] [G loss: 1.5439]\n",
      "1646 (5, 1) [D loss: (-1.6606)(R -1.1573, F -0.6191, G 0.0116)] [G loss: 0.3139]\n",
      "1647 (5, 1) [D loss: (-2.1091)(R -4.5910, F 2.3795, G 0.0102)] [G loss: -3.0309]\n",
      "1648 (5, 1) [D loss: (-2.3394)(R -7.5597, F 5.0923, G 0.0128)] [G loss: -5.4496]\n",
      "1649 (5, 1) [D loss: (-1.6273)(R -7.8759, F 6.0779, G 0.0171)] [G loss: -6.3275]\n",
      "1650 (5, 1) [D loss: (-1.6252)(R -8.7329, F 6.9603, G 0.0147)] [G loss: -6.2444]\n",
      "1651 (5, 1) [D loss: (-1.6821)(R -5.6694, F 3.8756, G 0.0112)] [G loss: -3.5122]\n",
      "1652 (5, 1) [D loss: (-1.8428)(R -3.7192, F 1.7625, G 0.0114)] [G loss: -0.7480]\n",
      "1653 (5, 1) [D loss: (-1.9450)(R -1.7676, F -0.3142, G 0.0137)] [G loss: 0.5022]\n",
      "1654 (5, 1) [D loss: (-2.4451)(R 0.3925, F -3.0099, G 0.0172)] [G loss: 3.1979]\n",
      "1655 (5, 1) [D loss: (-2.0930)(R 3.4524, F -5.7504, G 0.0205)] [G loss: 6.3391]\n",
      "1656 (5, 1) [D loss: (-2.0133)(R 4.5837, F -6.7434, G 0.0146)] [G loss: 6.8866]\n",
      "1657 (5, 1) [D loss: (-1.4513)(R 4.4640, F -6.0700, G 0.0155)] [G loss: 5.7883]\n",
      "1658 (5, 1) [D loss: (-1.4509)(R 2.3986, F -3.9523, G 0.0103)] [G loss: 3.5354]\n",
      "1659 (5, 1) [D loss: (-1.2416)(R 0.6183, F -1.9527, G 0.0093)] [G loss: 2.6099]\n",
      "1660 (5, 1) [D loss: (-1.3894)(R -0.1793, F -1.3151, G 0.0105)] [G loss: 1.2890]\n",
      "1661 (5, 1) [D loss: (-1.9760)(R -0.3393, F -1.7565, G 0.0120)] [G loss: 2.2414]\n",
      "1662 (5, 1) [D loss: (-1.6129)(R 0.5172, F -2.2902, G 0.0160)] [G loss: 2.6074]\n",
      "1663 (5, 1) [D loss: (-1.8546)(R 2.3463, F -4.3446, G 0.0144)] [G loss: 4.6440]\n",
      "1664 (5, 1) [D loss: (-1.9224)(R 4.7307, F -6.7689, G 0.0116)] [G loss: 6.9238]\n",
      "1665 (5, 1) [D loss: (-2.1163)(R 6.6566, F -8.9121, G 0.0139)] [G loss: 8.5666]\n",
      "1666 (5, 1) [D loss: (-1.7307)(R 7.7850, F -9.6543, G 0.0139)] [G loss: 9.7238]\n",
      "1667 (5, 1) [D loss: (-2.0731)(R 7.9351, F -10.1499, G 0.0142)] [G loss: 10.2106]\n",
      "1668 (5, 1) [D loss: (-1.9105)(R 6.5805, F -8.6460, G 0.0155)] [G loss: 8.5880]\n",
      "1669 (5, 1) [D loss: (-1.7673)(R 2.8852, F -4.8232, G 0.0171)] [G loss: 4.1177]\n",
      "1670 (5, 1) [D loss: (-2.5335)(R -1.1822, F -1.5077, G 0.0156)] [G loss: 0.1475]\n",
      "1671 (5, 1) [D loss: (-1.8477)(R -4.8516, F 2.8589, G 0.0145)] [G loss: -3.7452]\n",
      "1672 (5, 1) [D loss: (-1.5542)(R -7.0418, F 5.3711, G 0.0116)] [G loss: -5.3711]\n",
      "1673 (5, 1) [D loss: (-1.6633)(R -9.0438, F 7.2978, G 0.0083)] [G loss: -6.6113]\n",
      "1674 (5, 1) [D loss: (-2.5217)(R -8.7799, F 6.1552, G 0.0103)] [G loss: -6.2576]\n",
      "1675 (5, 1) [D loss: (-2.3984)(R -8.0338, F 5.5099, G 0.0125)] [G loss: -5.1511]\n",
      "1676 (5, 1) [D loss: (-2.0667)(R -5.1155, F 2.9220, G 0.0127)] [G loss: -2.4008]\n",
      "1677 (5, 1) [D loss: (-1.8229)(R -3.8519, F 1.8951, G 0.0134)] [G loss: -2.4106]\n",
      "1678 (5, 1) [D loss: (-2.0334)(R -4.7720, F 2.6204, G 0.0118)] [G loss: -3.2116]\n",
      "1679 (5, 1) [D loss: (-1.8304)(R -7.3803, F 5.4246, G 0.0125)] [G loss: -5.8145]\n",
      "1680 (5, 1) [D loss: (-2.4296)(R -9.7265, F 7.1148, G 0.0182)] [G loss: -7.8855]\n",
      "1681 (5, 1) [D loss: (-1.2325)(R -9.6562, F 8.2126, G 0.0211)] [G loss: -7.8500]\n",
      "1682 (5, 1) [D loss: (-1.6958)(R -8.9627, F 7.1344, G 0.0132)] [G loss: -8.0720]\n",
      "1683 (5, 1) [D loss: (-1.4624)(R -9.0049, F 7.4176, G 0.0125)] [G loss: -7.4938]\n",
      "1684 (5, 1) [D loss: (-1.1336)(R -8.0008, F 6.7502, G 0.0117)] [G loss: -6.6616]\n",
      "1685 (5, 1) [D loss: (-2.4944)(R -8.5325, F 5.9394, G 0.0099)] [G loss: -6.5069]\n",
      "1686 (5, 1) [D loss: (-1.7929)(R -8.8690, F 6.9518, G 0.0124)] [G loss: -6.5498]\n",
      "1687 (5, 1) [D loss: (-2.0439)(R -8.8872, F 6.7150, G 0.0128)] [G loss: -6.9066]\n",
      "1688 (5, 1) [D loss: (-2.3268)(R -10.5832, F 8.1160, G 0.0140)] [G loss: -9.2746]\n",
      "1689 (5, 1) [D loss: (-1.6037)(R -13.0095, F 11.2263, G 0.0180)] [G loss: -11.2851]\n",
      "1690 (5, 1) [D loss: (-1.8205)(R -13.2580, F 11.2996, G 0.0138)] [G loss: -11.9406]\n",
      "1691 (5, 1) [D loss: (-1.7165)(R -14.0971, F 12.1973, G 0.0183)] [G loss: -12.4667]\n",
      "1692 (5, 1) [D loss: (-2.2475)(R -12.4443, F 10.0262, G 0.0171)] [G loss: -10.7972]\n",
      "1693 (5, 1) [D loss: (-2.1491)(R -11.5453, F 9.2452, G 0.0151)] [G loss: -8.8466]\n",
      "1694 (5, 1) [D loss: (-1.6486)(R -7.7789, F 6.0242, G 0.0106)] [G loss: -5.0132]\n",
      "1695 (5, 1) [D loss: (-2.0397)(R -4.7037, F 2.5614, G 0.0103)] [G loss: -2.5141]\n",
      "1696 (5, 1) [D loss: (-2.0646)(R -3.7826, F 1.5955, G 0.0122)] [G loss: -1.9603]\n",
      "1697 (5, 1) [D loss: (-1.6791)(R -3.8631, F 2.0889, G 0.0095)] [G loss: -1.7129]\n",
      "1698 (5, 1) [D loss: (-2.2304)(R -5.9079, F 3.5228, G 0.0155)] [G loss: -3.8284]\n",
      "1699 (5, 1) [D loss: (-2.1548)(R -8.1700, F 5.7932, G 0.0222)] [G loss: -6.5482]\n",
      "1700 (5, 1) [D loss: (-1.7647)(R -9.0931, F 7.1614, G 0.0167)] [G loss: -6.9833]\n",
      "1701 (5, 1) [D loss: (-1.8039)(R -7.0530, F 5.1275, G 0.0122)] [G loss: -4.4745]\n",
      "1702 (5, 1) [D loss: (-1.4085)(R -2.8691, F 1.3554, G 0.0105)] [G loss: -0.7281]\n",
      "1703 (5, 1) [D loss: (-1.7140)(R 0.1047, F -1.9488, G 0.0130)] [G loss: 2.6408]\n",
      "1704 (5, 1) [D loss: (-2.2277)(R 2.4309, F -4.8326, G 0.0174)] [G loss: 5.4189]\n",
      "1705 (5, 1) [D loss: (-2.2143)(R 3.1505, F -5.5209, G 0.0156)] [G loss: 5.6954]\n",
      "1706 (5, 1) [D loss: (-1.8677)(R 2.4515, F -4.4705, G 0.0151)] [G loss: 4.0976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707 (5, 1) [D loss: (-1.4811)(R 0.7273, F -2.3469, G 0.0138)] [G loss: 2.0813]\n",
      "1708 (5, 1) [D loss: (-1.1266)(R -1.3715, F 0.1286, G 0.0116)] [G loss: -0.0506]\n",
      "1709 (5, 1) [D loss: (-1.4351)(R -3.8526, F 2.2951, G 0.0122)] [G loss: -2.5067]\n",
      "1710 (5, 1) [D loss: (-1.7544)(R -4.2589, F 2.3691, G 0.0135)] [G loss: -2.3508]\n",
      "1711 (5, 1) [D loss: (-2.0150)(R -3.7123, F 1.5572, G 0.0140)] [G loss: -1.6416]\n",
      "1712 (5, 1) [D loss: (-2.2372)(R -2.1942, F -0.1761, G 0.0133)] [G loss: 0.6801]\n",
      "1713 (5, 1) [D loss: (-2.2464)(R 0.1442, F -2.5425, G 0.0152)] [G loss: 2.3431]\n",
      "1714 (5, 1) [D loss: (-1.8136)(R 1.2970, F -3.2859, G 0.0175)] [G loss: 3.1798]\n",
      "1715 (5, 1) [D loss: (-1.2426)(R 3.2493, F -4.6243, G 0.0132)] [G loss: 4.4467]\n",
      "1716 (5, 1) [D loss: (-2.0077)(R 2.9285, F -5.0937, G 0.0157)] [G loss: 4.7069]\n",
      "1717 (5, 1) [D loss: (-1.6056)(R 2.7960, F -4.5554, G 0.0154)] [G loss: 4.6852]\n",
      "1718 (5, 1) [D loss: (-1.6634)(R 2.5880, F -4.4544, G 0.0203)] [G loss: 4.3694]\n",
      "1719 (5, 1) [D loss: (-1.4480)(R 1.6625, F -3.2729, G 0.0162)] [G loss: 2.8994]\n",
      "1720 (5, 1) [D loss: (-1.8311)(R -0.3201, F -1.6332, G 0.0122)] [G loss: 1.6170]\n",
      "1721 (5, 1) [D loss: (-1.4765)(R 0.3692, F -1.9916, G 0.0146)] [G loss: 2.1109]\n",
      "1722 (5, 1) [D loss: (-1.6486)(R -2.0361, F 0.2577, G 0.0130)] [G loss: -0.7374]\n",
      "1723 (5, 1) [D loss: (-1.5834)(R -3.0315, F 1.3428, G 0.0105)] [G loss: -1.6630]\n",
      "1724 (5, 1) [D loss: (-1.6892)(R -3.7853, F 1.9862, G 0.0110)] [G loss: -1.7559]\n",
      "1725 (5, 1) [D loss: (-1.5551)(R -3.4953, F 1.7975, G 0.0143)] [G loss: -1.5870]\n",
      "1726 (5, 1) [D loss: (-2.1830)(R -2.3886, F 0.0929, G 0.0113)] [G loss: -0.6127]\n",
      "1727 (5, 1) [D loss: (-1.8603)(R -3.1132, F 1.1278, G 0.0125)] [G loss: -0.6963]\n",
      "1728 (5, 1) [D loss: (-2.0093)(R -3.1626, F 1.0306, G 0.0123)] [G loss: -2.0489]\n",
      "1729 (5, 1) [D loss: (-1.8582)(R -5.9877, F 4.0026, G 0.0127)] [G loss: -4.7656]\n",
      "1730 (5, 1) [D loss: (-1.8254)(R -8.3772, F 6.3541, G 0.0198)] [G loss: -6.4459]\n",
      "1731 (5, 1) [D loss: (-2.2272)(R -9.4262, F 7.0339, G 0.0165)] [G loss: -7.2068]\n",
      "1732 (5, 1) [D loss: (-2.0294)(R -9.4821, F 7.2813, G 0.0171)] [G loss: -7.6293]\n",
      "1733 (5, 1) [D loss: (-1.6255)(R -9.2418, F 7.4650, G 0.0151)] [G loss: -7.0429]\n",
      "1734 (5, 1) [D loss: (-1.5558)(R -9.3721, F 7.7098, G 0.0106)] [G loss: -7.6682]\n",
      "1735 (5, 1) [D loss: (-1.2990)(R -9.1663, F 7.7582, G 0.0109)] [G loss: -7.4042]\n",
      "1736 (5, 1) [D loss: (-1.9853)(R -8.3459, F 6.2463, G 0.0114)] [G loss: -6.4218]\n",
      "1737 (5, 1) [D loss: (-1.8822)(R -6.1922, F 4.1795, G 0.0131)] [G loss: -3.8762]\n",
      "1738 (5, 1) [D loss: (-1.6772)(R -5.1436, F 3.3128, G 0.0154)] [G loss: -3.1274]\n",
      "1739 (5, 1) [D loss: (-1.2288)(R -4.7889, F 3.4393, G 0.0121)] [G loss: -3.4457]\n",
      "1740 (5, 1) [D loss: (-1.2920)(R -6.0270, F 4.6266, G 0.0108)] [G loss: -4.7483]\n",
      "1741 (5, 1) [D loss: (-1.7998)(R -8.1377, F 6.1974, G 0.0140)] [G loss: -6.6162]\n",
      "1742 (5, 1) [D loss: (-2.4391)(R -9.7490, F 7.1715, G 0.0138)] [G loss: -7.4140]\n",
      "1743 (5, 1) [D loss: (-1.9500)(R -9.5141, F 7.4329, G 0.0131)] [G loss: -7.3397]\n",
      "1744 (5, 1) [D loss: (-1.9840)(R -8.8621, F 6.7218, G 0.0156)] [G loss: -7.3057]\n",
      "1745 (5, 1) [D loss: (-2.0108)(R -8.5714, F 6.4292, G 0.0131)] [G loss: -6.8696]\n",
      "1746 (5, 1) [D loss: (-1.7130)(R -7.3986, F 5.5498, G 0.0136)] [G loss: -5.0519]\n",
      "1747 (5, 1) [D loss: (-1.8412)(R -6.2073, F 4.2211, G 0.0145)] [G loss: -4.0901]\n",
      "1748 (5, 1) [D loss: (-1.9153)(R -6.1793, F 4.1397, G 0.0124)] [G loss: -4.5037]\n",
      "1749 (5, 1) [D loss: (-1.6899)(R -6.0772, F 4.2404, G 0.0147)] [G loss: -4.4150]\n",
      "1750 (5, 1) [D loss: (-1.3531)(R -5.8142, F 4.3318, G 0.0129)] [G loss: -3.9179]\n",
      "1751 (5, 1) [D loss: (-1.5851)(R -6.3530, F 4.6392, G 0.0129)] [G loss: -5.0152]\n",
      "1752 (5, 1) [D loss: (-1.3167)(R -5.4672, F 4.0213, G 0.0129)] [G loss: -3.5994]\n",
      "1753 (5, 1) [D loss: (-2.0795)(R -4.9105, F 2.6971, G 0.0134)] [G loss: -3.0264]\n",
      "1754 (5, 1) [D loss: (-2.0827)(R -3.2517, F 1.0480, G 0.0121)] [G loss: -1.0150]\n",
      "1755 (5, 1) [D loss: (-1.9108)(R -0.8380, F -1.2146, G 0.0142)] [G loss: 2.3736]\n",
      "1756 (5, 1) [D loss: (-1.9118)(R 1.1358, F -3.2082, G 0.0161)] [G loss: 3.1825]\n",
      "1757 (5, 1) [D loss: (-2.0260)(R 1.4653, F -3.6388, G 0.0148)] [G loss: 3.6129]\n",
      "1758 (5, 1) [D loss: (-1.6759)(R 1.4415, F -3.2500, G 0.0133)] [G loss: 3.6167]\n",
      "1759 (5, 1) [D loss: (-1.7682)(R 1.8104, F -3.6997, G 0.0121)] [G loss: 3.4604]\n",
      "1760 (5, 1) [D loss: (-2.0501)(R 0.5396, F -2.7161, G 0.0126)] [G loss: 2.4618]\n",
      "1761 (5, 1) [D loss: (-2.0493)(R -0.0817, F -2.0854, G 0.0118)] [G loss: 1.6356]\n",
      "1762 (5, 1) [D loss: (-2.3467)(R -0.4061, F -2.0784, G 0.0138)] [G loss: 2.5768]\n",
      "1763 (5, 1) [D loss: (-1.9626)(R 0.9056, F -2.9944, G 0.0126)] [G loss: 3.3821]\n",
      "1764 (5, 1) [D loss: (-2.0431)(R 3.0281, F -5.1913, G 0.0120)] [G loss: 5.1696]\n",
      "1765 (5, 1) [D loss: (-1.5607)(R 4.3668, F -6.0606, G 0.0133)] [G loss: 6.1917]\n",
      "1766 (5, 1) [D loss: (-2.1970)(R 4.9639, F -7.3529, G 0.0192)] [G loss: 7.5705]\n",
      "1767 (5, 1) [D loss: (-1.9436)(R 6.4911, F -8.5991, G 0.0164)] [G loss: 8.5730]\n",
      "1768 (5, 1) [D loss: (-1.9783)(R 6.1845, F -8.3168, G 0.0154)] [G loss: 7.9119]\n",
      "1769 (5, 1) [D loss: (-1.6986)(R 5.4184, F -7.2585, G 0.0141)] [G loss: 7.2483]\n",
      "1770 (5, 1) [D loss: (-1.7124)(R 6.2961, F -8.1109, G 0.0102)] [G loss: 8.6194]\n",
      "1771 (5, 1) [D loss: (-1.0341)(R 7.6476, F -8.8255, G 0.0144)] [G loss: 8.8450]\n",
      "1772 (5, 1) [D loss: (-1.6552)(R 7.3244, F -9.1091, G 0.0130)] [G loss: 8.9313]\n",
      "1773 (5, 1) [D loss: (-1.5774)(R 6.9191, F -8.6248, G 0.0128)] [G loss: 8.2848]\n",
      "1774 (5, 1) [D loss: (-2.1273)(R 4.6993, F -6.9368, G 0.0110)] [G loss: 6.4515]\n",
      "1775 (5, 1) [D loss: (-1.5134)(R 4.7277, F -6.3894, G 0.0148)] [G loss: 6.0580]\n",
      "1776 (5, 1) [D loss: (-1.6076)(R 3.8834, F -5.6081, G 0.0117)] [G loss: 5.2871]\n",
      "1777 (5, 1) [D loss: (-2.3211)(R 3.1642, F -5.5735, G 0.0088)] [G loss: 5.3882]\n",
      "1778 (5, 1) [D loss: (-1.5001)(R 4.6400, F -6.2555, G 0.0115)] [G loss: 5.7598]\n",
      "1779 (5, 1) [D loss: (-1.9055)(R 4.6447, F -6.6817, G 0.0131)] [G loss: 7.2272]\n",
      "1780 (5, 1) [D loss: (-2.1692)(R 6.2058, F -8.5104, G 0.0135)] [G loss: 8.0114]\n",
      "1781 (5, 1) [D loss: (-2.3650)(R 5.6559, F -8.1882, G 0.0167)] [G loss: 7.9649]\n",
      "1782 (5, 1) [D loss: (-1.8030)(R 6.0984, F -8.0413, G 0.0140)] [G loss: 7.9655]\n",
      "1783 (5, 1) [D loss: (-1.7341)(R 5.1433, F -6.9970, G 0.0120)] [G loss: 6.4552]\n",
      "1784 (5, 1) [D loss: (-2.1008)(R 1.5035, F -3.7035, G 0.0099)] [G loss: 2.9204]\n",
      "1785 (5, 1) [D loss: (-2.2189)(R -1.4167, F -0.9160, G 0.0114)] [G loss: -0.0836]\n",
      "1786 (5, 1) [D loss: (-1.9192)(R -3.8482, F 1.7947, G 0.0134)] [G loss: -1.6665]\n",
      "1787 (5, 1) [D loss: (-2.1683)(R -6.0032, F 3.7077, G 0.0127)] [G loss: -3.5855]\n",
      "1788 (5, 1) [D loss: (-1.5390)(R -7.7311, F 6.0465, G 0.0146)] [G loss: -6.1488]\n",
      "1789 (5, 1) [D loss: (-1.6750)(R -7.8721, F 6.0850, G 0.0112)] [G loss: -5.6328]\n",
      "1790 (5, 1) [D loss: (-2.0094)(R -7.5124, F 5.3806, G 0.0122)] [G loss: -5.1784]\n",
      "1791 (5, 1) [D loss: (-2.3242)(R -7.5648, F 5.0875, G 0.0153)] [G loss: -4.7872]\n",
      "1792 (5, 1) [D loss: (-1.7369)(R -7.1410, F 5.2842, G 0.0120)] [G loss: -5.3694]\n",
      "1793 (5, 1) [D loss: (-1.7719)(R -8.4332, F 6.5019, G 0.0159)] [G loss: -6.6062]\n",
      "1794 (5, 1) [D loss: (-2.2244)(R -10.7392, F 8.3620, G 0.0153)] [G loss: -8.6132]\n",
      "1795 (5, 1) [D loss: (-1.8261)(R -12.8343, F 10.8174, G 0.0191)] [G loss: -11.7287]\n",
      "1796 (5, 1) [D loss: (-1.2706)(R -14.7908, F 13.3799, G 0.0140)] [G loss: -13.8593]\n",
      "1797 (5, 1) [D loss: (-1.1864)(R -15.1577, F 13.8581, G 0.0113)] [G loss: -13.8634]\n",
      "1798 (5, 1) [D loss: (-1.6789)(R -16.1451, F 14.3570, G 0.0109)] [G loss: -14.2190]\n",
      "1799 (5, 1) [D loss: (-1.4849)(R -15.0385, F 13.4483, G 0.0105)] [G loss: -12.8329]\n",
      "1800 (5, 1) [D loss: (-1.5517)(R -13.5003, F 11.8541, G 0.0094)] [G loss: -11.6077]\n",
      "1801 (5, 1) [D loss: (-1.2088)(R -11.5621, F 10.2776, G 0.0076)] [G loss: -9.8159]\n",
      "1802 (5, 1) [D loss: (-1.2386)(R -11.3667, F 10.0362, G 0.0092)] [G loss: -9.5434]\n",
      "1803 (5, 1) [D loss: (-1.6588)(R -10.2460, F 8.4911, G 0.0096)] [G loss: -8.5678]\n",
      "1804 (5, 1) [D loss: (-1.6506)(R -10.0326, F 8.2581, G 0.0124)] [G loss: -8.1747]\n",
      "1805 (5, 1) [D loss: (-1.6500)(R -9.4657, F 7.6770, G 0.0139)] [G loss: -7.5325]\n",
      "1806 (5, 1) [D loss: (-1.7314)(R -8.9588, F 7.1164, G 0.0111)] [G loss: -6.8930]\n",
      "1807 (5, 1) [D loss: (-1.5216)(R -7.5936, F 5.9488, G 0.0123)] [G loss: -5.9031]\n",
      "1808 (5, 1) [D loss: (-1.9601)(R -6.1663, F 4.0897, G 0.0116)] [G loss: -4.1312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809 (5, 1) [D loss: (-1.4634)(R -4.6558, F 3.1004, G 0.0092)] [G loss: -3.1032]\n",
      "1810 (5, 1) [D loss: (-2.3696)(R -5.2827, F 2.7845, G 0.0129)] [G loss: -3.0689]\n",
      "1811 (5, 1) [D loss: (-1.5219)(R -3.6949, F 2.0454, G 0.0128)] [G loss: -1.5825]\n",
      "1812 (5, 1) [D loss: (-2.2178)(R -2.1267, F -0.2176, G 0.0127)] [G loss: 0.2493]\n",
      "1813 (5, 1) [D loss: (-1.9745)(R -1.7605, F -0.3481, G 0.0134)] [G loss: 0.7631]\n",
      "1814 (5, 1) [D loss: (-1.4276)(R -1.1739, F -0.3922, G 0.0139)] [G loss: 1.1393]\n",
      "1815 (5, 1) [D loss: (-1.8163)(R 0.1692, F -2.1272, G 0.0142)] [G loss: 2.8076]\n",
      "1816 (5, 1) [D loss: (-2.1472)(R 3.1855, F -5.4645, G 0.0132)] [G loss: 5.4331]\n",
      "1817 (5, 1) [D loss: (-2.1766)(R 5.3506, F -7.7126, G 0.0185)] [G loss: 8.0648]\n",
      "1818 (5, 1) [D loss: (-1.9892)(R 7.3280, F -9.4978, G 0.0181)] [G loss: 9.8101]\n",
      "1819 (5, 1) [D loss: (-2.4395)(R 7.3562, F -9.9763, G 0.0181)] [G loss: 10.3070]\n",
      "1820 (5, 1) [D loss: (-2.1336)(R 7.6219, F -9.9207, G 0.0165)] [G loss: 9.3860]\n",
      "1821 (5, 1) [D loss: (-1.6427)(R 6.9427, F -8.7094, G 0.0124)] [G loss: 8.9441]\n",
      "1822 (5, 1) [D loss: (-1.6295)(R 7.2898, F -9.0394, G 0.0120)] [G loss: 9.0121]\n",
      "1823 (5, 1) [D loss: (-2.3900)(R 6.6185, F -9.1614, G 0.0153)] [G loss: 8.3351]\n",
      "1824 (5, 1) [D loss: (-2.6514)(R 8.2231, F -11.0302, G 0.0156)] [G loss: 10.5463]\n",
      "1825 (5, 1) [D loss: (-2.4618)(R 9.2891, F -11.9185, G 0.0168)] [G loss: 11.6187]\n",
      "1826 (5, 1) [D loss: (-1.8658)(R 10.4386, F -12.4462, G 0.0142)] [G loss: 11.4485]\n",
      "1827 (5, 1) [D loss: (-1.8359)(R 10.0123, F -11.9763, G 0.0128)] [G loss: 11.3499]\n",
      "1828 (5, 1) [D loss: (-1.7171)(R 9.3663, F -11.2017, G 0.0118)] [G loss: 10.8868]\n",
      "1829 (5, 1) [D loss: (-1.4381)(R 9.0328, F -10.5977, G 0.0127)] [G loss: 10.3074]\n",
      "1830 (5, 1) [D loss: (-1.6843)(R 7.8496, F -9.6455, G 0.0112)] [G loss: 8.4629]\n",
      "1831 (5, 1) [D loss: (-1.8346)(R 6.8504, F -8.8111, G 0.0126)] [G loss: 8.1859]\n",
      "1832 (5, 1) [D loss: (-1.2580)(R 4.4876, F -5.8562, G 0.0111)] [G loss: 5.2252]\n",
      "1833 (5, 1) [D loss: (-1.6501)(R 2.1139, F -3.8771, G 0.0113)] [G loss: 3.0249]\n",
      "1834 (5, 1) [D loss: (-1.5629)(R -0.9847, F -0.6842, G 0.0106)] [G loss: 0.3459]\n",
      "1835 (5, 1) [D loss: (-1.5590)(R -2.4768, F 0.8056, G 0.0112)] [G loss: -1.5459]\n",
      "1836 (5, 1) [D loss: (-2.0732)(R -6.0874, F 3.8804, G 0.0134)] [G loss: -4.8788]\n",
      "1837 (5, 1) [D loss: (-1.7385)(R -9.3080, F 7.4331, G 0.0136)] [G loss: -7.6108]\n",
      "1838 (5, 1) [D loss: (-2.5765)(R -12.1934, F 9.4551, G 0.0162)] [G loss: -9.8784]\n",
      "1839 (5, 1) [D loss: (-2.6004)(R -14.6584, F 11.8769, G 0.0181)] [G loss: -12.5308]\n",
      "1840 (5, 1) [D loss: (-2.4669)(R -16.0884, F 13.4150, G 0.0207)] [G loss: -13.5921]\n",
      "1841 (5, 1) [D loss: (-2.8483)(R -15.5009, F 12.4892, G 0.0163)] [G loss: -14.0723]\n",
      "1842 (5, 1) [D loss: (-2.0488)(R -16.5768, F 14.3455, G 0.0183)] [G loss: -13.6642]\n",
      "1843 (5, 1) [D loss: (-2.1672)(R -16.9634, F 14.6236, G 0.0173)] [G loss: -14.4851]\n",
      "1844 (5, 1) [D loss: (-2.0179)(R -18.4797, F 16.2568, G 0.0205)] [G loss: -16.4765]\n",
      "1845 (5, 1) [D loss: (-2.4761)(R -19.6981, F 17.0140, G 0.0208)] [G loss: -17.8598]\n",
      "1846 (5, 1) [D loss: (-1.8986)(R -19.7788, F 17.7020, G 0.0178)] [G loss: -17.6497]\n",
      "1847 (5, 1) [D loss: (-2.3654)(R -20.9269, F 18.3787, G 0.0183)] [G loss: -19.2913]\n",
      "1848 (5, 1) [D loss: (-2.2425)(R -19.1689, F 16.7907, G 0.0136)] [G loss: -17.4784]\n",
      "1849 (5, 1) [D loss: (-2.1825)(R -19.4004, F 17.0668, G 0.0151)] [G loss: -18.2478]\n",
      "1850 (5, 1) [D loss: (-1.5779)(R -18.3363, F 16.6471, G 0.0111)] [G loss: -16.8373]\n",
      "1851 (5, 1) [D loss: (-2.1219)(R -16.4591, F 14.2644, G 0.0073)] [G loss: -14.6325]\n",
      "1852 (5, 1) [D loss: (-1.4026)(R -16.1946, F 14.7042, G 0.0088)] [G loss: -14.1797]\n",
      "1853 (5, 1) [D loss: (-1.7538)(R -13.8772, F 12.0385, G 0.0085)] [G loss: -12.2054]\n",
      "1854 (5, 1) [D loss: (-1.5987)(R -12.6527, F 10.9726, G 0.0081)] [G loss: -10.9239]\n",
      "1855 (5, 1) [D loss: (-1.6060)(R -11.7847, F 10.0636, G 0.0115)] [G loss: -9.4858]\n",
      "1856 (5, 1) [D loss: (-1.7305)(R -9.6676, F 7.8380, G 0.0099)] [G loss: -7.6145]\n",
      "1857 (5, 1) [D loss: (-1.6492)(R -9.0545, F 7.2971, G 0.0108)] [G loss: -7.5472]\n",
      "1858 (5, 1) [D loss: (-1.9782)(R -8.1555, F 6.0717, G 0.0106)] [G loss: -6.4419]\n",
      "1859 (5, 1) [D loss: (-1.5888)(R -6.9235, F 5.2281, G 0.0107)] [G loss: -5.6767]\n",
      "1860 (5, 1) [D loss: (-1.2851)(R -5.2036, F 3.8052, G 0.0113)] [G loss: -3.0462]\n",
      "1861 (5, 1) [D loss: (-1.6145)(R -3.1129, F 1.3471, G 0.0151)] [G loss: -0.8826]\n",
      "1862 (5, 1) [D loss: (-1.8353)(R -0.3889, F -1.5826, G 0.0136)] [G loss: 2.4191]\n",
      "1863 (5, 1) [D loss: (-1.7056)(R 1.9521, F -3.7724, G 0.0115)] [G loss: 4.2859]\n",
      "1864 (5, 1) [D loss: (-2.1650)(R 3.5404, F -5.8485, G 0.0143)] [G loss: 5.9710]\n",
      "1865 (5, 1) [D loss: (-2.2852)(R 5.4582, F -7.9125, G 0.0169)] [G loss: 6.8777]\n",
      "1866 (5, 1) [D loss: (-1.6644)(R 6.1311, F -7.9608, G 0.0165)] [G loss: 7.9552]\n",
      "1867 (5, 1) [D loss: (-1.7333)(R 4.9202, F -6.8039, G 0.0150)] [G loss: 6.6093]\n",
      "1868 (5, 1) [D loss: (-2.0465)(R 4.8946, F -7.0747, G 0.0134)] [G loss: 7.1782]\n",
      "1869 (5, 1) [D loss: (-2.0389)(R 4.2977, F -6.4537, G 0.0117)] [G loss: 6.3957]\n",
      "1870 (5, 1) [D loss: (-2.2429)(R 4.3890, F -6.7577, G 0.0126)] [G loss: 7.3222]\n",
      "1871 (5, 1) [D loss: (-2.0052)(R 6.0864, F -8.2354, G 0.0144)] [G loss: 8.4340]\n",
      "1872 (5, 1) [D loss: (-1.5794)(R 8.0105, F -9.7844, G 0.0195)] [G loss: 10.2997]\n",
      "1873 (5, 1) [D loss: (-2.0706)(R 9.3514, F -11.6010, G 0.0179)] [G loss: 11.6488]\n",
      "1874 (5, 1) [D loss: (-1.7574)(R 9.8401, F -11.7470, G 0.0150)] [G loss: 11.3621]\n",
      "1875 (5, 1) [D loss: (-1.9783)(R 8.6102, F -10.6956, G 0.0107)] [G loss: 10.7097]\n",
      "1876 (5, 1) [D loss: (-1.9451)(R 8.2273, F -10.2790, G 0.0107)] [G loss: 9.7165]\n",
      "1877 (5, 1) [D loss: (-1.9237)(R 8.0760, F -10.1228, G 0.0123)] [G loss: 10.4585]\n",
      "1878 (5, 1) [D loss: (-1.7539)(R 7.0720, F -8.9561, G 0.0130)] [G loss: 8.1349]\n",
      "1879 (5, 1) [D loss: (-1.2807)(R 5.1612, F -6.5458, G 0.0104)] [G loss: 6.4372]\n",
      "1880 (5, 1) [D loss: (-2.0941)(R 4.2159, F -6.4273, G 0.0117)] [G loss: 6.1452]\n",
      "1881 (5, 1) [D loss: (-1.5079)(R 4.3384, F -5.9738, G 0.0128)] [G loss: 5.4788]\n",
      "1882 (5, 1) [D loss: (-1.5853)(R 4.3844, F -6.1031, G 0.0133)] [G loss: 5.8075]\n",
      "1883 (5, 1) [D loss: (-1.7275)(R 2.9487, F -4.7916, G 0.0115)] [G loss: 4.6885]\n",
      "1884 (5, 1) [D loss: (-1.8013)(R 1.3885, F -3.2974, G 0.0108)] [G loss: 2.4368]\n",
      "1885 (5, 1) [D loss: (-1.9224)(R 0.0893, F -2.1358, G 0.0124)] [G loss: 1.3178]\n",
      "1886 (5, 1) [D loss: (-1.8434)(R -2.9322, F 0.9432, G 0.0146)] [G loss: -1.3373]\n",
      "1887 (5, 1) [D loss: (-1.7280)(R -5.2877, F 3.4372, G 0.0123)] [G loss: -4.0637]\n",
      "1888 (5, 1) [D loss: (-1.5894)(R -6.6181, F 4.9011, G 0.0128)] [G loss: -5.4902]\n",
      "1889 (5, 1) [D loss: (-1.5962)(R -8.6488, F 6.9200, G 0.0133)] [G loss: -6.4386]\n",
      "1890 (5, 1) [D loss: (-1.7371)(R -7.8790, F 6.0198, G 0.0122)] [G loss: -5.7155]\n",
      "1891 (5, 1) [D loss: (-1.5736)(R -7.3636, F 5.6973, G 0.0093)] [G loss: -5.0649]\n",
      "1892 (5, 1) [D loss: (-1.6886)(R -5.3165, F 3.5247, G 0.0103)] [G loss: -2.9581]\n",
      "1893 (5, 1) [D loss: (-1.7298)(R -4.2509, F 2.3791, G 0.0142)] [G loss: -1.9207]\n",
      "1894 (5, 1) [D loss: (-1.9122)(R -2.7853, F 0.7610, G 0.0112)] [G loss: -0.4290]\n",
      "1895 (5, 1) [D loss: (-2.3213)(R -4.5228, F 2.0888, G 0.0113)] [G loss: -2.9620]\n",
      "1896 (5, 1) [D loss: (-1.9616)(R -7.6725, F 5.5702, G 0.0141)] [G loss: -6.1787]\n",
      "1897 (5, 1) [D loss: (-2.0507)(R -10.6303, F 8.4520, G 0.0128)] [G loss: -8.7759]\n",
      "1898 (5, 1) [D loss: (-1.5919)(R -12.0469, F 10.2987, G 0.0156)] [G loss: -10.4366]\n",
      "1899 (5, 1) [D loss: (-1.4971)(R -11.2368, F 9.6176, G 0.0122)] [G loss: -9.5713]\n",
      "1900 (5, 1) [D loss: (-1.6773)(R -11.4107, F 9.5983, G 0.0135)] [G loss: -9.5598]\n",
      "1901 (5, 1) [D loss: (-1.2374)(R -10.4522, F 9.1096, G 0.0105)] [G loss: -8.6449]\n",
      "1902 (5, 1) [D loss: (-1.7839)(R -7.4712, F 5.6037, G 0.0084)] [G loss: -5.0277]\n",
      "1903 (5, 1) [D loss: (-1.8275)(R -5.7016, F 3.7744, G 0.0100)] [G loss: -4.0923]\n",
      "1904 (5, 1) [D loss: (-1.4354)(R -5.6900, F 4.1439, G 0.0111)] [G loss: -3.3676]\n",
      "1905 (5, 1) [D loss: (-1.5390)(R -5.4025, F 3.7724, G 0.0091)] [G loss: -3.9302]\n",
      "1906 (5, 1) [D loss: (-0.7768)(R -4.9235, F 4.0337, G 0.0113)] [G loss: -3.8883]\n",
      "1907 (5, 1) [D loss: (-1.4362)(R -8.2023, F 6.6472, G 0.0119)] [G loss: -7.1276]\n",
      "1908 (5, 1) [D loss: (-1.4437)(R -9.1551, F 7.5832, G 0.0128)] [G loss: -7.7085]\n",
      "1909 (5, 1) [D loss: (-1.8267)(R -9.9331, F 7.9731, G 0.0133)] [G loss: -8.3797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910 (5, 1) [D loss: (-1.1014)(R -9.3505, F 8.1434, G 0.0106)] [G loss: -7.9507]\n",
      "1911 (5, 1) [D loss: (-1.4077)(R -8.0654, F 6.5626, G 0.0095)] [G loss: -5.9491]\n",
      "1912 (5, 1) [D loss: (-1.9511)(R -6.5486, F 4.5075, G 0.0090)] [G loss: -4.3622]\n",
      "1913 (5, 1) [D loss: (-1.9216)(R -4.3743, F 2.3423, G 0.0110)] [G loss: -2.0498]\n",
      "1914 (5, 1) [D loss: (-1.4622)(R -2.7682, F 1.1902, G 0.0116)] [G loss: -0.4860]\n",
      "1915 (5, 1) [D loss: (-2.0230)(R -2.5174, F 0.3602, G 0.0134)] [G loss: -0.6761]\n",
      "1916 (5, 1) [D loss: (-1.9603)(R -1.9038, F -0.1896, G 0.0133)] [G loss: 0.4648]\n",
      "1917 (5, 1) [D loss: (-1.3521)(R 0.0254, F -1.4829, G 0.0105)] [G loss: 1.4261]\n",
      "1918 (5, 1) [D loss: (-2.1800)(R -2.5525, F 0.2290, G 0.0143)] [G loss: -0.4397]\n",
      "1919 (5, 1) [D loss: (-1.9815)(R -4.3264, F 2.2006, G 0.0144)] [G loss: -2.3646]\n",
      "1920 (5, 1) [D loss: (-1.9699)(R -5.9484, F 3.8163, G 0.0162)] [G loss: -4.3153]\n",
      "1921 (5, 1) [D loss: (-2.0288)(R -6.0663, F 3.9204, G 0.0117)] [G loss: -4.0937]\n",
      "1922 (5, 1) [D loss: (-1.6955)(R -5.5227, F 3.7035, G 0.0124)] [G loss: -3.3616]\n",
      "1923 (5, 1) [D loss: (-1.8539)(R -2.6170, F 0.6293, G 0.0134)] [G loss: -0.0796]\n",
      "1924 (5, 1) [D loss: (-1.5919)(R 0.6422, F -2.3920, G 0.0158)] [G loss: 2.7091]\n",
      "1925 (5, 1) [D loss: (-1.8920)(R 2.3830, F -4.4270, G 0.0152)] [G loss: 5.2829]\n",
      "1926 (5, 1) [D loss: (-2.2980)(R 4.1434, F -6.6099, G 0.0169)] [G loss: 6.7053]\n",
      "1927 (5, 1) [D loss: (-1.4737)(R 6.8321, F -8.4629, G 0.0157)] [G loss: 8.2534]\n",
      "1928 (5, 1) [D loss: (-1.8080)(R 6.3352, F -8.2883, G 0.0145)] [G loss: 7.8291]\n",
      "1929 (5, 1) [D loss: (-1.7460)(R 4.4425, F -6.3472, G 0.0159)] [G loss: 6.7437]\n",
      "1930 (5, 1) [D loss: (-2.2878)(R 3.0710, F -5.4980, G 0.0139)] [G loss: 4.8681]\n",
      "1931 (5, 1) [D loss: (-2.2574)(R 0.9200, F -3.2973, G 0.0120)] [G loss: 3.2964]\n",
      "1932 (5, 1) [D loss: (-1.7899)(R 0.1260, F -2.0468, G 0.0131)] [G loss: 1.6626]\n",
      "1933 (5, 1) [D loss: (-1.8373)(R -0.4400, F -1.5425, G 0.0145)] [G loss: 1.7491]\n",
      "1934 (5, 1) [D loss: (-1.8359)(R 1.8061, F -3.7382, G 0.0096)] [G loss: 4.0021]\n",
      "1935 (5, 1) [D loss: (-1.8333)(R 3.3354, F -5.3034, G 0.0135)] [G loss: 5.2644]\n",
      "1936 (5, 1) [D loss: (-1.8832)(R 5.1109, F -7.1566, G 0.0163)] [G loss: 7.1851]\n",
      "1937 (5, 1) [D loss: (-1.7678)(R 5.7202, F -7.6644, G 0.0176)] [G loss: 7.1705]\n",
      "1938 (5, 1) [D loss: (-1.1532)(R 5.1774, F -6.4475, G 0.0117)] [G loss: 5.8483]\n",
      "1939 (5, 1) [D loss: (-1.6003)(R 2.8841, F -4.5871, G 0.0103)] [G loss: 4.5668]\n",
      "1940 (5, 1) [D loss: (-1.6165)(R 1.1449, F -2.8658, G 0.0104)] [G loss: 2.0286]\n",
      "1941 (5, 1) [D loss: (-2.2321)(R -1.9478, F -0.4138, G 0.0129)] [G loss: -0.3764]\n",
      "1942 (5, 1) [D loss: (-1.8987)(R -3.3198, F 1.2635, G 0.0158)] [G loss: -1.7523]\n",
      "1943 (5, 1) [D loss: (-1.7597)(R -3.0671, F 1.1768, G 0.0131)] [G loss: -0.8888]\n",
      "1944 (5, 1) [D loss: (-1.7230)(R -2.0985, F 0.2376, G 0.0138)] [G loss: -0.0834]\n",
      "1945 (5, 1) [D loss: (-1.6236)(R -1.5533, F -0.2047, G 0.0135)] [G loss: 0.3742]\n",
      "1946 (5, 1) [D loss: (-2.1178)(R -1.2754, F -0.9710, G 0.0129)] [G loss: 0.9473]\n",
      "1947 (5, 1) [D loss: (-1.8940)(R -1.6575, F -0.3630, G 0.0126)] [G loss: 0.2713]\n",
      "1948 (5, 1) [D loss: (-2.3435)(R -2.9548, F 0.4820, G 0.0129)] [G loss: -1.6276]\n",
      "1949 (5, 1) [D loss: (-1.9830)(R -7.6336, F 5.5406, G 0.0110)] [G loss: -6.1467]\n",
      "1950 (5, 1) [D loss: (-1.8127)(R -10.0066, F 8.0249, G 0.0169)] [G loss: -8.5721]\n",
      "1951 (5, 1) [D loss: (-1.5483)(R -13.0053, F 11.3055, G 0.0152)] [G loss: -11.5299]\n",
      "1952 (5, 1) [D loss: (-1.8065)(R -13.8539, F 11.9005, G 0.0147)] [G loss: -11.8601]\n",
      "1953 (5, 1) [D loss: (-1.8579)(R -11.7482, F 9.7742, G 0.0116)] [G loss: -9.6288]\n",
      "1954 (5, 1) [D loss: (-1.6465)(R -10.9536, F 9.1800, G 0.0127)] [G loss: -9.4742]\n",
      "1955 (5, 1) [D loss: (-2.1293)(R -11.2797, F 9.0048, G 0.0146)] [G loss: -9.0048]\n",
      "1956 (5, 1) [D loss: (-1.9946)(R -9.7876, F 7.6699, G 0.0123)] [G loss: -7.8217]\n",
      "1957 (5, 1) [D loss: (-2.0780)(R -9.1959, F 7.0160, G 0.0102)] [G loss: -7.3767]\n",
      "1958 (5, 1) [D loss: (-1.7840)(R -10.5341, F 8.6291, G 0.0121)] [G loss: -9.5187]\n",
      "1959 (5, 1) [D loss: (-2.1603)(R -13.0336, F 10.7479, G 0.0125)] [G loss: -11.5720]\n",
      "1960 (5, 1) [D loss: (-2.0613)(R -14.7126, F 12.4944, G 0.0157)] [G loss: -12.9699]\n",
      "1961 (5, 1) [D loss: (-1.8430)(R -15.0335, F 13.0497, G 0.0141)] [G loss: -13.2507]\n",
      "1962 (5, 1) [D loss: (-1.3857)(R -12.5317, F 11.0726, G 0.0073)] [G loss: -10.5850]\n",
      "1963 (5, 1) [D loss: (-1.2051)(R -9.0232, F 7.7245, G 0.0094)] [G loss: -6.7490]\n",
      "1964 (5, 1) [D loss: (-1.7935)(R -4.8316, F 2.9624, G 0.0076)] [G loss: -1.9284]\n",
      "1965 (5, 1) [D loss: (-1.7727)(R -1.2062, F -0.6541, G 0.0088)] [G loss: 1.0179]\n",
      "1966 (5, 1) [D loss: (-2.0094)(R 1.9895, F -4.1504, G 0.0151)] [G loss: 4.6895]\n",
      "1967 (5, 1) [D loss: (-2.1060)(R 1.9509, F -4.2174, G 0.0160)] [G loss: 4.5935]\n",
      "1968 (5, 1) [D loss: (-1.5700)(R 1.0811, F -2.7903, G 0.0139)] [G loss: 2.1277]\n",
      "1969 (5, 1) [D loss: (-1.2904)(R -2.1097, F 0.6806, G 0.0139)] [G loss: -1.4007]\n",
      "1970 (5, 1) [D loss: (-1.3763)(R -5.3976, F 3.8888, G 0.0132)] [G loss: -3.6773]\n",
      "1971 (5, 1) [D loss: (-2.1119)(R -6.3441, F 4.1247, G 0.0108)] [G loss: -3.8699]\n",
      "1972 (5, 1) [D loss: (-2.0487)(R -4.4607, F 2.2818, G 0.0130)] [G loss: -2.3685]\n",
      "1973 (5, 1) [D loss: (-1.7946)(R -1.4113, F -0.5080, G 0.0125)] [G loss: 0.9736]\n",
      "1974 (5, 1) [D loss: (-2.2512)(R 1.6322, F -4.0255, G 0.0142)] [G loss: 4.3663]\n",
      "1975 (5, 1) [D loss: (-1.5097)(R 5.5686, F -7.1926, G 0.0114)] [G loss: 7.1553]\n",
      "1976 (5, 1) [D loss: (-2.2043)(R 6.0638, F -8.4289, G 0.0161)] [G loss: 8.5872]\n",
      "1977 (5, 1) [D loss: (-1.6635)(R 7.3051, F -9.1410, G 0.0172)] [G loss: 9.2609]\n",
      "1978 (5, 1) [D loss: (-2.1190)(R 6.1409, F -8.3881, G 0.0128)] [G loss: 8.2992]\n",
      "1979 (5, 1) [D loss: (-1.6309)(R 5.4265, F -7.1892, G 0.0132)] [G loss: 7.1689]\n",
      "1980 (5, 1) [D loss: (-1.6633)(R 3.7975, F -5.6000, G 0.0139)] [G loss: 5.4113]\n",
      "1981 (5, 1) [D loss: (-1.9301)(R 0.7107, F -2.7392, G 0.0098)] [G loss: 1.8876]\n",
      "1982 (5, 1) [D loss: (-1.6344)(R -0.9298, F -0.8006, G 0.0096)] [G loss: 0.8004]\n",
      "1983 (5, 1) [D loss: (-1.7829)(R -1.1838, F -0.7185, G 0.0119)] [G loss: 0.8534]\n",
      "1984 (5, 1) [D loss: (-2.2522)(R -0.4807, F -1.8979, G 0.0126)] [G loss: 1.5745]\n",
      "1985 (5, 1) [D loss: (-2.0677)(R 0.9966, F -3.2286, G 0.0164)] [G loss: 3.5054]\n",
      "1986 (5, 1) [D loss: (-1.7021)(R 2.8927, F -4.7384, G 0.0144)] [G loss: 4.7150]\n",
      "1987 (5, 1) [D loss: (-1.6840)(R 4.2771, F -6.0992, G 0.0138)] [G loss: 6.0612]\n",
      "1988 (5, 1) [D loss: (-1.0814)(R 4.5112, F -5.7123, G 0.0120)] [G loss: 5.4879]\n",
      "1989 (5, 1) [D loss: (-1.6484)(R 2.4248, F -4.1809, G 0.0108)] [G loss: 4.2498]\n",
      "1990 (5, 1) [D loss: (-1.5767)(R 1.2956, F -2.9912, G 0.0119)] [G loss: 2.2183]\n",
      "1991 (5, 1) [D loss: (-1.8673)(R -1.1154, F -0.9116, G 0.0160)] [G loss: 0.8246]\n",
      "1992 (5, 1) [D loss: (-2.0152)(R -3.0671, F 0.9268, G 0.0125)] [G loss: -1.2995]\n",
      "1993 (5, 1) [D loss: (-2.0225)(R -4.9557, F 2.7927, G 0.0141)] [G loss: -3.1543]\n",
      "1994 (5, 1) [D loss: (-1.5518)(R -6.7254, F 5.0346, G 0.0139)] [G loss: -5.0423]\n",
      "1995 (5, 1) [D loss: (-1.2354)(R -5.2777, F 3.9433, G 0.0099)] [G loss: -3.7297]\n",
      "1996 (5, 1) [D loss: (-1.8162)(R -5.7896, F 3.8724, G 0.0101)] [G loss: -3.9952]\n",
      "1997 (5, 1) [D loss: (-1.7114)(R -5.1217, F 3.2868, G 0.0124)] [G loss: -3.1245]\n",
      "1998 (5, 1) [D loss: (-2.1777)(R -5.1992, F 2.8871, G 0.0134)] [G loss: -3.0350]\n",
      "1999 (5, 1) [D loss: (-2.0773)(R -6.8224, F 4.6043, G 0.0141)] [G loss: -5.1696]\n",
      "2000 (5, 1) [D loss: (-1.6702)(R -8.2405, F 6.4562, G 0.0114)] [G loss: -7.3310]\n",
      "2001 (5, 1) [D loss: (-1.9366)(R -8.9166, F 6.8744, G 0.0106)] [G loss: -7.2553]\n",
      "2002 (5, 1) [D loss: (-1.8025)(R -10.7064, F 8.7438, G 0.0160)] [G loss: -8.7995]\n",
      "2003 (5, 1) [D loss: (-2.2138)(R -11.6085, F 9.2440, G 0.0151)] [G loss: -9.7496]\n",
      "2004 (5, 1) [D loss: (-1.8612)(R -11.0336, F 8.9950, G 0.0177)] [G loss: -8.8169]\n",
      "2005 (5, 1) [D loss: (-1.1792)(R -10.0072, F 8.7032, G 0.0125)] [G loss: -8.1327]\n",
      "2006 (5, 1) [D loss: (-1.6509)(R -8.5762, F 6.8453, G 0.0080)] [G loss: -6.7110]\n",
      "2007 (5, 1) [D loss: (-1.7323)(R -7.5217, F 5.6919, G 0.0097)] [G loss: -5.4473]\n",
      "2008 (5, 1) [D loss: (-1.8215)(R -6.4760, F 4.5346, G 0.0120)] [G loss: -4.6640]\n",
      "2009 (5, 1) [D loss: (-1.8499)(R -7.5514, F 5.5950, G 0.0107)] [G loss: -6.2359]\n",
      "2010 (5, 1) [D loss: (-1.6793)(R -8.2426, F 6.4602, G 0.0103)] [G loss: -6.6638]\n",
      "2011 (5, 1) [D loss: (-1.8707)(R -11.1823, F 9.1742, G 0.0137)] [G loss: -9.1436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 (5, 1) [D loss: (-1.6217)(R -10.5995, F 8.8374, G 0.0140)] [G loss: -8.8319]\n",
      "2013 (5, 1) [D loss: (-1.7652)(R -9.8142, F 7.9440, G 0.0105)] [G loss: -8.0476]\n",
      "2014 (5, 1) [D loss: (-1.5162)(R -8.9362, F 7.3210, G 0.0099)] [G loss: -6.6440]\n",
      "2015 (5, 1) [D loss: (-1.6394)(R -5.9953, F 4.2394, G 0.0117)] [G loss: -3.4488]\n",
      "2016 (5, 1) [D loss: (-1.8808)(R -3.0520, F 1.0531, G 0.0118)] [G loss: -0.8273]\n",
      "2017 (5, 1) [D loss: (-1.9540)(R -1.7984, F -0.2598, G 0.0104)] [G loss: 0.5009]\n",
      "2018 (5, 1) [D loss: (-1.8033)(R -1.2142, F -0.7326, G 0.0144)] [G loss: 0.7885]\n",
      "2019 (5, 1) [D loss: (-1.8731)(R -2.7363, F 0.7243, G 0.0139)] [G loss: -0.9559]\n",
      "2020 (5, 1) [D loss: (-1.6950)(R -4.4017, F 2.5771, G 0.0130)] [G loss: -2.8668]\n",
      "2021 (5, 1) [D loss: (-1.7425)(R -6.1002, F 4.2062, G 0.0152)] [G loss: -4.5803]\n",
      "2022 (5, 1) [D loss: (-1.8814)(R -6.3704, F 4.3714, G 0.0118)] [G loss: -4.7510]\n",
      "2023 (5, 1) [D loss: (-1.8201)(R -6.1176, F 4.1843, G 0.0113)] [G loss: -3.9977]\n",
      "2024 (5, 1) [D loss: (-2.0509)(R -5.5806, F 3.4020, G 0.0128)] [G loss: -3.3525]\n",
      "2025 (5, 1) [D loss: (-1.6538)(R -3.0138, F 1.2501, G 0.0110)] [G loss: -0.8349]\n",
      "2026 (5, 1) [D loss: (-1.6037)(R -0.9758, F -0.7460, G 0.0118)] [G loss: 0.8963]\n",
      "2027 (5, 1) [D loss: (-2.2004)(R 1.0188, F -3.3614, G 0.0142)] [G loss: 3.8051]\n",
      "2028 (5, 1) [D loss: (-1.9297)(R 4.0388, F -6.1219, G 0.0153)] [G loss: 6.4880]\n",
      "2029 (5, 1) [D loss: (-2.1920)(R 4.8063, F -7.1705, G 0.0172)] [G loss: 7.0189]\n",
      "2030 (5, 1) [D loss: (-1.6118)(R 3.9751, F -5.7532, G 0.0166)] [G loss: 5.6501]\n",
      "2031 (5, 1) [D loss: (-1.2754)(R 3.2624, F -4.6767, G 0.0139)] [G loss: 4.3618]\n",
      "2032 (5, 1) [D loss: (-1.8467)(R 1.4447, F -3.3952, G 0.0104)] [G loss: 2.6973]\n",
      "2033 (5, 1) [D loss: (-1.9119)(R -1.5814, F -0.4345, G 0.0104)] [G loss: -0.3384]\n",
      "2034 (5, 1) [D loss: (-1.6887)(R -2.7018, F 0.8870, G 0.0126)] [G loss: -0.8868]\n",
      "2035 (5, 1) [D loss: (-1.7884)(R -2.9206, F 0.9926, G 0.0140)] [G loss: -1.0861]\n",
      "2036 (5, 1) [D loss: (-1.7891)(R -2.7558, F 0.8504, G 0.0116)] [G loss: -0.0572]\n",
      "2037 (5, 1) [D loss: (-1.8036)(R -0.3887, F -1.5500, G 0.0135)] [G loss: 1.7881]\n",
      "2038 (5, 1) [D loss: (-1.4779)(R 0.7573, F -2.3373, G 0.0102)] [G loss: 2.3294]\n",
      "2039 (5, 1) [D loss: (-1.2130)(R 1.5205, F -2.8595, G 0.0126)] [G loss: 3.0762]\n",
      "2040 (5, 1) [D loss: (-1.7959)(R 2.0726, F -3.9962, G 0.0128)] [G loss: 4.1224]\n",
      "2041 (5, 1) [D loss: (-1.5217)(R 2.6329, F -4.3035, G 0.0149)] [G loss: 4.4215]\n",
      "2042 (5, 1) [D loss: (-1.7688)(R 1.6344, F -3.5347, G 0.0132)] [G loss: 3.0039]\n",
      "2043 (5, 1) [D loss: (-1.6372)(R 0.4709, F -2.2511, G 0.0143)] [G loss: 2.1976]\n",
      "2044 (5, 1) [D loss: (-1.7875)(R -0.9748, F -0.9472, G 0.0134)] [G loss: 0.4704]\n",
      "2045 (5, 1) [D loss: (-1.7273)(R -2.8134, F 0.9768, G 0.0109)] [G loss: -1.3225]\n",
      "2046 (5, 1) [D loss: (-1.2764)(R -4.7052, F 3.2960, G 0.0133)] [G loss: -3.7031]\n",
      "2047 (5, 1) [D loss: (-1.8676)(R -6.5556, F 4.5736, G 0.0114)] [G loss: -5.0066]\n",
      "2048 (5, 1) [D loss: (-1.6469)(R -6.7393, F 5.0028, G 0.0090)] [G loss: -4.7369]\n",
      "2049 (5, 1) [D loss: (-1.8179)(R -5.6583, F 3.7228, G 0.0118)] [G loss: -3.5071]\n",
      "2050 (5, 1) [D loss: (-1.6500)(R -4.0068, F 2.2097, G 0.0147)] [G loss: -2.1004]\n",
      "2051 (5, 1) [D loss: (-1.9696)(R -3.5983, F 1.5056, G 0.0123)] [G loss: -1.7622]\n",
      "2052 (5, 1) [D loss: (-1.3641)(R -3.4386, F 1.9634, G 0.0111)] [G loss: -2.0135]\n",
      "2053 (5, 1) [D loss: (-1.8186)(R -4.8178, F 2.8820, G 0.0117)] [G loss: -2.6824]\n",
      "2054 (5, 1) [D loss: (-1.7571)(R -5.2642, F 3.3894, G 0.0118)] [G loss: -3.9613]\n",
      "2055 (5, 1) [D loss: (-1.7768)(R -6.5663, F 4.6530, G 0.0136)] [G loss: -5.2118]\n",
      "2056 (5, 1) [D loss: (-1.5288)(R -8.4501, F 6.7710, G 0.0150)] [G loss: -6.8972]\n",
      "2057 (5, 1) [D loss: (-1.4184)(R -8.0790, F 6.5573, G 0.0103)] [G loss: -6.2562]\n",
      "2058 (5, 1) [D loss: (-1.3535)(R -7.8371, F 6.3780, G 0.0106)] [G loss: -5.7905]\n",
      "2059 (5, 1) [D loss: (-1.6204)(R -6.0479, F 4.3173, G 0.0110)] [G loss: -3.6375]\n",
      "2060 (5, 1) [D loss: (-1.5579)(R -4.2191, F 2.5483, G 0.0113)] [G loss: -2.3803]\n",
      "2061 (5, 1) [D loss: (-1.8871)(R -4.7907, F 2.7858, G 0.0118)] [G loss: -3.2772]\n",
      "2062 (5, 1) [D loss: (-2.1332)(R -6.0411, F 3.7805, G 0.0127)] [G loss: -4.3235]\n",
      "2063 (5, 1) [D loss: (-1.6848)(R -7.0533, F 5.2449, G 0.0124)] [G loss: -5.3094]\n",
      "2064 (5, 1) [D loss: (-1.8545)(R -6.6644, F 4.7027, G 0.0107)] [G loss: -5.3366]\n",
      "2065 (5, 1) [D loss: (-1.4954)(R -7.1044, F 5.4829, G 0.0126)] [G loss: -5.5997]\n",
      "2066 (5, 1) [D loss: (-1.7440)(R -7.3070, F 5.4590, G 0.0104)] [G loss: -4.9260]\n",
      "2067 (5, 1) [D loss: (-1.7285)(R -5.6375, F 3.8030, G 0.0106)] [G loss: -3.4106]\n",
      "2068 (5, 1) [D loss: (-1.7323)(R -4.5936, F 2.7318, G 0.0130)] [G loss: -2.6804]\n",
      "2069 (5, 1) [D loss: (-2.0287)(R -4.2477, F 2.0717, G 0.0147)] [G loss: -2.4753]\n",
      "2070 (5, 1) [D loss: (-1.1895)(R -2.3980, F 1.0772, G 0.0131)] [G loss: -0.0951]\n",
      "2071 (5, 1) [D loss: (-1.8311)(R -1.4766, F -0.5009, G 0.0146)] [G loss: 0.9895]\n",
      "2072 (5, 1) [D loss: (-1.5603)(R -0.3831, F -1.3289, G 0.0152)] [G loss: 1.1651]\n",
      "2073 (5, 1) [D loss: (-1.5038)(R -0.9547, F -0.6578, G 0.0109)] [G loss: 0.7959]\n",
      "2074 (5, 1) [D loss: (-1.8341)(R -3.5897, F 1.6415, G 0.0114)] [G loss: -1.6796]\n",
      "2075 (5, 1) [D loss: (-1.6275)(R -4.5948, F 2.8294, G 0.0138)] [G loss: -3.3696]\n",
      "2076 (5, 1) [D loss: (-2.0417)(R -5.5380, F 3.3764, G 0.0120)] [G loss: -3.4381]\n",
      "2077 (5, 1) [D loss: (-1.5596)(R -4.8141, F 3.1163, G 0.0138)] [G loss: -2.9668]\n",
      "2078 (5, 1) [D loss: (-1.8726)(R -3.0526, F 1.0549, G 0.0125)] [G loss: -0.5377]\n",
      "2079 (5, 1) [D loss: (-1.7587)(R -0.2990, F -1.5770, G 0.0117)] [G loss: 2.2930]\n",
      "2080 (5, 1) [D loss: (-1.7837)(R 1.9971, F -3.9537, G 0.0173)] [G loss: 4.8059]\n",
      "2081 (5, 1) [D loss: (-1.5330)(R 3.6477, F -5.3460, G 0.0165)] [G loss: 5.0207]\n",
      "2082 (5, 1) [D loss: (-1.6009)(R 3.3557, F -5.1299, G 0.0173)] [G loss: 5.1993]\n",
      "2083 (5, 1) [D loss: (-2.0224)(R 2.1794, F -4.3040, G 0.0102)] [G loss: 3.9937]\n",
      "2084 (5, 1) [D loss: (-1.3524)(R 1.5169, F -2.9739, G 0.0105)] [G loss: 2.7672]\n",
      "2085 (5, 1) [D loss: (-1.4453)(R 0.0618, F -1.6253, G 0.0118)] [G loss: 1.3042]\n",
      "2086 (5, 1) [D loss: (-1.7568)(R -2.2791, F 0.4058, G 0.0116)] [G loss: -0.7462]\n",
      "2087 (5, 1) [D loss: (-1.3793)(R -3.7357, F 2.2252, G 0.0131)] [G loss: -2.5103]\n",
      "2088 (5, 1) [D loss: (-1.5450)(R -4.8239, F 3.1614, G 0.0117)] [G loss: -3.1122]\n",
      "2089 (5, 1) [D loss: (-1.6160)(R -4.3096, F 2.5860, G 0.0108)] [G loss: -2.1846]\n",
      "2090 (5, 1) [D loss: (-2.0670)(R -3.2809, F 1.1154, G 0.0098)] [G loss: -1.0529]\n",
      "2091 (5, 1) [D loss: (-1.4476)(R -1.1681, F -0.4307, G 0.0151)] [G loss: 0.4655]\n",
      "2092 (5, 1) [D loss: (-1.5137)(R -0.3654, F -1.2678, G 0.0119)] [G loss: 1.2737]\n",
      "2093 (5, 1) [D loss: (-1.6042)(R 0.7521, F -2.4794, G 0.0123)] [G loss: 2.9786]\n",
      "2094 (5, 1) [D loss: (-1.8206)(R 0.8222, F -2.7928, G 0.0150)] [G loss: 2.8305]\n",
      "2095 (5, 1) [D loss: (-1.2179)(R 0.2357, F -1.5877, G 0.0134)] [G loss: 1.5339]\n",
      "2096 (5, 1) [D loss: (-1.5688)(R -1.6825, F -0.0119, G 0.0126)] [G loss: -0.2448]\n",
      "2097 (5, 1) [D loss: (-1.6192)(R -3.6823, F 1.9541, G 0.0109)] [G loss: -2.7162]\n",
      "2098 (5, 1) [D loss: (-1.9660)(R -6.8992, F 4.8075, G 0.0126)] [G loss: -5.4990]\n",
      "2099 (5, 1) [D loss: (-1.6028)(R -9.6105, F 7.8020, G 0.0206)] [G loss: -8.1081]\n",
      "2100 (5, 1) [D loss: (-1.7501)(R -10.1491, F 8.2726, G 0.0126)] [G loss: -8.2176]\n",
      "2101 (5, 1) [D loss: (-1.6271)(R -8.7071, F 6.9624, G 0.0118)] [G loss: -6.2945]\n",
      "2102 (5, 1) [D loss: (-1.5226)(R -6.6881, F 5.0831, G 0.0082)] [G loss: -4.2971]\n",
      "2103 (5, 1) [D loss: (-1.7494)(R -4.7226, F 2.8596, G 0.0114)] [G loss: -2.9804]\n",
      "2104 (5, 1) [D loss: (-1.7787)(R -4.5797, F 2.6598, G 0.0141)] [G loss: -2.2782]\n",
      "2105 (5, 1) [D loss: (-1.7037)(R -3.4458, F 1.6099, G 0.0132)] [G loss: -1.5513]\n",
      "2106 (5, 1) [D loss: (-1.4072)(R -2.7836, F 1.2514, G 0.0125)] [G loss: -1.9165]\n",
      "2107 (5, 1) [D loss: (-1.5065)(R -4.5008, F 2.8700, G 0.0124)] [G loss: -3.4040]\n",
      "2108 (5, 1) [D loss: (-1.5826)(R -6.2568, F 4.5450, G 0.0129)] [G loss: -5.3456]\n",
      "2109 (5, 1) [D loss: (-1.3699)(R -7.1854, F 5.7027, G 0.0113)] [G loss: -5.8021]\n",
      "2110 (5, 1) [D loss: (-1.6577)(R -7.5021, F 5.7101, G 0.0134)] [G loss: -5.2013]\n",
      "2111 (5, 1) [D loss: (-1.8426)(R -6.9826, F 5.0202, G 0.0120)] [G loss: -5.4639]\n",
      "2112 (5, 1) [D loss: (-1.6510)(R -7.1573, F 5.3923, G 0.0114)] [G loss: -5.5890]\n",
      "2113 (5, 1) [D loss: (-1.5685)(R -6.5440, F 4.8739, G 0.0102)] [G loss: -4.6971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114 (5, 1) [D loss: (-1.6869)(R -5.1486, F 3.3610, G 0.0101)] [G loss: -2.8282]\n",
      "2115 (5, 1) [D loss: (-1.5366)(R -3.2818, F 1.6392, G 0.0106)] [G loss: -1.2159]\n",
      "2116 (5, 1) [D loss: (-1.5645)(R -1.8980, F 0.2170, G 0.0116)] [G loss: -0.0822]\n",
      "2117 (5, 1) [D loss: (-1.7405)(R -1.0452, F -0.8088, G 0.0114)] [G loss: 0.7058]\n",
      "2118 (5, 1) [D loss: (-1.7114)(R -1.5783, F -0.2753, G 0.0142)] [G loss: 0.0760]\n",
      "2119 (5, 1) [D loss: (-1.8043)(R -1.7055, F -0.2177, G 0.0119)] [G loss: 0.0607]\n",
      "2120 (5, 1) [D loss: (-1.6018)(R -2.2667, F 0.5176, G 0.0147)] [G loss: -0.4003]\n",
      "2121 (5, 1) [D loss: (-1.4158)(R -3.7364, F 2.2091, G 0.0111)] [G loss: -2.5865]\n",
      "2122 (5, 1) [D loss: (-1.6639)(R -4.5210, F 2.7276, G 0.0129)] [G loss: -2.4570]\n",
      "2123 (5, 1) [D loss: (-1.4228)(R -4.1157, F 2.5714, G 0.0122)] [G loss: -2.2153]\n",
      "2124 (5, 1) [D loss: (-1.8346)(R -2.7575, F 0.8078, G 0.0115)] [G loss: -0.3202]\n",
      "2125 (5, 1) [D loss: (-1.8086)(R -1.5915, F -0.3421, G 0.0125)] [G loss: 0.8581]\n",
      "2126 (5, 1) [D loss: (-1.4050)(R 0.3557, F -1.8946, G 0.0134)] [G loss: 2.4169]\n",
      "2127 (5, 1) [D loss: (-1.2995)(R 0.1396, F -1.5704, G 0.0131)] [G loss: 1.8576]\n",
      "2128 (5, 1) [D loss: (-1.7412)(R -0.4411, F -1.4034, G 0.0103)] [G loss: 1.4375]\n",
      "2129 (5, 1) [D loss: (-1.3822)(R -1.6603, F 0.1479, G 0.0130)] [G loss: -0.4697]\n",
      "2130 (5, 1) [D loss: (-1.6405)(R -3.1163, F 1.3302, G 0.0146)] [G loss: -1.6897]\n",
      "2131 (5, 1) [D loss: (-1.6331)(R -4.5635, F 2.7861, G 0.0144)] [G loss: -2.7829]\n",
      "2132 (5, 1) [D loss: (-1.6811)(R -4.5436, F 2.7535, G 0.0109)] [G loss: -2.7808]\n",
      "2133 (5, 1) [D loss: (-1.5650)(R -4.4813, F 2.7951, G 0.0121)] [G loss: -2.8204]\n",
      "2134 (5, 1) [D loss: (-2.0637)(R -3.4403, F 1.2582, G 0.0118)] [G loss: -1.4455]\n",
      "2135 (5, 1) [D loss: (-1.9299)(R -2.6718, F 0.6291, G 0.0113)] [G loss: -0.4961]\n",
      "2136 (5, 1) [D loss: (-1.4049)(R -1.5846, F 0.0779, G 0.0102)] [G loss: -0.1610]\n",
      "2137 (5, 1) [D loss: (-1.4487)(R -2.2417, F 0.6673, G 0.0126)] [G loss: -0.8939]\n",
      "2138 (5, 1) [D loss: (-1.8743)(R -3.0193, F 1.0648, G 0.0080)] [G loss: -1.5820]\n",
      "2139 (5, 1) [D loss: (-1.7653)(R -3.9469, F 2.0682, G 0.0113)] [G loss: -2.6551]\n",
      "2140 (5, 1) [D loss: (-1.7085)(R -5.6293, F 3.7916, G 0.0129)] [G loss: -3.7921]\n",
      "2141 (5, 1) [D loss: (-1.8030)(R -5.8400, F 3.9338, G 0.0103)] [G loss: -4.3674]\n",
      "2142 (5, 1) [D loss: (-1.4578)(R -5.8617, F 4.2809, G 0.0123)] [G loss: -4.3602]\n",
      "2143 (5, 1) [D loss: (-1.4494)(R -5.8297, F 4.2472, G 0.0133)] [G loss: -4.1729]\n",
      "2144 (5, 1) [D loss: (-2.0166)(R -5.6152, F 3.4941, G 0.0105)] [G loss: -3.7956]\n",
      "2145 (5, 1) [D loss: (-1.8710)(R -4.6721, F 2.6790, G 0.0122)] [G loss: -2.9743]\n",
      "2146 (5, 1) [D loss: (-1.5197)(R -3.3427, F 1.6985, G 0.0125)] [G loss: -0.9283]\n",
      "2147 (5, 1) [D loss: (-1.7690)(R -3.9904, F 2.0869, G 0.0135)] [G loss: -2.0912]\n",
      "2148 (5, 1) [D loss: (-1.6660)(R -4.9917, F 3.2098, G 0.0116)] [G loss: -3.8171]\n",
      "2149 (5, 1) [D loss: (-1.2744)(R -5.6573, F 4.2671, G 0.0116)] [G loss: -4.7294]\n",
      "2150 (5, 1) [D loss: (-1.8212)(R -6.7128, F 4.7688, G 0.0123)] [G loss: -4.8419]\n",
      "2151 (5, 1) [D loss: (-1.7072)(R -6.4139, F 4.5838, G 0.0123)] [G loss: -4.1786]\n",
      "2152 (5, 1) [D loss: (-1.7305)(R -6.0099, F 4.1824, G 0.0097)] [G loss: -4.6025]\n",
      "2153 (5, 1) [D loss: (-1.4093)(R -5.3480, F 3.8268, G 0.0112)] [G loss: -3.5393]\n",
      "2154 (5, 1) [D loss: (-1.5051)(R -3.5627, F 1.9413, G 0.0116)] [G loss: -1.4247]\n",
      "2155 (5, 1) [D loss: (-1.7232)(R -2.2296, F 0.3659, G 0.0141)] [G loss: -0.2741]\n",
      "2156 (5, 1) [D loss: (-1.8393)(R -2.3203, F 0.3485, G 0.0133)] [G loss: -0.8218]\n",
      "2157 (5, 1) [D loss: (-1.6276)(R -3.6466, F 1.9075, G 0.0112)] [G loss: -1.9964]\n",
      "2158 (5, 1) [D loss: (-1.9213)(R -4.8590, F 2.8025, G 0.0135)] [G loss: -3.0028]\n",
      "2159 (5, 1) [D loss: (-1.6219)(R -4.8202, F 3.0825, G 0.0116)] [G loss: -3.0981]\n",
      "2160 (5, 1) [D loss: (-1.7757)(R -5.5516, F 3.6579, G 0.0118)] [G loss: -3.9536]\n",
      "2161 (5, 1) [D loss: (-1.7357)(R -5.9689, F 4.1157, G 0.0117)] [G loss: -4.1951]\n",
      "2162 (5, 1) [D loss: (-1.0496)(R -5.2724, F 4.0933, G 0.0129)] [G loss: -3.3882]\n",
      "2163 (5, 1) [D loss: (-1.5397)(R -4.0715, F 2.4173, G 0.0115)] [G loss: -2.2437]\n",
      "2164 (5, 1) [D loss: (-1.8460)(R -2.2549, F 0.3136, G 0.0095)] [G loss: -0.2069]\n",
      "2165 (5, 1) [D loss: (-2.0844)(R -0.6294, F -1.5745, G 0.0119)] [G loss: 2.1131]\n",
      "2166 (5, 1) [D loss: (-1.4675)(R 1.5704, F -3.1708, G 0.0133)] [G loss: 3.5574]\n",
      "2167 (5, 1) [D loss: (-1.6865)(R 0.6124, F -2.4203, G 0.0121)] [G loss: 2.4829]\n",
      "2168 (5, 1) [D loss: (-1.5807)(R -0.7076, F -0.9808, G 0.0108)] [G loss: 0.7179]\n",
      "2169 (5, 1) [D loss: (-1.2479)(R -1.2657, F -0.0947, G 0.0113)] [G loss: -0.1649]\n",
      "2170 (5, 1) [D loss: (-1.4636)(R -2.2987, F 0.7322, G 0.0103)] [G loss: -1.3027]\n",
      "2171 (5, 1) [D loss: (-1.4067)(R -3.8763, F 2.3783, G 0.0091)] [G loss: -2.3644]\n",
      "2172 (5, 1) [D loss: (-1.4379)(R -3.4779, F 1.9261, G 0.0114)] [G loss: -2.0913]\n",
      "2173 (5, 1) [D loss: (-1.8123)(R -3.3728, F 1.4460, G 0.0114)] [G loss: -1.3497]\n",
      "2174 (5, 1) [D loss: (-1.7505)(R -2.0744, F 0.1889, G 0.0135)] [G loss: 0.1202]\n",
      "2175 (5, 1) [D loss: (-1.6680)(R -1.0419, F -0.7565, G 0.0130)] [G loss: 1.1104]\n",
      "2176 (5, 1) [D loss: (-1.5634)(R 0.8973, F -2.5802, G 0.0119)] [G loss: 2.7058]\n",
      "2177 (5, 1) [D loss: (-1.8206)(R 2.3966, F -4.3376, G 0.0120)] [G loss: 4.7872]\n",
      "2178 (5, 1) [D loss: (-1.5855)(R 2.5026, F -4.1965, G 0.0108)] [G loss: 3.9916]\n",
      "2179 (5, 1) [D loss: (-1.7621)(R 1.3502, F -3.2117, G 0.0099)] [G loss: 2.9354]\n",
      "2180 (5, 1) [D loss: (-1.5027)(R -1.2820, F -0.3120, G 0.0091)] [G loss: -0.2734]\n",
      "2181 (5, 1) [D loss: (-1.4908)(R -3.0843, F 1.4696, G 0.0124)] [G loss: -1.7615]\n",
      "2182 (5, 1) [D loss: (-1.2229)(R -3.2486, F 1.9073, G 0.0119)] [G loss: -1.8508]\n",
      "2183 (5, 1) [D loss: (-1.6502)(R -2.7831, F 1.0030, G 0.0130)] [G loss: -1.4530]\n",
      "2184 (5, 1) [D loss: (-1.5399)(R -1.2333, F -0.4127, G 0.0106)] [G loss: 0.8597]\n",
      "2185 (5, 1) [D loss: (-1.4826)(R 0.6225, F -2.2323, G 0.0127)] [G loss: 2.5500]\n",
      "2186 (5, 1) [D loss: (-1.4024)(R 1.5463, F -3.0598, G 0.0111)] [G loss: 2.7780]\n",
      "2187 (5, 1) [D loss: (-1.5416)(R 0.2884, F -1.9421, G 0.0112)] [G loss: 1.3650]\n",
      "2188 (5, 1) [D loss: (-1.8623)(R -1.1172, F -0.8599, G 0.0115)] [G loss: 0.4439]\n",
      "2189 (5, 1) [D loss: (-1.7706)(R -1.9222, F 0.0348, G 0.0117)] [G loss: -0.1842]\n",
      "2190 (5, 1) [D loss: (-1.5880)(R -2.7641, F 1.0754, G 0.0101)] [G loss: -1.6561]\n",
      "2191 (5, 1) [D loss: (-1.5262)(R -5.4230, F 3.7706, G 0.0126)] [G loss: -3.7642]\n",
      "2192 (5, 1) [D loss: (-1.7681)(R -7.0899, F 5.2062, G 0.0116)] [G loss: -5.0755]\n",
      "2193 (5, 1) [D loss: (-2.1154)(R -7.2148, F 5.0018, G 0.0098)] [G loss: -5.4081]\n",
      "2194 (5, 1) [D loss: (-1.6218)(R -4.6793, F 2.9566, G 0.0101)] [G loss: -2.5861]\n",
      "2195 (5, 1) [D loss: (-1.8640)(R -2.8807, F 0.8985, G 0.0118)] [G loss: -0.4216]\n",
      "2196 (5, 1) [D loss: (-1.3708)(R -1.3550, F -0.1330, G 0.0117)] [G loss: 0.2764]\n",
      "2197 (5, 1) [D loss: (-1.7685)(R -1.8529, F -0.0293, G 0.0114)] [G loss: 0.4944]\n",
      "2198 (5, 1) [D loss: (-1.5410)(R -2.8984, F 1.2417, G 0.0116)] [G loss: -1.6637]\n",
      "2199 (5, 1) [D loss: (-1.7649)(R -5.0800, F 3.2070, G 0.0108)] [G loss: -3.4384]\n",
      "2200 (5, 1) [D loss: (-1.3004)(R -6.1774, F 4.7832, G 0.0094)] [G loss: -4.2995]\n",
      "2201 (5, 1) [D loss: (-1.5349)(R -5.5080, F 3.8730, G 0.0100)] [G loss: -4.1278]\n",
      "2202 (5, 1) [D loss: (-1.3998)(R -4.9966, F 3.4926, G 0.0104)] [G loss: -3.2150]\n",
      "2203 (5, 1) [D loss: (-1.6103)(R -4.0307, F 2.3043, G 0.0116)] [G loss: -2.0931]\n",
      "2204 (5, 1) [D loss: (-1.6143)(R -2.6405, F 0.9044, G 0.0122)] [G loss: -1.0799]\n",
      "2205 (5, 1) [D loss: (-1.7234)(R -2.4616, F 0.6026, G 0.0136)] [G loss: -0.5821]\n",
      "2206 (5, 1) [D loss: (-1.6079)(R -2.3047, F 0.5697, G 0.0127)] [G loss: -0.4133]\n",
      "2207 (5, 1) [D loss: (-1.6080)(R -3.6167, F 1.8819, G 0.0127)] [G loss: -2.3797]\n",
      "2208 (5, 1) [D loss: (-1.4111)(R -5.4016, F 3.8664, G 0.0124)] [G loss: -4.1626]\n",
      "2209 (5, 1) [D loss: (-1.6535)(R -5.3583, F 3.6053, G 0.0100)] [G loss: -3.4094]\n",
      "2210 (5, 1) [D loss: (-1.8716)(R -5.0883, F 3.1064, G 0.0110)] [G loss: -3.5793]\n",
      "2211 (5, 1) [D loss: (-1.9435)(R -4.9502, F 2.9072, G 0.0100)] [G loss: -2.9606]\n",
      "2212 (5, 1) [D loss: (-1.7765)(R -4.0779, F 2.1683, G 0.0133)] [G loss: -1.9420]\n",
      "2213 (5, 1) [D loss: (-2.0169)(R -3.6608, F 1.5193, G 0.0125)] [G loss: -1.4916]\n",
      "2214 (5, 1) [D loss: (-1.4417)(R -1.8425, F 0.2863, G 0.0114)] [G loss: -0.1279]\n",
      "2215 (5, 1) [D loss: (-1.3597)(R -1.6037, F 0.1194, G 0.0125)] [G loss: 0.0661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2216 (5, 1) [D loss: (-1.8693)(R -2.3582, F 0.3563, G 0.0133)] [G loss: -0.6461]\n",
      "2217 (5, 1) [D loss: (-1.8326)(R -3.8153, F 1.8695, G 0.0113)] [G loss: -2.3675]\n",
      "2218 (5, 1) [D loss: (-1.4339)(R -5.7555, F 4.2130, G 0.0109)] [G loss: -4.4288]\n",
      "2219 (5, 1) [D loss: (-1.2502)(R -5.7112, F 4.3474, G 0.0114)] [G loss: -4.2685]\n",
      "2220 (5, 1) [D loss: (-1.8337)(R -5.4360, F 3.5003, G 0.0102)] [G loss: -3.4223]\n",
      "2221 (5, 1) [D loss: (-1.5780)(R -4.0163, F 2.3001, G 0.0138)] [G loss: -1.9256]\n",
      "2222 (5, 1) [D loss: (-1.7371)(R -2.2943, F 0.4351, G 0.0122)] [G loss: -0.2396]\n",
      "2223 (5, 1) [D loss: (-2.0771)(R -0.8725, F -1.3297, G 0.0125)] [G loss: 1.9579]\n",
      "2224 (5, 1) [D loss: (-1.1857)(R 1.2624, F -2.5900, G 0.0142)] [G loss: 2.6325]\n",
      "2225 (5, 1) [D loss: (-1.5939)(R -0.5820, F -1.1252, G 0.0113)] [G loss: 0.7211]\n",
      "2226 (5, 1) [D loss: (-1.8575)(R -3.4930, F 1.5561, G 0.0079)] [G loss: -2.2350]\n",
      "2227 (5, 1) [D loss: (-1.6207)(R -5.7808, F 4.0473, G 0.0113)] [G loss: -3.9354]\n",
      "2228 (5, 1) [D loss: (-1.6387)(R -6.9160, F 5.1638, G 0.0114)] [G loss: -5.2317]\n",
      "2229 (5, 1) [D loss: (-1.6332)(R -4.8642, F 3.1379, G 0.0093)] [G loss: -2.9050]\n",
      "2230 (5, 1) [D loss: (-1.3005)(R -2.6040, F 1.1744, G 0.0129)] [G loss: -0.5034]\n",
      "2231 (5, 1) [D loss: (-1.2423)(R -0.6297, F -0.7268, G 0.0114)] [G loss: 1.1575]\n",
      "2232 (5, 1) [D loss: (-1.5903)(R 0.4374, F -2.1518, G 0.0124)] [G loss: 2.2185]\n",
      "2233 (5, 1) [D loss: (-1.4052)(R 0.6321, F -2.1531, G 0.0116)] [G loss: 1.9666]\n",
      "2234 (5, 1) [D loss: (-1.4442)(R -0.8700, F -0.6719, G 0.0098)] [G loss: 0.5019]\n",
      "2235 (5, 1) [D loss: (-1.5180)(R -2.5639, F 0.9419, G 0.0104)] [G loss: -1.3526]\n",
      "2236 (5, 1) [D loss: (-1.1965)(R -3.8493, F 2.5325, G 0.0120)] [G loss: -2.3190]\n",
      "2237 (5, 1) [D loss: (-1.2991)(R -4.6189, F 3.2086, G 0.0111)] [G loss: -2.5709]\n",
      "2238 (5, 1) [D loss: (-1.3129)(R -3.1481, F 1.7372, G 0.0098)] [G loss: -1.5724]\n",
      "2239 (5, 1) [D loss: (-1.7018)(R -1.9989, F 0.1992, G 0.0098)] [G loss: -0.1285]\n",
      "2240 (5, 1) [D loss: (-1.3869)(R -0.4069, F -1.0856, G 0.0106)] [G loss: 1.4561]\n",
      "2241 (5, 1) [D loss: (-1.2719)(R 1.2259, F -2.6142, G 0.0116)] [G loss: 3.2797]\n",
      "2242 (5, 1) [D loss: (-1.3485)(R 1.0013, F -2.4639, G 0.0114)] [G loss: 1.9983]\n",
      "2243 (5, 1) [D loss: (-1.8806)(R -0.5837, F -1.3855, G 0.0089)] [G loss: 0.6235]\n",
      "2244 (5, 1) [D loss: (-1.6419)(R -2.4132, F 0.6797, G 0.0092)] [G loss: -0.9017]\n",
      "2245 (5, 1) [D loss: (-1.4840)(R -3.8111, F 2.2313, G 0.0096)] [G loss: -2.7459]\n",
      "2246 (5, 1) [D loss: (-1.6556)(R -5.6647, F 3.8888, G 0.0120)] [G loss: -3.3781]\n",
      "2247 (5, 1) [D loss: (-2.0269)(R -5.5459, F 3.4183, G 0.0101)] [G loss: -3.3922]\n",
      "2248 (5, 1) [D loss: (-1.3542)(R -4.9407, F 3.4706, G 0.0116)] [G loss: -2.9951]\n",
      "2249 (5, 1) [D loss: (-1.6881)(R -4.4669, F 2.6889, G 0.0090)] [G loss: -2.9191]\n",
      "2250 (5, 1) [D loss: (-1.2994)(R -2.3986, F 0.9867, G 0.0112)] [G loss: -0.6272]\n",
      "2251 (5, 1) [D loss: (-1.7861)(R -1.1223, F -0.7742, G 0.0110)] [G loss: 1.3501]\n",
      "2252 (5, 1) [D loss: (-1.6201)(R 0.1360, F -1.8522, G 0.0096)] [G loss: 1.4275]\n",
      "2253 (5, 1) [D loss: (-1.8665)(R -1.5345, F -0.4346, G 0.0103)] [G loss: 0.5140]\n",
      "2254 (5, 1) [D loss: (-1.4543)(R -1.3611, F -0.1869, G 0.0094)] [G loss: -0.2913]\n",
      "2255 (5, 1) [D loss: (-1.6574)(R -2.5149, F 0.7352, G 0.0122)] [G loss: -0.7856]\n",
      "2256 (5, 1) [D loss: (-1.2638)(R -3.1779, F 1.8141, G 0.0100)] [G loss: -1.7749]\n",
      "2257 (5, 1) [D loss: (-1.6572)(R -2.8456, F 1.0858, G 0.0103)] [G loss: -0.9068]\n",
      "2258 (5, 1) [D loss: (-1.4572)(R -2.2651, F 0.6935, G 0.0114)] [G loss: -0.2894]\n",
      "2259 (5, 1) [D loss: (-1.6514)(R -0.4234, F -1.3179, G 0.0090)] [G loss: 1.0584]\n",
      "2260 (5, 1) [D loss: (-1.7469)(R -0.0281, F -1.8410, G 0.0122)] [G loss: 1.9018]\n",
      "2261 (5, 1) [D loss: (-1.4154)(R -1.3296, F -0.1860, G 0.0100)] [G loss: 0.4127]\n",
      "2262 (5, 1) [D loss: (-1.4077)(R -1.5296, F 0.0127, G 0.0109)] [G loss: -0.3645]\n",
      "2263 (5, 1) [D loss: (-1.6229)(R -2.9211, F 1.2050, G 0.0093)] [G loss: -1.4696]\n",
      "2264 (5, 1) [D loss: (-1.6372)(R -3.2228, F 1.4767, G 0.0109)] [G loss: -1.9168]\n",
      "2265 (5, 1) [D loss: (-1.4526)(R -3.7719, F 2.2148, G 0.0105)] [G loss: -2.5543]\n",
      "2266 (5, 1) [D loss: (-1.7053)(R -5.2624, F 3.4307, G 0.0126)] [G loss: -3.3660]\n",
      "2267 (5, 1) [D loss: (-1.5394)(R -4.3388, F 2.6853, G 0.0114)] [G loss: -2.1664]\n",
      "2268 (5, 1) [D loss: (-1.9127)(R -2.9208, F 0.8837, G 0.0124)] [G loss: -0.5837]\n",
      "2269 (5, 1) [D loss: (-1.5760)(R -2.2753, F 0.5803, G 0.0119)] [G loss: -0.8143]\n",
      "2270 (5, 1) [D loss: (-1.6723)(R -3.8264, F 2.0510, G 0.0103)] [G loss: -2.2136]\n",
      "2271 (5, 1) [D loss: (-1.1553)(R -3.8715, F 2.6110, G 0.0105)] [G loss: -2.4851]\n",
      "2272 (5, 1) [D loss: (-1.6241)(R -4.5047, F 2.7750, G 0.0106)] [G loss: -2.5719]\n",
      "2273 (5, 1) [D loss: (-1.5728)(R -6.1378, F 4.4466, G 0.0118)] [G loss: -4.0555]\n",
      "2274 (5, 1) [D loss: (-1.4876)(R -6.0329, F 4.4425, G 0.0103)] [G loss: -4.4098]\n",
      "2275 (5, 1) [D loss: (-1.5289)(R -4.2766, F 2.6354, G 0.0112)] [G loss: -2.7167]\n",
      "2276 (5, 1) [D loss: (-1.4787)(R -1.6881, F 0.1255, G 0.0084)] [G loss: 0.2370]\n",
      "2277 (5, 1) [D loss: (-1.4560)(R -1.3009, F -0.2441, G 0.0089)] [G loss: 0.6209]\n",
      "2278 (5, 1) [D loss: (-1.7817)(R -1.0166, F -0.8841, G 0.0119)] [G loss: 0.8268]\n",
      "2279 (5, 1) [D loss: (-1.4899)(R -0.1847, F -1.4251, G 0.0120)] [G loss: 1.6093]\n",
      "2280 (5, 1) [D loss: (-1.5580)(R -0.3394, F -1.3290, G 0.0110)] [G loss: 1.2718]\n",
      "2281 (5, 1) [D loss: (-1.6029)(R -2.3590, F 0.6510, G 0.0105)] [G loss: -0.7962]\n",
      "2282 (5, 1) [D loss: (-1.6001)(R -3.6576, F 1.9558, G 0.0102)] [G loss: -2.4681]\n",
      "2283 (5, 1) [D loss: (-1.5493)(R -4.6456, F 2.9906, G 0.0106)] [G loss: -3.0180]\n",
      "2284 (5, 1) [D loss: (-1.5070)(R -3.1869, F 1.5405, G 0.0139)] [G loss: -1.2404]\n",
      "2285 (5, 1) [D loss: (-1.2139)(R -2.6630, F 1.3293, G 0.0120)] [G loss: -1.0293]\n",
      "2286 (5, 1) [D loss: (-1.6370)(R -1.0920, F -0.6314, G 0.0086)] [G loss: 0.9125]\n",
      "2287 (5, 1) [D loss: (-1.5842)(R 0.6742, F -2.3855, G 0.0127)] [G loss: 2.5726]\n",
      "2288 (5, 1) [D loss: (-1.6845)(R 1.4448, F -3.2540, G 0.0125)] [G loss: 2.8488]\n",
      "2289 (5, 1) [D loss: (-1.4181)(R 0.4884, F -2.0079, G 0.0101)] [G loss: 2.0668]\n",
      "2290 (5, 1) [D loss: (-1.4719)(R -1.8815, F 0.3071, G 0.0102)] [G loss: -0.7090]\n",
      "2291 (5, 1) [D loss: (-1.4434)(R -3.7694, F 2.2217, G 0.0104)] [G loss: -2.8581]\n",
      "2292 (5, 1) [D loss: (-1.7429)(R -5.8533, F 4.0082, G 0.0102)] [G loss: -4.3452]\n",
      "2293 (5, 1) [D loss: (-1.5170)(R -5.8517, F 4.2251, G 0.0110)] [G loss: -4.1572]\n",
      "2294 (5, 1) [D loss: (-1.8038)(R -4.3623, F 2.4644, G 0.0094)] [G loss: -1.8704]\n",
      "2295 (5, 1) [D loss: (-1.4400)(R -1.8616, F 0.3262, G 0.0095)] [G loss: 0.4554]\n",
      "2296 (5, 1) [D loss: (-1.6683)(R 1.0920, F -2.8794, G 0.0119)] [G loss: 3.2683]\n",
      "2297 (5, 1) [D loss: (-1.5863)(R 3.1588, F -4.9031, G 0.0158)] [G loss: 4.8689]\n",
      "2298 (5, 1) [D loss: (-1.9975)(R 1.8260, F -3.9522, G 0.0129)] [G loss: 3.7279]\n",
      "2299 (5, 1) [D loss: (-1.2986)(R 1.7244, F -3.1266, G 0.0104)] [G loss: 2.5317]\n",
      "2300 (5, 1) [D loss: (-1.4664)(R -2.2536, F 0.6931, G 0.0094)] [G loss: -1.2695]\n",
      "2301 (5, 1) [D loss: (-1.5694)(R -5.2897, F 3.5976, G 0.0123)] [G loss: -4.4102]\n",
      "2302 (5, 1) [D loss: (-1.3403)(R -8.8185, F 7.3308, G 0.0147)] [G loss: -7.4295]\n",
      "2303 (5, 1) [D loss: (-1.1580)(R -10.2008, F 8.8986, G 0.0144)] [G loss: -8.3904]\n",
      "2304 (5, 1) [D loss: (-1.0855)(R -8.5125, F 7.3372, G 0.0090)] [G loss: -6.7287]\n",
      "2305 (5, 1) [D loss: (-1.4122)(R -6.3067, F 4.7885, G 0.0106)] [G loss: -3.8522]\n",
      "2306 (5, 1) [D loss: (-1.5247)(R -2.7278, F 1.0640, G 0.0139)] [G loss: -0.2948]\n",
      "2307 (5, 1) [D loss: (-1.8492)(R -0.2125, F -1.7668, G 0.0130)] [G loss: 2.2318]\n",
      "2308 (5, 1) [D loss: (-1.6991)(R 1.9254, F -3.7812, G 0.0157)] [G loss: 3.5902]\n",
      "2309 (5, 1) [D loss: (-1.1756)(R 0.6444, F -1.9289, G 0.0109)] [G loss: 1.3547]\n",
      "2310 (5, 1) [D loss: (-1.7956)(R -2.9683, F 1.0718, G 0.0101)] [G loss: -2.2605]\n",
      "2311 (5, 1) [D loss: (-1.5032)(R -6.6972, F 5.0918, G 0.0102)] [G loss: -5.7834]\n",
      "2312 (5, 1) [D loss: (-2.0066)(R -9.6685, F 7.5378, G 0.0124)] [G loss: -7.8640]\n",
      "2313 (5, 1) [D loss: (-1.5530)(R -8.8177, F 7.1458, G 0.0119)] [G loss: -7.0640]\n",
      "2314 (5, 1) [D loss: (-1.5141)(R -6.4216, F 4.8286, G 0.0079)] [G loss: -4.4919]\n",
      "2315 (5, 1) [D loss: (-1.6844)(R -3.9831, F 2.2274, G 0.0071)] [G loss: -1.6222]\n",
      "2316 (5, 1) [D loss: (-2.0171)(R -1.2525, F -0.8762, G 0.0112)] [G loss: 0.9800]\n",
      "2317 (5, 1) [D loss: (-2.0477)(R 0.0219, F -2.2090, G 0.0139)] [G loss: 2.1074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2318 (5, 1) [D loss: (-1.6761)(R 0.1607, F -1.9717, G 0.0135)] [G loss: 2.1562]\n",
      "2319 (5, 1) [D loss: (-1.7085)(R -0.7965, F -1.0049, G 0.0093)] [G loss: 0.3305]\n",
      "2320 (5, 1) [D loss: (-1.4801)(R -5.2725, F 3.6769, G 0.0115)] [G loss: -4.3533]\n",
      "2321 (5, 1) [D loss: (-1.6641)(R -9.1557, F 7.3650, G 0.0127)] [G loss: -7.5319]\n",
      "2322 (5, 1) [D loss: (-1.7704)(R -10.7226, F 8.8062, G 0.0146)] [G loss: -9.2510]\n",
      "2323 (5, 1) [D loss: (-1.6633)(R -10.4985, F 8.7189, G 0.0116)] [G loss: -8.4002]\n",
      "2324 (5, 1) [D loss: (-1.6758)(R -8.5721, F 6.8018, G 0.0094)] [G loss: -6.3964]\n",
      "2325 (5, 1) [D loss: (-1.7583)(R -6.2330, F 4.3608, G 0.0114)] [G loss: -3.8731]\n",
      "2326 (5, 1) [D loss: (-1.8237)(R -4.8140, F 2.8618, G 0.0128)] [G loss: -2.3323]\n",
      "2327 (5, 1) [D loss: (-1.8553)(R -2.8307, F 0.8542, G 0.0121)] [G loss: -0.7831]\n",
      "2328 (5, 1) [D loss: (-1.5018)(R -1.9494, F 0.3256, G 0.0122)] [G loss: -0.1061]\n",
      "2329 (5, 1) [D loss: (-1.5752)(R -3.6192, F 1.9494, G 0.0095)] [G loss: -2.1663]\n",
      "2330 (5, 1) [D loss: (-1.7467)(R -5.1725, F 3.3192, G 0.0107)] [G loss: -3.2620]\n",
      "2331 (5, 1) [D loss: (-2.0588)(R -6.3334, F 4.1479, G 0.0127)] [G loss: -4.8431]\n",
      "2332 (5, 1) [D loss: (-1.8919)(R -8.0962, F 6.0750, G 0.0129)] [G loss: -6.2315]\n",
      "2333 (5, 1) [D loss: (-1.4258)(R -7.0522, F 5.5145, G 0.0112)] [G loss: -5.0970]\n",
      "2334 (5, 1) [D loss: (-1.4083)(R -5.2682, F 3.7476, G 0.0112)] [G loss: -3.3609]\n",
      "2335 (5, 1) [D loss: (-1.7484)(R -3.0583, F 1.2202, G 0.0090)] [G loss: -0.3371]\n",
      "2336 (5, 1) [D loss: (-1.7619)(R 0.0447, F -1.9445, G 0.0138)] [G loss: 1.9773]\n",
      "2337 (5, 1) [D loss: (-1.8180)(R -0.7923, F -1.1473, G 0.0122)] [G loss: 1.2479]\n",
      "2338 (5, 1) [D loss: (-1.5204)(R 0.0041, F -1.6583, G 0.0134)] [G loss: 2.2160]\n",
      "2339 (5, 1) [D loss: (-1.4246)(R -0.0132, F -1.4928, G 0.0081)] [G loss: 1.1034]\n",
      "2340 (5, 1) [D loss: (-1.5569)(R -1.6027, F -0.0690, G 0.0115)] [G loss: -0.3290]\n",
      "2341 (5, 1) [D loss: (-1.9514)(R -5.1551, F 3.0865, G 0.0117)] [G loss: -3.6469]\n",
      "2342 (5, 1) [D loss: (-1.8655)(R -6.3285, F 4.3291, G 0.0134)] [G loss: -4.4728]\n",
      "2343 (5, 1) [D loss: (-1.3957)(R -4.6632, F 3.1614, G 0.0106)] [G loss: -2.7066]\n",
      "2344 (5, 1) [D loss: (-1.5448)(R -2.9933, F 1.3390, G 0.0110)] [G loss: -0.8055]\n",
      "2345 (5, 1) [D loss: (-1.3267)(R -1.1495, F -0.2920, G 0.0115)] [G loss: 0.9843]\n",
      "2346 (5, 1) [D loss: (-1.5644)(R 0.8664, F -2.5392, G 0.0108)] [G loss: 2.4528]\n",
      "2347 (5, 1) [D loss: (-1.7290)(R 0.9726, F -2.8208, G 0.0119)] [G loss: 2.8113]\n",
      "2348 (5, 1) [D loss: (-1.6775)(R -0.4843, F -1.3078, G 0.0115)] [G loss: 1.0491]\n",
      "2349 (5, 1) [D loss: (-1.4488)(R -3.0742, F 1.5291, G 0.0096)] [G loss: -2.3190]\n",
      "2350 (5, 1) [D loss: (-1.7361)(R -6.4044, F 4.5496, G 0.0119)] [G loss: -4.8250]\n",
      "2351 (5, 1) [D loss: (-1.9405)(R -8.1622, F 6.0894, G 0.0132)] [G loss: -6.1932]\n",
      "2352 (5, 1) [D loss: (-2.1024)(R -7.2676, F 5.0294, G 0.0136)] [G loss: -4.3382]\n",
      "2353 (5, 1) [D loss: (-1.4351)(R -3.8948, F 2.3737, G 0.0086)] [G loss: -1.3831]\n",
      "2354 (5, 1) [D loss: (-1.5983)(R -1.6571, F -0.0429, G 0.0102)] [G loss: 0.8832]\n",
      "2355 (5, 1) [D loss: (-1.9090)(R 0.5933, F -2.6180, G 0.0116)] [G loss: 2.6918]\n",
      "2356 (5, 1) [D loss: (-1.7490)(R 3.1500, F -5.0266, G 0.0128)] [G loss: 5.5042]\n",
      "2357 (5, 1) [D loss: (-1.3873)(R 2.4538, F -3.9910, G 0.0150)] [G loss: 3.5949]\n",
      "2358 (5, 1) [D loss: (-1.4659)(R -0.0865, F -1.4873, G 0.0108)] [G loss: 1.3510]\n",
      "2359 (5, 1) [D loss: (-1.4266)(R -4.9767, F 3.4522, G 0.0098)] [G loss: -3.9386]\n",
      "2360 (5, 1) [D loss: (-2.1362)(R -9.2028, F 6.9245, G 0.0142)] [G loss: -8.3601]\n",
      "2361 (5, 1) [D loss: (-2.0829)(R -10.9304, F 8.7050, G 0.0143)] [G loss: -8.8837]\n",
      "2362 (5, 1) [D loss: (-1.4397)(R -8.4776, F 6.9312, G 0.0107)] [G loss: -6.2014]\n",
      "2363 (5, 1) [D loss: (-2.0599)(R -3.2327, F 1.1128, G 0.0060)] [G loss: -0.5530]\n",
      "2364 (5, 1) [D loss: (-1.8704)(R 2.5911, F -4.5494, G 0.0088)] [G loss: 5.6806]\n",
      "2365 (5, 1) [D loss: (-1.5091)(R 8.0603, F -9.7402, G 0.0171)] [G loss: 9.9217]\n",
      "2366 (5, 1) [D loss: (-1.7932)(R 9.0657, F -11.0417, G 0.0183)] [G loss: 10.4285]\n",
      "2367 (5, 1) [D loss: (-1.2589)(R 7.6340, F -8.9933, G 0.0100)] [G loss: 8.5243]\n",
      "2368 (5, 1) [D loss: (-1.2391)(R 4.7244, F -6.0456, G 0.0082)] [G loss: 5.5624]\n",
      "2369 (5, 1) [D loss: (-1.7918)(R 0.9378, F -2.8007, G 0.0071)] [G loss: 1.8884]\n",
      "2370 (5, 1) [D loss: (-2.0684)(R -3.5210, F 1.3360, G 0.0117)] [G loss: -2.2225]\n",
      "2371 (5, 1) [D loss: (-2.0453)(R -6.6692, F 4.4386, G 0.0185)] [G loss: -4.6288]\n",
      "2372 (5, 1) [D loss: (-1.5569)(R -8.0457, F 6.3351, G 0.0154)] [G loss: -6.1217]\n",
      "2373 (5, 1) [D loss: (-1.3691)(R -5.1028, F 3.6393, G 0.0094)] [G loss: -2.6564]\n",
      "2374 (5, 1) [D loss: (-1.0104)(R -0.3514, F -0.7331, G 0.0074)] [G loss: 1.6570]\n",
      "2375 (5, 1) [D loss: (-1.9846)(R 3.7996, F -5.8756, G 0.0091)] [G loss: 6.3646]\n",
      "2376 (5, 1) [D loss: (-2.1852)(R 7.2931, F -9.6272, G 0.0149)] [G loss: 10.0634]\n",
      "2377 (5, 1) [D loss: (-1.5601)(R 9.3653, F -11.1411, G 0.0216)] [G loss: 11.1570]\n",
      "2378 (5, 1) [D loss: (-1.2708)(R 6.6093, F -8.0000, G 0.0120)] [G loss: 7.3457]\n",
      "2379 (5, 1) [D loss: (-1.6454)(R 2.4223, F -4.1285, G 0.0061)] [G loss: 3.4592]\n",
      "2380 (5, 1) [D loss: (-1.8538)(R -1.9502, F 0.0217, G 0.0075)] [G loss: -0.7600]\n",
      "2381 (5, 1) [D loss: (-2.2113)(R -6.1649, F 3.8169, G 0.0137)] [G loss: -4.3347]\n",
      "2382 (5, 1) [D loss: (-2.2173)(R -8.9435, F 6.5512, G 0.0175)] [G loss: -6.7449]\n",
      "2383 (5, 1) [D loss: (-1.5430)(R -8.2278, F 6.5281, G 0.0157)] [G loss: -6.3233]\n",
      "2384 (5, 1) [D loss: (-1.4315)(R -5.4688, F 3.9706, G 0.0067)] [G loss: -3.1605]\n",
      "2385 (5, 1) [D loss: (-1.1714)(R -2.7768, F 1.5285, G 0.0077)] [G loss: -0.7111]\n",
      "2386 (5, 1) [D loss: (-1.3428)(R 0.1796, F -1.6042, G 0.0082)] [G loss: 2.2672]\n",
      "2387 (5, 1) [D loss: (-1.9087)(R 2.1035, F -4.1085, G 0.0096)] [G loss: 4.6051]\n",
      "2388 (5, 1) [D loss: (-1.4953)(R 4.2890, F -5.9078, G 0.0124)] [G loss: 6.2133]\n",
      "2389 (5, 1) [D loss: (-2.0303)(R 5.3012, F -7.4789, G 0.0147)] [G loss: 7.5239]\n",
      "2390 (5, 1) [D loss: (-1.9306)(R 5.2602, F -7.3251, G 0.0134)] [G loss: 7.3255]\n",
      "2391 (5, 1) [D loss: (-1.8167)(R 3.7373, F -5.6738, G 0.0120)] [G loss: 5.5023]\n",
      "2392 (5, 1) [D loss: (-1.5411)(R 0.2159, F -1.8597, G 0.0103)] [G loss: 1.4903]\n",
      "2393 (5, 1) [D loss: (-1.7913)(R -3.1628, F 1.2928, G 0.0079)] [G loss: -2.0987]\n",
      "2394 (5, 1) [D loss: (-1.7288)(R -6.9066, F 5.0477, G 0.0130)] [G loss: -5.6579]\n",
      "2395 (5, 1) [D loss: (-1.7668)(R -9.5146, F 7.6001, G 0.0148)] [G loss: -7.5473]\n",
      "2396 (5, 1) [D loss: (-2.1419)(R -9.9612, F 7.6243, G 0.0195)] [G loss: -7.8758]\n",
      "2397 (5, 1) [D loss: (-1.6973)(R -8.8047, F 6.9913, G 0.0116)] [G loss: -7.4827]\n",
      "2398 (5, 1) [D loss: (-1.6724)(R -8.8711, F 7.1067, G 0.0092)] [G loss: -7.6676]\n",
      "2399 (5, 1) [D loss: (-1.6175)(R -8.1781, F 6.4701, G 0.0091)] [G loss: -6.0377]\n",
      "2400 (5, 1) [D loss: (-1.9164)(R -7.2599, F 5.2461, G 0.0097)] [G loss: -4.7257]\n",
      "2401 (5, 1) [D loss: (-2.1617)(R -6.1372, F 3.8530, G 0.0122)] [G loss: -4.1024]\n",
      "2402 (5, 1) [D loss: (-1.9247)(R -5.0542, F 3.0030, G 0.0126)] [G loss: -2.4866]\n",
      "2403 (5, 1) [D loss: (-1.4376)(R -4.3194, F 2.7559, G 0.0126)] [G loss: -1.9625]\n",
      "2404 (5, 1) [D loss: (-1.3491)(R -3.3173, F 1.8578, G 0.0110)] [G loss: -2.0915]\n",
      "2405 (5, 1) [D loss: (-1.7773)(R -4.3498, F 2.4934, G 0.0079)] [G loss: -2.4661]\n",
      "2406 (5, 1) [D loss: (-1.5145)(R -5.2607, F 3.6693, G 0.0077)] [G loss: -3.7293]\n",
      "2407 (5, 1) [D loss: (-1.6060)(R -6.1956, F 4.5096, G 0.0080)] [G loss: -4.5130]\n",
      "2408 (5, 1) [D loss: (-1.9024)(R -8.2374, F 6.2000, G 0.0135)] [G loss: -6.4564]\n",
      "2409 (5, 1) [D loss: (-2.0536)(R -8.8184, F 6.6318, G 0.0133)] [G loss: -6.6306]\n",
      "2410 (5, 1) [D loss: (-1.3393)(R -8.6472, F 7.1916, G 0.0116)] [G loss: -6.8742]\n",
      "2411 (5, 1) [D loss: (-1.4012)(R -6.7155, F 5.2165, G 0.0098)] [G loss: -4.5516]\n",
      "2412 (5, 1) [D loss: (-1.7937)(R -4.9944, F 3.1179, G 0.0083)] [G loss: -3.1863]\n",
      "2413 (5, 1) [D loss: (-1.8126)(R -2.8724, F 0.9708, G 0.0089)] [G loss: -0.0668]\n",
      "2414 (5, 1) [D loss: (-1.8149)(R -0.2496, F -1.6706, G 0.0105)] [G loss: 1.9078]\n",
      "2415 (5, 1) [D loss: (-1.6176)(R 0.9235, F -2.6589, G 0.0118)] [G loss: 2.5310]\n",
      "2416 (5, 1) [D loss: (-1.5044)(R 0.8465, F -2.4760, G 0.0125)] [G loss: 2.6229]\n",
      "2417 (5, 1) [D loss: (-1.7066)(R -0.9264, F -0.9080, G 0.0128)] [G loss: 0.3602]\n",
      "2418 (5, 1) [D loss: (-1.4139)(R -3.7603, F 2.2518, G 0.0095)] [G loss: -2.8012]\n",
      "2419 (5, 1) [D loss: (-1.6938)(R -6.7125, F 4.9093, G 0.0109)] [G loss: -5.8188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2420 (5, 1) [D loss: (-1.9801)(R -8.4072, F 6.2866, G 0.0140)] [G loss: -6.4328]\n",
      "2421 (5, 1) [D loss: (-2.1989)(R -8.1129, F 5.7867, G 0.0127)] [G loss: -6.4519]\n",
      "2422 (5, 1) [D loss: (-1.8226)(R -8.2762, F 6.3101, G 0.0143)] [G loss: -6.5764]\n",
      "2423 (5, 1) [D loss: (-1.2453)(R -7.0776, F 5.7105, G 0.0122)] [G loss: -5.5830]\n",
      "2424 (5, 1) [D loss: (-1.3160)(R -5.5826, F 4.1731, G 0.0093)] [G loss: -3.7333]\n",
      "2425 (5, 1) [D loss: (-1.6248)(R -3.5953, F 1.8854, G 0.0085)] [G loss: -1.9946]\n",
      "2426 (5, 1) [D loss: (-1.2089)(R -1.2442, F -0.0764, G 0.0112)] [G loss: 0.4395]\n",
      "2427 (5, 1) [D loss: (-1.6113)(R -0.4033, F -1.3351, G 0.0127)] [G loss: 1.6020]\n",
      "2428 (5, 1) [D loss: (-1.5229)(R 1.3973, F -3.0420, G 0.0122)] [G loss: 3.1906]\n",
      "2429 (5, 1) [D loss: (-1.4711)(R 1.5651, F -3.1596, G 0.0123)] [G loss: 2.8537]\n",
      "2430 (5, 1) [D loss: (-1.5458)(R -0.7425, F -0.9178, G 0.0114)] [G loss: 0.3765]\n",
      "2431 (5, 1) [D loss: (-1.6585)(R -2.9316, F 1.1724, G 0.0101)] [G loss: -1.2156]\n",
      "2432 (5, 1) [D loss: (-1.7930)(R -3.9057, F 1.9842, G 0.0129)] [G loss: -2.3973]\n",
      "2433 (5, 1) [D loss: (-2.0361)(R -5.7137, F 3.5419, G 0.0136)] [G loss: -4.1179]\n",
      "2434 (5, 1) [D loss: (-2.1449)(R -7.1082, F 4.8457, G 0.0118)] [G loss: -5.6054]\n",
      "2435 (5, 1) [D loss: (-0.9393)(R -6.9155, F 5.8508, G 0.0125)] [G loss: -5.5951]\n",
      "2436 (5, 1) [D loss: (-1.2956)(R -7.1822, F 5.7973, G 0.0089)] [G loss: -5.6074]\n",
      "2437 (5, 1) [D loss: (-1.3397)(R -6.2918, F 4.8744, G 0.0078)] [G loss: -5.0395]\n",
      "2438 (5, 1) [D loss: (-1.4421)(R -5.6605, F 4.1082, G 0.0110)] [G loss: -4.0574]\n",
      "2439 (5, 1) [D loss: (-1.8550)(R -5.2406, F 3.2735, G 0.0112)] [G loss: -3.5774]\n",
      "2440 (5, 1) [D loss: (-1.9209)(R -4.1582, F 2.1258, G 0.0112)] [G loss: -1.8806]\n",
      "2441 (5, 1) [D loss: (-2.0071)(R -4.2200, F 2.0519, G 0.0161)] [G loss: -2.2899]\n",
      "2442 (5, 1) [D loss: (-1.4773)(R -4.4934, F 2.8877, G 0.0128)] [G loss: -3.0258]\n",
      "2443 (5, 1) [D loss: (-1.7600)(R -4.2643, F 2.3882, G 0.0116)] [G loss: -2.1653]\n",
      "2444 (5, 1) [D loss: (-1.8176)(R -3.2967, F 1.3742, G 0.0105)] [G loss: -1.5642]\n",
      "2445 (5, 1) [D loss: (-1.7061)(R -2.8610, F 1.0607, G 0.0094)] [G loss: -1.0368]\n",
      "2446 (5, 1) [D loss: (-1.7975)(R -3.8286, F 1.9238, G 0.0107)] [G loss: -1.9637]\n",
      "2447 (5, 1) [D loss: (-1.8963)(R -3.7482, F 1.7436, G 0.0108)] [G loss: -1.8472]\n",
      "2448 (5, 1) [D loss: (-1.6081)(R -4.2981, F 2.6000, G 0.0090)] [G loss: -2.9015]\n",
      "2449 (5, 1) [D loss: (-1.8024)(R -4.4521, F 2.5455, G 0.0104)] [G loss: -3.1774]\n",
      "2450 (5, 1) [D loss: (-1.7197)(R -4.3894, F 2.5683, G 0.0101)] [G loss: -2.7184]\n",
      "2451 (5, 1) [D loss: (-1.7411)(R -3.5155, F 1.6750, G 0.0099)] [G loss: -1.4110]\n",
      "2452 (5, 1) [D loss: (-1.6152)(R -2.2959, F 0.5904, G 0.0090)] [G loss: -0.0143]\n",
      "2453 (5, 1) [D loss: (-1.8941)(R -0.8988, F -1.1328, G 0.0138)] [G loss: 1.2617]\n",
      "2454 (5, 1) [D loss: (-1.9291)(R 0.6741, F -2.7543, G 0.0151)] [G loss: 2.9988]\n",
      "2455 (5, 1) [D loss: (-1.6126)(R 2.3442, F -4.0737, G 0.0117)] [G loss: 4.4062]\n",
      "2456 (5, 1) [D loss: (-1.6454)(R 2.9181, F -4.6861, G 0.0123)] [G loss: 4.6350]\n",
      "2457 (5, 1) [D loss: (-1.4295)(R 1.9824, F -3.5383, G 0.0126)] [G loss: 3.3513]\n",
      "2458 (5, 1) [D loss: (-1.4701)(R 1.3063, F -2.8808, G 0.0104)] [G loss: 2.3959]\n",
      "2459 (5, 1) [D loss: (-1.0225)(R 0.4606, F -1.5922, G 0.0109)] [G loss: 1.2545]\n",
      "2460 (5, 1) [D loss: (-1.6041)(R -2.7429, F 1.0211, G 0.0118)] [G loss: -1.5000]\n",
      "2461 (5, 1) [D loss: (-1.4453)(R -4.1418, F 2.5882, G 0.0108)] [G loss: -2.9144]\n",
      "2462 (5, 1) [D loss: (-1.7538)(R -4.7597, F 2.8861, G 0.0120)] [G loss: -2.9006]\n",
      "2463 (5, 1) [D loss: (-1.5746)(R -4.5196, F 2.8472, G 0.0098)] [G loss: -2.6305]\n",
      "2464 (5, 1) [D loss: (-1.8740)(R -3.3164, F 1.3210, G 0.0121)] [G loss: -1.1606]\n",
      "2465 (5, 1) [D loss: (-1.6197)(R -1.8748, F 0.1513, G 0.0104)] [G loss: 0.2989]\n",
      "2466 (5, 1) [D loss: (-1.7954)(R -0.5064, F -1.4074, G 0.0118)] [G loss: 1.7791]\n",
      "2467 (5, 1) [D loss: (-1.7817)(R 0.5019, F -2.4004, G 0.0117)] [G loss: 2.5782]\n",
      "2468 (5, 1) [D loss: (-1.6945)(R 2.0076, F -3.8198, G 0.0118)] [G loss: 3.7505]\n",
      "2469 (5, 1) [D loss: (-1.4069)(R 1.7420, F -3.2562, G 0.0107)] [G loss: 3.3254]\n",
      "2470 (5, 1) [D loss: (-1.5606)(R 0.5422, F -2.1966, G 0.0094)] [G loss: 2.2381]\n",
      "2471 (5, 1) [D loss: (-1.3460)(R -0.4487, F -0.9920, G 0.0095)] [G loss: 0.6996]\n",
      "2472 (5, 1) [D loss: (-1.7136)(R -1.4013, F -0.4229, G 0.0111)] [G loss: 0.0212]\n",
      "2473 (5, 1) [D loss: (-2.1481)(R -2.4156, F 0.1789, G 0.0088)] [G loss: 0.0555]\n",
      "2474 (5, 1) [D loss: (-1.8931)(R -2.4128, F 0.4162, G 0.0104)] [G loss: -0.5188]\n",
      "2475 (5, 1) [D loss: (-1.6963)(R -2.1857, F 0.3706, G 0.0119)] [G loss: -0.1829]\n",
      "2476 (5, 1) [D loss: (-1.7869)(R -1.6607, F -0.2456, G 0.0119)] [G loss: 0.7240]\n",
      "2477 (5, 1) [D loss: (-1.1341)(R -0.7590, F -0.4620, G 0.0087)] [G loss: 0.7844]\n",
      "2478 (5, 1) [D loss: (-0.7820)(R -0.3206, F -0.5594, G 0.0098)] [G loss: 1.2766]\n",
      "2479 (5, 1) [D loss: (-1.4761)(R 0.6494, F -2.2218, G 0.0096)] [G loss: 2.2037]\n",
      "2480 (5, 1) [D loss: (-1.2244)(R 1.7970, F -3.1485, G 0.0127)] [G loss: 3.6774]\n",
      "2481 (5, 1) [D loss: (-1.7641)(R 2.4296, F -4.3293, G 0.0136)] [G loss: 4.4679]\n",
      "2482 (5, 1) [D loss: (-1.7105)(R 3.0431, F -4.8721, G 0.0118)] [G loss: 4.4508]\n",
      "2483 (5, 1) [D loss: (-1.6482)(R 1.7877, F -3.5436, G 0.0108)] [G loss: 3.1841]\n",
      "2484 (5, 1) [D loss: (-1.9030)(R 1.0217, F -3.0134, G 0.0089)] [G loss: 2.9279]\n",
      "2485 (5, 1) [D loss: (-2.0071)(R 0.2914, F -2.4096, G 0.0111)] [G loss: 2.0513]\n",
      "2486 (5, 1) [D loss: (-2.0714)(R -0.7371, F -1.4617, G 0.0127)] [G loss: 1.4011]\n",
      "2487 (5, 1) [D loss: (-1.7419)(R 0.0207, F -1.8831, G 0.0120)] [G loss: 2.2785]\n",
      "2488 (5, 1) [D loss: (-1.4763)(R 1.9019, F -3.4788, G 0.0100)] [G loss: 3.1811]\n",
      "2489 (5, 1) [D loss: (-1.6756)(R 1.6040, F -3.3691, G 0.0090)] [G loss: 3.3236]\n",
      "2490 (5, 1) [D loss: (-1.1780)(R 2.5474, F -3.7921, G 0.0067)] [G loss: 3.6308]\n",
      "2491 (5, 1) [D loss: (-1.1038)(R 3.7702, F -4.9615, G 0.0087)] [G loss: 4.6990]\n",
      "2492 (5, 1) [D loss: (-1.2531)(R 4.1844, F -5.5114, G 0.0074)] [G loss: 5.3619]\n",
      "2493 (5, 1) [D loss: (-2.1629)(R 4.0099, F -6.2778, G 0.0105)] [G loss: 6.3493]\n",
      "2494 (5, 1) [D loss: (-1.8292)(R 5.8155, F -7.7919, G 0.0147)] [G loss: 7.6147]\n",
      "2495 (5, 1) [D loss: (-1.8353)(R 5.4709, F -7.4212, G 0.0115)] [G loss: 7.1798]\n",
      "2496 (5, 1) [D loss: (-1.5952)(R 4.3088, F -6.0521, G 0.0148)] [G loss: 5.8922]\n",
      "2497 (5, 1) [D loss: (-1.4362)(R 3.5314, F -5.0905, G 0.0123)] [G loss: 4.8490]\n",
      "2498 (5, 1) [D loss: (-1.3057)(R 2.3079, F -3.7119, G 0.0098)] [G loss: 3.0163]\n",
      "2499 (5, 1) [D loss: (-1.3359)(R -0.7676, F -0.6618, G 0.0094)] [G loss: -0.1306]\n",
      "2500 (5, 1) [D loss: (-0.9774)(R -3.7698, F 2.7083, G 0.0084)] [G loss: -2.9506]\n",
      "2501 (5, 1) [D loss: (-1.5351)(R -6.8748, F 5.2207, G 0.0119)] [G loss: -6.1820]\n",
      "2502 (5, 1) [D loss: (-2.0110)(R -9.2690, F 7.1474, G 0.0111)] [G loss: -7.4910]\n",
      "2503 (5, 1) [D loss: (-1.8571)(R -10.0348, F 8.0428, G 0.0135)] [G loss: -7.8494]\n",
      "2504 (5, 1) [D loss: (-1.6577)(R -8.5272, F 6.7587, G 0.0111)] [G loss: -5.9981]\n",
      "2505 (5, 1) [D loss: (-1.9406)(R -6.3391, F 4.2680, G 0.0131)] [G loss: -4.3923]\n",
      "2506 (5, 1) [D loss: (-1.9832)(R -4.1848, F 2.0991, G 0.0103)] [G loss: -2.3320]\n",
      "2507 (5, 1) [D loss: (-1.3663)(R -3.4994, F 2.0317, G 0.0101)] [G loss: -1.3943]\n",
      "2508 (5, 1) [D loss: (-0.8767)(R -2.3332, F 1.3838, G 0.0073)] [G loss: -1.2196]\n",
      "2509 (5, 1) [D loss: (-0.7956)(R -2.6597, F 1.7956, G 0.0069)] [G loss: -1.5589]\n",
      "2510 (5, 1) [D loss: (-1.0736)(R -4.0107, F 2.8588, G 0.0078)] [G loss: -3.2426]\n",
      "2511 (5, 1) [D loss: (-1.5234)(R -6.5221, F 4.9187, G 0.0080)] [G loss: -5.0082]\n",
      "2512 (5, 1) [D loss: (-1.7299)(R -7.5619, F 5.7570, G 0.0075)] [G loss: -5.8405]\n",
      "2513 (5, 1) [D loss: (-1.6338)(R -6.7447, F 5.0331, G 0.0078)] [G loss: -4.9055]\n",
      "2514 (5, 1) [D loss: (-1.2950)(R -5.5564, F 4.1902, G 0.0071)] [G loss: -3.2346]\n",
      "2515 (5, 1) [D loss: (-1.6746)(R -4.1505, F 2.3941, G 0.0082)] [G loss: -2.0259]\n",
      "2516 (5, 1) [D loss: (-1.7360)(R -2.6134, F 0.7725, G 0.0105)] [G loss: -0.5840]\n",
      "2517 (5, 1) [D loss: (-1.9547)(R -1.1598, F -0.8956, G 0.0101)] [G loss: 1.1841]\n",
      "2518 (5, 1) [D loss: (-1.3239)(R -1.0885, F -0.3545, G 0.0119)] [G loss: 0.2171]\n",
      "2519 (5, 1) [D loss: (-0.9110)(R -2.0854, F 1.0701, G 0.0104)] [G loss: -1.3963]\n",
      "2520 (5, 1) [D loss: (-1.1355)(R -3.4391, F 2.2087, G 0.0095)] [G loss: -2.3706]\n",
      "2521 (5, 1) [D loss: (-1.3415)(R -5.8606, F 4.4279, G 0.0091)] [G loss: -4.8709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2522 (5, 1) [D loss: (-1.6379)(R -7.5427, F 5.8159, G 0.0089)] [G loss: -6.5359]\n",
      "2523 (5, 1) [D loss: (-1.5530)(R -8.8687, F 7.2180, G 0.0098)] [G loss: -7.4408]\n",
      "2524 (5, 1) [D loss: (-1.8861)(R -9.1944, F 7.1837, G 0.0125)] [G loss: -7.7622]\n",
      "2525 (5, 1) [D loss: (-1.7701)(R -8.5468, F 6.6797, G 0.0097)] [G loss: -6.3206]\n",
      "2526 (5, 1) [D loss: (-1.6588)(R -6.0745, F 4.3183, G 0.0097)] [G loss: -4.4059]\n",
      "2527 (5, 1) [D loss: (-1.7361)(R -3.8622, F 2.0318, G 0.0094)] [G loss: -2.1212]\n",
      "2528 (5, 1) [D loss: (-1.3839)(R -3.3028, F 1.7911, G 0.0128)] [G loss: -1.0884]\n",
      "2529 (5, 1) [D loss: (-1.4797)(R -1.5661, F 0.0001, G 0.0086)] [G loss: 0.1642]\n",
      "2530 (5, 1) [D loss: (-1.1940)(R -1.5437, F 0.2712, G 0.0079)] [G loss: -0.3342]\n",
      "2531 (5, 1) [D loss: (-1.5124)(R -2.4042, F 0.7969, G 0.0095)] [G loss: -0.9904]\n",
      "2532 (5, 1) [D loss: (-1.3681)(R -1.7879, F 0.3409, G 0.0079)] [G loss: -0.6730]\n",
      "2533 (5, 1) [D loss: (-1.5201)(R -2.2230, F 0.6044, G 0.0098)] [G loss: -0.7456]\n",
      "2534 (5, 1) [D loss: (-1.6793)(R -2.5023, F 0.7071, G 0.0116)] [G loss: -1.1089]\n",
      "2535 (5, 1) [D loss: (-1.4775)(R -2.3298, F 0.7501, G 0.0102)] [G loss: -0.9339]\n",
      "2536 (5, 1) [D loss: (-1.8925)(R -1.6668, F -0.3320, G 0.0106)] [G loss: 0.2792]\n",
      "2537 (5, 1) [D loss: (-1.4126)(R -0.7997, F -0.7293, G 0.0116)] [G loss: 0.9216]\n",
      "2538 (5, 1) [D loss: (-1.6964)(R -1.2329, F -0.5930, G 0.0129)] [G loss: 0.7650]\n",
      "2539 (5, 1) [D loss: (-1.6171)(R -1.5257, F -0.1878, G 0.0096)] [G loss: -0.0756]\n",
      "2540 (5, 1) [D loss: (-1.5928)(R -2.5552, F 0.8505, G 0.0112)] [G loss: -0.9808]\n",
      "2541 (5, 1) [D loss: (-1.2220)(R -3.1948, F 1.8774, G 0.0095)] [G loss: -2.2942]\n",
      "2542 (5, 1) [D loss: (-1.1839)(R -5.3415, F 4.0526, G 0.0105)] [G loss: -4.4013]\n",
      "2543 (5, 1) [D loss: (-1.8375)(R -7.9371, F 5.9699, G 0.0130)] [G loss: -6.2870]\n",
      "2544 (5, 1) [D loss: (-1.7053)(R -9.5611, F 7.7428, G 0.0113)] [G loss: -7.7087]\n",
      "2545 (5, 1) [D loss: (-1.4956)(R -10.2344, F 8.6240, G 0.0115)] [G loss: -8.3933]\n",
      "2546 (5, 1) [D loss: (-1.3948)(R -8.9480, F 7.4599, G 0.0093)] [G loss: -6.9122]\n",
      "2547 (5, 1) [D loss: (-2.0974)(R -7.2982, F 5.1025, G 0.0098)] [G loss: -5.1477]\n",
      "2548 (5, 1) [D loss: (-1.5229)(R -5.3940, F 3.7652, G 0.0106)] [G loss: -3.2597]\n",
      "2549 (5, 1) [D loss: (-1.5284)(R -3.6936, F 2.0593, G 0.0106)] [G loss: -1.7041]\n",
      "2550 (5, 1) [D loss: (-1.5784)(R -2.3923, F 0.7079, G 0.0106)] [G loss: -0.7127]\n",
      "2551 (5, 1) [D loss: (-1.4721)(R -2.5847, F 1.0033, G 0.0109)] [G loss: -1.1729]\n",
      "2552 (5, 1) [D loss: (-1.3555)(R -3.7166, F 2.2742, G 0.0087)] [G loss: -2.5440]\n",
      "2553 (5, 1) [D loss: (-1.6031)(R -4.6581, F 2.9569, G 0.0098)] [G loss: -3.0904]\n",
      "2554 (5, 1) [D loss: (-1.4556)(R -3.8522, F 2.2969, G 0.0100)] [G loss: -2.1726]\n",
      "2555 (5, 1) [D loss: (-1.6508)(R -2.9055, F 1.1499, G 0.0105)] [G loss: -1.0363]\n",
      "2556 (5, 1) [D loss: (-1.6214)(R -2.0751, F 0.3646, G 0.0089)] [G loss: -0.0282]\n",
      "2557 (5, 1) [D loss: (-1.5185)(R -1.5511, F -0.1062, G 0.0139)] [G loss: 0.0032]\n",
      "2558 (5, 1) [D loss: (-1.5755)(R -0.0959, F -1.5911, G 0.0112)] [G loss: 2.1711]\n",
      "2559 (5, 1) [D loss: (-2.0155)(R 0.4742, F -2.6068, G 0.0117)] [G loss: 2.6123]\n",
      "2560 (5, 1) [D loss: (-1.4746)(R 1.1561, F -2.7351, G 0.0104)] [G loss: 2.6401]\n",
      "2561 (5, 1) [D loss: (-1.5618)(R 0.3408, F -1.9947, G 0.0092)] [G loss: 2.1694]\n",
      "2562 (5, 1) [D loss: (-1.7187)(R -0.5541, F -1.2602, G 0.0096)] [G loss: 0.7702]\n",
      "2563 (5, 1) [D loss: (-1.2600)(R -1.5814, F 0.2432, G 0.0078)] [G loss: -0.5733]\n",
      "2564 (5, 1) [D loss: (-1.4372)(R -2.5451, F 1.0181, G 0.0090)] [G loss: -1.3039]\n",
      "2565 (5, 1) [D loss: (-1.3941)(R -2.8580, F 1.3656, G 0.0098)] [G loss: -1.4052]\n",
      "2566 (5, 1) [D loss: (-1.4125)(R -3.1583, F 1.6333, G 0.0112)] [G loss: -1.6324]\n",
      "2567 (5, 1) [D loss: (-1.6192)(R -3.0993, F 1.3789, G 0.0101)] [G loss: -1.3763]\n",
      "2568 (5, 1) [D loss: (-1.6408)(R -1.9911, F 0.2378, G 0.0112)] [G loss: -0.0678]\n",
      "2569 (5, 1) [D loss: (-1.5917)(R -1.4286, F -0.2832, G 0.0120)] [G loss: 0.4302]\n",
      "2570 (5, 1) [D loss: (-1.4406)(R 0.0873, F -1.6394, G 0.0111)] [G loss: 1.6974]\n",
      "2571 (5, 1) [D loss: (-1.4217)(R 0.6866, F -2.2334, G 0.0125)] [G loss: 2.2822]\n",
      "2572 (5, 1) [D loss: (-1.6285)(R 0.1032, F -1.8352, G 0.0103)] [G loss: 1.3455]\n",
      "2573 (5, 1) [D loss: (-1.1785)(R 0.1726, F -1.4309, G 0.0080)] [G loss: 1.1863]\n",
      "2574 (5, 1) [D loss: (-1.4326)(R -1.0364, F -0.5029, G 0.0107)] [G loss: 0.4159]\n",
      "2575 (5, 1) [D loss: (-1.4856)(R -1.8626, F 0.2904, G 0.0087)] [G loss: -0.5453]\n",
      "2576 (5, 1) [D loss: (-1.4851)(R -3.4720, F 1.8757, G 0.0111)] [G loss: -2.1298]\n",
      "2577 (5, 1) [D loss: (-1.9250)(R -4.5029, F 2.4694, G 0.0109)] [G loss: -2.6954]\n",
      "2578 (5, 1) [D loss: (-1.4894)(R -3.7165, F 2.1115, G 0.0116)] [G loss: -1.7558]\n",
      "2579 (5, 1) [D loss: (-1.5367)(R -2.3072, F 0.6840, G 0.0087)] [G loss: -0.7277]\n",
      "2580 (5, 1) [D loss: (-1.3883)(R -1.7241, F 0.2292, G 0.0107)] [G loss: 0.2395]\n",
      "2581 (5, 1) [D loss: (-1.3416)(R -0.3317, F -1.1138, G 0.0104)] [G loss: 1.2702]\n",
      "2582 (5, 1) [D loss: (-1.6087)(R 0.3594, F -2.0869, G 0.0119)] [G loss: 2.0471]\n",
      "2583 (5, 1) [D loss: (-1.5870)(R 0.4907, F -2.2159, G 0.0138)] [G loss: 2.1887]\n",
      "2584 (5, 1) [D loss: (-1.3702)(R 0.0393, F -1.5225, G 0.0113)] [G loss: 1.7731]\n",
      "2585 (5, 1) [D loss: (-1.0754)(R 0.0728, F -1.2595, G 0.0111)] [G loss: 1.1765]\n",
      "2586 (5, 1) [D loss: (-1.5084)(R -2.1375, F 0.5288, G 0.0100)] [G loss: -1.0209]\n",
      "2587 (5, 1) [D loss: (-1.8086)(R -4.9244, F 3.0093, G 0.0106)] [G loss: -3.2103]\n",
      "2588 (5, 1) [D loss: (-1.6599)(R -5.3263, F 3.5589, G 0.0107)] [G loss: -3.7544]\n",
      "2589 (5, 1) [D loss: (-1.5020)(R -5.1088, F 3.4974, G 0.0109)] [G loss: -3.4178]\n",
      "2590 (5, 1) [D loss: (-1.7328)(R -4.7661, F 2.9238, G 0.0110)] [G loss: -2.8922]\n",
      "2591 (5, 1) [D loss: (-1.2112)(R -3.8708, F 2.5565, G 0.0103)] [G loss: -1.9189]\n",
      "2592 (5, 1) [D loss: (-1.3625)(R -2.6352, F 1.1625, G 0.0110)] [G loss: -1.0276]\n",
      "2593 (5, 1) [D loss: (-1.8392)(R -2.2897, F 0.3607, G 0.0090)] [G loss: -0.0476]\n",
      "2594 (5, 1) [D loss: (-1.3468)(R -0.3967, F -1.0519, G 0.0102)] [G loss: 1.2006]\n",
      "2595 (5, 1) [D loss: (-1.3207)(R -0.3654, F -1.0534, G 0.0098)] [G loss: 1.1878]\n",
      "2596 (5, 1) [D loss: (-1.7335)(R -0.3421, F -1.4859, G 0.0095)] [G loss: 1.2866]\n",
      "2597 (5, 1) [D loss: (-1.3599)(R -1.2768, F -0.1841, G 0.0101)] [G loss: 0.0601]\n",
      "2598 (5, 1) [D loss: (-1.4164)(R -2.7136, F 1.2248, G 0.0072)] [G loss: -1.3092]\n",
      "2599 (5, 1) [D loss: (-1.3777)(R -3.0980, F 1.6250, G 0.0095)] [G loss: -1.3218]\n",
      "2600 (5, 1) [D loss: (-1.6242)(R -2.8950, F 1.1735, G 0.0097)] [G loss: -1.5136]\n",
      "2601 (5, 1) [D loss: (-1.6828)(R -3.0238, F 1.2308, G 0.0110)] [G loss: -1.2382]\n",
      "2602 (5, 1) [D loss: (-1.5885)(R -2.2475, F 0.5574, G 0.0102)] [G loss: -0.3582]\n",
      "2603 (5, 1) [D loss: (-1.5075)(R -1.7769, F 0.1542, G 0.0115)] [G loss: -0.3199]\n",
      "2604 (5, 1) [D loss: (-1.3501)(R -1.3236, F -0.1289, G 0.0102)] [G loss: 0.1374]\n",
      "2605 (5, 1) [D loss: (-1.4997)(R -1.5995, F 0.0074, G 0.0092)] [G loss: -0.1795]\n",
      "2606 (5, 1) [D loss: (-1.3767)(R -1.4914, F 0.0105, G 0.0104)] [G loss: -0.0049]\n",
      "2607 (5, 1) [D loss: (-1.3029)(R -1.5748, F 0.1876, G 0.0084)] [G loss: -0.3516]\n",
      "2608 (5, 1) [D loss: (-1.6151)(R -2.8347, F 1.1166, G 0.0103)] [G loss: -1.3363]\n",
      "2609 (5, 1) [D loss: (-1.5659)(R -2.8786, F 1.2187, G 0.0094)] [G loss: -1.6802]\n",
      "2610 (5, 1) [D loss: (-1.5544)(R -3.5804, F 1.9249, G 0.0101)] [G loss: -2.3651]\n",
      "2611 (5, 1) [D loss: (-1.7261)(R -3.9500, F 2.1212, G 0.0103)] [G loss: -2.0090]\n",
      "2612 (5, 1) [D loss: (-1.3937)(R -3.5557, F 2.0567, G 0.0105)] [G loss: -2.0400]\n",
      "2613 (5, 1) [D loss: (-1.8504)(R -2.4940, F 0.5253, G 0.0118)] [G loss: -0.4237]\n",
      "2614 (5, 1) [D loss: (-1.5322)(R -0.8909, F -0.7411, G 0.0100)] [G loss: 1.2517]\n",
      "2615 (5, 1) [D loss: (-1.4080)(R 1.9872, F -3.4871, G 0.0092)] [G loss: 3.6204]\n",
      "2616 (5, 1) [D loss: (-1.3343)(R 2.1865, F -3.6362, G 0.0115)] [G loss: 3.5113]\n",
      "2617 (5, 1) [D loss: (-1.1961)(R 1.6699, F -2.9304, G 0.0064)] [G loss: 2.8198]\n",
      "2618 (5, 1) [D loss: (-1.4892)(R 0.7626, F -2.3483, G 0.0096)] [G loss: 2.5327]\n",
      "2619 (5, 1) [D loss: (-1.7062)(R 0.2031, F -1.9947, G 0.0085)] [G loss: 1.9050]\n",
      "2620 (5, 1) [D loss: (-1.3838)(R -0.3824, F -1.0918, G 0.0090)] [G loss: 0.8030]\n",
      "2621 (5, 1) [D loss: (-1.6101)(R -1.1512, F -0.5531, G 0.0094)] [G loss: 0.5913]\n",
      "2622 (5, 1) [D loss: (-1.4538)(R -1.0020, F -0.5617, G 0.0110)] [G loss: 0.7822]\n",
      "2623 (5, 1) [D loss: (-1.7281)(R -0.5929, F -1.2432, G 0.0108)] [G loss: 1.5779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624 (5, 1) [D loss: (-1.8959)(R 0.2213, F -2.2286, G 0.0111)] [G loss: 2.1583]\n",
      "2625 (5, 1) [D loss: (-1.6088)(R 1.5405, F -3.2755, G 0.0126)] [G loss: 3.3452]\n",
      "2626 (5, 1) [D loss: (-1.7677)(R 1.4823, F -3.3399, G 0.0090)] [G loss: 2.8286]\n",
      "2627 (5, 1) [D loss: (-1.5252)(R 0.3385, F -1.9458, G 0.0082)] [G loss: 1.4366]\n",
      "2628 (5, 1) [D loss: (-1.3338)(R -1.7651, F 0.3397, G 0.0092)] [G loss: -0.6047]\n",
      "2629 (5, 1) [D loss: (-1.3648)(R -3.2277, F 1.7821, G 0.0081)] [G loss: -2.1413]\n",
      "2630 (5, 1) [D loss: (-1.2713)(R -4.2675, F 2.8998, G 0.0096)] [G loss: -2.9172]\n",
      "2631 (5, 1) [D loss: (-1.5120)(R -4.1217, F 2.5193, G 0.0090)] [G loss: -2.4709]\n",
      "2632 (5, 1) [D loss: (-1.5582)(R -3.5118, F 1.8482, G 0.0105)] [G loss: -1.7816]\n",
      "2633 (5, 1) [D loss: (-1.7576)(R -2.6166, F 0.7652, G 0.0094)] [G loss: -0.2645]\n",
      "2634 (5, 1) [D loss: (-1.6192)(R -1.3692, F -0.3393, G 0.0089)] [G loss: 0.6499]\n",
      "2635 (5, 1) [D loss: (-1.4043)(R -0.1876, F -1.3320, G 0.0115)] [G loss: 1.5813]\n",
      "2636 (5, 1) [D loss: (-1.3638)(R 0.0799, F -1.5490, G 0.0105)] [G loss: 1.6114]\n",
      "2637 (5, 1) [D loss: (-1.4392)(R -0.1723, F -1.3664, G 0.0100)] [G loss: 0.7832]\n",
      "2638 (5, 1) [D loss: (-1.5887)(R -1.7151, F 0.0387, G 0.0088)] [G loss: -0.4827]\n",
      "2639 (5, 1) [D loss: (-1.3575)(R -2.7257, F 1.2599, G 0.0108)] [G loss: -1.2712]\n",
      "2640 (5, 1) [D loss: (-1.5231)(R -2.6989, F 1.0746, G 0.0101)] [G loss: -0.4603]\n",
      "2641 (5, 1) [D loss: (-1.3985)(R -1.4322, F -0.0451, G 0.0079)] [G loss: 0.0782]\n",
      "2642 (5, 1) [D loss: (-1.6080)(R -1.1725, F -0.5218, G 0.0086)] [G loss: 0.7523]\n",
      "2643 (5, 1) [D loss: (-1.4139)(R 1.0734, F -2.5771, G 0.0090)] [G loss: 2.7676]\n",
      "2644 (5, 1) [D loss: (-1.3905)(R 2.4996, F -4.0006, G 0.0111)] [G loss: 3.9280]\n",
      "2645 (5, 1) [D loss: (-1.2707)(R 2.2824, F -3.6631, G 0.0110)] [G loss: 3.6115]\n",
      "2646 (5, 1) [D loss: (-1.5805)(R 1.2382, F -2.9050, G 0.0086)] [G loss: 2.5966]\n",
      "2647 (5, 1) [D loss: (-1.0954)(R -1.1585, F -0.0425, G 0.0106)] [G loss: -0.3023]\n",
      "2648 (5, 1) [D loss: (-1.3214)(R -3.1552, F 1.7461, G 0.0088)] [G loss: -1.6709]\n",
      "2649 (5, 1) [D loss: (-1.6518)(R -5.6111, F 3.8581, G 0.0101)] [G loss: -4.6169]\n",
      "2650 (5, 1) [D loss: (-1.3253)(R -6.7601, F 5.3338, G 0.0101)] [G loss: -5.3043]\n",
      "2651 (5, 1) [D loss: (-1.6459)(R -7.9776, F 6.2336, G 0.0098)] [G loss: -6.3765]\n",
      "2652 (5, 1) [D loss: (-1.7201)(R -7.5447, F 5.7299, G 0.0095)] [G loss: -5.6630]\n",
      "2653 (5, 1) [D loss: (-1.6440)(R -5.2460, F 3.5216, G 0.0080)] [G loss: -3.1293]\n",
      "2654 (5, 1) [D loss: (-1.8754)(R -4.1309, F 2.1543, G 0.0101)] [G loss: -1.9908]\n",
      "2655 (5, 1) [D loss: (-1.9685)(R -3.7821, F 1.7306, G 0.0083)] [G loss: -1.7001]\n",
      "2656 (5, 1) [D loss: (-1.3967)(R -3.2855, F 1.7940, G 0.0095)] [G loss: -1.6853]\n",
      "2657 (5, 1) [D loss: (-1.4370)(R -3.1148, F 1.6153, G 0.0062)] [G loss: -1.5374]\n",
      "2658 (5, 1) [D loss: (-1.6617)(R -4.0039, F 2.2603, G 0.0082)] [G loss: -2.2778]\n",
      "2659 (5, 1) [D loss: (-1.5395)(R -4.9620, F 3.3395, G 0.0083)] [G loss: -3.4344]\n",
      "2660 (5, 1) [D loss: (-1.5157)(R -5.6732, F 4.0722, G 0.0085)] [G loss: -4.0494]\n",
      "2661 (5, 1) [D loss: (-1.4843)(R -5.1430, F 3.5467, G 0.0112)] [G loss: -2.9151]\n",
      "2662 (5, 1) [D loss: (-1.7818)(R -3.6662, F 1.7820, G 0.0102)] [G loss: -1.3956]\n",
      "2663 (5, 1) [D loss: (-1.4251)(R -1.4756, F -0.0501, G 0.0101)] [G loss: 0.4479]\n",
      "2664 (5, 1) [D loss: (-1.4294)(R -0.8510, F -0.6728, G 0.0094)] [G loss: 0.6581]\n",
      "2665 (5, 1) [D loss: (-1.1348)(R -0.4632, F -0.7567, G 0.0085)] [G loss: 1.4064]\n",
      "2666 (5, 1) [D loss: (-1.3322)(R -0.4245, F -0.9958, G 0.0088)] [G loss: 0.8547]\n",
      "2667 (5, 1) [D loss: (-1.4658)(R -2.5774, F 1.0179, G 0.0094)] [G loss: -1.7274]\n",
      "2668 (5, 1) [D loss: (-1.3564)(R -4.7203, F 3.2545, G 0.0109)] [G loss: -3.4542]\n",
      "2669 (5, 1) [D loss: (-1.7479)(R -6.3711, F 4.5304, G 0.0093)] [G loss: -5.0766]\n",
      "2670 (5, 1) [D loss: (-1.8409)(R -7.2994, F 5.3564, G 0.0102)] [G loss: -5.6268]\n",
      "2671 (5, 1) [D loss: (-1.3567)(R -6.5590, F 5.1172, G 0.0085)] [G loss: -4.6775]\n",
      "2672 (5, 1) [D loss: (-1.6628)(R -5.5570, F 3.8160, G 0.0078)] [G loss: -3.8093]\n",
      "2673 (5, 1) [D loss: (-1.5572)(R -4.2084, F 2.5674, G 0.0084)] [G loss: -2.5226]\n",
      "2674 (5, 1) [D loss: (-1.4422)(R -3.1463, F 1.6056, G 0.0098)] [G loss: -1.4205]\n",
      "2675 (5, 1) [D loss: (-1.4459)(R -2.0989, F 0.5497, G 0.0103)] [G loss: -0.5360]\n",
      "2676 (5, 1) [D loss: (-1.1740)(R -1.7230, F 0.4614, G 0.0088)] [G loss: -0.2165]\n",
      "2677 (5, 1) [D loss: (-1.2304)(R -2.0373, F 0.7314, G 0.0076)] [G loss: -0.8380]\n",
      "2678 (5, 1) [D loss: (-1.3213)(R -2.4677, F 1.0642, G 0.0082)] [G loss: -1.0278]\n",
      "2679 (5, 1) [D loss: (-1.4260)(R -3.2237, F 1.6999, G 0.0098)] [G loss: -1.8292]\n",
      "2680 (5, 1) [D loss: (-1.9643)(R -3.2925, F 1.2206, G 0.0108)] [G loss: -1.3851]\n",
      "2681 (5, 1) [D loss: (-1.5820)(R -2.6356, F 0.9578, G 0.0096)] [G loss: -0.6907]\n",
      "2682 (5, 1) [D loss: (-1.3510)(R -1.4705, F 0.0235, G 0.0096)] [G loss: 0.3616]\n",
      "2683 (5, 1) [D loss: (-1.2662)(R 0.5671, F -1.9561, G 0.0123)] [G loss: 2.0097]\n",
      "2684 (5, 1) [D loss: (-1.5937)(R 0.9599, F -2.6631, G 0.0110)] [G loss: 2.8742]\n",
      "2685 (5, 1) [D loss: (-1.4765)(R 1.7865, F -3.3743, G 0.0111)] [G loss: 3.3066]\n",
      "2686 (5, 1) [D loss: (-1.5314)(R 2.2471, F -3.8851, G 0.0107)] [G loss: 3.8620]\n",
      "2687 (5, 1) [D loss: (-0.8851)(R 2.4224, F -3.4095, G 0.0102)] [G loss: 3.4309]\n",
      "2688 (5, 1) [D loss: (-1.3157)(R 1.0355, F -2.4279, G 0.0077)] [G loss: 1.5345]\n",
      "2689 (5, 1) [D loss: (-1.2652)(R -0.9290, F -0.4481, G 0.0112)] [G loss: 0.2861]\n",
      "2690 (5, 1) [D loss: (-1.5650)(R -3.6000, F 1.9305, G 0.0105)] [G loss: -2.7549]\n",
      "2691 (5, 1) [D loss: (-1.4205)(R -5.2380, F 3.7183, G 0.0099)] [G loss: -3.4287]\n",
      "2692 (5, 1) [D loss: (-1.7966)(R -5.1475, F 3.2502, G 0.0101)] [G loss: -3.0788]\n",
      "2693 (5, 1) [D loss: (-1.7249)(R -3.2948, F 1.4746, G 0.0095)] [G loss: -1.3741]\n",
      "2694 (5, 1) [D loss: (-1.9085)(R -1.7230, F -0.3302, G 0.0145)] [G loss: 0.6015]\n",
      "2695 (5, 1) [D loss: (-1.5812)(R -0.5739, F -1.1587, G 0.0151)] [G loss: 1.4276]\n",
      "2696 (5, 1) [D loss: (-1.1771)(R 0.7475, F -2.0410, G 0.0116)] [G loss: 2.4737]\n",
      "2697 (5, 1) [D loss: (-1.1157)(R -0.0505, F -1.1620, G 0.0097)] [G loss: 1.1724]\n",
      "2698 (5, 1) [D loss: (-1.4125)(R -2.2234, F 0.7298, G 0.0081)] [G loss: -1.3899]\n",
      "2699 (5, 1) [D loss: (-1.5860)(R -4.7173, F 3.0414, G 0.0090)] [G loss: -3.2009]\n",
      "2700 (5, 1) [D loss: (-1.5829)(R -6.4325, F 4.7523, G 0.0097)] [G loss: -5.0703]\n",
      "2701 (5, 1) [D loss: (-1.5204)(R -6.4827, F 4.8620, G 0.0100)] [G loss: -4.7168]\n",
      "2702 (5, 1) [D loss: (-1.4995)(R -4.8159, F 3.2235, G 0.0093)] [G loss: -2.5743]\n",
      "2703 (5, 1) [D loss: (-1.3326)(R -1.9385, F 0.5272, G 0.0079)] [G loss: -0.0230]\n",
      "2704 (5, 1) [D loss: (-1.8323)(R 0.7733, F -2.7044, G 0.0099)] [G loss: 3.0597]\n",
      "2705 (5, 1) [D loss: (-1.9341)(R 3.4568, F -5.5013, G 0.0110)] [G loss: 5.5676]\n",
      "2706 (5, 1) [D loss: (-1.6824)(R 5.3664, F -7.2014, G 0.0153)] [G loss: 7.0252]\n",
      "2707 (5, 1) [D loss: (-1.3694)(R 4.7776, F -6.2467, G 0.0100)] [G loss: 6.0559]\n",
      "2708 (5, 1) [D loss: (-1.0480)(R 3.3714, F -4.5021, G 0.0083)] [G loss: 4.3453]\n",
      "2709 (5, 1) [D loss: (-1.2722)(R 1.3613, F -2.7058, G 0.0072)] [G loss: 2.0412]\n",
      "2710 (5, 1) [D loss: (-1.4814)(R -2.1590, F 0.5949, G 0.0083)] [G loss: -1.0700]\n",
      "2711 (5, 1) [D loss: (-2.0436)(R -5.3543, F 3.1978, G 0.0113)] [G loss: -3.4104]\n",
      "2712 (5, 1) [D loss: (-1.3085)(R -4.8141, F 3.3827, G 0.0123)] [G loss: -2.9905]\n",
      "2713 (5, 1) [D loss: (-1.8184)(R -3.1720, F 1.2613, G 0.0092)] [G loss: -1.1206]\n",
      "2714 (5, 1) [D loss: (-1.7160)(R -1.4412, F -0.3701, G 0.0095)] [G loss: 1.2268]\n",
      "2715 (5, 1) [D loss: (-1.7836)(R 1.2734, F -3.1783, G 0.0121)] [G loss: 3.3448]\n",
      "2716 (5, 1) [D loss: (-2.0199)(R 3.2134, F -5.3787, G 0.0145)] [G loss: 5.7560]\n",
      "2717 (5, 1) [D loss: (-1.3005)(R 4.3658, F -5.7867, G 0.0120)] [G loss: 5.7859]\n",
      "2718 (5, 1) [D loss: (-1.2053)(R 3.1494, F -4.4371, G 0.0082)] [G loss: 4.3278]\n",
      "2719 (5, 1) [D loss: (-1.2676)(R 0.8041, F -2.1328, G 0.0061)] [G loss: 1.5043]\n",
      "2720 (5, 1) [D loss: (-1.4731)(R -3.0604, F 1.5012, G 0.0086)] [G loss: -1.9747]\n",
      "2721 (5, 1) [D loss: (-1.8209)(R -6.4771, F 4.5664, G 0.0090)] [G loss: -5.2457]\n",
      "2722 (5, 1) [D loss: (-2.1319)(R -8.0166, F 5.7581, G 0.0127)] [G loss: -6.1229]\n",
      "2723 (5, 1) [D loss: (-1.6456)(R -8.6702, F 6.9137, G 0.0111)] [G loss: -6.4638]\n",
      "2724 (5, 1) [D loss: (-1.6912)(R -7.3482, F 5.5668, G 0.0090)] [G loss: -5.2493]\n",
      "2725 (5, 1) [D loss: (-1.6777)(R -4.4194, F 2.6670, G 0.0075)] [G loss: -2.0728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726 (5, 1) [D loss: (-1.5904)(R -1.9601, F 0.2857, G 0.0084)] [G loss: 0.7220]\n",
      "2727 (5, 1) [D loss: (-1.9455)(R 0.8766, F -2.9360, G 0.0114)] [G loss: 3.5098]\n",
      "2728 (5, 1) [D loss: (-1.4710)(R 3.0032, F -4.6073, G 0.0133)] [G loss: 5.0138]\n",
      "2729 (5, 1) [D loss: (-1.1674)(R 1.6213, F -2.8838, G 0.0095)] [G loss: 2.7825]\n",
      "2730 (5, 1) [D loss: (-1.3059)(R -0.9156, F -0.4665, G 0.0076)] [G loss: -0.4148]\n",
      "2731 (5, 1) [D loss: (-1.5333)(R -3.9921, F 2.3812, G 0.0078)] [G loss: -2.7211]\n",
      "2732 (5, 1) [D loss: (-1.6230)(R -7.1692, F 5.4259, G 0.0120)] [G loss: -6.0072]\n",
      "2733 (5, 1) [D loss: (-1.6913)(R -7.8176, F 6.0254, G 0.0101)] [G loss: -6.0310]\n",
      "2734 (5, 1) [D loss: (-1.3338)(R -6.6976, F 5.2647, G 0.0099)] [G loss: -4.8078]\n",
      "2735 (5, 1) [D loss: (-1.3774)(R -5.9183, F 4.4381, G 0.0103)] [G loss: -3.9218]\n",
      "2736 (5, 1) [D loss: (-1.5243)(R -3.1499, F 1.5401, G 0.0086)] [G loss: -0.7447]\n",
      "2737 (5, 1) [D loss: (-1.6458)(R 0.4956, F -2.2394, G 0.0098)] [G loss: 2.6591]\n",
      "2738 (5, 1) [D loss: (-1.2498)(R 2.3741, F -3.7394, G 0.0116)] [G loss: 3.5205]\n",
      "2739 (5, 1) [D loss: (-1.2145)(R 2.6669, F -3.9789, G 0.0097)] [G loss: 4.0301]\n",
      "2740 (5, 1) [D loss: (-1.2473)(R 1.9182, F -3.2266, G 0.0061)] [G loss: 2.9714]\n",
      "2741 (5, 1) [D loss: (-1.6008)(R 1.0740, F -2.7277, G 0.0053)] [G loss: 2.4679]\n",
      "2742 (5, 1) [D loss: (-1.6565)(R -0.0645, F -1.6814, G 0.0089)] [G loss: 1.1917]\n",
      "2743 (5, 1) [D loss: (-1.7445)(R -0.0696, F -1.7687, G 0.0094)] [G loss: 1.3480]\n",
      "2744 (5, 1) [D loss: (-1.4403)(R -1.5817, F 0.0321, G 0.0109)] [G loss: -0.3341]\n",
      "2745 (5, 1) [D loss: (-1.7007)(R -2.3835, F 0.5885, G 0.0094)] [G loss: -0.5151]\n",
      "2746 (5, 1) [D loss: (-1.8248)(R -0.4724, F -1.4525, G 0.0100)] [G loss: 1.6912]\n",
      "2747 (5, 1) [D loss: (-1.8452)(R 0.8457, F -2.8050, G 0.0114)] [G loss: 2.9944]\n",
      "2748 (5, 1) [D loss: (-1.2079)(R 2.8470, F -4.2193, G 0.0164)] [G loss: 4.4198]\n",
      "2749 (5, 1) [D loss: (-1.6493)(R 3.0185, F -4.7465, G 0.0079)] [G loss: 5.1280]\n",
      "2750 (5, 1) [D loss: (-1.0635)(R 2.9549, F -4.0990, G 0.0081)] [G loss: 3.9340]\n",
      "2751 (5, 1) [D loss: (-1.0622)(R 0.5231, F -1.6393, G 0.0054)] [G loss: 1.2123]\n",
      "2752 (5, 1) [D loss: (-1.3314)(R -1.9121, F 0.4986, G 0.0082)] [G loss: -1.0733]\n",
      "2753 (5, 1) [D loss: (-1.6564)(R -3.9044, F 2.1728, G 0.0075)] [G loss: -2.5454]\n",
      "2754 (5, 1) [D loss: (-1.7529)(R -6.1226, F 4.2233, G 0.0146)] [G loss: -4.4349]\n",
      "2755 (5, 1) [D loss: (-2.3440)(R -6.8731, F 4.4175, G 0.0112)] [G loss: -4.6948]\n",
      "2756 (5, 1) [D loss: (-1.4428)(R -6.0325, F 4.4737, G 0.0116)] [G loss: -4.1176]\n",
      "2757 (5, 1) [D loss: (-1.7897)(R -4.8751, F 2.9792, G 0.0106)] [G loss: -2.8973]\n",
      "2758 (5, 1) [D loss: (-1.9177)(R -4.0257, F 2.0121, G 0.0096)] [G loss: -2.3540]\n",
      "2759 (5, 1) [D loss: (-1.4181)(R -2.2736, F 0.7441, G 0.0111)] [G loss: -0.3832]\n",
      "2760 (5, 1) [D loss: (-0.9169)(R -1.4548, F 0.4631, G 0.0075)] [G loss: -0.2023]\n",
      "2761 (5, 1) [D loss: (-1.0980)(R -2.2703, F 1.1050, G 0.0067)] [G loss: -1.1017]\n",
      "2762 (5, 1) [D loss: (-1.0481)(R -3.2570, F 2.1461, G 0.0063)] [G loss: -2.0971]\n",
      "2763 (5, 1) [D loss: (-1.6384)(R -3.2956, F 1.5884, G 0.0069)] [G loss: -1.4870]\n",
      "2764 (5, 1) [D loss: (-1.7122)(R -2.6827, F 0.8851, G 0.0085)] [G loss: -0.3096]\n",
      "2765 (5, 1) [D loss: (-1.9935)(R -2.4783, F 0.3640, G 0.0121)] [G loss: -0.1375]\n",
      "2766 (5, 1) [D loss: (-1.8139)(R -1.2760, F -0.6566, G 0.0119)] [G loss: 1.3340]\n",
      "2767 (5, 1) [D loss: (-1.9280)(R -0.3396, F -1.6896, G 0.0101)] [G loss: 2.1077]\n",
      "2768 (5, 1) [D loss: (-2.0410)(R 1.6149, F -3.7588, G 0.0103)] [G loss: 4.5849]\n",
      "2769 (5, 1) [D loss: (-2.1791)(R 3.3857, F -5.6780, G 0.0113)] [G loss: 6.1113]\n",
      "2770 (5, 1) [D loss: (-1.5937)(R 5.4338, F -7.1662, G 0.0139)] [G loss: 6.9650]\n",
      "2771 (5, 1) [D loss: (-1.1544)(R 4.4266, F -5.6657, G 0.0085)] [G loss: 5.3452]\n",
      "2772 (5, 1) [D loss: (-1.2131)(R 1.4476, F -2.7210, G 0.0060)] [G loss: 2.2823]\n",
      "2773 (5, 1) [D loss: (-1.5079)(R -2.5455, F 0.9727, G 0.0065)] [G loss: -1.8733]\n",
      "2774 (5, 1) [D loss: (-1.8855)(R -6.1045, F 4.1262, G 0.0093)] [G loss: -5.1546]\n",
      "2775 (5, 1) [D loss: (-1.7038)(R -8.8929, F 7.0236, G 0.0165)] [G loss: -7.2746]\n",
      "2776 (5, 1) [D loss: (-1.8906)(R -9.2900, F 7.2481, G 0.0151)] [G loss: -7.4068]\n",
      "2777 (5, 1) [D loss: (-2.3258)(R -8.1905, F 5.7657, G 0.0099)] [G loss: -6.3097]\n",
      "2778 (5, 1) [D loss: (-2.1403)(R -6.9871, F 4.7528, G 0.0094)] [G loss: -4.4674]\n",
      "2779 (5, 1) [D loss: (-2.0786)(R -4.0495, F 1.8613, G 0.0110)] [G loss: -1.5440]\n",
      "2780 (5, 1) [D loss: (-2.3761)(R -1.7011, F -0.8129, G 0.0138)] [G loss: 1.0002]\n",
      "2781 (5, 1) [D loss: (-1.6068)(R 0.8240, F -2.5603, G 0.0130)] [G loss: 2.2264]\n",
      "2782 (5, 1) [D loss: (-0.9680)(R 0.0136, F -1.0632, G 0.0082)] [G loss: 1.2633]\n",
      "2783 (5, 1) [D loss: (-1.3686)(R -2.5840, F 1.1611, G 0.0054)] [G loss: -1.6841]\n",
      "2784 (5, 1) [D loss: (-1.3207)(R -4.7500, F 3.3517, G 0.0078)] [G loss: -4.3867]\n",
      "2785 (5, 1) [D loss: (-2.0118)(R -8.0222, F 5.8973, G 0.0113)] [G loss: -6.5575]\n",
      "2786 (5, 1) [D loss: (-2.1982)(R -9.5877, F 7.2525, G 0.0137)] [G loss: -7.7777]\n",
      "2787 (5, 1) [D loss: (-1.5803)(R -8.2985, F 6.5918, G 0.0126)] [G loss: -6.2322]\n",
      "2788 (5, 1) [D loss: (-2.2670)(R -7.6247, F 5.2753, G 0.0082)] [G loss: -5.3798]\n",
      "2789 (5, 1) [D loss: (-1.7068)(R -4.5504, F 2.7879, G 0.0056)] [G loss: -2.1703]\n",
      "2790 (5, 1) [D loss: (-2.1291)(R -1.2369, F -0.9761, G 0.0084)] [G loss: 1.6940]\n",
      "2791 (5, 1) [D loss: (-1.5548)(R 2.3574, F -4.0163, G 0.0104)] [G loss: 4.7905]\n",
      "2792 (5, 1) [D loss: (-1.7250)(R 3.9391, F -5.7901, G 0.0126)] [G loss: 5.8788]\n",
      "2793 (5, 1) [D loss: (-1.1300)(R 3.2494, F -4.4787, G 0.0099)] [G loss: 4.2787]\n",
      "2794 (5, 1) [D loss: (-1.3194)(R 1.6520, F -3.0427, G 0.0071)] [G loss: 2.6836]\n",
      "2795 (5, 1) [D loss: (-0.8086)(R 0.3237, F -1.2135, G 0.0081)] [G loss: 1.1519]\n",
      "2796 (5, 1) [D loss: (-1.4667)(R -2.5971, F 1.0480, G 0.0082)] [G loss: -1.4618]\n",
      "2797 (5, 1) [D loss: (-1.5534)(R -4.4019, F 2.7481, G 0.0100)] [G loss: -2.8661]\n",
      "2798 (5, 1) [D loss: (-1.5271)(R -5.5923, F 3.9676, G 0.0098)] [G loss: -4.1963]\n",
      "2799 (5, 1) [D loss: (-1.5204)(R -6.2981, F 4.6413, G 0.0136)] [G loss: -4.3383]\n",
      "2800 (5, 1) [D loss: (-1.8658)(R -5.4080, F 3.4272, G 0.0115)] [G loss: -3.4900]\n",
      "2801 (5, 1) [D loss: (-1.3152)(R -3.2851, F 1.8974, G 0.0072)] [G loss: -1.8111]\n",
      "2802 (5, 1) [D loss: (-1.6434)(R -2.2216, F 0.4744, G 0.0104)] [G loss: -0.2244]\n",
      "2803 (5, 1) [D loss: (-1.2744)(R -0.1644, F -1.2182, G 0.0108)] [G loss: 1.7728]\n",
      "2804 (5, 1) [D loss: (-1.7581)(R 1.5493, F -3.4061, G 0.0099)] [G loss: 3.8392]\n",
      "2805 (5, 1) [D loss: (-1.4249)(R 2.4417, F -3.9595, G 0.0093)] [G loss: 3.9678]\n",
      "2806 (5, 1) [D loss: (-1.3206)(R 2.8492, F -4.2698, G 0.0100)] [G loss: 4.3087]\n",
      "2807 (5, 1) [D loss: (-1.3390)(R 2.2973, F -3.7081, G 0.0072)] [G loss: 3.5032]\n",
      "2808 (5, 1) [D loss: (-1.2445)(R 0.5246, F -1.8428, G 0.0074)] [G loss: 1.6251]\n",
      "2809 (5, 1) [D loss: (-1.1335)(R -0.4874, F -0.7138, G 0.0068)] [G loss: 0.1067]\n",
      "2810 (5, 1) [D loss: (-1.5984)(R -3.0256, F 1.3277, G 0.0100)] [G loss: -1.7078]\n",
      "2811 (5, 1) [D loss: (-1.7087)(R -4.3974, F 2.5832, G 0.0105)] [G loss: -2.6694]\n",
      "2812 (5, 1) [D loss: (-1.7699)(R -5.3923, F 3.5140, G 0.0108)] [G loss: -3.5872]\n",
      "2813 (5, 1) [D loss: (-1.6386)(R -5.5417, F 3.7846, G 0.0118)] [G loss: -3.3161]\n",
      "2814 (5, 1) [D loss: (-1.4900)(R -3.4730, F 1.9006, G 0.0082)] [G loss: -1.4272]\n",
      "2815 (5, 1) [D loss: (-1.2048)(R -1.5418, F 0.2670, G 0.0070)] [G loss: 0.4139]\n",
      "2816 (5, 1) [D loss: (-1.6736)(R -0.1207, F -1.6411, G 0.0088)] [G loss: 2.0202]\n",
      "2817 (5, 1) [D loss: (-1.1488)(R 1.9079, F -3.1538, G 0.0097)] [G loss: 3.2304]\n",
      "2818 (5, 1) [D loss: (-1.3309)(R 2.1419, F -3.5517, G 0.0079)] [G loss: 3.2475]\n",
      "2819 (5, 1) [D loss: (-1.3311)(R 1.2901, F -2.7038, G 0.0083)] [G loss: 2.5427]\n",
      "2820 (5, 1) [D loss: (-1.4006)(R -0.5322, F -0.9602, G 0.0092)] [G loss: 0.5158]\n",
      "2821 (5, 1) [D loss: (-1.4527)(R -1.9780, F 0.4423, G 0.0083)] [G loss: -0.7303]\n",
      "2822 (5, 1) [D loss: (-1.3800)(R -2.6333, F 1.1605, G 0.0093)] [G loss: -1.1723]\n",
      "2823 (5, 1) [D loss: (-1.5460)(R -2.6495, F 0.9848, G 0.0119)] [G loss: -0.9703]\n",
      "2824 (5, 1) [D loss: (-1.7253)(R -2.3652, F 0.5356, G 0.0104)] [G loss: -0.5341]\n",
      "2825 (5, 1) [D loss: (-1.3058)(R -1.9625, F 0.5436, G 0.0113)] [G loss: 0.0252]\n",
      "2826 (5, 1) [D loss: (-1.8029)(R -1.2158, F -0.6795, G 0.0092)] [G loss: 1.0595]\n",
      "2827 (5, 1) [D loss: (-1.3920)(R 0.7131, F -2.2142, G 0.0109)] [G loss: 2.1785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2828 (5, 1) [D loss: (-1.7001)(R 1.3921, F -3.2074, G 0.0115)] [G loss: 3.0343]\n",
      "2829 (5, 1) [D loss: (-1.1644)(R 3.0283, F -4.2955, G 0.0103)] [G loss: 4.3641]\n",
      "2830 (5, 1) [D loss: (-1.3128)(R 3.2140, F -4.6217, G 0.0095)] [G loss: 4.5378]\n",
      "2831 (5, 1) [D loss: (-1.0779)(R 3.6579, F -4.8248, G 0.0089)] [G loss: 4.7101]\n",
      "2832 (5, 1) [D loss: (-1.4795)(R 2.8745, F -4.4257, G 0.0072)] [G loss: 4.3019]\n",
      "2833 (5, 1) [D loss: (-1.1381)(R 2.8470, F -4.0766, G 0.0091)] [G loss: 3.6478]\n",
      "2834 (5, 1) [D loss: (-1.3075)(R 1.3461, F -2.7149, G 0.0061)] [G loss: 2.4489]\n",
      "2835 (5, 1) [D loss: (-1.1158)(R 0.0363, F -1.2414, G 0.0089)] [G loss: 1.0154]\n",
      "2836 (5, 1) [D loss: (-1.4281)(R -0.1895, F -1.3078, G 0.0069)] [G loss: 1.3381]\n",
      "2837 (5, 1) [D loss: (-1.5265)(R -0.3348, F -1.2840, G 0.0092)] [G loss: 1.4797]\n",
      "2838 (5, 1) [D loss: (-1.4324)(R 0.2684, F -1.7946, G 0.0094)] [G loss: 2.2493]\n",
      "2839 (5, 1) [D loss: (-1.7034)(R 1.6256, F -3.4175, G 0.0088)] [G loss: 3.7158]\n",
      "2840 (5, 1) [D loss: (-1.5735)(R 2.9262, F -4.6463, G 0.0147)] [G loss: 4.7007]\n",
      "2841 (5, 1) [D loss: (-1.4922)(R 2.4541, F -4.0406, G 0.0094)] [G loss: 3.8619]\n",
      "2842 (5, 1) [D loss: (-1.5331)(R 2.0601, F -3.6918, G 0.0099)] [G loss: 3.5507]\n",
      "2843 (5, 1) [D loss: (-1.2610)(R 1.0886, F -2.4161, G 0.0066)] [G loss: 1.8645]\n",
      "2844 (5, 1) [D loss: (-1.0471)(R -0.2329, F -0.9002, G 0.0086)] [G loss: 0.5519]\n",
      "2845 (5, 1) [D loss: (-1.0559)(R -1.5428, F 0.4073, G 0.0080)] [G loss: -0.5271]\n",
      "2846 (5, 1) [D loss: (-1.3485)(R -2.1826, F 0.7444, G 0.0090)] [G loss: -0.8491]\n",
      "2847 (5, 1) [D loss: (-1.3436)(R -1.4508, F 0.0060, G 0.0101)] [G loss: -0.1719]\n",
      "2848 (5, 1) [D loss: (-1.7705)(R -1.2924, F -0.5703, G 0.0092)] [G loss: 0.4502]\n",
      "2849 (5, 1) [D loss: (-1.6103)(R -0.2713, F -1.4365, G 0.0097)] [G loss: 1.0896]\n",
      "2850 (5, 1) [D loss: (-1.7776)(R 0.1742, F -2.0331, G 0.0081)] [G loss: 2.2083]\n",
      "2851 (5, 1) [D loss: (-1.7718)(R 0.3568, F -2.2324, G 0.0104)] [G loss: 2.1758]\n",
      "2852 (5, 1) [D loss: (-1.5576)(R -0.6637, F -0.9880, G 0.0094)] [G loss: 1.0188]\n",
      "2853 (5, 1) [D loss: (-1.7463)(R -1.6532, F -0.1737, G 0.0081)] [G loss: -0.2291]\n",
      "2854 (5, 1) [D loss: (-1.5373)(R -1.9564, F 0.3412, G 0.0078)] [G loss: -0.5971]\n",
      "2855 (5, 1) [D loss: (-1.1833)(R -2.8295, F 1.5675, G 0.0079)] [G loss: -1.3910]\n",
      "2856 (5, 1) [D loss: (-0.9674)(R -2.3179, F 1.2818, G 0.0069)] [G loss: -1.0980]\n",
      "2857 (5, 1) [D loss: (-1.0985)(R -1.8456, F 0.6706, G 0.0076)] [G loss: -0.8415]\n",
      "2858 (5, 1) [D loss: (-1.4134)(R -1.7131, F 0.2250, G 0.0075)] [G loss: -0.2680]\n",
      "2859 (5, 1) [D loss: (-1.3873)(R -1.8410, F 0.3799, G 0.0074)] [G loss: -0.6381]\n",
      "2860 (5, 1) [D loss: (-1.3137)(R -1.2529, F -0.1388, G 0.0078)] [G loss: -0.2934]\n",
      "2861 (5, 1) [D loss: (-1.4286)(R -1.9960, F 0.4751, G 0.0092)] [G loss: -0.5769]\n",
      "2862 (5, 1) [D loss: (-1.5106)(R -1.8268, F 0.2153, G 0.0101)] [G loss: -0.0848]\n",
      "2863 (5, 1) [D loss: (-1.5675)(R -2.0883, F 0.4356, G 0.0085)] [G loss: -0.2525]\n",
      "2864 (5, 1) [D loss: (-1.8692)(R -2.5044, F 0.5354, G 0.0100)] [G loss: -1.0366]\n",
      "2865 (5, 1) [D loss: (-1.5269)(R -2.7693, F 1.1502, G 0.0092)] [G loss: -1.2459]\n",
      "2866 (5, 1) [D loss: (-1.5724)(R -3.8005, F 2.1192, G 0.0109)] [G loss: -2.5441]\n",
      "2867 (5, 1) [D loss: (-1.4123)(R -4.3561, F 2.8551, G 0.0089)] [G loss: -3.1055]\n",
      "2868 (5, 1) [D loss: (-1.2873)(R -4.4145, F 3.0508, G 0.0076)] [G loss: -2.7106]\n",
      "2869 (5, 1) [D loss: (-1.4498)(R -3.9247, F 2.3817, G 0.0093)] [G loss: -2.2910]\n",
      "2870 (5, 1) [D loss: (-1.2901)(R -2.8192, F 1.4528, G 0.0076)] [G loss: -1.3162]\n",
      "2871 (5, 1) [D loss: (-1.3453)(R -1.5641, F 0.1436, G 0.0075)] [G loss: -0.1057]\n",
      "2872 (5, 1) [D loss: (-1.5940)(R -0.6960, F -0.9800, G 0.0082)] [G loss: 1.0720]\n",
      "2873 (5, 1) [D loss: (-1.3435)(R -0.0537, F -1.3832, G 0.0093)] [G loss: 1.6089]\n",
      "2874 (5, 1) [D loss: (-1.8586)(R 0.1857, F -2.1471, G 0.0103)] [G loss: 2.1012]\n",
      "2875 (5, 1) [D loss: (-1.5618)(R 0.1869, F -1.8499, G 0.0101)] [G loss: 2.0872]\n",
      "2876 (5, 1) [D loss: (-1.3841)(R -0.2178, F -1.2521, G 0.0086)] [G loss: 0.9793]\n",
      "2877 (5, 1) [D loss: (-1.4298)(R -0.0522, F -1.4758, G 0.0098)] [G loss: 1.6073]\n",
      "2878 (5, 1) [D loss: (-1.2659)(R -0.1026, F -1.2477, G 0.0084)] [G loss: 0.9805]\n",
      "2879 (5, 1) [D loss: (-1.3279)(R -1.4531, F 0.0374, G 0.0088)] [G loss: -0.2877]\n",
      "2880 (5, 1) [D loss: (-1.4257)(R -1.6331, F 0.1344, G 0.0073)] [G loss: -0.0712]\n",
      "2881 (5, 1) [D loss: (-0.8944)(R -0.9491, F -0.0242, G 0.0079)] [G loss: -0.0834]\n",
      "2882 (5, 1) [D loss: (-1.3335)(R -1.9449, F 0.5308, G 0.0081)] [G loss: -0.5548]\n",
      "2883 (5, 1) [D loss: (-1.0950)(R -1.5562, F 0.3722, G 0.0089)] [G loss: 0.1006]\n",
      "2884 (5, 1) [D loss: (-1.4338)(R -0.6131, F -0.9154, G 0.0095)] [G loss: 1.2240]\n",
      "2885 (5, 1) [D loss: (-1.7350)(R 0.8824, F -2.7083, G 0.0091)] [G loss: 2.9202]\n",
      "2886 (5, 1) [D loss: (-1.4710)(R 1.6914, F -3.2657, G 0.0103)] [G loss: 3.4829]\n",
      "2887 (5, 1) [D loss: (-1.3608)(R 1.0015, F -2.4570, G 0.0095)] [G loss: 2.3675]\n",
      "2888 (5, 1) [D loss: (-1.3381)(R 0.7138, F -2.1330, G 0.0081)] [G loss: 2.0868]\n",
      "2889 (5, 1) [D loss: (-1.4567)(R -0.5646, F -0.9825, G 0.0090)] [G loss: 0.9857]\n",
      "2890 (5, 1) [D loss: (-1.3142)(R -1.8752, F 0.4799, G 0.0081)] [G loss: -1.0811]\n",
      "2891 (5, 1) [D loss: (-1.3111)(R -3.5279, F 2.1344, G 0.0082)] [G loss: -2.4843]\n",
      "2892 (5, 1) [D loss: (-1.3155)(R -3.7036, F 2.2976, G 0.0090)] [G loss: -2.3697]\n",
      "2893 (5, 1) [D loss: (-1.0881)(R -2.8353, F 1.6727, G 0.0074)] [G loss: -1.1948]\n",
      "2894 (5, 1) [D loss: (-1.1881)(R -1.6207, F 0.3691, G 0.0064)] [G loss: -0.0280]\n",
      "2895 (5, 1) [D loss: (-1.2306)(R -0.2499, F -1.0649, G 0.0084)] [G loss: 1.0423]\n",
      "2896 (5, 1) [D loss: (-1.6696)(R 0.6417, F -2.4133, G 0.0102)] [G loss: 2.4650]\n",
      "2897 (5, 1) [D loss: (-1.8408)(R 1.2774, F -3.2038, G 0.0086)] [G loss: 3.6319]\n",
      "2898 (5, 1) [D loss: (-1.0315)(R 2.6673, F -3.7947, G 0.0096)] [G loss: 3.8791]\n",
      "2899 (5, 1) [D loss: (-1.4597)(R 1.3612, F -2.9062, G 0.0085)] [G loss: 2.7273]\n",
      "2900 (5, 1) [D loss: (-1.2172)(R 0.2494, F -1.5578, G 0.0091)] [G loss: 1.0328]\n",
      "2901 (5, 1) [D loss: (-1.4929)(R -1.8586, F 0.2606, G 0.0105)] [G loss: -0.5233]\n",
      "2902 (5, 1) [D loss: (-1.5056)(R -3.3247, F 1.7301, G 0.0089)] [G loss: -1.8986]\n",
      "2903 (5, 1) [D loss: (-1.2781)(R -3.3081, F 1.9152, G 0.0115)] [G loss: -2.0959]\n",
      "2904 (5, 1) [D loss: (-1.4170)(R -4.4797, F 2.9648, G 0.0098)] [G loss: -3.1518]\n",
      "2905 (5, 1) [D loss: (-1.0396)(R -5.0024, F 3.8642, G 0.0099)] [G loss: -3.7514]\n",
      "2906 (5, 1) [D loss: (-1.3552)(R -5.0697, F 3.6348, G 0.0080)] [G loss: -3.4078]\n",
      "2907 (5, 1) [D loss: (-1.3645)(R -4.4223, F 2.9809, G 0.0077)] [G loss: -2.9629]\n",
      "2908 (5, 1) [D loss: (-1.2906)(R -3.5786, F 2.2102, G 0.0078)] [G loss: -1.9828]\n",
      "2909 (5, 1) [D loss: (-1.6094)(R -2.2253, F 0.5504, G 0.0066)] [G loss: -0.4535]\n",
      "2910 (5, 1) [D loss: (-1.6473)(R -1.8046, F 0.0661, G 0.0091)] [G loss: -0.1362]\n",
      "2911 (5, 1) [D loss: (-1.3954)(R -0.8443, F -0.6494, G 0.0098)] [G loss: 0.9471]\n",
      "2912 (5, 1) [D loss: (-1.2865)(R -1.2633, F -0.1084, G 0.0085)] [G loss: 0.2323]\n",
      "2913 (5, 1) [D loss: (-1.3394)(R -0.4000, F -1.0393, G 0.0100)] [G loss: 1.2710]\n",
      "2914 (5, 1) [D loss: (-1.3541)(R -1.1649, F -0.2773, G 0.0088)] [G loss: 0.1627]\n",
      "2915 (5, 1) [D loss: (-1.3463)(R -1.6783, F 0.2447, G 0.0087)] [G loss: -0.2595]\n",
      "2916 (5, 1) [D loss: (-1.4954)(R -1.9536, F 0.3567, G 0.0102)] [G loss: -0.5617]\n",
      "2917 (5, 1) [D loss: (-1.3107)(R -1.6501, F 0.2439, G 0.0096)] [G loss: -0.0257]\n",
      "2918 (5, 1) [D loss: (-1.2668)(R -0.6149, F -0.7363, G 0.0084)] [G loss: 1.4698]\n",
      "2919 (5, 1) [D loss: (-1.4362)(R 1.2121, F -2.7430, G 0.0095)] [G loss: 2.4291]\n",
      "2920 (5, 1) [D loss: (-1.3764)(R 2.2605, F -3.7169, G 0.0080)] [G loss: 3.7120]\n",
      "2921 (5, 1) [D loss: (-1.3923)(R 2.9167, F -4.4202, G 0.0111)] [G loss: 4.7820]\n",
      "2922 (5, 1) [D loss: (-1.6269)(R 3.1168, F -4.8330, G 0.0089)] [G loss: 4.8793]\n",
      "2923 (5, 1) [D loss: (-1.3659)(R 3.3506, F -4.8176, G 0.0101)] [G loss: 4.7310]\n",
      "2924 (5, 1) [D loss: (-1.7277)(R 1.9935, F -3.8216, G 0.0100)] [G loss: 3.5704]\n",
      "2925 (5, 1) [D loss: (-1.5822)(R 1.3113, F -3.0011, G 0.0108)] [G loss: 2.7892]\n",
      "2926 (5, 1) [D loss: (-1.6507)(R 0.1234, F -1.8680, G 0.0094)] [G loss: 1.6655]\n",
      "2927 (5, 1) [D loss: (-1.4920)(R -0.2575, F -1.3281, G 0.0094)] [G loss: 1.1820]\n",
      "2928 (5, 1) [D loss: (-1.4902)(R -0.9034, F -0.6712, G 0.0084)] [G loss: 0.6381]\n",
      "2929 (5, 1) [D loss: (-1.6662)(R -1.9646, F 0.2235, G 0.0075)] [G loss: -0.4001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2930 (5, 1) [D loss: (-1.6817)(R -3.3348, F 1.5355, G 0.0118)] [G loss: -1.9582]\n",
      "2931 (5, 1) [D loss: (-1.4861)(R -4.8532, F 3.2702, G 0.0097)] [G loss: -4.0984]\n",
      "2932 (5, 1) [D loss: (-1.6422)(R -6.2659, F 4.5282, G 0.0096)] [G loss: -5.1215]\n",
      "2933 (5, 1) [D loss: (-1.9318)(R -7.6307, F 5.5890, G 0.0110)] [G loss: -6.2649]\n",
      "2934 (5, 1) [D loss: (-1.5881)(R -7.6137, F 5.9226, G 0.0103)] [G loss: -5.6657]\n",
      "2935 (5, 1) [D loss: (-1.9424)(R -8.2852, F 6.2443, G 0.0099)] [G loss: -6.9257]\n",
      "2936 (5, 1) [D loss: (-1.7442)(R -8.2671, F 6.4315, G 0.0091)] [G loss: -6.4040]\n",
      "2937 (5, 1) [D loss: (-1.8558)(R -7.3559, F 5.4251, G 0.0075)] [G loss: -5.3418]\n",
      "2938 (5, 1) [D loss: (-1.3514)(R -5.7700, F 4.3467, G 0.0072)] [G loss: -3.9348]\n",
      "2939 (5, 1) [D loss: (-1.4734)(R -4.7927, F 3.2374, G 0.0082)] [G loss: -2.9660]\n",
      "2940 (5, 1) [D loss: (-1.1610)(R -3.1995, F 1.9474, G 0.0091)] [G loss: -1.7182]\n",
      "2941 (5, 1) [D loss: (-1.2346)(R -2.5094, F 1.2054, G 0.0069)] [G loss: -1.1784]\n",
      "2942 (5, 1) [D loss: (-1.4921)(R -2.1212, F 0.5687, G 0.0060)] [G loss: -0.5927]\n",
      "2943 (5, 1) [D loss: (-1.2179)(R -1.7737, F 0.4722, G 0.0084)] [G loss: -0.4257]\n",
      "2944 (5, 1) [D loss: (-1.3467)(R -1.7781, F 0.3456, G 0.0086)] [G loss: -0.2551]\n",
      "2945 (5, 1) [D loss: (-1.4419)(R -0.4643, F -1.0651, G 0.0088)] [G loss: 1.2454]\n",
      "2946 (5, 1) [D loss: (-1.6778)(R 1.3452, F -3.1129, G 0.0090)] [G loss: 3.1500]\n",
      "2947 (5, 1) [D loss: (-1.7407)(R 3.0835, F -4.9456, G 0.0121)] [G loss: 5.4655]\n",
      "2948 (5, 1) [D loss: (-2.0219)(R 5.2574, F -7.4171, G 0.0138)] [G loss: 7.8932]\n",
      "2949 (5, 1) [D loss: (-1.8506)(R 8.1791, F -10.1988, G 0.0169)] [G loss: 10.2261]\n",
      "2950 (5, 1) [D loss: (-1.5009)(R 9.7119, F -11.3639, G 0.0151)] [G loss: 11.0669]\n",
      "2951 (5, 1) [D loss: (-1.4168)(R 9.9847, F -11.5188, G 0.0117)] [G loss: 11.0078]\n",
      "2952 (5, 1) [D loss: (-1.7916)(R 9.3581, F -11.2570, G 0.0107)] [G loss: 10.7623]\n",
      "2953 (5, 1) [D loss: (-1.3734)(R 9.1020, F -10.5670, G 0.0092)] [G loss: 9.8131]\n",
      "2954 (5, 1) [D loss: (-1.5394)(R 8.0460, F -9.6721, G 0.0087)] [G loss: 9.2268]\n",
      "2955 (5, 1) [D loss: (-1.6136)(R 7.7962, F -9.4993, G 0.0090)] [G loss: 8.9862]\n",
      "2956 (5, 1) [D loss: (-1.4318)(R 6.3850, F -7.8955, G 0.0079)] [G loss: 7.3228]\n",
      "2957 (5, 1) [D loss: (-1.1938)(R 5.0879, F -6.3499, G 0.0068)] [G loss: 5.6047]\n",
      "2958 (5, 1) [D loss: (-1.3318)(R 2.9876, F -4.3775, G 0.0058)] [G loss: 4.0488]\n",
      "2959 (5, 1) [D loss: (-1.0711)(R 2.4292, F -3.5736, G 0.0073)] [G loss: 3.1444]\n",
      "2960 (5, 1) [D loss: (-1.5957)(R 1.1204, F -2.7925, G 0.0077)] [G loss: 2.1445]\n",
      "2961 (5, 1) [D loss: (-1.2958)(R -0.1547, F -1.2164, G 0.0075)] [G loss: 0.7048]\n",
      "2962 (5, 1) [D loss: (-1.4914)(R -1.0524, F -0.5362, G 0.0097)] [G loss: 0.2782]\n",
      "2963 (5, 1) [D loss: (-1.8096)(R -2.3552, F 0.4505, G 0.0095)] [G loss: -0.9270]\n",
      "2964 (5, 1) [D loss: (-1.8079)(R -4.0556, F 2.1193, G 0.0128)] [G loss: -2.7813]\n",
      "2965 (5, 1) [D loss: (-1.5001)(R -5.5405, F 3.9374, G 0.0103)] [G loss: -4.1550]\n",
      "2966 (5, 1) [D loss: (-2.0312)(R -7.7509, F 5.6037, G 0.0116)] [G loss: -6.4791]\n",
      "2967 (5, 1) [D loss: (-1.2829)(R -9.0109, F 7.6060, G 0.0122)] [G loss: -7.0939]\n",
      "2968 (5, 1) [D loss: (-1.7409)(R -8.2405, F 6.4301, G 0.0069)] [G loss: -6.4951]\n",
      "2969 (5, 1) [D loss: (-1.0218)(R -6.3175, F 5.2400, G 0.0056)] [G loss: -4.4609]\n",
      "2970 (5, 1) [D loss: (-1.4810)(R -5.5280, F 3.9921, G 0.0055)] [G loss: -3.9478]\n",
      "2971 (5, 1) [D loss: (-1.0922)(R -3.7355, F 2.5832, G 0.0060)] [G loss: -2.1359]\n",
      "2972 (5, 1) [D loss: (-1.5549)(R -1.7581, F 0.1306, G 0.0073)] [G loss: -0.1776]\n",
      "2973 (5, 1) [D loss: (-1.4946)(R -0.9007, F -0.6661, G 0.0072)] [G loss: 0.9479]\n",
      "2974 (5, 1) [D loss: (-1.4780)(R -0.0244, F -1.5371, G 0.0084)] [G loss: 1.9595]\n",
      "2975 (5, 1) [D loss: (-1.0959)(R 2.0928, F -3.2683, G 0.0080)] [G loss: 3.4925]\n",
      "2976 (5, 1) [D loss: (-1.0312)(R 2.6486, F -3.7696, G 0.0090)] [G loss: 3.9240]\n",
      "2977 (5, 1) [D loss: (-1.4479)(R 2.2289, F -3.7328, G 0.0056)] [G loss: 3.3498]\n",
      "2978 (5, 1) [D loss: (-1.4201)(R 1.5658, F -3.0684, G 0.0082)] [G loss: 2.9136]\n",
      "2979 (5, 1) [D loss: (-1.5095)(R 1.0298, F -2.6152, G 0.0076)] [G loss: 2.5006]\n",
      "2980 (5, 1) [D loss: (-1.3645)(R 1.3788, F -2.8299, G 0.0087)] [G loss: 3.0671]\n",
      "2981 (5, 1) [D loss: (-1.6161)(R 2.0424, F -3.7334, G 0.0075)] [G loss: 3.8431]\n",
      "2982 (5, 1) [D loss: (-1.5245)(R 3.0050, F -4.6017, G 0.0072)] [G loss: 4.5545]\n",
      "2983 (5, 1) [D loss: (-1.1166)(R 3.7208, F -4.9203, G 0.0083)] [G loss: 5.1259]\n",
      "2984 (5, 1) [D loss: (-1.3643)(R 3.7568, F -5.1978, G 0.0077)] [G loss: 5.1081]\n",
      "2985 (5, 1) [D loss: (-1.2748)(R 3.4265, F -4.7920, G 0.0091)] [G loss: 4.4885]\n",
      "2986 (5, 1) [D loss: (-1.5812)(R 2.5499, F -4.2080, G 0.0077)] [G loss: 3.7870]\n",
      "2987 (5, 1) [D loss: (-1.0077)(R 1.2758, F -2.3825, G 0.0099)] [G loss: 1.9649]\n",
      "2988 (5, 1) [D loss: (-1.7730)(R -2.6975, F 0.8309, G 0.0094)] [G loss: -1.5485]\n",
      "2989 (5, 1) [D loss: (-1.2353)(R -4.7772, F 3.4410, G 0.0101)] [G loss: -3.3306]\n",
      "2990 (5, 1) [D loss: (-1.6161)(R -6.7659, F 5.0545, G 0.0095)] [G loss: -5.7186]\n",
      "2991 (5, 1) [D loss: (-1.7119)(R -7.8603, F 6.0398, G 0.0109)] [G loss: -6.5732]\n",
      "2992 (5, 1) [D loss: (-1.8305)(R -8.0820, F 6.1533, G 0.0098)] [G loss: -6.3951]\n",
      "2993 (5, 1) [D loss: (-1.2934)(R -7.2042, F 5.8205, G 0.0090)] [G loss: -5.3000]\n",
      "2994 (5, 1) [D loss: (-1.5171)(R -4.8991, F 3.3035, G 0.0079)] [G loss: -3.3752]\n",
      "2995 (5, 1) [D loss: (-1.5601)(R -4.5691, F 2.9424, G 0.0066)] [G loss: -3.0884]\n",
      "2996 (5, 1) [D loss: (-1.3804)(R -4.7624, F 3.3061, G 0.0076)] [G loss: -3.1846]\n",
      "2997 (5, 1) [D loss: (-1.5021)(R -4.8625, F 3.2704, G 0.0090)] [G loss: -3.4783]\n",
      "2998 (5, 1) [D loss: (-1.5258)(R -4.2809, F 2.6614, G 0.0094)] [G loss: -2.7855]\n",
      "2999 (5, 1) [D loss: (-1.5203)(R -3.7278, F 2.1249, G 0.0083)] [G loss: -2.2962]\n",
      "3000 (5, 1) [D loss: (-1.4788)(R -4.0463, F 2.4671, G 0.0100)] [G loss: -2.3915]\n",
      "3001 (5, 1) [D loss: (-1.2304)(R -3.6448, F 2.3168, G 0.0098)] [G loss: -1.9147]\n",
      "3002 (5, 1) [D loss: (-1.2686)(R -2.3225, F 0.9702, G 0.0084)] [G loss: -0.6040]\n",
      "3003 (5, 1) [D loss: (-1.4168)(R -0.9831, F -0.4910, G 0.0057)] [G loss: 0.6883]\n",
      "3004 (5, 1) [D loss: (-1.0607)(R 0.8017, F -1.9681, G 0.0106)] [G loss: 2.1470]\n",
      "3005 (5, 1) [D loss: (-1.2876)(R 2.2158, F -3.6006, G 0.0097)] [G loss: 3.8515]\n",
      "3006 (5, 1) [D loss: (-1.5072)(R 2.6990, F -4.2955, G 0.0089)] [G loss: 4.5099]\n",
      "3007 (5, 1) [D loss: (-1.4340)(R 3.9879, F -5.5244, G 0.0103)] [G loss: 5.5779]\n",
      "3008 (5, 1) [D loss: (-1.2476)(R 5.0411, F -6.4006, G 0.0112)] [G loss: 6.2552]\n",
      "3009 (5, 1) [D loss: (-1.2029)(R 5.2902, F -6.5782, G 0.0085)] [G loss: 6.6292]\n",
      "3010 (5, 1) [D loss: (-1.0802)(R 5.1037, F -6.2736, G 0.0090)] [G loss: 6.1869]\n",
      "3011 (5, 1) [D loss: (-1.3046)(R 3.6476, F -5.0413, G 0.0089)] [G loss: 4.6332]\n",
      "3012 (5, 1) [D loss: (-1.5956)(R 3.2333, F -4.9162, G 0.0087)] [G loss: 4.9629]\n",
      "3013 (5, 1) [D loss: (-1.0597)(R 3.3301, F -4.4534, G 0.0064)] [G loss: 4.3520]\n",
      "3014 (5, 1) [D loss: (-1.2677)(R 1.9597, F -3.3331, G 0.0106)] [G loss: 3.2830]\n",
      "3015 (5, 1) [D loss: (-1.3650)(R 0.4058, F -1.8690, G 0.0098)] [G loss: 1.9634]\n",
      "3016 (5, 1) [D loss: (-1.0687)(R 0.3392, F -1.5043, G 0.0096)] [G loss: 1.5768]\n",
      "3017 (5, 1) [D loss: (-1.1697)(R -0.4057, F -0.8605, G 0.0096)] [G loss: 0.9798]\n",
      "3018 (5, 1) [D loss: (-1.2864)(R -0.8068, F -0.5582, G 0.0079)] [G loss: 0.2553]\n",
      "3019 (5, 1) [D loss: (-1.3957)(R -1.7148, F 0.2114, G 0.0108)] [G loss: -0.1865]\n",
      "3020 (5, 1) [D loss: (-1.5065)(R -1.6300, F 0.0360, G 0.0087)] [G loss: 0.0097]\n",
      "3021 (5, 1) [D loss: (-1.2186)(R -2.0465, F 0.7397, G 0.0088)] [G loss: -0.7183]\n",
      "3022 (5, 1) [D loss: (-1.6234)(R -2.7665, F 1.0734, G 0.0070)] [G loss: -1.4124]\n",
      "3023 (5, 1) [D loss: (-1.5520)(R -2.8822, F 1.2265, G 0.0104)] [G loss: -2.0133]\n",
      "3024 (5, 1) [D loss: (-1.5603)(R -3.8259, F 2.1844, G 0.0081)] [G loss: -2.3707]\n",
      "3025 (5, 1) [D loss: (-1.4044)(R -4.4131, F 2.9212, G 0.0087)] [G loss: -2.8493]\n",
      "3026 (5, 1) [D loss: (-1.5198)(R -5.4809, F 3.8503, G 0.0111)] [G loss: -3.9573]\n",
      "3027 (5, 1) [D loss: (-1.2096)(R -4.1225, F 2.8345, G 0.0078)] [G loss: -2.0374]\n",
      "3028 (5, 1) [D loss: (-1.2974)(R -2.6190, F 1.2396, G 0.0082)] [G loss: -1.1490]\n",
      "3029 (5, 1) [D loss: (-1.4332)(R -1.9784, F 0.4762, G 0.0069)] [G loss: -0.6255]\n",
      "3030 (5, 1) [D loss: (-1.2864)(R -1.6401, F 0.2650, G 0.0089)] [G loss: -0.3305]\n",
      "3031 (5, 1) [D loss: (-1.5376)(R -1.1476, F -0.4696, G 0.0080)] [G loss: 0.6704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032 (5, 1) [D loss: (-1.1541)(R 0.2921, F -1.5331, G 0.0087)] [G loss: 1.5810]\n",
      "3033 (5, 1) [D loss: (-1.3935)(R 1.0202, F -2.4923, G 0.0079)] [G loss: 2.3912]\n",
      "3034 (5, 1) [D loss: (-1.3193)(R 1.2479, F -2.6443, G 0.0077)] [G loss: 2.7706]\n",
      "3035 (5, 1) [D loss: (-1.3533)(R 1.6600, F -3.1090, G 0.0096)] [G loss: 3.0955]\n",
      "3036 (5, 1) [D loss: (-1.2319)(R 2.6430, F -3.9834, G 0.0109)] [G loss: 4.2108]\n",
      "3037 (5, 1) [D loss: (-1.4548)(R 3.5608, F -5.1274, G 0.0112)] [G loss: 4.7261]\n",
      "3038 (5, 1) [D loss: (-1.2177)(R 4.1913, F -5.4983, G 0.0089)] [G loss: 5.8409]\n",
      "3039 (5, 1) [D loss: (-1.4634)(R 5.2330, F -6.7911, G 0.0095)] [G loss: 6.6883]\n",
      "3040 (5, 1) [D loss: (-1.4554)(R 5.6436, F -7.1752, G 0.0076)] [G loss: 7.1003]\n",
      "3041 (5, 1) [D loss: (-1.1269)(R 5.9042, F -7.1047, G 0.0074)] [G loss: 7.0716]\n",
      "3042 (5, 1) [D loss: (-1.6559)(R 5.2879, F -7.0356, G 0.0092)] [G loss: 6.8287]\n",
      "3043 (5, 1) [D loss: (-1.3182)(R 5.5557, F -6.9651, G 0.0091)] [G loss: 6.3463]\n",
      "3044 (5, 1) [D loss: (-1.1856)(R 3.9925, F -5.2462, G 0.0068)] [G loss: 5.1793]\n",
      "3045 (5, 1) [D loss: (-1.3347)(R 3.3335, F -4.7464, G 0.0078)] [G loss: 4.3817]\n",
      "3046 (5, 1) [D loss: (-1.2574)(R 3.2390, F -4.5804, G 0.0084)] [G loss: 4.2653]\n",
      "3047 (5, 1) [D loss: (-1.5198)(R 2.6547, F -4.2686, G 0.0094)] [G loss: 4.3328]\n",
      "3048 (5, 1) [D loss: (-1.3871)(R 2.6874, F -4.1442, G 0.0070)] [G loss: 4.1875]\n",
      "3049 (5, 1) [D loss: (-1.2732)(R 1.4985, F -2.8447, G 0.0073)] [G loss: 2.3966]\n",
      "3050 (5, 1) [D loss: (-1.3422)(R -0.6957, F -0.7135, G 0.0067)] [G loss: 0.3316]\n",
      "3051 (5, 1) [D loss: (-1.2329)(R -3.8208, F 2.4969, G 0.0091)] [G loss: -2.7081]\n",
      "3052 (5, 1) [D loss: (-1.5883)(R -6.0158, F 4.3269, G 0.0101)] [G loss: -4.6457]\n",
      "3053 (5, 1) [D loss: (-1.6519)(R -7.9213, F 6.1585, G 0.0111)] [G loss: -6.2839]\n",
      "3054 (5, 1) [D loss: (-1.3372)(R -8.6814, F 7.2589, G 0.0085)] [G loss: -6.3933]\n",
      "3055 (5, 1) [D loss: (-1.1797)(R -8.0429, F 6.7734, G 0.0090)] [G loss: -6.7652]\n",
      "3056 (5, 1) [D loss: (-1.3750)(R -6.7704, F 5.3270, G 0.0068)] [G loss: -4.6491]\n",
      "3057 (5, 1) [D loss: (-1.4073)(R -4.6701, F 3.1993, G 0.0063)] [G loss: -2.7141]\n",
      "3058 (5, 1) [D loss: (-1.2118)(R -2.6688, F 1.3774, G 0.0080)] [G loss: -1.1429]\n",
      "3059 (5, 1) [D loss: (-1.2635)(R -1.9893, F 0.6270, G 0.0099)] [G loss: -0.3691]\n",
      "3060 (5, 1) [D loss: (-1.0917)(R -1.0871, F -0.0806, G 0.0076)] [G loss: 0.6157]\n",
      "3061 (5, 1) [D loss: (-1.1386)(R -1.2663, F 0.0651, G 0.0063)] [G loss: -0.4179]\n",
      "3062 (5, 1) [D loss: (-1.4640)(R -3.1376, F 1.5922, G 0.0081)] [G loss: -2.1035]\n",
      "3063 (5, 1) [D loss: (-1.2537)(R -4.1201, F 2.7904, G 0.0076)] [G loss: -2.3086]\n",
      "3064 (5, 1) [D loss: (-1.6838)(R -4.5211, F 2.7608, G 0.0076)] [G loss: -2.6148]\n",
      "3065 (5, 1) [D loss: (-1.3528)(R -3.7493, F 2.3135, G 0.0083)] [G loss: -1.9547]\n",
      "3066 (5, 1) [D loss: (-1.3913)(R -1.7660, F 0.3086, G 0.0066)] [G loss: 0.1924]\n",
      "3067 (5, 1) [D loss: (-1.3608)(R 1.4730, F -2.8936, G 0.0060)] [G loss: 3.1955]\n",
      "3068 (5, 1) [D loss: (-1.3344)(R 4.1817, F -5.6244, G 0.0108)] [G loss: 6.1124]\n",
      "3069 (5, 1) [D loss: (-1.5791)(R 7.2968, F -9.0141, G 0.0138)] [G loss: 9.1516]\n",
      "3070 (5, 1) [D loss: (-1.6339)(R 8.1608, F -9.9100, G 0.0115)] [G loss: 9.7180]\n",
      "3071 (5, 1) [D loss: (-0.9691)(R 7.7554, F -8.8026, G 0.0078)] [G loss: 8.4657]\n",
      "3072 (5, 1) [D loss: (-1.3384)(R 5.2013, F -6.5997, G 0.0060)] [G loss: 6.4116]\n",
      "3073 (5, 1) [D loss: (-1.3700)(R 2.6813, F -4.1116, G 0.0060)] [G loss: 3.2914]\n",
      "3074 (5, 1) [D loss: (-1.4833)(R -0.7782, F -0.7873, G 0.0082)] [G loss: 0.2531]\n",
      "3075 (5, 1) [D loss: (-1.5226)(R -3.7579, F 2.1293, G 0.0106)] [G loss: -2.3309]\n",
      "3076 (5, 1) [D loss: (-1.8340)(R -6.5935, F 4.6281, G 0.0131)] [G loss: -5.4129]\n",
      "3077 (5, 1) [D loss: (-1.3782)(R -8.0587, F 6.5982, G 0.0082)] [G loss: -6.4495]\n",
      "3078 (5, 1) [D loss: (-1.4105)(R -7.3404, F 5.8510, G 0.0079)] [G loss: -6.0086]\n",
      "3079 (5, 1) [D loss: (-1.0815)(R -6.5457, F 5.3820, G 0.0082)] [G loss: -4.5949]\n",
      "3080 (5, 1) [D loss: (-1.3814)(R -5.8630, F 4.3983, G 0.0083)] [G loss: -4.4493]\n",
      "3081 (5, 1) [D loss: (-1.5382)(R -4.7637, F 3.1540, G 0.0071)] [G loss: -2.4875]\n",
      "3082 (5, 1) [D loss: (-1.5609)(R -3.6644, F 2.0231, G 0.0080)] [G loss: -2.4842]\n",
      "3083 (5, 1) [D loss: (-1.1188)(R -5.4286, F 4.2206, G 0.0089)] [G loss: -4.3184]\n",
      "3084 (5, 1) [D loss: (-1.2883)(R -6.3134, F 4.9344, G 0.0091)] [G loss: -5.1466]\n",
      "3085 (5, 1) [D loss: (-1.2163)(R -7.5099, F 6.1864, G 0.0107)] [G loss: -6.2265]\n",
      "3086 (5, 1) [D loss: (-1.2507)(R -7.1243, F 5.7996, G 0.0074)] [G loss: -5.6048]\n",
      "3087 (5, 1) [D loss: (-1.6420)(R -5.7932, F 4.0758, G 0.0075)] [G loss: -4.0960]\n",
      "3088 (5, 1) [D loss: (-1.2801)(R -4.2182, F 2.8710, G 0.0067)] [G loss: -2.0338]\n",
      "3089 (5, 1) [D loss: (-1.2930)(R -2.3440, F 0.9795, G 0.0072)] [G loss: -0.6532]\n",
      "3090 (5, 1) [D loss: (-1.2936)(R 0.2161, F -1.5929, G 0.0083)] [G loss: 1.9518]\n",
      "3091 (5, 1) [D loss: (-1.3202)(R 2.1864, F -3.5985, G 0.0092)] [G loss: 3.9252]\n",
      "3092 (5, 1) [D loss: (-1.2105)(R 4.8536, F -6.1701, G 0.0106)] [G loss: 6.3683]\n",
      "3093 (5, 1) [D loss: (-1.4629)(R 6.0915, F -7.6620, G 0.0108)] [G loss: 7.7954]\n",
      "3094 (5, 1) [D loss: (-1.2834)(R 6.4068, F -7.7970, G 0.0107)] [G loss: 7.9121]\n",
      "3095 (5, 1) [D loss: (-1.2240)(R 5.6385, F -6.9459, G 0.0083)] [G loss: 6.6979]\n",
      "3096 (5, 1) [D loss: (-1.1273)(R 3.9909, F -5.1966, G 0.0078)] [G loss: 4.3893]\n",
      "3097 (5, 1) [D loss: (-1.5583)(R 1.1234, F -2.7609, G 0.0079)] [G loss: 2.4006]\n",
      "3098 (5, 1) [D loss: (-1.2647)(R -0.3670, F -0.9790, G 0.0081)] [G loss: 0.8403]\n",
      "3099 (5, 1) [D loss: (-1.6415)(R -0.4276, F -1.2871, G 0.0073)] [G loss: 1.3191]\n",
      "3100 (5, 1) [D loss: (-1.5288)(R 0.8366, F -2.4407, G 0.0075)] [G loss: 2.6383]\n",
      "3101 (5, 1) [D loss: (-1.7923)(R 1.8818, F -3.7722, G 0.0098)] [G loss: 3.9303]\n",
      "3102 (5, 1) [D loss: (-1.2055)(R 4.2919, F -5.6150, G 0.0118)] [G loss: 5.5708]\n",
      "3103 (5, 1) [D loss: (-1.1095)(R 3.1354, F -4.3282, G 0.0083)] [G loss: 3.7548]\n",
      "3104 (5, 1) [D loss: (-1.0164)(R 1.1741, F -2.2564, G 0.0066)] [G loss: 1.7044]\n",
      "3105 (5, 1) [D loss: (-1.4313)(R -1.5373, F 0.0442, G 0.0062)] [G loss: -0.6201]\n",
      "3106 (5, 1) [D loss: (-1.4581)(R -3.8537, F 2.3251, G 0.0071)] [G loss: -2.6678]\n",
      "3107 (5, 1) [D loss: (-1.8584)(R -5.2122, F 3.2751, G 0.0079)] [G loss: -3.8601]\n",
      "3108 (5, 1) [D loss: (-1.4405)(R -5.4356, F 3.9083, G 0.0087)] [G loss: -4.5257]\n",
      "3109 (5, 1) [D loss: (-1.4601)(R -6.0463, F 4.5016, G 0.0085)] [G loss: -4.5674]\n",
      "3110 (5, 1) [D loss: (-1.8638)(R -6.2681, F 4.3105, G 0.0094)] [G loss: -4.9064]\n",
      "3111 (5, 1) [D loss: (-1.7543)(R -5.9127, F 4.0709, G 0.0087)] [G loss: -4.3398]\n",
      "3112 (5, 1) [D loss: (-1.5485)(R -5.2673, F 3.6218, G 0.0097)] [G loss: -3.5310]\n",
      "3113 (5, 1) [D loss: (-1.4195)(R -4.9520, F 3.4548, G 0.0078)] [G loss: -3.8172]\n",
      "3114 (5, 1) [D loss: (-1.3654)(R -5.6633, F 4.2066, G 0.0091)] [G loss: -4.3113]\n",
      "3115 (5, 1) [D loss: (-1.1157)(R -5.3476, F 4.1482, G 0.0084)] [G loss: -3.6980]\n",
      "3116 (5, 1) [D loss: (-1.3932)(R -4.1655, F 2.6900, G 0.0082)] [G loss: -2.7439]\n",
      "3117 (5, 1) [D loss: (-1.4025)(R -2.6052, F 1.1232, G 0.0080)] [G loss: -0.9439]\n",
      "3118 (5, 1) [D loss: (-1.5274)(R -0.9424, F -0.6609, G 0.0076)] [G loss: 1.5543]\n",
      "3119 (5, 1) [D loss: (-1.7429)(R 1.5290, F -3.3632, G 0.0091)] [G loss: 3.9763]\n",
      "3120 (5, 1) [D loss: (-1.8166)(R 4.2613, F -6.1931, G 0.0115)] [G loss: 6.5959]\n",
      "3121 (5, 1) [D loss: (-1.5724)(R 7.1618, F -8.8588, G 0.0125)] [G loss: 8.8151]\n",
      "3122 (5, 1) [D loss: (-1.5163)(R 8.2439, F -9.8829, G 0.0123)] [G loss: 10.1063]\n",
      "3123 (5, 1) [D loss: (-1.4706)(R 8.5352, F -10.1016, G 0.0096)] [G loss: 9.8343]\n",
      "3124 (5, 1) [D loss: (-1.5069)(R 8.0359, F -9.6307, G 0.0088)] [G loss: 9.3852]\n",
      "3125 (5, 1) [D loss: (-1.9292)(R 6.6261, F -8.6334, G 0.0078)] [G loss: 8.5885]\n",
      "3126 (5, 1) [D loss: (-1.8392)(R 6.8719, F -8.8300, G 0.0119)] [G loss: 8.8890]\n",
      "3127 (5, 1) [D loss: (-2.1613)(R 7.0992, F -9.3822, G 0.0122)] [G loss: 9.0518]\n",
      "3128 (5, 1) [D loss: (-1.2939)(R 7.0551, F -8.4550, G 0.0106)] [G loss: 7.9587]\n",
      "3129 (5, 1) [D loss: (-1.3606)(R 6.5693, F -8.0192, G 0.0089)] [G loss: 7.8015]\n",
      "3130 (5, 1) [D loss: (-1.4316)(R 7.6835, F -9.2070, G 0.0092)] [G loss: 9.2616]\n",
      "3131 (5, 1) [D loss: (-0.9584)(R 9.1495, F -10.1976, G 0.0090)] [G loss: 9.7958]\n",
      "3132 (5, 1) [D loss: (-1.7200)(R 7.7407, F -9.5181, G 0.0057)] [G loss: 9.0548]\n",
      "3133 (5, 1) [D loss: (-1.9836)(R 6.6161, F -8.6776, G 0.0078)] [G loss: 8.2544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134 (5, 1) [D loss: (-1.1554)(R 5.8717, F -7.1205, G 0.0093)] [G loss: 6.4084]\n",
      "3135 (5, 1) [D loss: (-1.3769)(R 2.4509, F -3.9047, G 0.0077)] [G loss: 3.3192]\n",
      "3136 (5, 1) [D loss: (-1.4193)(R -1.1907, F -0.2944, G 0.0066)] [G loss: -0.9254]\n",
      "3137 (5, 1) [D loss: (-1.7121)(R -6.5025, F 4.6984, G 0.0092)] [G loss: -5.5042]\n",
      "3138 (5, 1) [D loss: (-2.2882)(R -10.5201, F 8.0718, G 0.0160)] [G loss: -8.7537]\n",
      "3139 (5, 1) [D loss: (-1.9998)(R -11.6049, F 9.4356, G 0.0169)] [G loss: -9.7128]\n",
      "3140 (5, 1) [D loss: (-1.4414)(R -10.7006, F 9.1469, G 0.0112)] [G loss: -8.9990]\n",
      "3141 (5, 1) [D loss: (-0.9198)(R -8.3253, F 7.3457, G 0.0060)] [G loss: -6.5300]\n",
      "3142 (5, 1) [D loss: (-1.0554)(R -6.2106, F 5.1067, G 0.0049)] [G loss: -4.5555]\n",
      "3143 (5, 1) [D loss: (-1.9105)(R -4.5418, F 2.5744, G 0.0057)] [G loss: -2.3961]\n",
      "3144 (5, 1) [D loss: (-1.7507)(R -1.8369, F 0.0135, G 0.0073)] [G loss: 0.4472]\n",
      "3145 (5, 1) [D loss: (-1.5456)(R 0.3753, F -2.0084, G 0.0087)] [G loss: 1.8160]\n",
      "3146 (5, 1) [D loss: (-1.2317)(R 0.5897, F -1.8941, G 0.0073)] [G loss: 1.9321]\n",
      "3147 (5, 1) [D loss: (-1.0317)(R -0.6999, F -0.3996, G 0.0068)] [G loss: 0.5619]\n",
      "3148 (5, 1) [D loss: (-1.4349)(R -1.9281, F 0.4199, G 0.0073)] [G loss: -0.6806]\n",
      "3149 (5, 1) [D loss: (-1.4165)(R -2.2587, F 0.7675, G 0.0075)] [G loss: -0.5775]\n",
      "3150 (5, 1) [D loss: (-1.8109)(R -0.7429, F -1.1441, G 0.0076)] [G loss: 1.3298]\n",
      "3151 (5, 1) [D loss: (-1.6518)(R 0.8221, F -2.5604, G 0.0087)] [G loss: 2.7669]\n",
      "3152 (5, 1) [D loss: (-1.5543)(R 3.3604, F -5.0108, G 0.0096)] [G loss: 5.0319]\n",
      "3153 (5, 1) [D loss: (-1.1894)(R 6.0410, F -7.3467, G 0.0116)] [G loss: 7.5604]\n",
      "3154 (5, 1) [D loss: (-1.0831)(R 9.4348, F -10.6387, G 0.0121)] [G loss: 10.9057]\n",
      "3155 (5, 1) [D loss: (-1.6449)(R 9.1722, F -10.9224, G 0.0105)] [G loss: 10.9528]\n",
      "3156 (5, 1) [D loss: (-1.3961)(R 9.5265, F -11.0221, G 0.0099)] [G loss: 10.5619]\n",
      "3157 (5, 1) [D loss: (-1.6081)(R 7.3993, F -9.0736, G 0.0066)] [G loss: 8.5295]\n",
      "3158 (5, 1) [D loss: (-1.4748)(R 5.0895, F -6.6285, G 0.0064)] [G loss: 6.2890]\n",
      "3159 (5, 1) [D loss: (-0.7218)(R 3.7248, F -4.5115, G 0.0065)] [G loss: 3.9067]\n",
      "3160 (5, 1) [D loss: (-1.4404)(R -0.8259, F -0.6817, G 0.0067)] [G loss: 0.1342]\n",
      "3161 (5, 1) [D loss: (-1.4266)(R -4.4528, F 2.9351, G 0.0091)] [G loss: -3.5027]\n",
      "3162 (5, 1) [D loss: (-1.5566)(R -6.7153, F 5.0627, G 0.0096)] [G loss: -4.6193]\n",
      "3163 (5, 1) [D loss: (-1.6617)(R -6.7233, F 4.9758, G 0.0086)] [G loss: -5.7446]\n",
      "3164 (5, 1) [D loss: (-1.5932)(R -7.5811, F 5.8827, G 0.0105)] [G loss: -5.7098]\n",
      "3165 (5, 1) [D loss: (-1.5964)(R -7.2564, F 5.5835, G 0.0077)] [G loss: -5.8710]\n",
      "3166 (5, 1) [D loss: (-1.6959)(R -7.5196, F 5.7555, G 0.0068)] [G loss: -6.0215]\n",
      "3167 (5, 1) [D loss: (-1.6478)(R -7.7949, F 6.0661, G 0.0081)] [G loss: -5.9652]\n",
      "3168 (5, 1) [D loss: (-1.5626)(R -7.7088, F 6.0696, G 0.0077)] [G loss: -5.9434]\n",
      "3169 (5, 1) [D loss: (-1.3312)(R -5.6774, F 4.2768, G 0.0069)] [G loss: -4.1079]\n",
      "3170 (5, 1) [D loss: (-1.5636)(R -5.3892, F 3.7484, G 0.0077)] [G loss: -4.0915]\n",
      "3171 (5, 1) [D loss: (-1.0746)(R -6.2000, F 5.0503, G 0.0075)] [G loss: -4.8244]\n",
      "3172 (5, 1) [D loss: (-1.4089)(R -5.4661, F 3.9803, G 0.0077)] [G loss: -4.2142]\n",
      "3173 (5, 1) [D loss: (-1.4788)(R -5.5479, F 3.9909, G 0.0078)] [G loss: -4.0031]\n",
      "3174 (5, 1) [D loss: (-1.0872)(R -4.4749, F 3.3130, G 0.0075)] [G loss: -3.0582]\n",
      "3175 (5, 1) [D loss: (-1.2716)(R -2.9683, F 1.6113, G 0.0085)] [G loss: -1.2151]\n",
      "3176 (5, 1) [D loss: (-1.4191)(R -1.6667, F 0.1661, G 0.0082)] [G loss: -0.1374]\n",
      "3177 (5, 1) [D loss: (-1.0681)(R -0.0671, F -1.0898, G 0.0089)] [G loss: 1.5547]\n",
      "3178 (5, 1) [D loss: (-1.4674)(R 0.9139, F -2.4543, G 0.0073)] [G loss: 2.8633]\n",
      "3179 (5, 1) [D loss: (-1.2825)(R 1.4841, F -2.8573, G 0.0091)] [G loss: 3.0716]\n",
      "3180 (5, 1) [D loss: (-1.5672)(R 1.7046, F -3.3553, G 0.0083)] [G loss: 3.5263]\n",
      "3181 (5, 1) [D loss: (-1.3515)(R 2.0319, F -3.4752, G 0.0092)] [G loss: 3.0461]\n",
      "3182 (5, 1) [D loss: (-1.3995)(R 1.1056, F -2.5792, G 0.0074)] [G loss: 2.5534]\n",
      "3183 (5, 1) [D loss: (-1.0517)(R 1.0426, F -2.1824, G 0.0088)] [G loss: 1.7666]\n",
      "3184 (5, 1) [D loss: (-1.1165)(R 0.1073, F -1.2979, G 0.0074)] [G loss: 1.1822]\n",
      "3185 (5, 1) [D loss: (-1.2828)(R -0.1608, F -1.1931, G 0.0071)] [G loss: 1.1973]\n",
      "3186 (5, 1) [D loss: (-1.3702)(R -1.3610, F -0.0784, G 0.0069)] [G loss: -0.2696]\n",
      "3187 (5, 1) [D loss: (-1.5573)(R -2.9316, F 1.2912, G 0.0083)] [G loss: -1.7239]\n",
      "3188 (5, 1) [D loss: (-1.3488)(R -3.6155, F 2.1606, G 0.0106)] [G loss: -2.0276]\n",
      "3189 (5, 1) [D loss: (-1.4334)(R -3.6938, F 2.1723, G 0.0088)] [G loss: -2.6612]\n",
      "3190 (5, 1) [D loss: (-1.1745)(R -4.2539, F 2.9971, G 0.0082)] [G loss: -2.8222]\n",
      "3191 (5, 1) [D loss: (-1.2979)(R -3.7720, F 2.4048, G 0.0069)] [G loss: -1.9576]\n",
      "3192 (5, 1) [D loss: (-1.3943)(R -3.1016, F 1.6312, G 0.0076)] [G loss: -1.8764]\n",
      "3193 (5, 1) [D loss: (-1.4097)(R -3.0968, F 1.5916, G 0.0095)] [G loss: -1.4541]\n",
      "3194 (5, 1) [D loss: (-1.2340)(R -2.1807, F 0.8363, G 0.0110)] [G loss: -0.8269]\n",
      "3195 (5, 1) [D loss: (-1.2225)(R -2.0555, F 0.7472, G 0.0086)] [G loss: -0.6797]\n",
      "3196 (5, 1) [D loss: (-1.2166)(R -2.5725, F 1.2673, G 0.0089)] [G loss: -1.2735]\n",
      "3197 (5, 1) [D loss: (-1.0626)(R -2.0731, F 0.9099, G 0.0101)] [G loss: -0.4995]\n",
      "3198 (5, 1) [D loss: (-1.0987)(R -1.3468, F 0.1707, G 0.0077)] [G loss: -0.0709]\n",
      "3199 (5, 1) [D loss: (-1.2430)(R -0.8321, F -0.4832, G 0.0072)] [G loss: 0.7330]\n",
      "3200 (5, 1) [D loss: (-1.4920)(R 0.5514, F -2.1456, G 0.0102)] [G loss: 2.3836]\n",
      "3201 (5, 1) [D loss: (-1.2282)(R 1.5070, F -2.8018, G 0.0067)] [G loss: 2.9356]\n",
      "3202 (5, 1) [D loss: (-1.5675)(R 2.1478, F -3.8028, G 0.0087)] [G loss: 3.7159]\n",
      "3203 (5, 1) [D loss: (-1.3706)(R 1.7377, F -3.1936, G 0.0085)] [G loss: 2.9658]\n",
      "3204 (5, 1) [D loss: (-1.3778)(R 2.0775, F -3.5362, G 0.0081)] [G loss: 3.5552]\n",
      "3205 (5, 1) [D loss: (-1.5390)(R 3.5777, F -5.2100, G 0.0093)] [G loss: 5.2745]\n",
      "3206 (5, 1) [D loss: (-1.8337)(R 5.3212, F -7.2480, G 0.0093)] [G loss: 7.1221]\n",
      "3207 (5, 1) [D loss: (-1.3346)(R 6.1738, F -7.6112, G 0.0103)] [G loss: 7.8021]\n",
      "3208 (5, 1) [D loss: (-1.5205)(R 6.3718, F -8.0237, G 0.0131)] [G loss: 7.7540]\n",
      "3209 (5, 1) [D loss: (-1.3191)(R 7.8075, F -9.2289, G 0.0102)] [G loss: 8.9966]\n",
      "3210 (5, 1) [D loss: (-1.8349)(R 8.6129, F -10.5965, G 0.0149)] [G loss: 10.2646]\n",
      "3211 (5, 1) [D loss: (-1.4514)(R 7.9463, F -9.4959, G 0.0098)] [G loss: 9.2265]\n",
      "3212 (5, 1) [D loss: (-1.0965)(R 7.3490, F -8.5133, G 0.0068)] [G loss: 7.8145]\n",
      "3213 (5, 1) [D loss: (-1.3317)(R 4.6654, F -6.0589, G 0.0062)] [G loss: 5.5713]\n",
      "3214 (5, 1) [D loss: (-1.5012)(R 2.6578, F -4.2239, G 0.0065)] [G loss: 3.6140]\n",
      "3215 (5, 1) [D loss: (-1.4441)(R 0.4143, F -1.9225, G 0.0064)] [G loss: 1.5591]\n",
      "3216 (5, 1) [D loss: (-1.1679)(R -0.6778, F -0.5771, G 0.0087)] [G loss: 0.4551]\n",
      "3217 (5, 1) [D loss: (-1.1439)(R -0.2915, F -0.9322, G 0.0080)] [G loss: 0.8945]\n",
      "3218 (5, 1) [D loss: (-1.1626)(R 0.0222, F -1.2656, G 0.0081)] [G loss: 1.3537]\n",
      "3219 (5, 1) [D loss: (-1.3605)(R 1.5145, F -2.9634, G 0.0088)] [G loss: 2.9089]\n",
      "3220 (5, 1) [D loss: (-1.6876)(R 3.1136, F -4.8884, G 0.0087)] [G loss: 5.2002]\n",
      "3221 (5, 1) [D loss: (-1.4501)(R 5.0043, F -6.5818, G 0.0127)] [G loss: 6.5623]\n",
      "3222 (5, 1) [D loss: (-0.8527)(R 5.5987, F -6.5472, G 0.0096)] [G loss: 6.1532]\n",
      "3223 (5, 1) [D loss: (-1.1736)(R 4.2707, F -5.5190, G 0.0075)] [G loss: 5.0543]\n",
      "3224 (5, 1) [D loss: (-1.3403)(R 1.6893, F -3.1017, G 0.0072)] [G loss: 2.7375]\n",
      "3225 (5, 1) [D loss: (-1.1801)(R 0.4525, F -1.7165, G 0.0084)] [G loss: 1.2459]\n",
      "3226 (5, 1) [D loss: (-1.6170)(R -2.9225, F 1.2191, G 0.0086)] [G loss: -1.3962]\n",
      "3227 (5, 1) [D loss: (-1.3118)(R -3.9533, F 2.5630, G 0.0079)] [G loss: -2.3476]\n",
      "3228 (5, 1) [D loss: (-1.4604)(R -4.3119, F 2.7735, G 0.0078)] [G loss: -2.4635]\n",
      "3229 (5, 1) [D loss: (-0.8756)(R -2.6892, F 1.7460, G 0.0068)] [G loss: -0.8284]\n",
      "3230 (5, 1) [D loss: (-0.9464)(R -0.1360, F -0.8609, G 0.0050)] [G loss: 1.5212]\n",
      "3231 (5, 1) [D loss: (-1.2743)(R 2.2740, F -3.6113, G 0.0063)] [G loss: 3.9443]\n",
      "3232 (5, 1) [D loss: (-1.3651)(R 4.0230, F -5.4634, G 0.0075)] [G loss: 5.7692]\n",
      "3233 (5, 1) [D loss: (-1.4831)(R 5.1929, F -6.7776, G 0.0102)] [G loss: 6.8300]\n",
      "3234 (5, 1) [D loss: (-1.2933)(R 4.1001, F -5.4730, G 0.0080)] [G loss: 4.9634]\n",
      "3235 (5, 1) [D loss: (-1.6525)(R 0.7791, F -2.5036, G 0.0072)] [G loss: 1.9649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3236 (5, 1) [D loss: (-1.1812)(R -1.3174, F 0.0687, G 0.0067)] [G loss: -0.1371]\n",
      "3237 (5, 1) [D loss: (-1.4274)(R -3.7679, F 2.2407, G 0.0100)] [G loss: -2.5508]\n",
      "3238 (5, 1) [D loss: (-1.2982)(R -7.1294, F 5.7150, G 0.0116)] [G loss: -5.5925]\n",
      "3239 (5, 1) [D loss: (-1.7757)(R -8.3956, F 6.5005, G 0.0119)] [G loss: -6.9568]\n",
      "3240 (5, 1) [D loss: (-1.5413)(R -9.0754, F 7.4336, G 0.0100)] [G loss: -7.5290]\n",
      "3241 (5, 1) [D loss: (-1.5947)(R -8.3722, F 6.7019, G 0.0076)] [G loss: -6.9504]\n",
      "3242 (5, 1) [D loss: (-1.1462)(R -9.3221, F 8.0981, G 0.0078)] [G loss: -7.6160]\n",
      "3243 (5, 1) [D loss: (-1.3878)(R -7.9178, F 6.4596, G 0.0070)] [G loss: -6.4414]\n",
      "3244 (5, 1) [D loss: (-1.7050)(R -6.8281, F 5.0596, G 0.0063)] [G loss: -5.3069]\n",
      "3245 (5, 1) [D loss: (-1.8416)(R -7.1444, F 5.2132, G 0.0090)] [G loss: -5.6315]\n",
      "3246 (5, 1) [D loss: (-1.4095)(R -7.3873, F 5.8906, G 0.0087)] [G loss: -6.1998]\n",
      "3247 (5, 1) [D loss: (-1.2830)(R -6.6269, F 5.2659, G 0.0078)] [G loss: -5.7239]\n",
      "3248 (5, 1) [D loss: (-0.9240)(R -6.9112, F 5.9202, G 0.0067)] [G loss: -5.8142]\n",
      "3249 (5, 1) [D loss: (-1.3126)(R -5.9630, F 4.5918, G 0.0059)] [G loss: -4.3409]\n",
      "3250 (5, 1) [D loss: (-1.3083)(R -5.9741, F 4.5927, G 0.0073)] [G loss: -4.7505]\n",
      "3251 (5, 1) [D loss: (-1.4553)(R -5.5863, F 4.0739, G 0.0057)] [G loss: -4.2094]\n",
      "3252 (5, 1) [D loss: (-1.0910)(R -5.2126, F 4.0377, G 0.0084)] [G loss: -3.9522]\n",
      "3253 (5, 1) [D loss: (-1.3859)(R -3.3710, F 1.9249, G 0.0060)] [G loss: -1.5200]\n",
      "3254 (5, 1) [D loss: (-0.9312)(R -0.7834, F -0.2131, G 0.0065)] [G loss: 0.2839]\n",
      "3255 (5, 1) [D loss: (-1.6196)(R -0.2284, F -1.4506, G 0.0059)] [G loss: 1.7491]\n",
      "3256 (5, 1) [D loss: (-1.2531)(R 0.7412, F -2.0707, G 0.0076)] [G loss: 2.0649]\n",
      "3257 (5, 1) [D loss: (-1.6073)(R 0.8501, F -2.5337, G 0.0076)] [G loss: 2.3064]\n",
      "3258 (5, 1) [D loss: (-1.2963)(R -0.1842, F -1.1925, G 0.0080)] [G loss: 0.9568]\n",
      "3259 (5, 1) [D loss: (-1.4851)(R 0.0714, F -1.6504, G 0.0094)] [G loss: 1.5037]\n",
      "3260 (5, 1) [D loss: (-1.2603)(R -0.6481, F -0.7077, G 0.0096)] [G loss: 0.3615]\n",
      "3261 (5, 1) [D loss: (-1.1299)(R -0.6828, F -0.5305, G 0.0083)] [G loss: 0.2374]\n",
      "3262 (5, 1) [D loss: (-1.0880)(R -1.4539, F 0.2849, G 0.0081)] [G loss: -0.1987]\n",
      "3263 (5, 1) [D loss: (-1.1693)(R -1.7460, F 0.4877, G 0.0089)] [G loss: -0.5668]\n",
      "3264 (5, 1) [D loss: (-1.1307)(R -2.3288, F 1.1061, G 0.0092)] [G loss: -1.1401]\n",
      "3265 (5, 1) [D loss: (-1.5704)(R -2.9618, F 1.2993, G 0.0092)] [G loss: -1.9245]\n",
      "3266 (5, 1) [D loss: (-1.0348)(R -1.6839, F 0.5747, G 0.0074)] [G loss: -0.3775]\n",
      "3267 (5, 1) [D loss: (-1.3906)(R 0.2969, F -1.7708, G 0.0083)] [G loss: 1.7982]\n",
      "3268 (5, 1) [D loss: (-1.0108)(R 1.5275, F -2.5997, G 0.0061)] [G loss: 2.8281]\n",
      "3269 (5, 1) [D loss: (-1.3547)(R 1.1485, F -2.5848, G 0.0082)] [G loss: 2.4550]\n",
      "3270 (5, 1) [D loss: (-1.5523)(R 0.7961, F -2.4376, G 0.0089)] [G loss: 2.1714]\n",
      "3271 (5, 1) [D loss: (-1.4810)(R 0.7336, F -2.2968, G 0.0082)] [G loss: 2.1259]\n",
      "3272 (5, 1) [D loss: (-1.2477)(R 0.8115, F -2.1493, G 0.0090)] [G loss: 2.1069]\n",
      "3273 (5, 1) [D loss: (-1.3012)(R 0.5573, F -1.9473, G 0.0089)] [G loss: 2.0780]\n",
      "3274 (5, 1) [D loss: (-1.0550)(R 1.2700, F -2.4152, G 0.0090)] [G loss: 2.5978]\n",
      "3275 (5, 1) [D loss: (-1.6483)(R 0.9028, F -2.6380, G 0.0087)] [G loss: 2.3499]\n",
      "3276 (5, 1) [D loss: (-1.0659)(R 2.0880, F -3.2404, G 0.0086)] [G loss: 3.5103]\n",
      "3277 (5, 1) [D loss: (-1.3460)(R 2.8895, F -4.3337, G 0.0098)] [G loss: 4.3931]\n",
      "3278 (5, 1) [D loss: (-1.1864)(R 2.8950, F -4.1489, G 0.0067)] [G loss: 4.2270]\n",
      "3279 (5, 1) [D loss: (-1.1285)(R 3.3102, F -4.5320, G 0.0093)] [G loss: 4.6541]\n",
      "3280 (5, 1) [D loss: (-1.2971)(R 3.4210, F -4.8186, G 0.0101)] [G loss: 5.0169]\n",
      "3281 (5, 1) [D loss: (-1.3968)(R 4.8438, F -6.3321, G 0.0091)] [G loss: 6.5678]\n",
      "3282 (5, 1) [D loss: (-1.6828)(R 4.8557, F -6.6225, G 0.0084)] [G loss: 6.9062]\n",
      "3283 (5, 1) [D loss: (-1.0832)(R 5.8217, F -7.0048, G 0.0100)] [G loss: 7.1082]\n",
      "3284 (5, 1) [D loss: (-1.1763)(R 6.4145, F -7.6747, G 0.0084)] [G loss: 7.6573]\n",
      "3285 (5, 1) [D loss: (-1.8566)(R 5.6263, F -7.5697, G 0.0087)] [G loss: 7.1274]\n",
      "3286 (5, 1) [D loss: (-1.4905)(R 5.9073, F -7.4677, G 0.0070)] [G loss: 7.7230]\n",
      "3287 (5, 1) [D loss: (-1.3085)(R 6.4994, F -7.8847, G 0.0077)] [G loss: 7.6883]\n",
      "3288 (5, 1) [D loss: (-1.0613)(R 6.9139, F -8.0785, G 0.0103)] [G loss: 7.8262]\n",
      "3289 (5, 1) [D loss: (-0.7373)(R 6.2570, F -7.0723, G 0.0078)] [G loss: 6.4772]\n",
      "3290 (5, 1) [D loss: (-1.2966)(R 3.4734, F -4.8379, G 0.0068)] [G loss: 4.7321]\n",
      "3291 (5, 1) [D loss: (-1.4035)(R 2.2894, F -3.7474, G 0.0054)] [G loss: 2.8464]\n",
      "3292 (5, 1) [D loss: (-1.4210)(R -0.1434, F -1.3405, G 0.0063)] [G loss: 1.0368]\n",
      "3293 (5, 1) [D loss: (-1.1988)(R -0.8592, F -0.4263, G 0.0087)] [G loss: 0.4130]\n",
      "3294 (5, 1) [D loss: (-1.2478)(R -1.4963, F 0.1654, G 0.0083)] [G loss: 0.2155]\n",
      "3295 (5, 1) [D loss: (-1.1983)(R -0.8897, F -0.3865, G 0.0078)] [G loss: 0.1384]\n",
      "3296 (5, 1) [D loss: (-1.1365)(R -0.5643, F -0.6444, G 0.0072)] [G loss: 0.9374]\n",
      "3297 (5, 1) [D loss: (-1.1682)(R 1.1296, F -2.3774, G 0.0080)] [G loss: 2.6808]\n",
      "3298 (5, 1) [D loss: (-1.2967)(R 2.3502, F -3.7399, G 0.0093)] [G loss: 3.9328]\n",
      "3299 (5, 1) [D loss: (-1.1300)(R 2.7084, F -3.9193, G 0.0081)] [G loss: 3.9501]\n",
      "3300 (5, 1) [D loss: (-1.4471)(R 2.1960, F -3.7298, G 0.0087)] [G loss: 3.6983]\n",
      "3301 (5, 1) [D loss: (-1.3037)(R 1.0656, F -2.4474, G 0.0078)] [G loss: 1.9357]\n",
      "3302 (5, 1) [D loss: (-1.0435)(R -0.1853, F -0.9230, G 0.0065)] [G loss: 0.2955]\n",
      "3303 (5, 1) [D loss: (-1.4978)(R -2.1121, F 0.5392, G 0.0075)] [G loss: -0.6673]\n",
      "3304 (5, 1) [D loss: (-1.3496)(R -1.3812, F -0.0561, G 0.0088)] [G loss: -0.2009]\n",
      "3305 (5, 1) [D loss: (-1.1634)(R -1.8214, F 0.5691, G 0.0089)] [G loss: -0.4790]\n",
      "3306 (5, 1) [D loss: (-1.1487)(R -0.8845, F -0.3294, G 0.0065)] [G loss: 1.1186]\n",
      "3307 (5, 1) [D loss: (-1.2042)(R 0.5501, F -1.8241, G 0.0070)] [G loss: 2.0410]\n",
      "3308 (5, 1) [D loss: (-1.4948)(R 1.4205, F -2.9893, G 0.0074)] [G loss: 3.1371]\n",
      "3309 (5, 1) [D loss: (-1.0962)(R 2.5234, F -3.7033, G 0.0084)] [G loss: 3.5047]\n",
      "3310 (5, 1) [D loss: (-1.2141)(R 2.5987, F -3.8786, G 0.0066)] [G loss: 4.0209]\n",
      "3311 (5, 1) [D loss: (-1.2954)(R 2.9375, F -4.2998, G 0.0067)] [G loss: 4.2600]\n",
      "3312 (5, 1) [D loss: (-1.3997)(R 2.8143, F -4.3063, G 0.0092)] [G loss: 4.4147]\n",
      "3313 (5, 1) [D loss: (-1.1400)(R 2.3438, F -3.5579, G 0.0074)] [G loss: 3.5544]\n",
      "3314 (5, 1) [D loss: (-1.1461)(R 1.0761, F -2.2881, G 0.0066)] [G loss: 1.7112]\n",
      "3315 (5, 1) [D loss: (-1.1597)(R -0.3825, F -0.8479, G 0.0071)] [G loss: 0.5904]\n",
      "3316 (5, 1) [D loss: (-1.3072)(R -1.3607, F -0.0106, G 0.0064)] [G loss: -0.3773]\n",
      "3317 (5, 1) [D loss: (-0.9956)(R -2.6445, F 1.5574, G 0.0092)] [G loss: -1.8523]\n",
      "3318 (5, 1) [D loss: (-1.3207)(R -4.3516, F 2.9559, G 0.0075)] [G loss: -3.1173]\n",
      "3319 (5, 1) [D loss: (-1.1107)(R -3.8585, F 2.6745, G 0.0073)] [G loss: -3.0281]\n",
      "3320 (5, 1) [D loss: (-1.6008)(R -5.3133, F 3.6399, G 0.0073)] [G loss: -4.0515]\n",
      "3321 (5, 1) [D loss: (-1.4169)(R -6.1137, F 4.6262, G 0.0071)] [G loss: -4.8246]\n",
      "3322 (5, 1) [D loss: (-1.4913)(R -5.3402, F 3.7917, G 0.0057)] [G loss: -3.8964]\n",
      "3323 (5, 1) [D loss: (-1.6374)(R -6.0618, F 4.3308, G 0.0094)] [G loss: -4.5649]\n",
      "3324 (5, 1) [D loss: (-1.4808)(R -6.7038, F 5.1422, G 0.0081)] [G loss: -5.6077]\n",
      "3325 (5, 1) [D loss: (-1.3147)(R -5.6564, F 4.2673, G 0.0074)] [G loss: -4.4587]\n",
      "3326 (5, 1) [D loss: (-0.9431)(R -5.3439, F 4.3281, G 0.0073)] [G loss: -3.7034]\n",
      "3327 (5, 1) [D loss: (-0.9169)(R -4.2646, F 3.2794, G 0.0068)] [G loss: -2.9608]\n",
      "3328 (5, 1) [D loss: (-1.3245)(R -4.3247, F 2.9248, G 0.0075)] [G loss: -3.2577]\n",
      "3329 (5, 1) [D loss: (-1.3313)(R -5.0047, F 3.6005, G 0.0073)] [G loss: -3.8452]\n",
      "3330 (5, 1) [D loss: (-1.2757)(R -4.4451, F 3.1101, G 0.0059)] [G loss: -3.0389]\n",
      "3331 (5, 1) [D loss: (-1.5821)(R -3.3751, F 1.7277, G 0.0065)] [G loss: -2.1555]\n",
      "3332 (5, 1) [D loss: (-1.3141)(R -3.1599, F 1.7733, G 0.0072)] [G loss: -1.7713]\n",
      "3333 (5, 1) [D loss: (-1.3362)(R -3.1419, F 1.7414, G 0.0064)] [G loss: -1.8560]\n",
      "3334 (5, 1) [D loss: (-1.1788)(R -3.4702, F 2.2202, G 0.0071)] [G loss: -1.9426]\n",
      "3335 (5, 1) [D loss: (-1.5542)(R -4.4134, F 2.7881, G 0.0071)] [G loss: -3.2594]\n",
      "3336 (5, 1) [D loss: (-1.2271)(R -3.6000, F 2.3030, G 0.0070)] [G loss: -2.5044]\n",
      "3337 (5, 1) [D loss: (-1.1852)(R -3.0143, F 1.7604, G 0.0069)] [G loss: -1.9432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338 (5, 1) [D loss: (-1.4253)(R -2.1492, F 0.6489, G 0.0075)] [G loss: -0.9779]\n",
      "3339 (5, 1) [D loss: (-1.0331)(R -1.4494, F 0.3250, G 0.0091)] [G loss: -0.3861]\n",
      "3340 (5, 1) [D loss: (-1.1668)(R -1.9487, F 0.6977, G 0.0084)] [G loss: -0.9432]\n",
      "3341 (5, 1) [D loss: (-1.3076)(R -2.0479, F 0.6623, G 0.0078)] [G loss: -0.4563]\n",
      "3342 (5, 1) [D loss: (-1.2622)(R -2.2899, F 0.9395, G 0.0088)] [G loss: -1.2433]\n",
      "3343 (5, 1) [D loss: (-1.0687)(R -1.7803, F 0.6322, G 0.0079)] [G loss: -0.6278]\n",
      "3344 (5, 1) [D loss: (-1.3320)(R -0.9938, F -0.3974, G 0.0059)] [G loss: 0.4780]\n",
      "3345 (5, 1) [D loss: (-1.2586)(R -1.1217, F -0.2012, G 0.0064)] [G loss: 0.3206]\n",
      "3346 (5, 1) [D loss: (-1.2444)(R 0.7046, F -2.0288, G 0.0080)] [G loss: 2.3747]\n",
      "3347 (5, 1) [D loss: (-1.3898)(R 2.2311, F -3.7017, G 0.0081)] [G loss: 4.0760]\n",
      "3348 (5, 1) [D loss: (-1.4132)(R 3.1984, F -4.6959, G 0.0084)] [G loss: 4.8303]\n",
      "3349 (5, 1) [D loss: (-1.2493)(R 4.0446, F -5.3727, G 0.0079)] [G loss: 5.7323]\n",
      "3350 (5, 1) [D loss: (-1.4885)(R 4.2242, F -5.8001, G 0.0087)] [G loss: 5.9153]\n",
      "3351 (5, 1) [D loss: (-0.9244)(R 4.9399, F -5.9375, G 0.0073)] [G loss: 5.9614]\n",
      "3352 (5, 1) [D loss: (-0.9353)(R 4.3133, F -5.3267, G 0.0078)] [G loss: 5.0362]\n",
      "3353 (5, 1) [D loss: (-1.3460)(R 3.5294, F -4.9465, G 0.0071)] [G loss: 4.6878]\n",
      "3354 (5, 1) [D loss: (-1.1943)(R 4.0954, F -5.3800, G 0.0090)] [G loss: 5.3225]\n",
      "3355 (5, 1) [D loss: (-1.2185)(R 3.3091, F -4.5988, G 0.0071)] [G loss: 4.4908]\n",
      "3356 (5, 1) [D loss: (-1.1855)(R 2.7324, F -3.9921, G 0.0074)] [G loss: 3.8178]\n",
      "3357 (5, 1) [D loss: (-1.4265)(R 2.2090, F -3.6964, G 0.0061)] [G loss: 3.5809]\n",
      "3358 (5, 1) [D loss: (-1.4616)(R 2.6204, F -4.1644, G 0.0082)] [G loss: 4.1632]\n",
      "3359 (5, 1) [D loss: (-1.2732)(R 2.3999, F -3.7533, G 0.0080)] [G loss: 3.7174]\n",
      "3360 (5, 1) [D loss: (-1.3638)(R 2.0356, F -3.4717, G 0.0072)] [G loss: 3.1655]\n",
      "3361 (5, 1) [D loss: (-1.2730)(R 2.9201, F -4.2785, G 0.0085)] [G loss: 4.4314]\n",
      "3362 (5, 1) [D loss: (-0.9842)(R 3.4788, F -4.5564, G 0.0093)] [G loss: 4.5549]\n",
      "3363 (5, 1) [D loss: (-1.4869)(R 2.2651, F -3.8149, G 0.0063)] [G loss: 3.9209]\n",
      "3364 (5, 1) [D loss: (-1.4031)(R 2.2190, F -3.6997, G 0.0078)] [G loss: 3.6532]\n",
      "3365 (5, 1) [D loss: (-1.3697)(R 1.8749, F -3.3195, G 0.0075)] [G loss: 3.5267]\n",
      "3366 (5, 1) [D loss: (-1.2416)(R 1.3118, F -2.6208, G 0.0067)] [G loss: 2.4268]\n",
      "3367 (5, 1) [D loss: (-1.2742)(R 0.7058, F -2.0520, G 0.0072)] [G loss: 1.6212]\n",
      "3368 (5, 1) [D loss: (-1.3283)(R 0.1929, F -1.6029, G 0.0082)] [G loss: 1.2185]\n",
      "3369 (5, 1) [D loss: (-1.4070)(R 0.2732, F -1.7516, G 0.0071)] [G loss: 2.2294]\n",
      "3370 (5, 1) [D loss: (-0.9906)(R 2.3049, F -3.3708, G 0.0075)] [G loss: 3.4461]\n",
      "3371 (5, 1) [D loss: (-1.4250)(R 1.5270, F -3.0353, G 0.0083)] [G loss: 3.1836]\n",
      "3372 (5, 1) [D loss: (-1.1062)(R 1.1455, F -2.3230, G 0.0071)] [G loss: 2.3820]\n",
      "3373 (5, 1) [D loss: (-1.3723)(R 2.3324, F -3.7713, G 0.0067)] [G loss: 3.8473]\n",
      "3374 (5, 1) [D loss: (-1.5604)(R 2.2464, F -3.8785, G 0.0072)] [G loss: 3.8375]\n",
      "3375 (5, 1) [D loss: (-1.4485)(R 1.7939, F -3.3042, G 0.0062)] [G loss: 2.9655]\n",
      "3376 (5, 1) [D loss: (-1.4298)(R 1.4806, F -2.9802, G 0.0070)] [G loss: 2.5595]\n",
      "3377 (5, 1) [D loss: (-1.2298)(R 0.7067, F -2.0132, G 0.0077)] [G loss: 1.7989]\n",
      "3378 (5, 1) [D loss: (-1.5869)(R -0.1890, F -1.4616, G 0.0064)] [G loss: 1.3812]\n",
      "3379 (5, 1) [D loss: (-1.4717)(R 0.0711, F -1.6239, G 0.0081)] [G loss: 1.8102]\n",
      "3380 (5, 1) [D loss: (-1.3180)(R 1.0389, F -2.4226, G 0.0066)] [G loss: 2.0814]\n",
      "3381 (5, 1) [D loss: (-1.3345)(R -0.0713, F -1.3381, G 0.0075)] [G loss: 1.1868]\n",
      "3382 (5, 1) [D loss: (-1.3197)(R -0.7219, F -0.6844, G 0.0087)] [G loss: 0.1056]\n",
      "3383 (5, 1) [D loss: (-1.2005)(R -0.5116, F -0.7571, G 0.0068)] [G loss: 1.0612]\n",
      "3384 (5, 1) [D loss: (-1.3069)(R -1.4833, F 0.1136, G 0.0063)] [G loss: -0.6086]\n",
      "3385 (5, 1) [D loss: (-1.4776)(R -3.2279, F 1.6714, G 0.0079)] [G loss: -2.1988]\n",
      "3386 (5, 1) [D loss: (-1.3484)(R -4.8499, F 3.4198, G 0.0082)] [G loss: -3.6887]\n",
      "3387 (5, 1) [D loss: (-1.1362)(R -5.9727, F 4.7627, G 0.0074)] [G loss: -4.9410]\n",
      "3388 (5, 1) [D loss: (-1.2142)(R -6.6809, F 5.3956, G 0.0071)] [G loss: -5.2535]\n",
      "3389 (5, 1) [D loss: (-1.3417)(R -7.0157, F 5.5985, G 0.0076)] [G loss: -5.7652]\n",
      "3390 (5, 1) [D loss: (-1.5651)(R -6.7621, F 5.1247, G 0.0072)] [G loss: -5.3427]\n",
      "3391 (5, 1) [D loss: (-1.2987)(R -6.5575, F 5.1822, G 0.0077)] [G loss: -4.9231]\n",
      "3392 (5, 1) [D loss: (-1.2399)(R -5.7991, F 4.4863, G 0.0073)] [G loss: -4.4324]\n",
      "3393 (5, 1) [D loss: (-1.2700)(R -5.6820, F 4.3432, G 0.0069)] [G loss: -4.5585]\n",
      "3394 (5, 1) [D loss: (-1.2552)(R -6.2128, F 4.8866, G 0.0071)] [G loss: -5.0138]\n",
      "3395 (5, 1) [D loss: (-1.0609)(R -6.4184, F 5.2755, G 0.0082)] [G loss: -5.8077]\n",
      "3396 (5, 1) [D loss: (-1.1648)(R -6.4488, F 5.2165, G 0.0067)] [G loss: -5.2101]\n",
      "3397 (5, 1) [D loss: (-1.4754)(R -5.1898, F 3.6651, G 0.0049)] [G loss: -3.7014]\n",
      "3398 (5, 1) [D loss: (-1.2282)(R -5.1561, F 3.8508, G 0.0077)] [G loss: -3.3988]\n",
      "3399 (5, 1) [D loss: (-1.2014)(R -4.4857, F 3.2138, G 0.0071)] [G loss: -3.2893]\n",
      "3400 (5, 1) [D loss: (-1.3521)(R -4.3070, F 2.8841, G 0.0071)] [G loss: -2.7574]\n",
      "3401 (5, 1) [D loss: (-1.2001)(R -3.4854, F 2.2166, G 0.0069)] [G loss: -1.9218]\n",
      "3402 (5, 1) [D loss: (-1.2623)(R -2.9298, F 1.5748, G 0.0093)] [G loss: -1.4537]\n",
      "3403 (5, 1) [D loss: (-1.3983)(R -2.2762, F 0.7996, G 0.0078)] [G loss: -0.7745]\n",
      "3404 (5, 1) [D loss: (-1.2774)(R -1.9848, F 0.6291, G 0.0078)] [G loss: -0.7146]\n",
      "3405 (5, 1) [D loss: (-1.0489)(R -2.0344, F 0.8900, G 0.0095)] [G loss: -0.6197]\n",
      "3406 (5, 1) [D loss: (-1.4148)(R -1.7088, F 0.2074, G 0.0087)] [G loss: -0.5348]\n",
      "3407 (5, 1) [D loss: (-1.2587)(R -2.4401, F 1.1143, G 0.0067)] [G loss: -1.3530]\n",
      "3408 (5, 1) [D loss: (-1.2851)(R -2.4445, F 1.0867, G 0.0073)] [G loss: -1.1293]\n",
      "3409 (5, 1) [D loss: (-1.3786)(R -2.3749, F 0.9199, G 0.0076)] [G loss: -0.7564]\n",
      "3410 (5, 1) [D loss: (-1.2877)(R -1.3551, F -0.0096, G 0.0077)] [G loss: 0.2207]\n",
      "3411 (5, 1) [D loss: (-1.1012)(R 0.3428, F -1.5121, G 0.0068)] [G loss: 1.6168]\n",
      "3412 (5, 1) [D loss: (-1.1440)(R 1.1771, F -2.3918, G 0.0071)] [G loss: 2.9098]\n",
      "3413 (5, 1) [D loss: (-1.4920)(R 1.8627, F -3.4287, G 0.0074)] [G loss: 3.7089]\n",
      "3414 (5, 1) [D loss: (-1.3550)(R 2.6085, F -4.0542, G 0.0091)] [G loss: 4.0706]\n",
      "3415 (5, 1) [D loss: (-1.4330)(R 2.8911, F -4.4044, G 0.0080)] [G loss: 4.3085]\n",
      "3416 (5, 1) [D loss: (-1.1917)(R 2.8448, F -4.0933, G 0.0057)] [G loss: 4.1589]\n",
      "3417 (5, 1) [D loss: (-1.1977)(R 2.8276, F -4.1126, G 0.0087)] [G loss: 4.1502]\n",
      "3418 (5, 1) [D loss: (-1.2219)(R 3.6824, F -4.9949, G 0.0091)] [G loss: 5.0881]\n",
      "3419 (5, 1) [D loss: (-1.1534)(R 3.9190, F -5.1667, G 0.0094)] [G loss: 4.9831]\n",
      "3420 (5, 1) [D loss: (-1.4717)(R 3.9127, F -5.4695, G 0.0085)] [G loss: 5.7614]\n",
      "3421 (5, 1) [D loss: (-1.3812)(R 5.1755, F -6.6444, G 0.0088)] [G loss: 6.6294]\n",
      "3422 (5, 1) [D loss: (-1.5110)(R 5.9804, F -7.5993, G 0.0108)] [G loss: 7.7083]\n",
      "3423 (5, 1) [D loss: (-1.5063)(R 6.8036, F -8.4055, G 0.0096)] [G loss: 8.2977]\n",
      "3424 (5, 1) [D loss: (-1.6169)(R 6.8388, F -8.5473, G 0.0092)] [G loss: 8.4705]\n",
      "3425 (5, 1) [D loss: (-1.2799)(R 7.6575, F -9.0174, G 0.0080)] [G loss: 8.9796]\n",
      "3426 (5, 1) [D loss: (-0.8848)(R 7.2397, F -8.2222, G 0.0098)] [G loss: 7.6925]\n",
      "3427 (5, 1) [D loss: (-1.1125)(R 4.9499, F -6.1282, G 0.0066)] [G loss: 5.6379]\n",
      "3428 (5, 1) [D loss: (-1.1985)(R 4.3632, F -5.6199, G 0.0058)] [G loss: 5.3774]\n",
      "3429 (5, 1) [D loss: (-1.1285)(R 4.0429, F -5.2382, G 0.0067)] [G loss: 5.2267]\n",
      "3430 (5, 1) [D loss: (-0.9955)(R 3.3869, F -4.4376, G 0.0055)] [G loss: 4.3196]\n",
      "3431 (5, 1) [D loss: (-1.2721)(R 3.5361, F -4.8829, G 0.0075)] [G loss: 4.7731]\n",
      "3432 (5, 1) [D loss: (-1.0711)(R 3.9333, F -5.0800, G 0.0076)] [G loss: 4.7847]\n",
      "3433 (5, 1) [D loss: (-1.3248)(R 4.3171, F -5.7252, G 0.0083)] [G loss: 5.4719]\n",
      "3434 (5, 1) [D loss: (-1.4335)(R 3.2785, F -4.7626, G 0.0051)] [G loss: 4.4234]\n",
      "3435 (5, 1) [D loss: (-1.4364)(R 2.1416, F -3.6430, G 0.0065)] [G loss: 3.3422]\n",
      "3436 (5, 1) [D loss: (-1.1234)(R 0.9995, F -2.1946, G 0.0072)] [G loss: 1.7322]\n",
      "3437 (5, 1) [D loss: (-1.2944)(R 0.0574, F -1.4312, G 0.0079)] [G loss: 1.3109]\n",
      "3438 (5, 1) [D loss: (-1.0948)(R -0.7763, F -0.3808, G 0.0062)] [G loss: 0.4580]\n",
      "3439 (5, 1) [D loss: (-1.3806)(R -1.1807, F -0.2776, G 0.0078)] [G loss: 0.6027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3440 (5, 1) [D loss: (-1.2438)(R -0.8545, F -0.4702, G 0.0081)] [G loss: 0.5009]\n",
      "3441 (5, 1) [D loss: (-1.2686)(R 0.0575, F -1.4072, G 0.0081)] [G loss: 1.7970]\n",
      "3442 (5, 1) [D loss: (-1.3607)(R 0.2688, F -1.6998, G 0.0070)] [G loss: 1.6187]\n",
      "3443 (5, 1) [D loss: (-1.2845)(R 0.3751, F -1.7211, G 0.0062)] [G loss: 1.8231]\n",
      "3444 (5, 1) [D loss: (-1.3837)(R 1.5793, F -3.0378, G 0.0075)] [G loss: 2.8860]\n",
      "3445 (5, 1) [D loss: (-1.2747)(R 1.3549, F -2.7034, G 0.0074)] [G loss: 2.6460]\n",
      "3446 (5, 1) [D loss: (-1.2030)(R 1.2282, F -2.5038, G 0.0073)] [G loss: 2.6279]\n",
      "3447 (5, 1) [D loss: (-1.1633)(R 1.5526, F -2.7878, G 0.0072)] [G loss: 2.7743]\n",
      "3448 (5, 1) [D loss: (-1.3431)(R 1.6353, F -3.0406, G 0.0062)] [G loss: 2.7166]\n",
      "3449 (5, 1) [D loss: (-1.3408)(R 0.3377, F -1.7418, G 0.0063)] [G loss: 1.6755]\n",
      "3450 (5, 1) [D loss: (-1.2606)(R -0.1028, F -1.2276, G 0.0070)] [G loss: 0.9244]\n",
      "3451 (5, 1) [D loss: (-1.1407)(R -1.6279, F 0.4088, G 0.0078)] [G loss: -0.6667]\n",
      "3452 (5, 1) [D loss: (-1.1264)(R -2.8000, F 1.6089, G 0.0065)] [G loss: -1.9732]\n",
      "3453 (5, 1) [D loss: (-1.2142)(R -4.3306, F 3.0441, G 0.0072)] [G loss: -3.5598]\n",
      "3454 (5, 1) [D loss: (-1.0654)(R -5.4449, F 4.2938, G 0.0086)] [G loss: -4.2932]\n",
      "3455 (5, 1) [D loss: (-1.4669)(R -6.7266, F 5.1839, G 0.0076)] [G loss: -5.1947]\n",
      "3456 (5, 1) [D loss: (-1.3902)(R -7.5569, F 6.0784, G 0.0088)] [G loss: -5.9873]\n",
      "3457 (5, 1) [D loss: (-1.4957)(R -8.5923, F 7.0103, G 0.0086)] [G loss: -7.1961]\n",
      "3458 (5, 1) [D loss: (-1.1568)(R -9.0456, F 7.7909, G 0.0098)] [G loss: -7.8591]\n",
      "3459 (5, 1) [D loss: (-1.4284)(R -10.0570, F 8.5334, G 0.0095)] [G loss: -8.5079]\n",
      "3460 (5, 1) [D loss: (-1.6400)(R -10.4504, F 8.7065, G 0.0104)] [G loss: -9.3413]\n",
      "3461 (5, 1) [D loss: (-1.6797)(R -10.5112, F 8.7644, G 0.0067)] [G loss: -9.4811]\n",
      "3462 (5, 1) [D loss: (-1.5167)(R -9.7790, F 8.1921, G 0.0070)] [G loss: -8.5917]\n",
      "3463 (5, 1) [D loss: (-1.6406)(R -8.6817, F 6.9914, G 0.0050)] [G loss: -7.4762]\n",
      "3464 (5, 1) [D loss: (-1.2908)(R -7.2871, F 5.9494, G 0.0047)] [G loss: -5.9097]\n",
      "3465 (5, 1) [D loss: (-1.3395)(R -6.7277, F 5.3321, G 0.0056)] [G loss: -5.7710]\n",
      "3466 (5, 1) [D loss: (-1.3920)(R -5.3941, F 3.9470, G 0.0055)] [G loss: -3.8962]\n",
      "3467 (5, 1) [D loss: (-1.3543)(R -3.9718, F 2.5615, G 0.0056)] [G loss: -2.9384]\n",
      "3468 (5, 1) [D loss: (-0.9708)(R -3.5426, F 2.4970, G 0.0075)] [G loss: -2.1095]\n",
      "3469 (5, 1) [D loss: (-1.3740)(R -2.6946, F 1.2547, G 0.0066)] [G loss: -1.5940]\n",
      "3470 (5, 1) [D loss: (-1.1400)(R -2.1143, F 0.9071, G 0.0067)] [G loss: -0.8023]\n",
      "3471 (5, 1) [D loss: (-1.2517)(R -1.5065, F 0.1850, G 0.0070)] [G loss: -0.2834]\n",
      "3472 (5, 1) [D loss: (-1.0859)(R -0.8904, F -0.2839, G 0.0088)] [G loss: 0.4373]\n",
      "3473 (5, 1) [D loss: (-1.3431)(R -0.3431, F -1.0693, G 0.0069)] [G loss: 1.4705]\n",
      "3474 (5, 1) [D loss: (-1.1579)(R 0.3091, F -1.5361, G 0.0069)] [G loss: 1.6036]\n",
      "3475 (5, 1) [D loss: (-1.2169)(R -0.0944, F -1.1873, G 0.0065)] [G loss: 1.4448]\n",
      "3476 (5, 1) [D loss: (-1.3750)(R -0.4363, F -1.0335, G 0.0095)] [G loss: 0.9975]\n",
      "3477 (5, 1) [D loss: (-1.1226)(R -0.1470, F -1.0419, G 0.0066)] [G loss: 1.0875]\n",
      "3478 (5, 1) [D loss: (-1.1372)(R -0.5025, F -0.7013, G 0.0067)] [G loss: 1.0203]\n",
      "3479 (5, 1) [D loss: (-0.9136)(R -0.3699, F -0.6166, G 0.0073)] [G loss: 0.6402]\n",
      "3480 (5, 1) [D loss: (-1.3999)(R -0.2533, F -1.2237, G 0.0077)] [G loss: 1.3022]\n",
      "3481 (5, 1) [D loss: (-1.3718)(R -0.3644, F -1.0683, G 0.0061)] [G loss: 0.7898]\n",
      "3482 (5, 1) [D loss: (-1.2833)(R -0.3816, F -0.9758, G 0.0074)] [G loss: 0.9793]\n",
      "3483 (5, 1) [D loss: (-1.0924)(R 0.5329, F -1.6850, G 0.0060)] [G loss: 1.7316]\n",
      "3484 (5, 1) [D loss: (-1.2670)(R 1.1125, F -2.4618, G 0.0082)] [G loss: 2.4254]\n",
      "3485 (5, 1) [D loss: (-1.3178)(R 1.9675, F -3.3662, G 0.0081)] [G loss: 3.6090]\n",
      "3486 (5, 1) [D loss: (-1.0978)(R 2.4733, F -3.6573, G 0.0086)] [G loss: 3.6119]\n",
      "3487 (5, 1) [D loss: (-1.5158)(R 2.9724, F -4.5765, G 0.0088)] [G loss: 4.7928]\n",
      "3488 (5, 1) [D loss: (-1.3743)(R 3.7208, F -5.1677, G 0.0073)] [G loss: 5.3388]\n",
      "3489 (5, 1) [D loss: (-1.0506)(R 3.9617, F -5.0823, G 0.0070)] [G loss: 4.8824]\n",
      "3490 (5, 1) [D loss: (-1.6300)(R 3.5324, F -5.2277, G 0.0065)] [G loss: 5.4958]\n",
      "3491 (5, 1) [D loss: (-1.0450)(R 5.5128, F -6.6482, G 0.0090)] [G loss: 6.4417]\n",
      "3492 (5, 1) [D loss: (-1.4338)(R 4.9009, F -6.4170, G 0.0082)] [G loss: 6.3946]\n",
      "3493 (5, 1) [D loss: (-1.7112)(R 5.3589, F -7.1685, G 0.0098)] [G loss: 7.2303]\n",
      "3494 (5, 1) [D loss: (-1.2128)(R 5.7151, F -7.0037, G 0.0076)] [G loss: 6.7294]\n",
      "3495 (5, 1) [D loss: (-1.3560)(R 5.5289, F -6.9675, G 0.0083)] [G loss: 7.0173]\n",
      "3496 (5, 1) [D loss: (-1.5165)(R 6.1500, F -7.7479, G 0.0081)] [G loss: 7.6528]\n",
      "3497 (5, 1) [D loss: (-1.1816)(R 6.0527, F -7.3190, G 0.0085)] [G loss: 7.1708]\n",
      "3498 (5, 1) [D loss: (-1.1440)(R 6.5095, F -7.7421, G 0.0089)] [G loss: 7.7311]\n",
      "3499 (5, 1) [D loss: (-1.7050)(R 6.9538, F -8.7514, G 0.0093)] [G loss: 8.4592]\n",
      "3500 (5, 1) [D loss: (-1.3351)(R 7.0380, F -8.4579, G 0.0085)] [G loss: 7.9810]\n",
      "3501 (5, 1) [D loss: (-1.5503)(R 6.7527, F -8.3945, G 0.0091)] [G loss: 8.0499]\n",
      "3502 (5, 1) [D loss: (-1.4365)(R 5.8794, F -7.3703, G 0.0054)] [G loss: 7.0503]\n",
      "3503 (5, 1) [D loss: (-1.4946)(R 4.2135, F -5.7552, G 0.0047)] [G loss: 5.5946]\n",
      "3504 (5, 1) [D loss: (-1.2070)(R 2.5512, F -3.8284, G 0.0070)] [G loss: 3.5692]\n",
      "3505 (5, 1) [D loss: (-1.1290)(R 1.2679, F -2.4517, G 0.0055)] [G loss: 2.1520]\n",
      "3506 (5, 1) [D loss: (-1.2244)(R 0.6430, F -1.9366, G 0.0069)] [G loss: 1.9653]\n",
      "3507 (5, 1) [D loss: (-1.3363)(R 1.1342, F -2.5347, G 0.0064)] [G loss: 2.0976]\n",
      "3508 (5, 1) [D loss: (-1.2546)(R 0.6834, F -2.0194, G 0.0081)] [G loss: 1.8744]\n",
      "3509 (5, 1) [D loss: (-1.0658)(R 0.1574, F -1.3008, G 0.0078)] [G loss: 1.2295]\n",
      "3510 (5, 1) [D loss: (-1.3970)(R -1.0558, F -0.4107, G 0.0070)] [G loss: 0.2774]\n",
      "3511 (5, 1) [D loss: (-1.3442)(R -0.8957, F -0.5313, G 0.0083)] [G loss: 0.3118]\n",
      "3512 (5, 1) [D loss: (-1.1813)(R -0.8272, F -0.4399, G 0.0086)] [G loss: 0.4356]\n",
      "3513 (5, 1) [D loss: (-1.3156)(R -0.4381, F -0.9781, G 0.0101)] [G loss: 1.2037]\n",
      "3514 (5, 1) [D loss: (-1.4325)(R -0.4725, F -1.0362, G 0.0076)] [G loss: 0.7717]\n",
      "3515 (5, 1) [D loss: (-1.3308)(R -1.0446, F -0.3768, G 0.0091)] [G loss: 0.2083]\n",
      "3516 (5, 1) [D loss: (-1.2514)(R -2.0755, F 0.7417, G 0.0082)] [G loss: -1.0176]\n",
      "3517 (5, 1) [D loss: (-1.0074)(R -2.7353, F 1.6632, G 0.0065)] [G loss: -1.5585]\n",
      "3518 (5, 1) [D loss: (-0.8991)(R -3.0525, F 2.0972, G 0.0056)] [G loss: -1.7453]\n",
      "3519 (5, 1) [D loss: (-1.2185)(R -2.7241, F 1.4369, G 0.0069)] [G loss: -1.5387]\n",
      "3520 (5, 1) [D loss: (-0.9168)(R -2.4622, F 1.4792, G 0.0066)] [G loss: -0.9962]\n",
      "3521 (5, 1) [D loss: (-1.1482)(R -1.6053, F 0.4012, G 0.0056)] [G loss: -0.1281]\n",
      "3522 (5, 1) [D loss: (-1.4228)(R -1.2331, F -0.2559, G 0.0066)] [G loss: 0.1698]\n",
      "3523 (5, 1) [D loss: (-1.6136)(R -1.0772, F -0.6249, G 0.0088)] [G loss: 0.3629]\n",
      "3524 (5, 1) [D loss: (-1.2410)(R -2.2498, F 0.9316, G 0.0077)] [G loss: -1.0477]\n",
      "3525 (5, 1) [D loss: (-1.3125)(R -4.1098, F 2.7051, G 0.0092)] [G loss: -2.8018]\n",
      "3526 (5, 1) [D loss: (-1.5312)(R -6.1048, F 4.4682, G 0.0105)] [G loss: -4.9914]\n",
      "3527 (5, 1) [D loss: (-1.3643)(R -8.1558, F 6.6880, G 0.0103)] [G loss: -7.0479]\n",
      "3528 (5, 1) [D loss: (-1.7211)(R -10.1786, F 8.3311, G 0.0126)] [G loss: -9.0432]\n",
      "3529 (5, 1) [D loss: (-1.4971)(R -11.3826, F 9.7825, G 0.0103)] [G loss: -10.4518]\n",
      "3530 (5, 1) [D loss: (-1.6031)(R -11.6850, F 9.9733, G 0.0109)] [G loss: -10.4602]\n",
      "3531 (5, 1) [D loss: (-1.2015)(R -12.1172, F 10.8127, G 0.0103)] [G loss: -10.2389]\n",
      "3532 (5, 1) [D loss: (-0.9526)(R -10.1380, F 9.1110, G 0.0074)] [G loss: -9.1150]\n",
      "3533 (5, 1) [D loss: (-1.5485)(R -9.1197, F 7.5172, G 0.0054)] [G loss: -7.9545]\n",
      "3534 (5, 1) [D loss: (-1.1989)(R -7.5443, F 6.2979, G 0.0047)] [G loss: -5.9806]\n",
      "3535 (5, 1) [D loss: (-0.7171)(R -6.3942, F 5.6272, G 0.0050)] [G loss: -5.1801]\n",
      "3536 (5, 1) [D loss: (-1.0245)(R -4.6668, F 3.5873, G 0.0055)] [G loss: -3.6250]\n",
      "3537 (5, 1) [D loss: (-1.0243)(R -3.9551, F 2.8736, G 0.0057)] [G loss: -2.6241]\n",
      "3538 (5, 1) [D loss: (-1.3256)(R -3.8455, F 2.4487, G 0.0071)] [G loss: -2.6970]\n",
      "3539 (5, 1) [D loss: (-1.1861)(R -2.4214, F 1.1730, G 0.0062)] [G loss: -1.0706]\n",
      "3540 (5, 1) [D loss: (-1.3074)(R -1.4739, F 0.1003, G 0.0066)] [G loss: -0.0402]\n",
      "3541 (5, 1) [D loss: (-1.4394)(R 0.0508, F -1.5656, G 0.0075)] [G loss: 1.7736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3542 (5, 1) [D loss: (-1.2357)(R 0.9851, F -2.2927, G 0.0072)] [G loss: 2.2960]\n",
      "3543 (5, 1) [D loss: (-1.3119)(R 2.0898, F -3.4795, G 0.0078)] [G loss: 4.2959]\n",
      "3544 (5, 1) [D loss: (-1.1358)(R 3.9567, F -5.1713, G 0.0079)] [G loss: 5.3140]\n",
      "3545 (5, 1) [D loss: (-0.9262)(R 4.4838, F -5.4981, G 0.0088)] [G loss: 5.6600]\n",
      "3546 (5, 1) [D loss: (-1.2118)(R 3.5755, F -4.8577, G 0.0070)] [G loss: 4.9244]\n",
      "3547 (5, 1) [D loss: (-0.9964)(R 2.3889, F -3.4645, G 0.0079)] [G loss: 3.4038]\n",
      "3548 (5, 1) [D loss: (-1.1242)(R 0.8504, F -2.0438, G 0.0069)] [G loss: 1.7254]\n",
      "3549 (5, 1) [D loss: (-1.3272)(R -1.0375, F -0.3596, G 0.0070)] [G loss: -0.1239]\n",
      "3550 (5, 1) [D loss: (-1.0907)(R -1.0543, F -0.1038, G 0.0067)] [G loss: 0.1681]\n",
      "3551 (5, 1) [D loss: (-1.2559)(R -1.1339, F -0.1843, G 0.0062)] [G loss: 0.0926]\n",
      "3552 (5, 1) [D loss: (-1.3411)(R -1.0320, F -0.3750, G 0.0066)] [G loss: 0.2477]\n",
      "3553 (5, 1) [D loss: (-1.2885)(R -0.1364, F -1.2269, G 0.0075)] [G loss: 1.5751]\n",
      "3554 (5, 1) [D loss: (-1.2631)(R 1.7653, F -3.0972, G 0.0069)] [G loss: 3.5388]\n",
      "3555 (5, 1) [D loss: (-1.2594)(R 3.7188, F -5.0757, G 0.0098)] [G loss: 5.2942]\n",
      "3556 (5, 1) [D loss: (-1.4364)(R 4.2311, F -5.7468, G 0.0079)] [G loss: 5.6359]\n",
      "3557 (5, 1) [D loss: (-1.5190)(R 3.9874, F -5.5834, G 0.0077)] [G loss: 5.5896]\n",
      "3558 (5, 1) [D loss: (-1.4862)(R 3.9380, F -5.5041, G 0.0080)] [G loss: 5.4192]\n",
      "3559 (5, 1) [D loss: (-1.6608)(R 4.7039, F -6.4388, G 0.0074)] [G loss: 6.2425]\n",
      "3560 (5, 1) [D loss: (-1.4134)(R 5.7628, F -7.2629, G 0.0087)] [G loss: 7.0868]\n",
      "3561 (5, 1) [D loss: (-1.7199)(R 5.8316, F -7.6327, G 0.0081)] [G loss: 7.5047]\n",
      "3562 (5, 1) [D loss: (-1.7036)(R 6.8630, F -8.6400, G 0.0073)] [G loss: 8.8109]\n",
      "3563 (5, 1) [D loss: (-1.2000)(R 9.7825, F -11.0969, G 0.0114)] [G loss: 10.5847]\n",
      "3564 (5, 1) [D loss: (-1.6644)(R 9.9528, F -11.7312, G 0.0114)] [G loss: 11.5309]\n",
      "3565 (5, 1) [D loss: (-1.1201)(R 11.2510, F -12.4909, G 0.0120)] [G loss: 12.1115]\n",
      "3566 (5, 1) [D loss: (-1.9773)(R 12.1711, F -14.2975, G 0.0149)] [G loss: 13.6236]\n",
      "3567 (5, 1) [D loss: (-1.6082)(R 13.7363, F -15.4823, G 0.0138)] [G loss: 14.2618]\n",
      "3568 (5, 1) [D loss: (-1.2633)(R 13.4400, F -14.7942, G 0.0091)] [G loss: 13.4349]\n",
      "3569 (5, 1) [D loss: (-0.9661)(R 12.3954, F -13.4474, G 0.0086)] [G loss: 12.2562]\n",
      "3570 (5, 1) [D loss: (-1.5861)(R 10.7059, F -12.3582, G 0.0066)] [G loss: 11.4502]\n",
      "3571 (5, 1) [D loss: (-1.5207)(R 10.0308, F -11.6189, G 0.0067)] [G loss: 10.6944]\n",
      "3572 (5, 1) [D loss: (-1.4197)(R 9.2956, F -10.7755, G 0.0060)] [G loss: 9.9709]\n",
      "3573 (5, 1) [D loss: (-1.4651)(R 8.3404, F -9.8634, G 0.0058)] [G loss: 8.8413]\n",
      "3574 (5, 1) [D loss: (-1.1124)(R 9.6362, F -10.8235, G 0.0075)] [G loss: 9.7046]\n",
      "3575 (5, 1) [D loss: (-1.3304)(R 8.3195, F -9.6972, G 0.0047)] [G loss: 8.1843]\n",
      "3576 (5, 1) [D loss: (-1.7914)(R 8.5214, F -10.3979, G 0.0085)] [G loss: 9.4180]\n",
      "3577 (5, 1) [D loss: (-1.4472)(R 8.5512, F -10.0806, G 0.0082)] [G loss: 8.9491]\n",
      "3578 (5, 1) [D loss: (-0.8373)(R 6.1201, F -7.0063, G 0.0049)] [G loss: 6.0567]\n",
      "3579 (5, 1) [D loss: (-1.1791)(R 2.5625, F -3.8024, G 0.0061)] [G loss: 3.0727]\n",
      "3580 (5, 1) [D loss: (-1.5773)(R -0.9325, F -0.7044, G 0.0060)] [G loss: -0.0200]\n",
      "3581 (5, 1) [D loss: (-1.3335)(R -4.6974, F 3.2844, G 0.0079)] [G loss: -3.2560]\n",
      "3582 (5, 1) [D loss: (-1.0467)(R -6.2298, F 5.0913, G 0.0092)] [G loss: -4.7602]\n",
      "3583 (5, 1) [D loss: (-1.2854)(R -6.5370, F 5.1790, G 0.0073)] [G loss: -4.5731]\n",
      "3584 (5, 1) [D loss: (-1.4579)(R -5.9626, F 4.4443, G 0.0060)] [G loss: -4.3179]\n",
      "3585 (5, 1) [D loss: (-1.4029)(R -6.3423, F 4.8661, G 0.0073)] [G loss: -4.2573]\n",
      "3586 (5, 1) [D loss: (-1.7162)(R -7.5150, F 5.6950, G 0.0104)] [G loss: -6.4832]\n",
      "3587 (5, 1) [D loss: (-1.5218)(R -10.4254, F 8.7948, G 0.0109)] [G loss: -8.6130]\n",
      "3588 (5, 1) [D loss: (-2.2520)(R -13.0531, F 10.6347, G 0.0166)] [G loss: -11.2141]\n",
      "3589 (5, 1) [D loss: (-1.9025)(R -14.9521, F 12.8422, G 0.0207)] [G loss: -13.1253]\n",
      "3590 (5, 1) [D loss: (-2.1327)(R -15.4633, F 13.1840, G 0.0147)] [G loss: -13.6577]\n",
      "3591 (5, 1) [D loss: (-1.9020)(R -15.3955, F 13.3876, G 0.0106)] [G loss: -13.7293]\n",
      "3592 (5, 1) [D loss: (-1.4229)(R -16.4878, F 14.8876, G 0.0177)] [G loss: -14.4818]\n",
      "3593 (5, 1) [D loss: (-3.0023)(R -17.6247, F 14.4778, G 0.0145)] [G loss: -16.5119]\n",
      "3594 (5, 1) [D loss: (-1.5563)(R -18.6875, F 16.9174, G 0.0214)] [G loss: -16.6411]\n",
      "3595 (5, 1) [D loss: (-1.9854)(R -18.7344, F 16.5515, G 0.0198)] [G loss: -17.3997]\n",
      "3596 (5, 1) [D loss: (-2.1216)(R -17.9272, F 15.6874, G 0.0118)] [G loss: -16.5622]\n",
      "3597 (5, 1) [D loss: (-1.5851)(R -15.9186, F 14.2373, G 0.0096)] [G loss: -15.1603]\n",
      "3598 (5, 1) [D loss: (-1.6669)(R -15.9172, F 14.1675, G 0.0083)] [G loss: -15.1510]\n",
      "3599 (5, 1) [D loss: (-1.8348)(R -15.5856, F 13.6472, G 0.0104)] [G loss: -14.5115]\n",
      "3600 (5, 1) [D loss: (-1.6183)(R -13.8800, F 12.1971, G 0.0065)] [G loss: -12.8126]\n",
      "3601 (5, 1) [D loss: (-1.7977)(R -12.8204, F 10.9540, G 0.0069)] [G loss: -11.8618]\n",
      "3602 (5, 1) [D loss: (-0.9819)(R -10.8587, F 9.8267, G 0.0050)] [G loss: -10.0450]\n",
      "3603 (5, 1) [D loss: (-1.6393)(R -10.2729, F 8.5892, G 0.0044)] [G loss: -9.2491]\n",
      "3604 (5, 1) [D loss: (-1.1763)(R -9.9657, F 8.7397, G 0.0050)] [G loss: -8.9467]\n",
      "3605 (5, 1) [D loss: (-1.1056)(R -8.6623, F 7.5082, G 0.0048)] [G loss: -8.1926]\n",
      "3606 (5, 1) [D loss: (-1.1311)(R -7.8967, F 6.7271, G 0.0038)] [G loss: -7.0031]\n",
      "3607 (5, 1) [D loss: (-1.3069)(R -6.4834, F 5.1332, G 0.0043)] [G loss: -4.9088]\n",
      "3608 (5, 1) [D loss: (-1.1529)(R -3.7213, F 2.5252, G 0.0043)] [G loss: -2.9144]\n",
      "3609 (5, 1) [D loss: (-1.2920)(R -2.0672, F 0.7141, G 0.0061)] [G loss: -0.0771]\n",
      "3610 (5, 1) [D loss: (-1.4529)(R 0.9701, F -2.5013, G 0.0078)] [G loss: 2.9780]\n",
      "3611 (5, 1) [D loss: (-1.1615)(R 2.7299, F -4.0052, G 0.0114)] [G loss: 4.6126]\n",
      "3612 (5, 1) [D loss: (-1.1731)(R 2.8130, F -4.0576, G 0.0071)] [G loss: 3.9910]\n",
      "3613 (5, 1) [D loss: (-1.4098)(R 1.7182, F -3.1862, G 0.0058)] [G loss: 3.1106]\n",
      "3614 (5, 1) [D loss: (-1.4300)(R 0.0349, F -1.5152, G 0.0050)] [G loss: 0.9652]\n",
      "3615 (5, 1) [D loss: (-1.4877)(R -2.4445, F 0.8607, G 0.0096)] [G loss: -1.3976]\n",
      "3616 (5, 1) [D loss: (-1.4001)(R -3.5325, F 2.0342, G 0.0098)] [G loss: -2.2410]\n",
      "3617 (5, 1) [D loss: (-0.9764)(R -2.3991, F 1.3625, G 0.0060)] [G loss: -1.2020]\n",
      "3618 (5, 1) [D loss: (-1.3058)(R -1.1843, F -0.1824, G 0.0061)] [G loss: 0.1373]\n",
      "3619 (5, 1) [D loss: (-1.1527)(R 0.6962, F -1.9154, G 0.0066)] [G loss: 2.0939]\n",
      "3620 (5, 1) [D loss: (-1.6291)(R 2.0264, F -3.7192, G 0.0064)] [G loss: 4.4182]\n",
      "3621 (5, 1) [D loss: (-1.5885)(R 5.2357, F -6.9500, G 0.0126)] [G loss: 7.8984]\n",
      "3622 (5, 1) [D loss: (-1.5981)(R 7.4028, F -9.1384, G 0.0138)] [G loss: 9.8741]\n",
      "3623 (5, 1) [D loss: (-1.4672)(R 9.2845, F -10.8796, G 0.0128)] [G loss: 11.1094]\n",
      "3624 (5, 1) [D loss: (-2.0490)(R 8.9747, F -11.1248, G 0.0101)] [G loss: 11.2364]\n",
      "3625 (5, 1) [D loss: (-1.5004)(R 10.2754, F -11.8831, G 0.0107)] [G loss: 11.9168]\n",
      "3626 (5, 1) [D loss: (-1.7877)(R 10.7827, F -12.6872, G 0.0117)] [G loss: 12.5419]\n",
      "3627 (5, 1) [D loss: (-2.0370)(R 11.0483, F -13.1739, G 0.0089)] [G loss: 12.8621]\n",
      "3628 (5, 1) [D loss: (-2.0730)(R 10.7821, F -12.9611, G 0.0106)] [G loss: 12.6715]\n",
      "3629 (5, 1) [D loss: (-2.2113)(R 12.3953, F -14.7547, G 0.0148)] [G loss: 14.2842]\n",
      "3630 (5, 1) [D loss: (-1.9971)(R 14.4363, F -16.5945, G 0.0161)] [G loss: 16.0661]\n",
      "3631 (5, 1) [D loss: (-1.6025)(R 16.8937, F -18.7187, G 0.0222)] [G loss: 17.9466]\n",
      "3632 (5, 1) [D loss: (-2.8068)(R 17.7173, F -20.7692, G 0.0245)] [G loss: 19.7338]\n",
      "3633 (5, 1) [D loss: (-2.1884)(R 19.0124, F -21.4228, G 0.0222)] [G loss: 19.8705]\n",
      "3634 (5, 1) [D loss: (-1.6916)(R 17.9890, F -19.8352, G 0.0155)] [G loss: 18.3029]\n",
      "3635 (5, 1) [D loss: (-2.3402)(R 17.2193, F -19.6967, G 0.0137)] [G loss: 18.0991]\n",
      "3636 (5, 1) [D loss: (-1.9327)(R 18.4614, F -20.5850, G 0.0191)] [G loss: 19.0991]\n",
      "3637 (5, 1) [D loss: (-1.3186)(R 17.1937, F -18.6286, G 0.0116)] [G loss: 16.3691]\n",
      "3638 (5, 1) [D loss: (-2.2052)(R 14.1818, F -16.4381, G 0.0051)] [G loss: 14.6823]\n",
      "3639 (5, 1) [D loss: (-1.6295)(R 14.3886, F -16.0725, G 0.0054)] [G loss: 14.3327]\n",
      "3640 (5, 1) [D loss: (-2.5342)(R 15.3309, F -17.9688, G 0.0104)] [G loss: 15.3846]\n",
      "3641 (5, 1) [D loss: (-3.6996)(R 14.5395, F -18.3934, G 0.0154)] [G loss: 16.4983]\n",
      "3642 (5, 1) [D loss: (-3.8919)(R 17.7140, F -22.0387, G 0.0433)] [G loss: 18.8181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3643 (5, 1) [D loss: (-2.6300)(R 18.6229, F -21.7069, G 0.0454)] [G loss: 17.6295]\n",
      "3644 (5, 1) [D loss: (-2.1795)(R 16.3402, F -18.6880, G 0.0168)] [G loss: 15.0717]\n",
      "3645 (5, 1) [D loss: (-1.9495)(R 18.3299, F -20.4268, G 0.0147)] [G loss: 16.9845]\n",
      "3646 (5, 1) [D loss: (-1.3369)(R 17.6441, F -19.0289, G 0.0048)] [G loss: 15.5731]\n",
      "3647 (5, 1) [D loss: (-1.6210)(R 16.2957, F -17.9742, G 0.0058)] [G loss: 15.2277]\n",
      "3648 (5, 1) [D loss: (-3.9064)(R 14.3420, F -18.3742, G 0.0126)] [G loss: 15.6429]\n",
      "3649 (5, 1) [D loss: (-2.9223)(R 12.4446, F -15.5890, G 0.0222)] [G loss: 13.1699]\n",
      "3650 (5, 1) [D loss: (-2.6270)(R 6.0552, F -8.7645, G 0.0082)] [G loss: 6.8782]\n",
      "3651 (5, 1) [D loss: (-0.6780)(R 4.0990, F -4.8107, G 0.0034)] [G loss: 3.2931]\n",
      "3652 (5, 1) [D loss: (-1.4403)(R -1.0599, F -0.4196, G 0.0039)] [G loss: -0.2340]\n",
      "3653 (5, 1) [D loss: (-2.1503)(R -5.2003, F 3.0168, G 0.0033)] [G loss: -4.0439]\n",
      "3654 (5, 1) [D loss: (-3.0999)(R -10.7018, F 7.5207, G 0.0081)] [G loss: -7.8399]\n",
      "3655 (5, 1) [D loss: (-3.6293)(R -14.7409, F 10.8728, G 0.0239)] [G loss: -10.4124]\n",
      "3656 (5, 1) [D loss: (-2.4216)(R -13.3719, F 10.7926, G 0.0158)] [G loss: -9.2197]\n",
      "3657 (5, 1) [D loss: (-2.5262)(R -11.7885, F 9.1495, G 0.0113)] [G loss: -9.3212]\n",
      "3658 (5, 1) [D loss: (-2.0509)(R -12.8667, F 10.7204, G 0.0095)] [G loss: -10.0025]\n",
      "3659 (5, 1) [D loss: (-2.0786)(R -14.1225, F 11.8738, G 0.0170)] [G loss: -11.4089]\n",
      "3660 (5, 1) [D loss: (-3.0383)(R -18.5846, F 15.1623, G 0.0384)] [G loss: -13.9170]\n",
      "3661 (5, 1) [D loss: (-4.7876)(R -19.7898, F 14.5962, G 0.0406)] [G loss: -15.7031]\n",
      "3662 (5, 1) [D loss: (-3.4408)(R -20.5331, F 16.6474, G 0.0445)] [G loss: -16.3526]\n",
      "3663 (5, 1) [D loss: (-2.8123)(R -19.0598, F 15.9927, G 0.0255)] [G loss: -16.5749]\n",
      "3664 (5, 1) [D loss: (-2.7191)(R -21.0020, F 17.9932, G 0.0290)] [G loss: -18.9613]\n",
      "3665 (5, 1) [D loss: (-2.7926)(R -22.7648, F 19.6739, G 0.0298)] [G loss: -19.7308]\n",
      "3666 (5, 1) [D loss: (-4.1021)(R -24.3583, F 19.9052, G 0.0351)] [G loss: -21.4970]\n",
      "3667 (5, 1) [D loss: (-3.3430)(R -22.6552, F 19.0715, G 0.0241)] [G loss: -19.8353]\n",
      "3668 (5, 1) [D loss: (-3.3085)(R -21.7528, F 18.2365, G 0.0208)] [G loss: -19.5934]\n",
      "3669 (5, 1) [D loss: (-2.0800)(R -20.7937, F 18.5859, G 0.0128)] [G loss: -18.9867]\n",
      "3670 (5, 1) [D loss: (-1.9313)(R -18.3331, F 16.3481, G 0.0054)] [G loss: -17.4175]\n",
      "3671 (5, 1) [D loss: (-0.9158)(R -18.2311, F 17.2505, G 0.0065)] [G loss: -17.0266]\n",
      "3672 (5, 1) [D loss: (-2.4979)(R -16.2880, F 13.7590, G 0.0031)] [G loss: -15.0488]\n",
      "3673 (5, 1) [D loss: (-1.6882)(R -14.2408, F 12.5039, G 0.0049)] [G loss: -12.7104]\n",
      "3674 (5, 1) [D loss: (-1.7691)(R -11.4958, F 9.6817, G 0.0045)] [G loss: -10.0128]\n",
      "3675 (5, 1) [D loss: (-1.3912)(R -9.1690, F 7.7326, G 0.0045)] [G loss: -7.9459]\n",
      "3676 (5, 1) [D loss: (-1.5923)(R -8.0907, F 6.4445, G 0.0054)] [G loss: -6.7881]\n",
      "3677 (5, 1) [D loss: (-1.3894)(R -7.9316, F 6.4916, G 0.0051)] [G loss: -6.5928]\n",
      "3678 (5, 1) [D loss: (-1.1859)(R -6.7580, F 5.5293, G 0.0043)] [G loss: -5.9103]\n",
      "3679 (5, 1) [D loss: (-1.2009)(R -7.3815, F 6.1339, G 0.0047)] [G loss: -5.8501]\n",
      "3680 (5, 1) [D loss: (-1.7175)(R -6.3342, F 4.5657, G 0.0051)] [G loss: -4.7670]\n",
      "3681 (5, 1) [D loss: (-1.1284)(R -6.3432, F 5.1470, G 0.0068)] [G loss: -5.4547]\n",
      "3682 (5, 1) [D loss: (-1.5503)(R -6.1089, F 4.5178, G 0.0041)] [G loss: -5.1486]\n",
      "3683 (5, 1) [D loss: (-1.2894)(R -6.3567, F 4.9992, G 0.0068)] [G loss: -5.2056]\n",
      "3684 (5, 1) [D loss: (-1.4658)(R -6.4515, F 4.9112, G 0.0074)] [G loss: -5.0853]\n",
      "3685 (5, 1) [D loss: (-1.4838)(R -6.3589, F 4.7937, G 0.0081)] [G loss: -5.4899]\n",
      "3686 (5, 1) [D loss: (-1.6812)(R -5.8450, F 4.1036, G 0.0060)] [G loss: -5.0722]\n",
      "3687 (5, 1) [D loss: (-2.0071)(R -6.8171, F 4.7358, G 0.0074)] [G loss: -6.5147]\n",
      "3688 (5, 1) [D loss: (-1.2127)(R -8.6087, F 7.2832, G 0.0113)] [G loss: -8.0721]\n",
      "3689 (5, 1) [D loss: (-0.9124)(R -8.8875, F 7.8642, G 0.0111)] [G loss: -8.2819]\n",
      "3690 (5, 1) [D loss: (-1.0348)(R -9.2930, F 8.1576, G 0.0101)] [G loss: -9.5777]\n",
      "3691 (5, 1) [D loss: (-1.1200)(R -9.5469, F 8.3414, G 0.0085)] [G loss: -9.7085]\n",
      "3692 (5, 1) [D loss: (-1.5506)(R -10.2449, F 8.6245, G 0.0070)] [G loss: -9.9653]\n",
      "3693 (5, 1) [D loss: (-1.0905)(R -9.3086, F 8.1673, G 0.0051)] [G loss: -8.9932]\n",
      "3694 (5, 1) [D loss: (-1.2948)(R -8.7182, F 7.3654, G 0.0058)] [G loss: -7.9709]\n",
      "3695 (5, 1) [D loss: (-1.8051)(R -7.5475, F 5.6818, G 0.0061)] [G loss: -6.2984]\n",
      "3696 (5, 1) [D loss: (-1.0008)(R -5.1827, F 4.1235, G 0.0058)] [G loss: -3.8893]\n",
      "3697 (5, 1) [D loss: (-0.8432)(R -2.0802, F 1.1853, G 0.0052)] [G loss: -0.4995]\n",
      "3698 (5, 1) [D loss: (-1.2941)(R 0.1280, F -1.4894, G 0.0067)] [G loss: 2.0842]\n",
      "3699 (5, 1) [D loss: (-1.1837)(R 3.3847, F -4.6489, G 0.0080)] [G loss: 5.7911]\n",
      "3700 (5, 1) [D loss: (-1.0809)(R 6.0180, F -7.1798, G 0.0081)] [G loss: 8.2299]\n",
      "3701 (5, 1) [D loss: (-1.6579)(R 7.9632, F -9.6979, G 0.0077)] [G loss: 10.2774]\n",
      "3702 (5, 1) [D loss: (-2.0562)(R 9.2875, F -11.4538, G 0.0110)] [G loss: 11.7208]\n",
      "3703 (5, 1) [D loss: (-1.7746)(R 10.4382, F -12.3126, G 0.0100)] [G loss: 12.3706]\n",
      "3704 (5, 1) [D loss: (-1.9211)(R 10.6599, F -12.6829, G 0.0102)] [G loss: 12.8804]\n",
      "3705 (5, 1) [D loss: (-1.5246)(R 11.4864, F -13.1113, G 0.0100)] [G loss: 13.4348]\n",
      "3706 (5, 1) [D loss: (-1.8677)(R 12.5207, F -14.4979, G 0.0110)] [G loss: 14.6128]\n",
      "3707 (5, 1) [D loss: (-1.9107)(R 13.3695, F -15.3921, G 0.0112)] [G loss: 15.4410]\n",
      "3708 (5, 1) [D loss: (-1.9750)(R 13.5574, F -15.6651, G 0.0133)] [G loss: 15.6251]\n",
      "3709 (5, 1) [D loss: (-2.0543)(R 15.6180, F -17.8781, G 0.0206)] [G loss: 18.2228]\n",
      "3710 (5, 1) [D loss: (-2.4179)(R 17.0450, F -19.6996, G 0.0237)] [G loss: 19.4945]\n",
      "3711 (5, 1) [D loss: (-2.2593)(R 17.6121, F -20.0711, G 0.0200)] [G loss: 19.4585]\n",
      "3712 (5, 1) [D loss: (-1.7324)(R 17.9677, F -19.8849, G 0.0185)] [G loss: 19.5100]\n",
      "3713 (5, 1) [D loss: (-1.4309)(R 16.6283, F -18.1459, G 0.0087)] [G loss: 17.2556]\n",
      "3714 (5, 1) [D loss: (-0.8815)(R 14.8659, F -15.7954, G 0.0048)] [G loss: 15.2520]\n",
      "3715 (5, 1) [D loss: (-1.6666)(R 12.1582, F -13.8588, G 0.0034)] [G loss: 13.1642]\n",
      "3716 (5, 1) [D loss: (-2.0404)(R 10.2501, F -12.3430, G 0.0052)] [G loss: 11.9554]\n",
      "3717 (5, 1) [D loss: (-1.6134)(R 9.8475, F -11.5144, G 0.0054)] [G loss: 11.1646]\n",
      "3718 (5, 1) [D loss: (-1.8135)(R 9.2747, F -11.1590, G 0.0071)] [G loss: 10.9319]\n",
      "3719 (5, 1) [D loss: (-1.9033)(R 10.7528, F -12.7586, G 0.0102)] [G loss: 12.3374]\n",
      "3720 (5, 1) [D loss: (-1.6040)(R 12.8916, F -14.6359, G 0.0140)] [G loss: 14.1080]\n",
      "3721 (5, 1) [D loss: (-1.9522)(R 12.5447, F -14.6363, G 0.0139)] [G loss: 14.0051]\n",
      "3722 (5, 1) [D loss: (-1.5804)(R 11.0172, F -12.6765, G 0.0079)] [G loss: 11.9942]\n",
      "3723 (5, 1) [D loss: (-0.9101)(R 9.6602, F -10.6265, G 0.0056)] [G loss: 9.9455]\n",
      "3724 (5, 1) [D loss: (-1.0776)(R 7.2318, F -8.3515, G 0.0042)] [G loss: 7.8334]\n",
      "3725 (5, 1) [D loss: (-1.0689)(R 4.3034, F -5.4080, G 0.0036)] [G loss: 4.4671]\n",
      "3726 (5, 1) [D loss: (-1.7196)(R 0.1219, F -1.8808, G 0.0039)] [G loss: 0.9685]\n",
      "3727 (5, 1) [D loss: (-2.2384)(R -3.6341, F 1.3375, G 0.0058)] [G loss: -1.6353]\n",
      "3728 (5, 1) [D loss: (-2.2519)(R -5.4339, F 3.0715, G 0.0111)] [G loss: -3.2228]\n",
      "3729 (5, 1) [D loss: (-1.6673)(R -5.3274, F 3.5680, G 0.0092)] [G loss: -3.1790]\n",
      "3730 (5, 1) [D loss: (-0.9906)(R -2.3566, F 1.2940, G 0.0072)] [G loss: -0.1137]\n",
      "3731 (5, 1) [D loss: (-1.2402)(R 1.1768, F -2.4729, G 0.0056)] [G loss: 3.4765]\n",
      "3732 (5, 1) [D loss: (-1.8161)(R 6.5260, F -8.4196, G 0.0078)] [G loss: 9.0069]\n",
      "3733 (5, 1) [D loss: (-1.5421)(R 11.7493, F -13.4750, G 0.0184)] [G loss: 13.2087]\n",
      "3734 (5, 1) [D loss: (-1.8784)(R 12.7489, F -14.7966, G 0.0169)] [G loss: 14.0551]\n",
      "3735 (5, 1) [D loss: (-1.4329)(R 10.2668, F -11.7707, G 0.0071)] [G loss: 10.7308]\n",
      "3736 (5, 1) [D loss: (-1.0281)(R 7.8570, F -8.9353, G 0.0050)] [G loss: 8.1486]\n",
      "3737 (5, 1) [D loss: (-1.0179)(R 3.4844, F -4.5321, G 0.0030)] [G loss: 3.6296]\n",
      "3738 (5, 1) [D loss: (-1.9937)(R -2.9692, F 0.9303, G 0.0045)] [G loss: -2.1977]\n",
      "3739 (5, 1) [D loss: (-2.6805)(R -8.8280, F 6.0447, G 0.0103)] [G loss: -7.3489]\n",
      "3740 (5, 1) [D loss: (-1.9035)(R -11.7220, F 9.5496, G 0.0269)] [G loss: -9.2147]\n",
      "3741 (5, 1) [D loss: (-2.6380)(R -11.7809, F 9.0019, G 0.0141)] [G loss: -9.5045]\n",
      "3742 (5, 1) [D loss: (-1.2425)(R -10.0933, F 8.7777, G 0.0073)] [G loss: -8.1241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3743 (5, 1) [D loss: (-1.0462)(R -8.2188, F 7.1263, G 0.0046)] [G loss: -6.6922]\n",
      "3744 (5, 1) [D loss: (-1.0548)(R -6.2146, F 5.1221, G 0.0038)] [G loss: -4.9181]\n",
      "3745 (5, 1) [D loss: (-0.8830)(R -4.9071, F 3.9759, G 0.0048)] [G loss: -3.3090]\n",
      "3746 (5, 1) [D loss: (-1.3300)(R -4.1491, F 2.7544, G 0.0065)] [G loss: -2.9554]\n",
      "3747 (5, 1) [D loss: (-1.9092)(R -6.1637, F 4.1765, G 0.0078)] [G loss: -5.4611]\n",
      "3748 (5, 1) [D loss: (-1.5843)(R -8.0382, F 6.3618, G 0.0092)] [G loss: -6.6302]\n",
      "3749 (5, 1) [D loss: (-2.1410)(R -11.5206, F 9.2108, G 0.0169)] [G loss: -10.2521]\n",
      "3750 (5, 1) [D loss: (-2.2686)(R -14.2648, F 11.7409, G 0.0255)] [G loss: -12.2443]\n",
      "3751 (5, 1) [D loss: (-2.4169)(R -15.0178, F 12.3653, G 0.0236)] [G loss: -13.3671]\n",
      "3752 (5, 1) [D loss: (-1.9285)(R -15.1737, F 13.0650, G 0.0180)] [G loss: -13.5406]\n",
      "3753 (5, 1) [D loss: (-1.6218)(R -14.0200, F 12.2949, G 0.0103)] [G loss: -12.9019]\n",
      "3754 (5, 1) [D loss: (-1.1908)(R -13.1682, F 11.9120, G 0.0065)] [G loss: -12.6893]\n",
      "3755 (5, 1) [D loss: (-0.7147)(R -12.3562, F 11.5908, G 0.0051)] [G loss: -11.9255]\n",
      "3756 (5, 1) [D loss: (-1.6555)(R -11.2495, F 9.5595, G 0.0034)] [G loss: -11.2618]\n",
      "3757 (5, 1) [D loss: (-0.3597)(R -10.7932, F 10.3957, G 0.0038)] [G loss: -10.8032]\n",
      "3758 (5, 1) [D loss: (-1.2442)(R -10.7272, F 9.4437, G 0.0039)] [G loss: -9.9692]\n",
      "3759 (5, 1) [D loss: (-0.9677)(R -9.0769, F 8.0674, G 0.0042)] [G loss: -8.3672]\n",
      "3760 (5, 1) [D loss: (-1.2748)(R -7.7099, F 6.3907, G 0.0044)] [G loss: -6.6136]\n",
      "3761 (5, 1) [D loss: (-1.8979)(R -6.8239, F 4.8836, G 0.0042)] [G loss: -5.5098]\n",
      "3762 (5, 1) [D loss: (-1.4815)(R -5.7564, F 4.2105, G 0.0064)] [G loss: -4.5262]\n",
      "3763 (5, 1) [D loss: (-1.6109)(R -3.9841, F 2.3165, G 0.0057)] [G loss: -2.8393]\n",
      "3764 (5, 1) [D loss: (-1.0713)(R -2.7660, F 1.6190, G 0.0076)] [G loss: -1.5520]\n",
      "3765 (5, 1) [D loss: (-1.5213)(R -0.9568, F -0.6195, G 0.0055)] [G loss: 0.9494]\n",
      "3766 (5, 1) [D loss: (-1.0889)(R 1.8539, F -3.0011, G 0.0058)] [G loss: 3.7079]\n",
      "3767 (5, 1) [D loss: (-1.1445)(R 4.3576, F -5.5776, G 0.0076)] [G loss: 6.1348]\n",
      "3768 (5, 1) [D loss: (-1.1831)(R 6.7581, F -8.0249, G 0.0084)] [G loss: 8.5767]\n",
      "3769 (5, 1) [D loss: (-1.1711)(R 8.0864, F -9.3474, G 0.0090)] [G loss: 9.4393]\n",
      "3770 (5, 1) [D loss: (-1.6690)(R 8.8051, F -10.5569, G 0.0083)] [G loss: 10.9748]\n",
      "3771 (5, 1) [D loss: (-1.7501)(R 9.5941, F -11.4278, G 0.0084)] [G loss: 11.8212]\n",
      "3772 (5, 1) [D loss: (-1.5319)(R 11.3075, F -12.9538, G 0.0114)] [G loss: 13.1454]\n",
      "3773 (5, 1) [D loss: (-1.8673)(R 11.3016, F -13.2590, G 0.0090)] [G loss: 13.5128]\n",
      "3774 (5, 1) [D loss: (-1.5511)(R 12.2356, F -13.8846, G 0.0098)] [G loss: 13.7734]\n",
      "3775 (5, 1) [D loss: (-1.8222)(R 11.6796, F -13.5970, G 0.0095)] [G loss: 13.4101]\n",
      "3776 (5, 1) [D loss: (-1.3858)(R 11.3837, F -12.8379, G 0.0068)] [G loss: 12.5643]\n",
      "3777 (5, 1) [D loss: (-1.9707)(R 10.6806, F -12.7342, G 0.0083)] [G loss: 13.3445]\n",
      "3778 (5, 1) [D loss: (-1.6802)(R 11.9608, F -13.7185, G 0.0077)] [G loss: 13.5998]\n",
      "3779 (5, 1) [D loss: (-1.3755)(R 11.6272, F -13.0819, G 0.0079)] [G loss: 12.9192]\n",
      "3780 (5, 1) [D loss: (-1.3283)(R 11.8609, F -13.2631, G 0.0074)] [G loss: 13.3407]\n",
      "3781 (5, 1) [D loss: (-1.5702)(R 11.0282, F -12.6502, G 0.0052)] [G loss: 12.5156]\n",
      "3782 (5, 1) [D loss: (-1.2371)(R 10.9316, F -12.2226, G 0.0054)] [G loss: 11.9524]\n",
      "3783 (5, 1) [D loss: (-1.4434)(R 10.6348, F -12.1379, G 0.0060)] [G loss: 11.8420]\n",
      "3784 (5, 1) [D loss: (-1.5087)(R 9.3434, F -10.9126, G 0.0060)] [G loss: 10.3735]\n",
      "3785 (5, 1) [D loss: (-1.2540)(R 9.0877, F -10.3858, G 0.0044)] [G loss: 10.3134]\n",
      "3786 (5, 1) [D loss: (-1.6065)(R 7.9688, F -9.6316, G 0.0056)] [G loss: 9.4985]\n",
      "3787 (5, 1) [D loss: (-1.3926)(R 7.1265, F -8.5697, G 0.0051)] [G loss: 7.8878]\n",
      "3788 (5, 1) [D loss: (-1.4435)(R 5.1095, F -6.5987, G 0.0046)] [G loss: 6.3812]\n",
      "3789 (5, 1) [D loss: (-1.6400)(R 4.5548, F -6.2618, G 0.0067)] [G loss: 6.0696]\n",
      "3790 (5, 1) [D loss: (-1.4100)(R 4.2871, F -5.7788, G 0.0082)] [G loss: 5.5952]\n",
      "3791 (5, 1) [D loss: (-1.4265)(R 3.5232, F -5.0258, G 0.0076)] [G loss: 4.6938]\n",
      "3792 (5, 1) [D loss: (-0.9369)(R 3.3183, F -4.3276, G 0.0072)] [G loss: 4.3626]\n",
      "3793 (5, 1) [D loss: (-0.9007)(R 4.3199, F -5.2844, G 0.0064)] [G loss: 5.2400]\n",
      "3794 (5, 1) [D loss: (-1.2681)(R 4.2840, F -5.6207, G 0.0069)] [G loss: 5.4832]\n",
      "3795 (5, 1) [D loss: (-1.2670)(R 4.7776, F -6.1218, G 0.0077)] [G loss: 5.9857]\n",
      "3796 (5, 1) [D loss: (-0.8132)(R 4.1534, F -5.0414, G 0.0075)] [G loss: 4.7801]\n",
      "3797 (5, 1) [D loss: (-1.0386)(R 3.4078, F -4.5130, G 0.0067)] [G loss: 4.0948]\n",
      "3798 (5, 1) [D loss: (-1.3232)(R 2.7307, F -4.1341, G 0.0080)] [G loss: 3.7165]\n",
      "3799 (5, 1) [D loss: (-1.2479)(R 2.5836, F -3.8986, G 0.0067)] [G loss: 3.5956]\n",
      "3800 (5, 1) [D loss: (-1.5197)(R 1.7845, F -3.3971, G 0.0093)] [G loss: 3.1626]\n",
      "3801 (5, 1) [D loss: (-1.3766)(R 0.5082, F -1.9855, G 0.0101)] [G loss: 1.2419]\n",
      "3802 (5, 1) [D loss: (-1.6341)(R -1.6659, F -0.0705, G 0.0102)] [G loss: -1.0370]\n",
      "3803 (5, 1) [D loss: (-1.8065)(R -4.2072, F 2.3012, G 0.0099)] [G loss: -3.1226]\n",
      "3804 (5, 1) [D loss: (-1.3297)(R -6.0959, F 4.6681, G 0.0098)] [G loss: -5.2564]\n",
      "3805 (5, 1) [D loss: (-2.0393)(R -8.0877, F 5.9280, G 0.0120)] [G loss: -7.0108]\n",
      "3806 (5, 1) [D loss: (-1.3504)(R -8.8043, F 7.3487, G 0.0105)] [G loss: -7.4211]\n",
      "3807 (5, 1) [D loss: (-1.0972)(R -8.9080, F 7.7198, G 0.0091)] [G loss: -7.6900]\n",
      "3808 (5, 1) [D loss: (-0.9329)(R -8.7902, F 7.7932, G 0.0064)] [G loss: -7.5237]\n",
      "3809 (5, 1) [D loss: (-1.0267)(R -7.4392, F 6.3610, G 0.0052)] [G loss: -6.0946]\n",
      "3810 (5, 1) [D loss: (-1.2650)(R -6.5516, F 5.2268, G 0.0060)] [G loss: -4.9599]\n",
      "3811 (5, 1) [D loss: (-1.1507)(R -5.2115, F 4.0144, G 0.0046)] [G loss: -4.0764]\n",
      "3812 (5, 1) [D loss: (-0.9983)(R -3.8854, F 2.8375, G 0.0050)] [G loss: -2.3267]\n",
      "3813 (5, 1) [D loss: (-1.3103)(R -2.4061, F 1.0365, G 0.0059)] [G loss: -1.0897]\n",
      "3814 (5, 1) [D loss: (-1.1316)(R -0.8718, F -0.3262, G 0.0066)] [G loss: 0.3998]\n",
      "3815 (5, 1) [D loss: (-1.3535)(R 0.4153, F -1.8392, G 0.0070)] [G loss: 2.0254]\n",
      "3816 (5, 1) [D loss: (-1.2921)(R 2.1537, F -3.5155, G 0.0070)] [G loss: 3.5196]\n",
      "3817 (5, 1) [D loss: (-1.2016)(R 2.6099, F -3.8783, G 0.0067)] [G loss: 3.7131]\n",
      "3818 (5, 1) [D loss: (-1.0859)(R 2.8539, F -4.0079, G 0.0068)] [G loss: 4.1142]\n",
      "3819 (5, 1) [D loss: (-1.3154)(R 2.6219, F -4.0053, G 0.0068)] [G loss: 3.7416]\n",
      "3820 (5, 1) [D loss: (-1.3339)(R 2.1788, F -3.5768, G 0.0064)] [G loss: 3.3994]\n",
      "3821 (5, 1) [D loss: (-1.1380)(R 1.8688, F -3.0713, G 0.0065)] [G loss: 2.9599]\n",
      "3822 (5, 1) [D loss: (-1.2676)(R 1.4102, F -2.7410, G 0.0063)] [G loss: 2.7262]\n",
      "3823 (5, 1) [D loss: (-1.2392)(R 1.8821, F -3.1897, G 0.0068)] [G loss: 3.1665]\n",
      "3824 (5, 1) [D loss: (-1.2999)(R 2.6320, F -3.9991, G 0.0067)] [G loss: 3.9504]\n",
      "3825 (5, 1) [D loss: (-1.0641)(R 3.1338, F -4.2612, G 0.0063)] [G loss: 4.4886]\n",
      "3826 (5, 1) [D loss: (-1.0612)(R 3.8481, F -4.9754, G 0.0066)] [G loss: 5.0091]\n",
      "3827 (5, 1) [D loss: (-0.8965)(R 4.2321, F -5.1993, G 0.0071)] [G loss: 5.4488]\n",
      "3828 (5, 1) [D loss: (-1.2824)(R 4.3578, F -5.7051, G 0.0065)] [G loss: 5.8557]\n",
      "3829 (5, 1) [D loss: (-0.8976)(R 5.0449, F -6.0136, G 0.0071)] [G loss: 5.9940]\n",
      "3830 (5, 1) [D loss: (-1.2605)(R 4.0978, F -5.4348, G 0.0076)] [G loss: 5.4873]\n",
      "3831 (5, 1) [D loss: (-0.9307)(R 3.8058, F -4.8009, G 0.0064)] [G loss: 4.6001]\n",
      "3832 (5, 1) [D loss: (-0.8640)(R 2.0697, F -2.9952, G 0.0062)] [G loss: 3.3994]\n",
      "3833 (5, 1) [D loss: (-1.3394)(R 1.9730, F -3.3648, G 0.0052)] [G loss: 2.7183]\n",
      "3834 (5, 1) [D loss: (-1.2419)(R 0.3084, F -1.6196, G 0.0069)] [G loss: 1.2440]\n",
      "3835 (5, 1) [D loss: (-1.2340)(R -2.6418, F 1.3277, G 0.0080)] [G loss: -1.9776]\n",
      "3836 (5, 1) [D loss: (-1.3143)(R -5.1052, F 3.7049, G 0.0086)] [G loss: -3.9978]\n",
      "3837 (5, 1) [D loss: (-1.8024)(R -6.0223, F 4.1228, G 0.0097)] [G loss: -4.8882]\n",
      "3838 (5, 1) [D loss: (-1.5850)(R -6.3376, F 4.6641, G 0.0088)] [G loss: -5.2531]\n",
      "3839 (5, 1) [D loss: (-1.3126)(R -5.7077, F 4.3293, G 0.0066)] [G loss: -4.2537]\n",
      "3840 (5, 1) [D loss: (-1.2664)(R -3.9873, F 2.6612, G 0.0060)] [G loss: -2.4548]\n",
      "3841 (5, 1) [D loss: (-1.3387)(R -1.0052, F -0.3875, G 0.0054)] [G loss: 0.6471]\n",
      "3842 (5, 1) [D loss: (-1.3372)(R 2.0312, F -3.4283, G 0.0060)] [G loss: 3.7219]\n",
      "3843 (5, 1) [D loss: (-1.5060)(R 4.4105, F -5.9957, G 0.0079)] [G loss: 6.0340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844 (5, 1) [D loss: (-1.2455)(R 6.2944, F -7.6502, G 0.0110)] [G loss: 7.8513]\n",
      "3845 (5, 1) [D loss: (-1.4090)(R 7.6836, F -9.1627, G 0.0070)] [G loss: 9.0419]\n",
      "3846 (5, 1) [D loss: (-1.3188)(R 9.1019, F -10.5147, G 0.0094)] [G loss: 10.1887]\n",
      "3847 (5, 1) [D loss: (-1.5450)(R 8.6331, F -10.2672, G 0.0089)] [G loss: 10.2078]\n",
      "3848 (5, 1) [D loss: (-1.4104)(R 9.6987, F -11.1930, G 0.0084)] [G loss: 11.0191]\n",
      "3849 (5, 1) [D loss: (-1.5164)(R 9.4330, F -11.0210, G 0.0072)] [G loss: 10.9309]\n",
      "3850 (5, 1) [D loss: (-1.5792)(R 9.8508, F -11.5101, G 0.0080)] [G loss: 11.1575]\n",
      "3851 (5, 1) [D loss: (-1.4049)(R 9.5433, F -11.0245, G 0.0076)] [G loss: 11.0237]\n",
      "3852 (5, 1) [D loss: (-1.0370)(R 9.7704, F -10.8864, G 0.0079)] [G loss: 10.7862]\n",
      "3853 (5, 1) [D loss: (-1.4083)(R 9.5039, F -10.9754, G 0.0063)] [G loss: 10.7537]\n",
      "3854 (5, 1) [D loss: (-1.6094)(R 10.0170, F -11.7241, G 0.0098)] [G loss: 11.4203]\n",
      "3855 (5, 1) [D loss: (-1.6912)(R 10.4870, F -12.2629, G 0.0085)] [G loss: 11.7696]\n",
      "3856 (5, 1) [D loss: (-1.4669)(R 10.5524, F -12.1045, G 0.0085)] [G loss: 11.6347]\n",
      "3857 (5, 1) [D loss: (-1.5587)(R 11.4385, F -13.1025, G 0.0105)] [G loss: 12.6452]\n",
      "3858 (5, 1) [D loss: (-1.0972)(R 11.3408, F -12.5341, G 0.0096)] [G loss: 12.0873]\n",
      "3859 (5, 1) [D loss: (-1.2111)(R 10.6330, F -11.9421, G 0.0098)] [G loss: 11.1080]\n",
      "3860 (5, 1) [D loss: (-1.0185)(R 8.7363, F -9.8045, G 0.0050)] [G loss: 8.9812]\n",
      "3861 (5, 1) [D loss: (-1.1351)(R 6.7318, F -7.9061, G 0.0039)] [G loss: 7.1913]\n",
      "3862 (5, 1) [D loss: (-1.2105)(R 3.1736, F -4.4204, G 0.0036)] [G loss: 3.7622]\n",
      "3863 (5, 1) [D loss: (-1.1947)(R -0.4239, F -0.8159, G 0.0045)] [G loss: -0.0276]\n",
      "3864 (5, 1) [D loss: (-1.5005)(R -4.4378, F 2.8637, G 0.0074)] [G loss: -3.6753]\n",
      "3865 (5, 1) [D loss: (-1.7690)(R -8.0663, F 6.2055, G 0.0092)] [G loss: -6.8317]\n",
      "3866 (5, 1) [D loss: (-1.4595)(R -9.4517, F 7.8816, G 0.0111)] [G loss: -8.0348]\n",
      "3867 (5, 1) [D loss: (-1.8422)(R -10.2563, F 8.3364, G 0.0078)] [G loss: -8.6411]\n",
      "3868 (5, 1) [D loss: (-1.2161)(R -9.9458, F 8.6571, G 0.0073)] [G loss: -8.2533]\n",
      "3869 (5, 1) [D loss: (-1.1698)(R -9.3867, F 8.1582, G 0.0059)] [G loss: -7.8903]\n",
      "3870 (5, 1) [D loss: (-1.1042)(R -9.2989, F 8.1291, G 0.0066)] [G loss: -7.9322]\n",
      "3871 (5, 1) [D loss: (-1.4734)(R -9.7247, F 8.1902, G 0.0061)] [G loss: -7.9698]\n",
      "3872 (5, 1) [D loss: (-1.6154)(R -10.5236, F 8.8340, G 0.0074)] [G loss: -9.1050]\n",
      "3873 (5, 1) [D loss: (-1.3459)(R -10.3800, F 8.9654, G 0.0069)] [G loss: -9.2571]\n",
      "3874 (5, 1) [D loss: (-1.4791)(R -11.3894, F 9.8364, G 0.0074)] [G loss: -10.4368]\n",
      "3875 (5, 1) [D loss: (-1.2807)(R -11.6625, F 10.3026, G 0.0079)] [G loss: -10.4975]\n",
      "3876 (5, 1) [D loss: (-1.2160)(R -11.3824, F 10.0961, G 0.0070)] [G loss: -10.1262]\n",
      "3877 (5, 1) [D loss: (-1.0822)(R -11.2376, F 10.0750, G 0.0080)] [G loss: -10.3121]\n",
      "3878 (5, 1) [D loss: (-1.1863)(R -10.4263, F 9.1858, G 0.0054)] [G loss: -9.2266]\n",
      "3879 (5, 1) [D loss: (-0.9357)(R -8.5722, F 7.5797, G 0.0057)] [G loss: -7.4741]\n",
      "3880 (5, 1) [D loss: (-1.1683)(R -7.0948, F 5.8844, G 0.0042)] [G loss: -5.9011]\n",
      "3881 (5, 1) [D loss: (-0.9312)(R -5.1889, F 4.2149, G 0.0043)] [G loss: -3.9216]\n",
      "3882 (5, 1) [D loss: (-1.2830)(R -3.2521, F 1.9201, G 0.0049)] [G loss: -1.6320]\n",
      "3883 (5, 1) [D loss: (-1.4740)(R -1.1850, F -0.3374, G 0.0048)] [G loss: 0.5211]\n",
      "3884 (5, 1) [D loss: (-1.0290)(R 1.0394, F -2.1414, G 0.0073)] [G loss: 2.5815]\n",
      "3885 (5, 1) [D loss: (-1.2510)(R 2.5905, F -3.9030, G 0.0061)] [G loss: 4.0713]\n",
      "3886 (5, 1) [D loss: (-1.1563)(R 2.9741, F -4.2230, G 0.0093)] [G loss: 4.2810]\n",
      "3887 (5, 1) [D loss: (-1.0945)(R 3.2988, F -4.4772, G 0.0084)] [G loss: 4.8154]\n",
      "3888 (5, 1) [D loss: (-1.2293)(R 3.4808, F -4.7935, G 0.0083)] [G loss: 4.6340]\n",
      "3889 (5, 1) [D loss: (-1.2693)(R 3.1946, F -4.5354, G 0.0071)] [G loss: 4.6969]\n",
      "3890 (5, 1) [D loss: (-1.0707)(R 3.5561, F -4.7125, G 0.0086)] [G loss: 4.9100]\n",
      "3891 (5, 1) [D loss: (-1.2207)(R 3.8036, F -5.0993, G 0.0075)] [G loss: 5.0334]\n",
      "3892 (5, 1) [D loss: (-1.0841)(R 4.1867, F -5.3375, G 0.0067)] [G loss: 5.2332]\n",
      "3893 (5, 1) [D loss: (-1.3793)(R 4.4595, F -5.9274, G 0.0089)] [G loss: 5.9674]\n",
      "3894 (5, 1) [D loss: (-1.2406)(R 5.9754, F -7.3088, G 0.0093)] [G loss: 7.7699]\n",
      "3895 (5, 1) [D loss: (-1.5613)(R 7.4001, F -9.0462, G 0.0085)] [G loss: 9.3657]\n",
      "3896 (5, 1) [D loss: (-1.8944)(R 8.4343, F -10.4360, G 0.0107)] [G loss: 10.3044]\n",
      "3897 (5, 1) [D loss: (-1.5201)(R 9.5771, F -11.1948, G 0.0098)] [G loss: 11.2359]\n",
      "3898 (5, 1) [D loss: (-1.4968)(R 10.2356, F -11.8304, G 0.0098)] [G loss: 11.9312]\n",
      "3899 (5, 1) [D loss: (-0.9785)(R 11.0662, F -12.1342, G 0.0089)] [G loss: 11.6565]\n",
      "3900 (5, 1) [D loss: (-1.2234)(R 10.3787, F -11.6685, G 0.0066)] [G loss: 11.4486]\n",
      "3901 (5, 1) [D loss: (-1.3411)(R 10.0444, F -11.4402, G 0.0055)] [G loss: 10.7648]\n",
      "3902 (5, 1) [D loss: (-0.7332)(R 8.7789, F -9.5784, G 0.0066)] [G loss: 9.0293]\n",
      "3903 (5, 1) [D loss: (-1.1002)(R 6.3182, F -7.4566, G 0.0038)] [G loss: 7.0112]\n",
      "3904 (5, 1) [D loss: (-1.3281)(R 4.9336, F -6.3071, G 0.0045)] [G loss: 6.0004]\n",
      "3905 (5, 1) [D loss: (-1.1644)(R 4.4180, F -5.6471, G 0.0065)] [G loss: 5.1029]\n",
      "3906 (5, 1) [D loss: (-1.2492)(R 3.3876, F -4.6940, G 0.0057)] [G loss: 4.6524]\n",
      "3907 (5, 1) [D loss: (-1.1910)(R 3.8497, F -5.1028, G 0.0062)] [G loss: 4.8775]\n",
      "3908 (5, 1) [D loss: (-1.3402)(R 3.4638, F -4.8665, G 0.0062)] [G loss: 4.7601]\n",
      "3909 (5, 1) [D loss: (-1.1820)(R 4.1621, F -5.4153, G 0.0071)] [G loss: 5.3375]\n",
      "3910 (5, 1) [D loss: (-1.3421)(R 4.8902, F -6.3096, G 0.0077)] [G loss: 6.3045]\n",
      "3911 (5, 1) [D loss: (-1.3343)(R 5.3296, F -6.7430, G 0.0079)] [G loss: 6.3412]\n",
      "3912 (5, 1) [D loss: (-1.1306)(R 4.9740, F -6.1735, G 0.0069)] [G loss: 5.9992]\n",
      "3913 (5, 1) [D loss: (-1.2107)(R 4.2024, F -5.4707, G 0.0058)] [G loss: 4.7967]\n",
      "3914 (5, 1) [D loss: (-1.0939)(R 3.1457, F -4.2945, G 0.0055)] [G loss: 3.9911]\n",
      "3915 (5, 1) [D loss: (-1.1452)(R 1.8767, F -3.0761, G 0.0054)] [G loss: 2.8031]\n",
      "3916 (5, 1) [D loss: (-0.9088)(R 0.7998, F -1.7688, G 0.0060)] [G loss: 1.0691]\n",
      "3917 (5, 1) [D loss: (-1.0057)(R -0.8333, F -0.2342, G 0.0062)] [G loss: 0.3676]\n",
      "3918 (5, 1) [D loss: (-1.3438)(R -1.2234, F -0.1918, G 0.0071)] [G loss: -0.0909]\n",
      "3919 (5, 1) [D loss: (-1.1406)(R -1.3143, F 0.1114, G 0.0062)] [G loss: -0.1137]\n",
      "3920 (5, 1) [D loss: (-1.2714)(R -2.0600, F 0.7319, G 0.0057)] [G loss: -0.8133]\n",
      "3921 (5, 1) [D loss: (-1.1271)(R -1.8512, F 0.6503, G 0.0074)] [G loss: -0.0989]\n",
      "3922 (5, 1) [D loss: (-1.2698)(R -0.6053, F -0.7161, G 0.0052)] [G loss: 0.7034]\n",
      "3923 (5, 1) [D loss: (-1.4472)(R -1.3795, F -0.1400, G 0.0072)] [G loss: 0.0750]\n",
      "3924 (5, 1) [D loss: (-1.4107)(R -1.8755, F 0.3980, G 0.0067)] [G loss: -0.6116]\n",
      "3925 (5, 1) [D loss: (-1.1295)(R -3.1034, F 1.8959, G 0.0078)] [G loss: -1.9801]\n",
      "3926 (5, 1) [D loss: (-1.3315)(R -4.7672, F 3.3567, G 0.0079)] [G loss: -3.6257]\n",
      "3927 (5, 1) [D loss: (-1.2845)(R -6.7602, F 5.3807, G 0.0095)] [G loss: -5.8842]\n",
      "3928 (5, 1) [D loss: (-1.3901)(R -8.4980, F 6.9922, G 0.0116)] [G loss: -7.2530]\n",
      "3929 (5, 1) [D loss: (-1.4678)(R -9.5967, F 8.0478, G 0.0081)] [G loss: -8.2843]\n",
      "3930 (5, 1) [D loss: (-1.4983)(R -10.8827, F 9.3063, G 0.0078)] [G loss: -9.7280]\n",
      "3931 (5, 1) [D loss: (-2.0007)(R -11.8874, F 9.7818, G 0.0105)] [G loss: -10.6006]\n",
      "3932 (5, 1) [D loss: (-1.5542)(R -11.7914, F 10.1641, G 0.0073)] [G loss: -10.6764]\n",
      "3933 (5, 1) [D loss: (-1.3829)(R -11.3252, F 9.8789, G 0.0063)] [G loss: -9.9739]\n",
      "3934 (5, 1) [D loss: (-1.2913)(R -10.1744, F 8.8309, G 0.0052)] [G loss: -8.8290]\n",
      "3935 (5, 1) [D loss: (-1.4156)(R -9.4758, F 8.0066, G 0.0054)] [G loss: -8.3451]\n",
      "3936 (5, 1) [D loss: (-1.4950)(R -9.2611, F 7.7081, G 0.0058)] [G loss: -8.2461]\n",
      "3937 (5, 1) [D loss: (-1.2513)(R -8.8427, F 7.5282, G 0.0063)] [G loss: -7.9893]\n",
      "3938 (5, 1) [D loss: (-1.4391)(R -9.1787, F 7.6461, G 0.0093)] [G loss: -8.7309]\n",
      "3939 (5, 1) [D loss: (-1.1193)(R -9.7370, F 8.5421, G 0.0076)] [G loss: -8.8211]\n",
      "3940 (5, 1) [D loss: (-1.2311)(R -9.7099, F 8.4164, G 0.0062)] [G loss: -8.7899]\n",
      "3941 (5, 1) [D loss: (-1.3659)(R -9.6997, F 8.2643, G 0.0070)] [G loss: -9.0081]\n",
      "3942 (5, 1) [D loss: (-1.0077)(R -10.0772, F 8.9896, G 0.0080)] [G loss: -9.1635]\n",
      "3943 (5, 1) [D loss: (-1.2568)(R -9.6140, F 8.3065, G 0.0051)] [G loss: -8.4220]\n",
      "3944 (5, 1) [D loss: (-0.9228)(R -8.0824, F 7.1102, G 0.0049)] [G loss: -7.2583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945 (5, 1) [D loss: (-1.3891)(R -6.6750, F 5.2390, G 0.0047)] [G loss: -5.8189]\n",
      "3946 (5, 1) [D loss: (-1.0171)(R -4.9873, F 3.9230, G 0.0047)] [G loss: -3.6409]\n",
      "3947 (5, 1) [D loss: (-0.8473)(R -3.2689, F 2.3773, G 0.0044)] [G loss: -1.8400]\n",
      "3948 (5, 1) [D loss: (-0.9517)(R -1.3553, F 0.3534, G 0.0050)] [G loss: 0.0825]\n",
      "3949 (5, 1) [D loss: (-1.1801)(R -0.3994, F -0.8496, G 0.0069)] [G loss: 0.8540]\n",
      "3950 (5, 1) [D loss: (-1.1034)(R 0.5044, F -1.6778, G 0.0070)] [G loss: 2.0039]\n",
      "3951 (5, 1) [D loss: (-1.2408)(R 2.1895, F -3.5049, G 0.0075)] [G loss: 4.1376]\n",
      "3952 (5, 1) [D loss: (-1.1634)(R 3.6027, F -4.8577, G 0.0092)] [G loss: 5.0607]\n",
      "3953 (5, 1) [D loss: (-1.6238)(R 4.5622, F -6.2890, G 0.0103)] [G loss: 6.5103]\n",
      "3954 (5, 1) [D loss: (-1.1392)(R 5.5094, F -6.7201, G 0.0071)] [G loss: 6.8883]\n",
      "3955 (5, 1) [D loss: (-1.3300)(R 5.2511, F -6.6550, G 0.0074)] [G loss: 6.8815]\n",
      "3956 (5, 1) [D loss: (-1.4168)(R 5.3067, F -6.8012, G 0.0078)] [G loss: 7.0433]\n",
      "3957 (5, 1) [D loss: (-1.3234)(R 5.6289, F -7.0338, G 0.0082)] [G loss: 7.2750]\n",
      "3958 (5, 1) [D loss: (-1.5300)(R 6.1036, F -7.7118, G 0.0078)] [G loss: 7.7574]\n",
      "3959 (5, 1) [D loss: (-1.1842)(R 7.4188, F -8.6937, G 0.0091)] [G loss: 8.7817]\n",
      "3960 (5, 1) [D loss: (-1.3437)(R 8.8237, F -10.2534, G 0.0086)] [G loss: 10.2507]\n",
      "3961 (5, 1) [D loss: (-1.8808)(R 9.4442, F -11.4321, G 0.0107)] [G loss: 11.4921]\n",
      "3962 (5, 1) [D loss: (-1.4911)(R 11.1760, F -12.7969, G 0.0130)] [G loss: 12.5669]\n",
      "3963 (5, 1) [D loss: (-0.9756)(R 12.9119, F -14.0233, G 0.0136)] [G loss: 13.6975]\n",
      "3964 (5, 1) [D loss: (-1.8726)(R 12.5008, F -14.4929, G 0.0119)] [G loss: 14.0021]\n",
      "3965 (5, 1) [D loss: (-1.1822)(R 12.4674, F -13.7506, G 0.0101)] [G loss: 13.2977]\n",
      "3966 (5, 1) [D loss: (-1.6977)(R 11.5937, F -13.3652, G 0.0074)] [G loss: 12.8417]\n",
      "3967 (5, 1) [D loss: (-1.1057)(R 12.0291, F -13.2198, G 0.0085)] [G loss: 13.0178]\n",
      "3968 (5, 1) [D loss: (-1.9218)(R 11.0246, F -13.0135, G 0.0067)] [G loss: 12.4997]\n",
      "3969 (5, 1) [D loss: (-1.5232)(R 11.0882, F -12.6787, G 0.0067)] [G loss: 11.9689]\n",
      "3970 (5, 1) [D loss: (-1.1327)(R 11.3628, F -12.5694, G 0.0074)] [G loss: 11.9852]\n",
      "3971 (5, 1) [D loss: (-1.6730)(R 10.6907, F -12.4246, G 0.0061)] [G loss: 11.4488]\n",
      "3972 (5, 1) [D loss: (-1.2790)(R 11.4973, F -12.8430, G 0.0067)] [G loss: 12.0857]\n",
      "3973 (5, 1) [D loss: (-1.7466)(R 12.7079, F -14.5464, G 0.0092)] [G loss: 13.3183]\n",
      "3974 (5, 1) [D loss: (-1.5088)(R 12.1593, F -13.7577, G 0.0090)] [G loss: 12.3712]\n",
      "3975 (5, 1) [D loss: (-1.8126)(R 12.0968, F -14.0081, G 0.0099)] [G loss: 12.5818]\n",
      "3976 (5, 1) [D loss: (-1.4030)(R 13.0063, F -14.4971, G 0.0088)] [G loss: 13.2911]\n",
      "3977 (5, 1) [D loss: (-1.5287)(R 12.2028, F -13.8067, G 0.0075)] [G loss: 12.1468]\n",
      "3978 (5, 1) [D loss: (-0.8117)(R 13.1912, F -14.0803, G 0.0077)] [G loss: 12.4793]\n",
      "3979 (5, 1) [D loss: (-0.9108)(R 11.7372, F -12.7144, G 0.0066)] [G loss: 11.2800]\n",
      "3980 (5, 1) [D loss: (-1.1122)(R 10.8342, F -12.0019, G 0.0055)] [G loss: 10.8385]\n",
      "3981 (5, 1) [D loss: (-1.1632)(R 10.3024, F -11.5346, G 0.0069)] [G loss: 9.8095]\n",
      "3982 (5, 1) [D loss: (-1.0094)(R 8.3925, F -9.4662, G 0.0064)] [G loss: 8.4773]\n",
      "3983 (5, 1) [D loss: (-1.4036)(R 6.8750, F -8.3259, G 0.0047)] [G loss: 7.2507]\n",
      "3984 (5, 1) [D loss: (-0.9906)(R 6.2012, F -7.2513, G 0.0060)] [G loss: 5.7874]\n",
      "3985 (5, 1) [D loss: (-0.9168)(R 3.5075, F -4.4754, G 0.0051)] [G loss: 3.5655]\n",
      "3986 (5, 1) [D loss: (-0.9823)(R 1.3684, F -2.3967, G 0.0046)] [G loss: 1.7556]\n",
      "3987 (5, 1) [D loss: (-1.5176)(R -1.0815, F -0.4885, G 0.0052)] [G loss: -0.2081]\n",
      "3988 (5, 1) [D loss: (-1.0736)(R -3.0416, F 1.9199, G 0.0048)] [G loss: -1.7361]\n",
      "3989 (5, 1) [D loss: (-1.4912)(R -5.8280, F 4.2840, G 0.0053)] [G loss: -4.3841]\n",
      "3990 (5, 1) [D loss: (-1.6692)(R -8.1077, F 6.3474, G 0.0091)] [G loss: -6.2739]\n",
      "3991 (5, 1) [D loss: (-1.6923)(R -9.1404, F 7.3608, G 0.0087)] [G loss: -6.8452]\n",
      "3992 (5, 1) [D loss: (-1.8581)(R -10.0721, F 8.1114, G 0.0103)] [G loss: -8.2823]\n",
      "3993 (5, 1) [D loss: (-2.3241)(R -11.9155, F 9.4563, G 0.0135)] [G loss: -9.9801]\n",
      "3994 (5, 1) [D loss: (-2.9783)(R -15.1096, F 11.9627, G 0.0169)] [G loss: -13.0913]\n",
      "3995 (5, 1) [D loss: (-2.3620)(R -18.6278, F 16.0057, G 0.0260)] [G loss: -15.8239]\n",
      "3996 (5, 1) [D loss: (-2.6841)(R -20.7573, F 17.7911, G 0.0282)] [G loss: -18.9813]\n",
      "3997 (5, 1) [D loss: (-2.6293)(R -23.7953, F 20.7658, G 0.0400)] [G loss: -21.4604]\n",
      "3998 (5, 1) [D loss: (-2.6168)(R -23.6528, F 20.7509, G 0.0285)] [G loss: -21.8705]\n",
      "3999 (5, 1) [D loss: (-2.7884)(R -24.2800, F 21.2589, G 0.0233)] [G loss: -21.8926]\n",
      "4000 (5, 1) [D loss: (-2.7122)(R -23.7177, F 20.8118, G 0.0194)] [G loss: -21.6106]\n",
      "4001 (5, 1) [D loss: (-1.9630)(R -21.1168, F 19.0731, G 0.0081)] [G loss: -19.5777]\n",
      "4002 (5, 1) [D loss: (-1.9364)(R -19.9704, F 17.9806, G 0.0053)] [G loss: -19.0737]\n",
      "4003 (5, 1) [D loss: (-1.7290)(R -20.1623, F 18.3482, G 0.0085)] [G loss: -19.6310]\n",
      "4004 (5, 1) [D loss: (-1.5967)(R -18.5461, F 16.9017, G 0.0048)] [G loss: -18.1187]\n",
      "4005 (5, 1) [D loss: (-1.5941)(R -17.3706, F 15.7413, G 0.0035)] [G loss: -16.6976]\n",
      "4006 (5, 1) [D loss: (-2.0359)(R -17.4342, F 15.3410, G 0.0057)] [G loss: -17.6203]\n",
      "4007 (5, 1) [D loss: (-1.4704)(R -16.2326, F 14.7202, G 0.0042)] [G loss: -15.8729]\n",
      "4008 (5, 1) [D loss: (-1.6791)(R -15.6214, F 13.9035, G 0.0039)] [G loss: -15.2644]\n",
      "4009 (5, 1) [D loss: (-1.3562)(R -14.9588, F 13.5586, G 0.0044)] [G loss: -14.4670]\n",
      "4010 (5, 1) [D loss: (-1.2106)(R -14.0680, F 12.8193, G 0.0038)] [G loss: -13.4178]\n",
      "4011 (5, 1) [D loss: (-0.8790)(R -12.1827, F 11.2685, G 0.0035)] [G loss: -11.6348]\n",
      "4012 (5, 1) [D loss: (-0.9599)(R -9.6755, F 8.6894, G 0.0026)] [G loss: -9.2613]\n",
      "4013 (5, 1) [D loss: (-0.8568)(R -8.4289, F 7.5388, G 0.0033)] [G loss: -7.6418]\n",
      "4014 (5, 1) [D loss: (-0.8681)(R -6.8714, F 5.9591, G 0.0044)] [G loss: -6.0368]\n",
      "4015 (5, 1) [D loss: (-1.1265)(R -5.2352, F 4.0584, G 0.0050)] [G loss: -4.2048]\n",
      "4016 (5, 1) [D loss: (-1.2346)(R -3.6912, F 2.4188, G 0.0038)] [G loss: -2.8382]\n",
      "4017 (5, 1) [D loss: (-1.1880)(R -2.9461, F 1.7107, G 0.0047)] [G loss: -1.7859]\n",
      "4018 (5, 1) [D loss: (-1.2405)(R -2.5778, F 1.2813, G 0.0056)] [G loss: -1.0998]\n",
      "4019 (5, 1) [D loss: (-1.0498)(R -0.5971, F -0.5077, G 0.0055)] [G loss: 0.2671]\n",
      "4020 (5, 1) [D loss: (-0.7958)(R 0.3477, F -1.2009, G 0.0057)] [G loss: 1.1440]\n",
      "4021 (5, 1) [D loss: (-1.1374)(R 0.6777, F -1.8695, G 0.0054)] [G loss: 2.2353]\n",
      "4022 (5, 1) [D loss: (-1.3803)(R 1.6946, F -3.1382, G 0.0063)] [G loss: 3.3173]\n",
      "4023 (5, 1) [D loss: (-1.2959)(R 2.5043, F -3.8790, G 0.0079)] [G loss: 4.3196]\n",
      "4024 (5, 1) [D loss: (-1.0719)(R 3.0327, F -4.1807, G 0.0076)] [G loss: 4.4503]\n",
      "4025 (5, 1) [D loss: (-1.4691)(R 3.9180, F -5.4751, G 0.0088)] [G loss: 6.2363]\n",
      "4026 (5, 1) [D loss: (-1.1968)(R 5.2745, F -6.5446, G 0.0073)] [G loss: 6.8689]\n",
      "4027 (5, 1) [D loss: (-1.1917)(R 6.3492, F -7.6219, G 0.0081)] [G loss: 8.1258]\n",
      "4028 (5, 1) [D loss: (-1.0163)(R 7.7078, F -8.8177, G 0.0094)] [G loss: 9.3730]\n",
      "4029 (5, 1) [D loss: (-1.4057)(R 8.1748, F -9.6690, G 0.0089)] [G loss: 9.8387]\n",
      "4030 (5, 1) [D loss: (-1.4019)(R 9.3687, F -10.8476, G 0.0077)] [G loss: 11.0311]\n",
      "4031 (5, 1) [D loss: (-1.4894)(R 9.4808, F -11.0505, G 0.0080)] [G loss: 11.8265]\n",
      "4032 (5, 1) [D loss: (-1.4674)(R 10.2950, F -11.8481, G 0.0086)] [G loss: 11.6060]\n",
      "4033 (5, 1) [D loss: (-1.5075)(R 10.5584, F -12.1654, G 0.0099)] [G loss: 12.2286]\n",
      "4034 (5, 1) [D loss: (-2.1091)(R 10.5204, F -12.7112, G 0.0082)] [G loss: 12.6775]\n",
      "4035 (5, 1) [D loss: (-1.6558)(R 11.3119, F -13.0518, G 0.0084)] [G loss: 12.7555]\n",
      "4036 (5, 1) [D loss: (-1.8582)(R 10.3926, F -12.3398, G 0.0089)] [G loss: 12.1786]\n",
      "4037 (5, 1) [D loss: (-1.4365)(R 10.1394, F -11.6588, G 0.0083)] [G loss: 11.3907]\n",
      "4038 (5, 1) [D loss: (-1.3709)(R 10.4198, F -11.8703, G 0.0080)] [G loss: 11.7179]\n",
      "4039 (5, 1) [D loss: (-1.4381)(R 11.1656, F -12.6821, G 0.0078)] [G loss: 12.2915]\n",
      "4040 (5, 1) [D loss: (-2.1935)(R 12.6219, F -14.9335, G 0.0118)] [G loss: 14.5175]\n",
      "4041 (5, 1) [D loss: (-1.2193)(R 13.1385, F -14.4577, G 0.0100)] [G loss: 13.9491]\n",
      "4042 (5, 1) [D loss: (-0.9598)(R 13.3091, F -14.3412, G 0.0072)] [G loss: 13.5029]\n",
      "4043 (5, 1) [D loss: (-0.8978)(R 13.2409, F -14.2097, G 0.0071)] [G loss: 13.0250]\n",
      "4044 (5, 1) [D loss: (-1.6942)(R 12.3651, F -14.1391, G 0.0080)] [G loss: 13.6522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045 (5, 1) [D loss: (-1.7896)(R 12.7029, F -14.5807, G 0.0088)] [G loss: 13.5117]\n",
      "4046 (5, 1) [D loss: (-2.3177)(R 11.9981, F -14.3932, G 0.0077)] [G loss: 12.9943]\n",
      "4047 (5, 1) [D loss: (-1.4263)(R 12.5159, F -14.0298, G 0.0088)] [G loss: 12.8902]\n",
      "4048 (5, 1) [D loss: (-1.7301)(R 11.5341, F -13.3223, G 0.0058)] [G loss: 12.2386]\n",
      "4049 (5, 1) [D loss: (-1.0129)(R 10.9620, F -12.0321, G 0.0057)] [G loss: 11.0108]\n",
      "4050 (5, 1) [D loss: (-0.6933)(R 9.5185, F -10.2572, G 0.0045)] [G loss: 9.4155]\n",
      "4051 (5, 1) [D loss: (-0.7324)(R 8.6701, F -9.4450, G 0.0043)] [G loss: 8.6738]\n",
      "4052 (5, 1) [D loss: (-1.2220)(R 6.6503, F -7.9128, G 0.0040)] [G loss: 7.1160]\n",
      "4053 (5, 1) [D loss: (-0.8923)(R 5.1123, F -6.0535, G 0.0049)] [G loss: 5.4402]\n",
      "4054 (5, 1) [D loss: (-1.0826)(R 2.8349, F -3.9544, G 0.0037)] [G loss: 3.3577]\n",
      "4055 (5, 1) [D loss: (-1.1206)(R 0.8689, F -2.0504, G 0.0061)] [G loss: 1.5267]\n",
      "4056 (5, 1) [D loss: (-1.4957)(R -0.8401, F -0.7134, G 0.0058)] [G loss: -0.2290]\n",
      "4057 (5, 1) [D loss: (-1.6577)(R -4.0488, F 2.3105, G 0.0081)] [G loss: -3.0692]\n",
      "4058 (5, 1) [D loss: (-1.7823)(R -7.0104, F 5.0898, G 0.0138)] [G loss: -5.4545]\n",
      "4059 (5, 1) [D loss: (-1.4468)(R -8.8308, F 7.2611, G 0.0123)] [G loss: -7.0936]\n",
      "4060 (5, 1) [D loss: (-2.3219)(R -10.1920, F 7.7452, G 0.0125)] [G loss: -9.0540]\n",
      "4061 (5, 1) [D loss: (-2.0588)(R -13.5195, F 11.2596, G 0.0201)] [G loss: -11.7074]\n",
      "4062 (5, 1) [D loss: (-1.8775)(R -15.2552, F 13.1941, G 0.0184)] [G loss: -12.7804]\n",
      "4063 (5, 1) [D loss: (-2.1421)(R -15.3884, F 13.1275, G 0.0119)] [G loss: -13.6520]\n",
      "4064 (5, 1) [D loss: (-1.7363)(R -16.3689, F 14.4887, G 0.0144)] [G loss: -14.7553]\n",
      "4065 (5, 1) [D loss: (-2.2160)(R -17.2106, F 14.8730, G 0.0122)] [G loss: -15.6006]\n",
      "4066 (5, 1) [D loss: (-1.8662)(R -16.7633, F 14.7976, G 0.0100)] [G loss: -15.4999]\n",
      "4067 (5, 1) [D loss: (-1.3126)(R -15.6419, F 14.2617, G 0.0068)] [G loss: -14.5076]\n",
      "4068 (5, 1) [D loss: (-1.3416)(R -13.6295, F 12.2614, G 0.0027)] [G loss: -12.6977]\n",
      "4069 (5, 1) [D loss: (-0.7275)(R -12.0468, F 11.2902, G 0.0029)] [G loss: -10.9661]\n",
      "4070 (5, 1) [D loss: (-1.1626)(R -10.8969, F 9.7099, G 0.0024)] [G loss: -9.4411]\n",
      "4071 (5, 1) [D loss: (-1.0663)(R -9.6673, F 8.5711, G 0.0030)] [G loss: -8.9984]\n",
      "4072 (5, 1) [D loss: (-1.1893)(R -8.9475, F 7.7203, G 0.0038)] [G loss: -8.2702]\n",
      "4073 (5, 1) [D loss: (-1.7135)(R -9.9867, F 8.2113, G 0.0062)] [G loss: -9.9707]\n",
      "4074 (5, 1) [D loss: (-1.1606)(R -10.5660, F 9.3465, G 0.0059)] [G loss: -9.9867]\n",
      "4075 (5, 1) [D loss: (-1.4554)(R -10.6788, F 9.1560, G 0.0067)] [G loss: -10.1029]\n",
      "4076 (5, 1) [D loss: (-1.3339)(R -10.8024, F 9.3962, G 0.0072)] [G loss: -10.1510]\n",
      "4077 (5, 1) [D loss: (-1.1995)(R -10.4892, F 9.2271, G 0.0063)] [G loss: -9.6535]\n",
      "4078 (5, 1) [D loss: (-1.0017)(R -9.4648, F 8.4083, G 0.0055)] [G loss: -8.7672]\n",
      "4079 (5, 1) [D loss: (-1.1458)(R -7.6272, F 6.4411, G 0.0040)] [G loss: -6.6022]\n",
      "4080 (5, 1) [D loss: (-1.2104)(R -5.4904, F 4.2414, G 0.0039)] [G loss: -4.5572]\n",
      "4081 (5, 1) [D loss: (-1.2949)(R -4.3347, F 3.0060, G 0.0034)] [G loss: -2.8344]\n",
      "4082 (5, 1) [D loss: (-1.0935)(R -2.2163, F 1.0813, G 0.0042)] [G loss: -1.1767]\n",
      "4083 (5, 1) [D loss: (-0.9194)(R -1.0125, F 0.0484, G 0.0045)] [G loss: -0.1140]\n",
      "4084 (5, 1) [D loss: (-1.1344)(R -1.3960, F 0.2077, G 0.0054)] [G loss: -0.5772]\n",
      "4085 (5, 1) [D loss: (-1.0281)(R -1.5736, F 0.4823, G 0.0063)] [G loss: -0.9508]\n",
      "4086 (5, 1) [D loss: (-1.0923)(R -2.0183, F 0.8603, G 0.0066)] [G loss: -1.2284]\n",
      "4087 (5, 1) [D loss: (-1.1912)(R -2.4333, F 1.1771, G 0.0065)] [G loss: -1.2300]\n",
      "4088 (5, 1) [D loss: (-1.1746)(R -2.0351, F 0.7823, G 0.0078)] [G loss: -0.7938]\n",
      "4089 (5, 1) [D loss: (-1.4364)(R -1.4569, F -0.0487, G 0.0069)] [G loss: 0.2972]\n",
      "4090 (5, 1) [D loss: (-1.1657)(R 0.0202, F -1.2381, G 0.0052)] [G loss: 1.9831]\n",
      "4091 (5, 1) [D loss: (-1.2961)(R 1.8015, F -3.1696, G 0.0072)] [G loss: 3.2487]\n",
      "4092 (5, 1) [D loss: (-1.2553)(R 4.1703, F -5.5078, G 0.0082)] [G loss: 6.2809]\n",
      "4093 (5, 1) [D loss: (-1.2539)(R 5.7493, F -7.1077, G 0.0104)] [G loss: 7.7618]\n",
      "4094 (5, 1) [D loss: (-1.2730)(R 7.5576, F -8.9165, G 0.0086)] [G loss: 9.5538]\n",
      "4095 (5, 1) [D loss: (-1.2837)(R 9.6933, F -11.0667, G 0.0090)] [G loss: 11.5609]\n",
      "4096 (5, 1) [D loss: (-1.5344)(R 9.6945, F -11.3138, G 0.0085)] [G loss: 11.5760]\n",
      "4097 (5, 1) [D loss: (-1.7225)(R 10.3946, F -12.2054, G 0.0088)] [G loss: 12.1683]\n",
      "4098 (5, 1) [D loss: (-1.5944)(R 9.8776, F -11.5401, G 0.0068)] [G loss: 11.8250]\n",
      "4099 (5, 1) [D loss: (-1.1896)(R 10.1019, F -11.3678, G 0.0076)] [G loss: 11.2737]\n",
      "4100 (5, 1) [D loss: (-1.0339)(R 9.9179, F -11.0308, G 0.0079)] [G loss: 11.0974]\n",
      "4101 (5, 1) [D loss: (-1.6966)(R 8.9832, F -10.7463, G 0.0066)] [G loss: 10.7526]\n",
      "4102 (5, 1) [D loss: (-1.8231)(R 9.9499, F -11.8472, G 0.0074)] [G loss: 12.0553]\n",
      "4103 (5, 1) [D loss: (-1.2790)(R 11.1695, F -12.5435, G 0.0095)] [G loss: 12.6363]\n",
      "4104 (5, 1) [D loss: (-1.8674)(R 12.6691, F -14.6633, G 0.0127)] [G loss: 14.6393]\n",
      "4105 (5, 1) [D loss: (-1.9999)(R 14.0858, F -16.2573, G 0.0172)] [G loss: 15.2360]\n",
      "4106 (5, 1) [D loss: (-1.9995)(R 14.7577, F -16.8827, G 0.0125)] [G loss: 16.2428]\n",
      "4107 (5, 1) [D loss: (-1.4741)(R 15.9729, F -17.5837, G 0.0137)] [G loss: 16.4931]\n",
      "4108 (5, 1) [D loss: (-1.0448)(R 17.0192, F -18.1878, G 0.0124)] [G loss: 17.0542]\n",
      "4109 (5, 1) [D loss: (-1.4088)(R 17.1715, F -18.7021, G 0.0122)] [G loss: 17.2329]\n",
      "4110 (5, 1) [D loss: (-2.1978)(R 16.1839, F -18.5081, G 0.0126)] [G loss: 17.0944]\n",
      "4111 (5, 1) [D loss: (-1.9531)(R 17.0701, F -19.1794, G 0.0156)] [G loss: 17.5036]\n",
      "4112 (5, 1) [D loss: (-2.4732)(R 16.7333, F -19.3565, G 0.0150)] [G loss: 17.6926]\n",
      "4113 (5, 1) [D loss: (-1.1143)(R 16.6596, F -17.8864, G 0.0112)] [G loss: 16.0382]\n",
      "4114 (5, 1) [D loss: (-2.0049)(R 15.2184, F -17.2961, G 0.0073)] [G loss: 15.8125]\n",
      "4115 (5, 1) [D loss: (-1.1103)(R 16.6020, F -17.8214, G 0.0109)] [G loss: 16.1846]\n",
      "4116 (5, 1) [D loss: (-1.0614)(R 14.0586, F -15.1624, G 0.0042)] [G loss: 13.5108]\n",
      "4117 (5, 1) [D loss: (-0.7078)(R 11.6883, F -12.4248, G 0.0029)] [G loss: 10.9490]\n",
      "4118 (5, 1) [D loss: (-0.8628)(R 7.6804, F -8.5670, G 0.0024)] [G loss: 7.3283]\n",
      "4119 (5, 1) [D loss: (-0.7150)(R 4.6167, F -5.3620, G 0.0030)] [G loss: 4.1990]\n",
      "4120 (5, 1) [D loss: (-0.8729)(R 1.5053, F -2.4182, G 0.0040)] [G loss: 1.4590]\n",
      "4121 (5, 1) [D loss: (-0.7759)(R -1.8990, F 1.0700, G 0.0053)] [G loss: -1.2772]\n",
      "4122 (5, 1) [D loss: (-1.4484)(R -4.4634, F 2.9265, G 0.0088)] [G loss: -3.4218]\n",
      "4123 (5, 1) [D loss: (-2.0954)(R -6.7929, F 4.5821, G 0.0115)] [G loss: -5.0986]\n",
      "4124 (5, 1) [D loss: (-2.3296)(R -8.8860, F 6.3983, G 0.0158)] [G loss: -6.5250]\n",
      "4125 (5, 1) [D loss: (-1.8695)(R -9.2723, F 7.2617, G 0.0141)] [G loss: -6.9642]\n",
      "4126 (5, 1) [D loss: (-1.4344)(R -8.1989, F 6.6488, G 0.0116)] [G loss: -5.4780]\n",
      "4127 (5, 1) [D loss: (-1.7574)(R -8.6719, F 6.8280, G 0.0086)] [G loss: -6.6809]\n",
      "4128 (5, 1) [D loss: (-1.4085)(R -10.4639, F 8.9617, G 0.0094)] [G loss: -8.7740]\n",
      "4129 (5, 1) [D loss: (-1.6718)(R -12.8280, F 11.0689, G 0.0087)] [G loss: -11.4462]\n",
      "4130 (5, 1) [D loss: (-1.5525)(R -15.1810, F 13.5261, G 0.0102)] [G loss: -12.9710]\n",
      "4131 (5, 1) [D loss: (-1.7014)(R -15.6113, F 13.8205, G 0.0089)] [G loss: -13.7178]\n",
      "4132 (5, 1) [D loss: (-1.8835)(R -16.4368, F 14.4548, G 0.0098)] [G loss: -14.4608]\n",
      "4133 (5, 1) [D loss: (-0.6267)(R -15.8924, F 15.1829, G 0.0083)] [G loss: -13.9673]\n",
      "4134 (5, 1) [D loss: (-0.8112)(R -13.5521, F 12.7116, G 0.0029)] [G loss: -11.3620]\n",
      "4135 (5, 1) [D loss: (-1.3221)(R -11.1530, F 9.8045, G 0.0026)] [G loss: -9.4703]\n",
      "4136 (5, 1) [D loss: (-1.2807)(R -8.9806, F 7.6693, G 0.0031)] [G loss: -7.0718]\n",
      "4137 (5, 1) [D loss: (-1.4112)(R -7.5125, F 6.0665, G 0.0035)] [G loss: -6.0841]\n",
      "4138 (5, 1) [D loss: (-1.4426)(R -7.2249, F 5.7263, G 0.0056)] [G loss: -6.1536]\n",
      "4139 (5, 1) [D loss: (-1.6583)(R -8.2880, F 6.5458, G 0.0084)] [G loss: -7.5607]\n",
      "4140 (5, 1) [D loss: (-1.7402)(R -10.6206, F 8.7849, G 0.0096)] [G loss: -9.9741]\n",
      "4141 (5, 1) [D loss: (-2.3214)(R -13.8296, F 11.3564, G 0.0152)] [G loss: -13.4569]\n",
      "4142 (5, 1) [D loss: (-1.9605)(R -15.8677, F 13.7054, G 0.0202)] [G loss: -15.6160]\n",
      "4143 (5, 1) [D loss: (-2.4648)(R -16.0203, F 13.4058, G 0.0150)] [G loss: -15.1363]\n",
      "4144 (5, 1) [D loss: (-1.4422)(R -15.0969, F 13.5413, G 0.0113)] [G loss: -14.4180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4145 (5, 1) [D loss: (-1.3774)(R -14.7793, F 13.3225, G 0.0079)] [G loss: -14.2316]\n",
      "4146 (5, 1) [D loss: (-1.4522)(R -13.7345, F 12.2182, G 0.0064)] [G loss: -13.4126]\n",
      "4147 (5, 1) [D loss: (-1.1710)(R -12.6523, F 11.4333, G 0.0048)] [G loss: -11.9855]\n",
      "4148 (5, 1) [D loss: (-1.0454)(R -11.0825, F 10.0031, G 0.0034)] [G loss: -10.2824]\n",
      "4149 (5, 1) [D loss: (-1.3876)(R -9.6971, F 8.2819, G 0.0028)] [G loss: -8.9844]\n",
      "4150 (5, 1) [D loss: (-1.0790)(R -9.0209, F 7.9058, G 0.0036)] [G loss: -8.2646]\n",
      "4151 (5, 1) [D loss: (-0.8588)(R -8.0914, F 7.1809, G 0.0052)] [G loss: -7.3085]\n",
      "4152 (5, 1) [D loss: (-0.6220)(R -7.0053, F 6.3378, G 0.0046)] [G loss: -6.3271]\n",
      "4153 (5, 1) [D loss: (-1.1665)(R -6.6762, F 5.4560, G 0.0054)] [G loss: -6.3711]\n",
      "4154 (5, 1) [D loss: (-0.8776)(R -6.6670, F 5.7318, G 0.0058)] [G loss: -5.9027]\n",
      "4155 (5, 1) [D loss: (-1.2902)(R -5.4018, F 4.0603, G 0.0051)] [G loss: -4.5349]\n",
      "4156 (5, 1) [D loss: (-0.8425)(R -4.1073, F 3.2184, G 0.0046)] [G loss: -3.2218]\n",
      "4157 (5, 1) [D loss: (-1.3889)(R -3.2573, F 1.8182, G 0.0050)] [G loss: -2.1883]\n",
      "4158 (5, 1) [D loss: (-1.2370)(R -1.5508, F 0.2556, G 0.0058)] [G loss: -0.2496]\n",
      "4159 (5, 1) [D loss: (-0.8631)(R 0.8701, F -1.7869, G 0.0054)] [G loss: 2.5166]\n",
      "4160 (5, 1) [D loss: (-1.2252)(R 3.9060, F -5.1957, G 0.0064)] [G loss: 5.8464]\n",
      "4161 (5, 1) [D loss: (-1.6556)(R 6.3151, F -8.0731, G 0.0102)] [G loss: 8.5425]\n",
      "4162 (5, 1) [D loss: (-1.0659)(R 8.7611, F -9.9273, G 0.0100)] [G loss: 10.6633]\n",
      "4163 (5, 1) [D loss: (-1.3574)(R 10.0859, F -11.5544, G 0.0111)] [G loss: 12.3165]\n",
      "4164 (5, 1) [D loss: (-0.7109)(R 12.3342, F -13.1359, G 0.0091)] [G loss: 14.0464]\n",
      "4165 (5, 1) [D loss: (-1.1537)(R 12.5769, F -13.8141, G 0.0084)] [G loss: 13.7266]\n",
      "4166 (5, 1) [D loss: (-1.3371)(R 12.0586, F -13.4798, G 0.0084)] [G loss: 13.5865]\n",
      "4167 (5, 1) [D loss: (-1.4156)(R 11.1541, F -12.6202, G 0.0051)] [G loss: 12.8261]\n",
      "4168 (5, 1) [D loss: (-1.5835)(R 10.8074, F -12.4441, G 0.0053)] [G loss: 12.9604]\n",
      "4169 (5, 1) [D loss: (-1.3919)(R 11.2742, F -12.7369, G 0.0071)] [G loss: 12.8522]\n",
      "4170 (5, 1) [D loss: (-1.4309)(R 11.2147, F -12.7166, G 0.0071)] [G loss: 13.0272]\n",
      "4171 (5, 1) [D loss: (-1.9144)(R 11.6767, F -13.6806, G 0.0089)] [G loss: 13.9803]\n",
      "4172 (5, 1) [D loss: (-1.5882)(R 12.9889, F -14.6794, G 0.0102)] [G loss: 14.5660]\n",
      "4173 (5, 1) [D loss: (-1.5881)(R 13.8038, F -15.4940, G 0.0102)] [G loss: 15.4343]\n",
      "4174 (5, 1) [D loss: (-2.5368)(R 15.7714, F -18.4797, G 0.0172)] [G loss: 17.6437]\n",
      "4175 (5, 1) [D loss: (-1.3735)(R 17.4954, F -19.0383, G 0.0169)] [G loss: 18.6594]\n",
      "4176 (5, 1) [D loss: (-1.2040)(R 17.4655, F -18.8208, G 0.0151)] [G loss: 17.7488]\n",
      "4177 (5, 1) [D loss: (-2.5843)(R 18.0839, F -20.8406, G 0.0172)] [G loss: 19.6408]\n",
      "4178 (5, 1) [D loss: (-1.9381)(R 19.9119, F -22.0465, G 0.0196)] [G loss: 19.9615]\n",
      "4179 (5, 1) [D loss: (-2.0912)(R 19.3778, F -21.6474, G 0.0178)] [G loss: 19.9856]\n",
      "4180 (5, 1) [D loss: (-2.0435)(R 18.8124, F -20.9892, G 0.0133)] [G loss: 18.8217]\n",
      "4181 (5, 1) [D loss: (-1.6292)(R 19.4682, F -21.2564, G 0.0159)] [G loss: 19.3662]\n",
      "4182 (5, 1) [D loss: (-1.9505)(R 20.6220, F -22.7519, G 0.0179)] [G loss: 20.7505]\n",
      "4183 (5, 1) [D loss: (-1.8863)(R 20.9286, F -22.9991, G 0.0184)] [G loss: 20.8567]\n",
      "4184 (5, 1) [D loss: (-1.5418)(R 18.7768, F -20.3794, G 0.0061)] [G loss: 18.0607]\n",
      "4185 (5, 1) [D loss: (-0.8872)(R 17.3547, F -18.2796, G 0.0038)] [G loss: 16.5206]\n",
      "4186 (5, 1) [D loss: (-1.2921)(R 12.5986, F -13.9134, G 0.0023)] [G loss: 12.2229]\n",
      "4187 (5, 1) [D loss: (-1.1086)(R 9.7035, F -10.8357, G 0.0024)] [G loss: 9.8229]\n",
      "4188 (5, 1) [D loss: (-0.8965)(R 7.4282, F -8.3512, G 0.0027)] [G loss: 7.2756]\n",
      "4189 (5, 1) [D loss: (-0.9318)(R 5.0742, F -6.0358, G 0.0030)] [G loss: 5.0638]\n",
      "4190 (5, 1) [D loss: (-0.9098)(R 2.6032, F -3.5510, G 0.0038)] [G loss: 3.2164]\n",
      "4191 (5, 1) [D loss: (-1.1954)(R 1.2773, F -2.5297, G 0.0057)] [G loss: 1.6042]\n",
      "4192 (5, 1) [D loss: (-1.6089)(R -0.9162, F -0.7503, G 0.0058)] [G loss: 0.2774]\n",
      "4193 (5, 1) [D loss: (-1.9993)(R -2.7072, F 0.6196, G 0.0088)] [G loss: -0.8571]\n",
      "4194 (5, 1) [D loss: (-1.5093)(R -3.6352, F 2.0353, G 0.0091)] [G loss: -1.8600]\n",
      "4195 (5, 1) [D loss: (-1.4884)(R -4.1262, F 2.5557, G 0.0082)] [G loss: -2.5661]\n",
      "4196 (5, 1) [D loss: (-1.7168)(R -6.0872, F 4.3099, G 0.0061)] [G loss: -4.3303]\n",
      "4197 (5, 1) [D loss: (-1.5889)(R -8.6082, F 6.9299, G 0.0089)] [G loss: -6.6659]\n",
      "4198 (5, 1) [D loss: (-1.8830)(R -10.7057, F 8.7262, G 0.0096)] [G loss: -8.1911]\n",
      "4199 (5, 1) [D loss: (-1.8436)(R -12.8323, F 10.8493, G 0.0139)] [G loss: -10.7889]\n",
      "4200 (5, 1) [D loss: (-1.9827)(R -13.8213, F 11.7020, G 0.0137)] [G loss: -11.3675]\n",
      "4201 (5, 1) [D loss: (-1.1336)(R -14.1706, F 12.9240, G 0.0113)] [G loss: -11.8579]\n",
      "4202 (5, 1) [D loss: (-1.9908)(R -13.4106, F 11.3678, G 0.0052)] [G loss: -11.2474]\n",
      "4203 (5, 1) [D loss: (-1.8297)(R -14.4435, F 12.5256, G 0.0088)] [G loss: -12.4243]\n",
      "4204 (5, 1) [D loss: (-2.0939)(R -14.6257, F 12.4470, G 0.0085)] [G loss: -12.8789]\n",
      "4205 (5, 1) [D loss: (-2.1088)(R -15.8994, F 13.6312, G 0.0159)] [G loss: -14.2671]\n",
      "4206 (5, 1) [D loss: (-2.2398)(R -16.8373, F 14.4406, G 0.0157)] [G loss: -15.0749]\n",
      "4207 (5, 1) [D loss: (-3.3753)(R -18.4082, F 14.8236, G 0.0209)] [G loss: -16.9448]\n",
      "4208 (5, 1) [D loss: (-2.0286)(R -18.1635, F 15.9576, G 0.0177)] [G loss: -17.0453]\n",
      "4209 (5, 1) [D loss: (-2.3196)(R -18.6982, F 16.2032, G 0.0175)] [G loss: -18.2777]\n",
      "4210 (5, 1) [D loss: (-2.1969)(R -18.8349, F 16.4843, G 0.0154)] [G loss: -18.2903]\n",
      "4211 (5, 1) [D loss: (-2.1436)(R -19.2063, F 16.9025, G 0.0160)] [G loss: -18.7630]\n",
      "4212 (5, 1) [D loss: (-1.9793)(R -18.5966, F 16.5222, G 0.0095)] [G loss: -18.2818]\n",
      "4213 (5, 1) [D loss: (-1.6803)(R -17.6050, F 15.8700, G 0.0055)] [G loss: -17.3276]\n",
      "4214 (5, 1) [D loss: (-0.6465)(R -14.5790, F 13.9153, G 0.0017)] [G loss: -14.1413]\n",
      "4215 (5, 1) [D loss: (-0.9361)(R -12.3725, F 11.4101, G 0.0026)] [G loss: -12.6944]\n",
      "4216 (5, 1) [D loss: (-1.3084)(R -10.6779, F 9.3439, G 0.0026)] [G loss: -10.1106]\n",
      "4217 (5, 1) [D loss: (-0.9915)(R -7.8230, F 6.8019, G 0.0030)] [G loss: -6.7570]\n",
      "4218 (5, 1) [D loss: (-1.2254)(R -5.1706, F 3.9210, G 0.0024)] [G loss: -4.1792]\n",
      "4219 (5, 1) [D loss: (-0.9505)(R -2.5837, F 1.5992, G 0.0034)] [G loss: -1.3697]\n",
      "4220 (5, 1) [D loss: (-0.8996)(R -0.6172, F -0.3260, G 0.0044)] [G loss: 0.2713]\n",
      "4221 (5, 1) [D loss: (-0.6451)(R -0.3262, F -0.3741, G 0.0055)] [G loss: 0.2265]\n",
      "4222 (5, 1) [D loss: (-0.9356)(R -0.6872, F -0.3072, G 0.0059)] [G loss: -0.1287]\n",
      "4223 (5, 1) [D loss: (-1.3093)(R -1.7501, F 0.3789, G 0.0062)] [G loss: -1.0248]\n",
      "4224 (5, 1) [D loss: (-1.2710)(R -2.3112, F 0.9559, G 0.0084)] [G loss: -1.3217]\n",
      "4225 (5, 1) [D loss: (-1.3651)(R -2.9547, F 1.5190, G 0.0071)] [G loss: -2.0766]\n",
      "4226 (5, 1) [D loss: (-1.2609)(R -2.7441, F 1.4175, G 0.0066)] [G loss: -1.4780]\n",
      "4227 (5, 1) [D loss: (-1.3244)(R -1.2752, F -0.1086, G 0.0059)] [G loss: 0.1537]\n",
      "4228 (5, 1) [D loss: (-0.9462)(R 1.1765, F -2.1717, G 0.0049)] [G loss: 2.6274]\n",
      "4229 (5, 1) [D loss: (-1.3920)(R 3.5044, F -4.9547, G 0.0058)] [G loss: 5.6876]\n",
      "4230 (5, 1) [D loss: (-1.2769)(R 7.2413, F -8.6060, G 0.0088)] [G loss: 9.5766]\n",
      "4231 (5, 1) [D loss: (-2.0811)(R 10.0920, F -12.2874, G 0.0114)] [G loss: 13.1236]\n",
      "4232 (5, 1) [D loss: (-1.7644)(R 14.0395, F -15.9350, G 0.0131)] [G loss: 16.6607]\n",
      "4233 (5, 1) [D loss: (-1.1003)(R 15.9227, F -17.1847, G 0.0162)] [G loss: 17.3190]\n",
      "4234 (5, 1) [D loss: (-1.0785)(R 14.0762, F -15.2411, G 0.0086)] [G loss: 15.3649]\n",
      "4235 (5, 1) [D loss: (-1.3958)(R 13.1345, F -14.5779, G 0.0048)] [G loss: 14.6985]\n",
      "4236 (5, 1) [D loss: (-1.2179)(R 11.7170, F -12.9828, G 0.0048)] [G loss: 13.1401]\n",
      "4237 (5, 1) [D loss: (-1.7500)(R 9.4978, F -11.2904, G 0.0043)] [G loss: 11.3538]\n",
      "4238 (5, 1) [D loss: (-1.7207)(R 8.8072, F -10.5713, G 0.0043)] [G loss: 10.2956]\n",
      "4239 (5, 1) [D loss: (-1.5721)(R 7.1474, F -8.7643, G 0.0045)] [G loss: 8.8624]\n",
      "4240 (5, 1) [D loss: (-1.2095)(R 6.9108, F -8.1650, G 0.0045)] [G loss: 7.9552]\n",
      "4241 (5, 1) [D loss: (-1.5030)(R 7.1646, F -8.7311, G 0.0063)] [G loss: 9.0523]\n",
      "4242 (5, 1) [D loss: (-1.9711)(R 8.1844, F -10.2523, G 0.0097)] [G loss: 10.7299]\n",
      "4243 (5, 1) [D loss: (-1.9013)(R 11.5385, F -13.5803, G 0.0141)] [G loss: 13.9598]\n",
      "4244 (5, 1) [D loss: (-2.3378)(R 13.9979, F -16.5011, G 0.0165)] [G loss: 16.3004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4245 (5, 1) [D loss: (-1.6471)(R 16.8819, F -18.7059, G 0.0177)] [G loss: 17.8222]\n",
      "4246 (5, 1) [D loss: (-2.5206)(R 16.8040, F -19.4794, G 0.0155)] [G loss: 18.4255]\n",
      "4247 (5, 1) [D loss: (-1.4248)(R 17.8002, F -19.3642, G 0.0139)] [G loss: 18.2517]\n",
      "4248 (5, 1) [D loss: (-1.6791)(R 16.6187, F -18.3857, G 0.0088)] [G loss: 17.0624]\n",
      "4249 (5, 1) [D loss: (-1.9712)(R 16.2253, F -18.2855, G 0.0089)] [G loss: 17.3173]\n",
      "4250 (5, 1) [D loss: (-2.8077)(R 16.2187, F -19.1524, G 0.0126)] [G loss: 17.9482]\n",
      "4251 (5, 1) [D loss: (-2.7776)(R 16.9243, F -19.8903, G 0.0188)] [G loss: 18.6104]\n",
      "4252 (5, 1) [D loss: (-1.1303)(R 18.6091, F -19.8755, G 0.0136)] [G loss: 17.7884]\n",
      "4253 (5, 1) [D loss: (-1.3231)(R 18.7228, F -20.1659, G 0.0120)] [G loss: 18.8607]\n",
      "4254 (5, 1) [D loss: (-1.8192)(R 19.9840, F -21.9476, G 0.0144)] [G loss: 20.2041]\n",
      "4255 (5, 1) [D loss: (-1.7996)(R 21.3130, F -23.2537, G 0.0141)] [G loss: 21.1145]\n",
      "4256 (5, 1) [D loss: (-1.4668)(R 22.3571, F -24.0249, G 0.0201)] [G loss: 21.4448]\n",
      "4257 (5, 1) [D loss: (-1.7289)(R 21.4932, F -23.3783, G 0.0156)] [G loss: 20.4701]\n",
      "4258 (5, 1) [D loss: (-1.1603)(R 17.7331, F -18.9476, G 0.0054)] [G loss: 17.3020]\n",
      "4259 (5, 1) [D loss: (-0.9460)(R 13.5658, F -14.5325, G 0.0021)] [G loss: 12.8968]\n",
      "4260 (5, 1) [D loss: (-0.6050)(R 9.0563, F -9.6980, G 0.0037)] [G loss: 8.4875]\n",
      "4261 (5, 1) [D loss: (-1.5725)(R 2.4933, F -4.1063, G 0.0041)] [G loss: 2.8047]\n",
      "4262 (5, 1) [D loss: (-2.5412)(R -3.7182, F 1.1519, G 0.0025)] [G loss: -2.4784]\n",
      "4263 (5, 1) [D loss: (-2.5906)(R -9.2414, F 6.5094, G 0.0141)] [G loss: -7.2694]\n",
      "4264 (5, 1) [D loss: (-1.4600)(R -12.1861, F 10.5742, G 0.0152)] [G loss: -9.1322]\n",
      "4265 (5, 1) [D loss: (-1.4687)(R -9.3261, F 7.7877, G 0.0070)] [G loss: -7.0615]\n",
      "4266 (5, 1) [D loss: (-0.9965)(R -9.1334, F 8.0764, G 0.0061)] [G loss: -7.0930]\n",
      "4267 (5, 1) [D loss: (-1.5974)(R -9.7167, F 8.0648, G 0.0055)] [G loss: -7.0484]\n",
      "4268 (5, 1) [D loss: (-1.7564)(R -9.3537, F 7.5266, G 0.0071)] [G loss: -7.0147]\n",
      "4269 (5, 1) [D loss: (-2.2109)(R -9.1420, F 6.8503, G 0.0081)] [G loss: -6.8154]\n",
      "4270 (5, 1) [D loss: (-2.3454)(R -11.2857, F 8.7997, G 0.0141)] [G loss: -8.8764]\n",
      "4271 (5, 1) [D loss: (-3.1606)(R -13.5682, F 10.2104, G 0.0197)] [G loss: -11.7753]\n",
      "4272 (5, 1) [D loss: (-2.7842)(R -17.2119, F 14.0867, G 0.0341)] [G loss: -14.8210]\n",
      "4273 (5, 1) [D loss: (-2.6801)(R -19.9775, F 16.8922, G 0.0405)] [G loss: -17.3406]\n",
      "4274 (5, 1) [D loss: (-3.2973)(R -22.1584, F 18.4080, G 0.0453)] [G loss: -20.1999]\n",
      "4275 (5, 1) [D loss: (-3.1446)(R -22.9672, F 19.4301, G 0.0392)] [G loss: -20.7366]\n",
      "4276 (5, 1) [D loss: (-2.3507)(R -21.1626, F 18.5834, G 0.0228)] [G loss: -19.8240]\n",
      "4277 (5, 1) [D loss: (-1.8936)(R -19.5463, F 17.5558, G 0.0097)] [G loss: -18.4739]\n",
      "4278 (5, 1) [D loss: (-2.9283)(R -20.5866, F 17.5325, G 0.0126)] [G loss: -19.3705]\n",
      "4279 (5, 1) [D loss: (-1.9674)(R -18.8347, F 16.8199, G 0.0047)] [G loss: -17.2487]\n",
      "4280 (5, 1) [D loss: (-1.4602)(R -17.3598, F 15.8377, G 0.0062)] [G loss: -16.3291]\n",
      "4281 (5, 1) [D loss: (-0.9176)(R -15.3677, F 14.4233, G 0.0027)] [G loss: -13.9188]\n",
      "4282 (5, 1) [D loss: (-1.2664)(R -12.5300, F 11.2487, G 0.0015)] [G loss: -11.0918]\n",
      "4283 (5, 1) [D loss: (-0.8282)(R -10.8325, F 9.9849, G 0.0019)] [G loss: -10.3758]\n",
      "4284 (5, 1) [D loss: (-0.9472)(R -10.5477, F 9.5808, G 0.0020)] [G loss: -10.4551]\n",
      "4285 (5, 1) [D loss: (-0.3165)(R -10.2363, F 9.8961, G 0.0024)] [G loss: -10.2043]\n",
      "4286 (5, 1) [D loss: (-0.9107)(R -10.3261, F 9.3912, G 0.0024)] [G loss: -10.0438]\n",
      "4287 (5, 1) [D loss: (-0.6136)(R -8.8857, F 8.2440, G 0.0028)] [G loss: -8.5622]\n",
      "4288 (5, 1) [D loss: (-0.8704)(R -8.6336, F 7.7341, G 0.0029)] [G loss: -8.1229]\n",
      "4289 (5, 1) [D loss: (-1.0619)(R -8.6067, F 7.5012, G 0.0044)] [G loss: -7.7107]\n",
      "4290 (5, 1) [D loss: (-1.1816)(R -7.7308, F 6.5101, G 0.0039)] [G loss: -7.2891]\n",
      "4291 (5, 1) [D loss: (-1.2461)(R -6.7988, F 5.5074, G 0.0045)] [G loss: -6.0321]\n",
      "4292 (5, 1) [D loss: (-1.3382)(R -5.8060, F 4.4236, G 0.0044)] [G loss: -4.8525]\n",
      "4293 (5, 1) [D loss: (-1.1864)(R -4.0972, F 2.8616, G 0.0049)] [G loss: -3.0738]\n",
      "4294 (5, 1) [D loss: (-1.1339)(R -2.7780, F 1.5848, G 0.0059)] [G loss: -1.7695]\n",
      "4295 (5, 1) [D loss: (-1.3754)(R -1.3872, F -0.0433, G 0.0055)] [G loss: 0.1878]\n",
      "4296 (5, 1) [D loss: (-1.2094)(R 0.6014, F -1.8679, G 0.0057)] [G loss: 2.0740]\n",
      "4297 (5, 1) [D loss: (-1.0352)(R 2.3793, F -3.4771, G 0.0063)] [G loss: 3.6581]\n",
      "4298 (5, 1) [D loss: (-1.3209)(R 3.0327, F -4.4208, G 0.0067)] [G loss: 4.5788]\n",
      "4299 (5, 1) [D loss: (-0.8975)(R 3.2102, F -4.1672, G 0.0059)] [G loss: 4.4227]\n",
      "4300 (5, 1) [D loss: (-1.0906)(R 2.8181, F -3.9597, G 0.0051)] [G loss: 3.7736]\n",
      "4301 (5, 1) [D loss: (-1.0771)(R 1.4433, F -2.5695, G 0.0049)] [G loss: 2.4729]\n",
      "4302 (5, 1) [D loss: (-1.0208)(R 0.8569, F -1.9374, G 0.0060)] [G loss: 1.6435]\n",
      "4303 (5, 1) [D loss: (-1.0553)(R 0.1558, F -1.2644, G 0.0053)] [G loss: 0.9114]\n",
      "4304 (5, 1) [D loss: (-1.0850)(R 0.3875, F -1.5313, G 0.0059)] [G loss: 1.3558]\n",
      "4305 (5, 1) [D loss: (-1.2861)(R 1.1825, F -2.5242, G 0.0056)] [G loss: 2.4541]\n",
      "4306 (5, 1) [D loss: (-1.4864)(R 2.3689, F -3.9116, G 0.0056)] [G loss: 4.2870]\n",
      "4307 (5, 1) [D loss: (-1.3586)(R 4.6529, F -6.0872, G 0.0076)] [G loss: 6.6526]\n",
      "4308 (5, 1) [D loss: (-1.4529)(R 7.7250, F -9.2866, G 0.0109)] [G loss: 9.8854]\n",
      "4309 (5, 1) [D loss: (-1.7602)(R 9.9616, F -11.8537, G 0.0132)] [G loss: 12.8938]\n",
      "4310 (5, 1) [D loss: (-2.0040)(R 12.7296, F -14.9574, G 0.0224)] [G loss: 15.0474]\n",
      "4311 (5, 1) [D loss: (-1.6322)(R 13.9229, F -15.7005, G 0.0145)] [G loss: 15.9260]\n",
      "4312 (5, 1) [D loss: (-2.1987)(R 14.0059, F -16.3270, G 0.0122)] [G loss: 16.3045]\n",
      "4313 (5, 1) [D loss: (-1.4275)(R 14.7467, F -16.3099, G 0.0136)] [G loss: 16.3458]\n",
      "4314 (5, 1) [D loss: (-1.6886)(R 13.9524, F -15.7210, G 0.0080)] [G loss: 15.4408]\n",
      "4315 (5, 1) [D loss: (-1.4357)(R 14.1290, F -15.6255, G 0.0061)] [G loss: 15.3298]\n",
      "4316 (5, 1) [D loss: (-1.1983)(R 14.1825, F -15.4416, G 0.0061)] [G loss: 14.8537]\n",
      "4317 (5, 1) [D loss: (-1.6782)(R 14.4132, F -16.1539, G 0.0062)] [G loss: 15.5907]\n",
      "4318 (5, 1) [D loss: (-1.7759)(R 14.5358, F -16.4014, G 0.0090)] [G loss: 15.7803]\n",
      "4319 (5, 1) [D loss: (-2.7369)(R 15.3052, F -18.1491, G 0.0107)] [G loss: 17.4132]\n",
      "4320 (5, 1) [D loss: (-2.9510)(R 16.8102, F -19.9654, G 0.0204)] [G loss: 18.9365]\n",
      "4321 (5, 1) [D loss: (-2.5013)(R 19.4828, F -22.2579, G 0.0274)] [G loss: 20.9162]\n",
      "4322 (5, 1) [D loss: (-2.9444)(R 21.5291, F -24.7597, G 0.0286)] [G loss: 23.3298]\n",
      "4323 (5, 1) [D loss: (-2.2668)(R 24.7747, F -27.4190, G 0.0377)] [G loss: 24.8955]\n",
      "4324 (5, 1) [D loss: (-3.0925)(R 25.9278, F -29.4388, G 0.0419)] [G loss: 26.5272]\n",
      "4325 (5, 1) [D loss: (-2.4751)(R 26.8678, F -29.7057, G 0.0363)] [G loss: 26.5894]\n",
      "4326 (5, 1) [D loss: (-2.3530)(R 24.3814, F -26.9329, G 0.0198)] [G loss: 24.3160]\n",
      "4327 (5, 1) [D loss: (-1.7567)(R 23.8071, F -25.6999, G 0.0136)] [G loss: 23.2484]\n",
      "4328 (5, 1) [D loss: (-1.5288)(R 22.0380, F -23.6442, G 0.0077)] [G loss: 21.1102]\n",
      "4329 (5, 1) [D loss: (-1.4531)(R 18.5999, F -20.0734, G 0.0020)] [G loss: 17.8506]\n",
      "4330 (5, 1) [D loss: (-0.6848)(R 16.3290, F -17.0346, G 0.0021)] [G loss: 15.1562]\n",
      "4331 (5, 1) [D loss: (-1.2496)(R 13.1467, F -14.4196, G 0.0023)] [G loss: 13.0845]\n",
      "4332 (5, 1) [D loss: (-1.6116)(R 9.2999, F -10.9299, G 0.0018)] [G loss: 9.5374]\n",
      "4333 (5, 1) [D loss: (-1.7762)(R 4.5760, F -6.3677, G 0.0016)] [G loss: 5.2276]\n",
      "4334 (5, 1) [D loss: (-1.4130)(R 0.4638, F -1.9078, G 0.0031)] [G loss: 0.5901]\n",
      "4335 (5, 1) [D loss: (-0.6887)(R -2.8497, F 2.1270, G 0.0034)] [G loss: -2.3607]\n",
      "4336 (5, 1) [D loss: (0.1652)(R -3.8962, F 4.0355, G 0.0026)] [G loss: -3.8521]\n",
      "4337 (5, 1) [D loss: (-0.6436)(R -5.2577, F 4.5883, G 0.0026)] [G loss: -4.5214]\n",
      "4338 (5, 1) [D loss: (-1.4138)(R -6.3438, F 4.9017, G 0.0028)] [G loss: -4.6232]\n",
      "4339 (5, 1) [D loss: (-1.7779)(R -7.6480, F 5.8119, G 0.0058)] [G loss: -5.8487]\n",
      "4340 (5, 1) [D loss: (-2.4041)(R -8.8257, F 6.3287, G 0.0093)] [G loss: -6.4883]\n",
      "4341 (5, 1) [D loss: (-2.4958)(R -10.3613, F 7.7115, G 0.0154)] [G loss: -7.7538]\n",
      "4342 (5, 1) [D loss: (-2.4415)(R -12.3864, F 9.7421, G 0.0203)] [G loss: -9.9326]\n",
      "4343 (5, 1) [D loss: (-2.9538)(R -15.4864, F 12.2825, G 0.0250)] [G loss: -13.1365]\n",
      "4344 (5, 1) [D loss: (-2.7642)(R -18.0701, F 14.9736, G 0.0332)] [G loss: -15.7683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4345 (5, 1) [D loss: (-3.2190)(R -21.8520, F 18.1861, G 0.0447)] [G loss: -19.2741]\n",
      "4346 (5, 1) [D loss: (-3.8204)(R -23.9902, F 19.6823, G 0.0488)] [G loss: -21.4837]\n",
      "4347 (5, 1) [D loss: (-3.0699)(R -25.2411, F 21.6527, G 0.0518)] [G loss: -22.7698]\n",
      "4348 (5, 1) [D loss: (-2.5373)(R -23.0084, F 20.2472, G 0.0224)] [G loss: -20.8490]\n",
      "4349 (5, 1) [D loss: (-1.8773)(R -20.9564, F 18.9822, G 0.0097)] [G loss: -19.8574]\n",
      "4350 (5, 1) [D loss: (-1.5069)(R -19.2825, F 17.7393, G 0.0036)] [G loss: -17.9475]\n",
      "4351 (5, 1) [D loss: (-0.6948)(R -17.5820, F 16.8626, G 0.0025)] [G loss: -15.9032]\n",
      "4352 (5, 1) [D loss: (-0.9987)(R -16.5757, F 15.5525, G 0.0025)] [G loss: -14.6908]\n",
      "4353 (5, 1) [D loss: (-1.6902)(R -14.2677, F 12.5529, G 0.0025)] [G loss: -12.2444]\n",
      "4354 (5, 1) [D loss: (-1.4679)(R -11.9472, F 10.4457, G 0.0034)] [G loss: -9.8214]\n",
      "4355 (5, 1) [D loss: (-1.6593)(R -9.0214, F 7.3225, G 0.0040)] [G loss: -7.2782]\n",
      "4356 (5, 1) [D loss: (-1.2923)(R -7.4377, F 6.0940, G 0.0051)] [G loss: -6.4323]\n",
      "4357 (5, 1) [D loss: (-0.6596)(R -6.1698, F 5.4810, G 0.0029)] [G loss: -5.1424]\n",
      "4358 (5, 1) [D loss: (-0.6910)(R -6.0410, F 5.3130, G 0.0037)] [G loss: -5.8763]\n",
      "4359 (5, 1) [D loss: (-0.8100)(R -6.7487, F 5.9064, G 0.0032)] [G loss: -6.2489]\n",
      "4360 (5, 1) [D loss: (-1.2105)(R -8.8980, F 7.6429, G 0.0045)] [G loss: -8.8735]\n",
      "4361 (5, 1) [D loss: (-2.0285)(R -11.2500, F 9.1644, G 0.0057)] [G loss: -10.8627]\n",
      "4362 (5, 1) [D loss: (-1.4687)(R -12.7601, F 11.1980, G 0.0093)] [G loss: -12.2368]\n",
      "4363 (5, 1) [D loss: (-1.8419)(R -13.0642, F 11.1450, G 0.0077)] [G loss: -12.2318]\n",
      "4364 (5, 1) [D loss: (-1.2390)(R -12.1433, F 10.8416, G 0.0063)] [G loss: -11.4321]\n",
      "4365 (5, 1) [D loss: (-0.7885)(R -11.5814, F 10.7407, G 0.0052)] [G loss: -11.3126]\n",
      "4366 (5, 1) [D loss: (-0.8481)(R -11.3936, F 10.4858, G 0.0060)] [G loss: -10.7384]\n",
      "4367 (5, 1) [D loss: (-0.4797)(R -10.4035, F 9.8867, G 0.0037)] [G loss: -9.8177]\n",
      "4368 (5, 1) [D loss: (-0.7626)(R -8.5973, F 7.7954, G 0.0039)] [G loss: -7.8129]\n",
      "4369 (5, 1) [D loss: (-0.7912)(R -7.3251, F 6.4946, G 0.0039)] [G loss: -6.3306]\n",
      "4370 (5, 1) [D loss: (-1.1578)(R -6.7021, F 5.4992, G 0.0045)] [G loss: -5.7094]\n",
      "4371 (5, 1) [D loss: (-1.0041)(R -5.8020, F 4.7460, G 0.0052)] [G loss: -4.7331]\n",
      "4372 (5, 1) [D loss: (-1.2586)(R -5.3612, F 4.0382, G 0.0064)] [G loss: -4.2313]\n",
      "4373 (5, 1) [D loss: (-1.0424)(R -4.9384, F 3.8332, G 0.0063)] [G loss: -3.8896]\n",
      "4374 (5, 1) [D loss: (-0.8147)(R -4.7829, F 3.9117, G 0.0057)] [G loss: -4.0403]\n",
      "4375 (5, 1) [D loss: (-0.7271)(R -4.6164, F 3.8293, G 0.0060)] [G loss: -3.8225]\n",
      "4376 (5, 1) [D loss: (-1.2045)(R -4.4050, F 3.1558, G 0.0045)] [G loss: -3.9044]\n",
      "4377 (5, 1) [D loss: (-1.3231)(R -4.9424, F 3.5565, G 0.0063)] [G loss: -4.1874]\n",
      "4378 (5, 1) [D loss: (-1.0755)(R -4.9010, F 3.7611, G 0.0064)] [G loss: -4.1180]\n",
      "4379 (5, 1) [D loss: (-1.1658)(R -4.9375, F 3.7148, G 0.0057)] [G loss: -3.7346]\n",
      "4380 (5, 1) [D loss: (-1.1262)(R -3.8202, F 2.6363, G 0.0058)] [G loss: -2.6594]\n",
      "4381 (5, 1) [D loss: (-1.4537)(R -2.7023, F 1.1965, G 0.0052)] [G loss: -1.4019]\n",
      "4382 (5, 1) [D loss: (-1.1502)(R -1.3864, F 0.1732, G 0.0063)] [G loss: 0.3407]\n",
      "4383 (5, 1) [D loss: (-1.5863)(R 0.4319, F -2.0802, G 0.0062)] [G loss: 2.2801]\n",
      "4384 (5, 1) [D loss: (-1.5468)(R 2.3095, F -3.9394, G 0.0083)] [G loss: 4.3229]\n",
      "4385 (5, 1) [D loss: (-1.6131)(R 4.0417, F -5.7189, G 0.0064)] [G loss: 6.5278]\n",
      "4386 (5, 1) [D loss: (-1.6521)(R 6.8060, F -8.5777, G 0.0120)] [G loss: 8.8334]\n",
      "4387 (5, 1) [D loss: (-1.8190)(R 8.1858, F -10.1324, G 0.0128)] [G loss: 10.7494]\n",
      "4388 (5, 1) [D loss: (-1.6870)(R 10.1326, F -11.9668, G 0.0147)] [G loss: 12.1667]\n",
      "4389 (5, 1) [D loss: (-1.6136)(R 11.0075, F -12.7565, G 0.0135)] [G loss: 13.1312]\n",
      "4390 (5, 1) [D loss: (-1.5294)(R 10.8054, F -12.4481, G 0.0113)] [G loss: 12.5483]\n",
      "4391 (5, 1) [D loss: (-1.1285)(R 11.8535, F -13.0807, G 0.0099)] [G loss: 13.1840]\n",
      "4392 (5, 1) [D loss: (-1.4259)(R 12.1588, F -13.7046, G 0.0120)] [G loss: 13.9001]\n",
      "4393 (5, 1) [D loss: (-1.3036)(R 12.8418, F -14.2475, G 0.0102)] [G loss: 14.1624]\n",
      "4394 (5, 1) [D loss: (-1.6106)(R 12.2478, F -13.9518, G 0.0093)] [G loss: 13.7215]\n",
      "4395 (5, 1) [D loss: (-1.7058)(R 12.1556, F -13.9493, G 0.0088)] [G loss: 13.8805]\n",
      "4396 (5, 1) [D loss: (-1.7338)(R 12.3926, F -14.1938, G 0.0067)] [G loss: 13.6019]\n",
      "4397 (5, 1) [D loss: (-1.9670)(R 12.8477, F -14.9015, G 0.0087)] [G loss: 14.2825]\n",
      "4398 (5, 1) [D loss: (-1.2721)(R 13.7278, F -15.0948, G 0.0095)] [G loss: 14.3675]\n",
      "4399 (5, 1) [D loss: (-2.0347)(R 14.1568, F -16.2984, G 0.0107)] [G loss: 15.1076]\n",
      "4400 (5, 1) [D loss: (-1.5477)(R 14.4025, F -16.0546, G 0.0104)] [G loss: 14.7133]\n",
      "4401 (5, 1) [D loss: (-1.1941)(R 14.9497, F -16.2329, G 0.0089)] [G loss: 15.1021]\n",
      "4402 (5, 1) [D loss: (-1.5982)(R 15.6586, F -17.3806, G 0.0124)] [G loss: 16.0148]\n",
      "4403 (5, 1) [D loss: (-2.1481)(R 16.2057, F -18.4805, G 0.0127)] [G loss: 16.8700]\n",
      "4404 (5, 1) [D loss: (-1.7327)(R 16.8983, F -18.7595, G 0.0129)] [G loss: 16.8946]\n",
      "4405 (5, 1) [D loss: (-1.4127)(R 17.2959, F -18.8251, G 0.0117)] [G loss: 17.2400]\n",
      "4406 (5, 1) [D loss: (-1.5944)(R 17.1796, F -18.8747, G 0.0101)] [G loss: 17.2511]\n",
      "4407 (5, 1) [D loss: (-0.5430)(R 16.9896, F -17.6141, G 0.0081)] [G loss: 16.0632]\n",
      "4408 (5, 1) [D loss: (-1.7832)(R 15.6824, F -17.5149, G 0.0049)] [G loss: 15.2738]\n",
      "4409 (5, 1) [D loss: (-0.8121)(R 15.1630, F -16.0259, G 0.0051)] [G loss: 14.1296]\n",
      "4410 (5, 1) [D loss: (-1.2079)(R 12.3733, F -13.6010, G 0.0020)] [G loss: 11.9139]\n",
      "4411 (5, 1) [D loss: (-0.6852)(R 11.9150, F -12.6233, G 0.0023)] [G loss: 11.3513]\n",
      "4412 (5, 1) [D loss: (-0.6102)(R 10.0448, F -10.6823, G 0.0027)] [G loss: 9.6816]\n",
      "4413 (5, 1) [D loss: (-0.7307)(R 6.9738, F -7.7305, G 0.0026)] [G loss: 6.5179]\n",
      "4414 (5, 1) [D loss: (-0.7188)(R 4.4613, F -5.2040, G 0.0024)] [G loss: 4.2827]\n",
      "4415 (5, 1) [D loss: (-0.8873)(R 0.2327, F -1.1477, G 0.0028)] [G loss: 0.4308]\n",
      "4416 (5, 1) [D loss: (-1.3929)(R -3.7682, F 2.3436, G 0.0032)] [G loss: -2.9884]\n",
      "4417 (5, 1) [D loss: (-1.7082)(R -7.4122, F 5.6357, G 0.0068)] [G loss: -5.8753]\n",
      "4418 (5, 1) [D loss: (-1.6761)(R -9.9043, F 8.1348, G 0.0093)] [G loss: -8.1606]\n",
      "4419 (5, 1) [D loss: (-1.1573)(R -10.4639, F 9.2156, G 0.0091)] [G loss: -8.8055]\n",
      "4420 (5, 1) [D loss: (-1.8166)(R -11.8715, F 9.9572, G 0.0098)] [G loss: -9.5178]\n",
      "4421 (5, 1) [D loss: (-1.5338)(R -12.1269, F 10.4873, G 0.0106)] [G loss: -10.4313]\n",
      "4422 (5, 1) [D loss: (-1.9082)(R -13.0188, F 11.0167, G 0.0094)] [G loss: -10.3274]\n",
      "4423 (5, 1) [D loss: (-2.4038)(R -14.0428, F 11.4873, G 0.0152)] [G loss: -11.4260]\n",
      "4424 (5, 1) [D loss: (-1.8512)(R -13.8624, F 11.8508, G 0.0160)] [G loss: -11.4481]\n",
      "4425 (5, 1) [D loss: (-2.3722)(R -15.7364, F 13.1354, G 0.0229)] [G loss: -13.8172]\n",
      "4426 (5, 1) [D loss: (-3.0796)(R -18.7327, F 15.3700, G 0.0283)] [G loss: -17.0562]\n",
      "4427 (5, 1) [D loss: (-2.2285)(R -20.6667, F 18.0793, G 0.0359)] [G loss: -19.2358]\n",
      "4428 (5, 1) [D loss: (-2.3853)(R -23.7547, F 20.8967, G 0.0473)] [G loss: -22.2504]\n",
      "4429 (5, 1) [D loss: (-2.0077)(R -23.1440, F 20.7962, G 0.0340)] [G loss: -21.6455]\n",
      "4430 (5, 1) [D loss: (-2.5482)(R -23.6260, F 20.8129, G 0.0265)] [G loss: -22.0903]\n",
      "4431 (5, 1) [D loss: (-1.9369)(R -21.2379, F 19.1884, G 0.0113)] [G loss: -20.3175]\n",
      "4432 (5, 1) [D loss: (-1.4877)(R -21.4504, F 19.8423, G 0.0120)] [G loss: -20.2274]\n",
      "4433 (5, 1) [D loss: (-1.9519)(R -20.1173, F 18.0937, G 0.0072)] [G loss: -18.9246]\n",
      "4434 (5, 1) [D loss: (-1.3373)(R -18.2616, F 16.8848, G 0.0040)] [G loss: -16.7702]\n",
      "4435 (5, 1) [D loss: (-0.8327)(R -17.1254, F 16.2561, G 0.0037)] [G loss: -15.8874]\n",
      "4436 (5, 1) [D loss: (-1.1894)(R -14.7170, F 13.4976, G 0.0030)] [G loss: -13.5084]\n",
      "4437 (5, 1) [D loss: (-0.7949)(R -12.7571, F 11.9401, G 0.0022)] [G loss: -11.9734]\n",
      "4438 (5, 1) [D loss: (-1.4657)(R -12.0978, F 10.6023, G 0.0030)] [G loss: -11.3765]\n",
      "4439 (5, 1) [D loss: (-0.7569)(R -11.0926, F 10.3123, G 0.0023)] [G loss: -10.5259]\n",
      "4440 (5, 1) [D loss: (-0.5760)(R -10.6503, F 10.0415, G 0.0033)] [G loss: -10.5370]\n",
      "4441 (5, 1) [D loss: (-0.5461)(R -10.8756, F 10.3001, G 0.0029)] [G loss: -10.5345]\n",
      "4442 (5, 1) [D loss: (-1.3776)(R -10.8447, F 9.4428, G 0.0024)] [G loss: -10.3967]\n",
      "4443 (5, 1) [D loss: (-0.6085)(R -10.8923, F 10.2527, G 0.0031)] [G loss: -10.6465]\n",
      "4444 (5, 1) [D loss: (-1.4525)(R -10.7955, F 9.3050, G 0.0038)] [G loss: -9.9231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445 (5, 1) [D loss: (-1.2737)(R -9.7571, F 8.4455, G 0.0038)] [G loss: -9.2351]\n",
      "4446 (5, 1) [D loss: (-0.8543)(R -9.2181, F 8.3166, G 0.0047)] [G loss: -8.5397]\n",
      "4447 (5, 1) [D loss: (-0.8760)(R -8.2597, F 7.3425, G 0.0041)] [G loss: -7.9134]\n",
      "4448 (5, 1) [D loss: (-0.8586)(R -6.9080, F 6.0141, G 0.0035)] [G loss: -6.2217]\n",
      "4449 (5, 1) [D loss: (-0.9921)(R -6.1161, F 5.0758, G 0.0048)] [G loss: -5.2691]\n",
      "4450 (5, 1) [D loss: (-1.0506)(R -4.9228, F 3.8271, G 0.0045)] [G loss: -3.8166]\n",
      "4451 (5, 1) [D loss: (-1.0693)(R -4.0851, F 2.9617, G 0.0054)] [G loss: -3.3465]\n",
      "4452 (5, 1) [D loss: (-1.3528)(R -3.4399, F 2.0318, G 0.0055)] [G loss: -2.0415]\n",
      "4453 (5, 1) [D loss: (-1.0124)(R -2.5702, F 1.5015, G 0.0056)] [G loss: -1.7116]\n",
      "4454 (5, 1) [D loss: (-1.2700)(R -2.4599, F 1.1230, G 0.0067)] [G loss: -0.8430]\n",
      "4455 (5, 1) [D loss: (-0.9893)(R -1.1644, F 0.1175, G 0.0058)] [G loss: 0.2245]\n",
      "4456 (5, 1) [D loss: (-0.9762)(R -0.3005, F -0.7328, G 0.0057)] [G loss: 1.1722]\n",
      "4457 (5, 1) [D loss: (-0.9280)(R 0.0886, F -1.0874, G 0.0071)] [G loss: 1.2473]\n",
      "4458 (5, 1) [D loss: (-1.1909)(R -0.0381, F -1.2067, G 0.0054)] [G loss: 1.4239]\n",
      "4459 (5, 1) [D loss: (-1.2419)(R 0.3387, F -1.6491, G 0.0069)] [G loss: 1.8602]\n",
      "4460 (5, 1) [D loss: (-1.2886)(R 1.1392, F -2.4937, G 0.0066)] [G loss: 2.5790]\n",
      "4461 (5, 1) [D loss: (-1.2465)(R 1.9150, F -3.2157, G 0.0054)] [G loss: 3.7539]\n",
      "4462 (5, 1) [D loss: (-1.2198)(R 3.1144, F -4.4068, G 0.0073)] [G loss: 4.7657]\n",
      "4463 (5, 1) [D loss: (-1.4724)(R 3.9451, F -5.4850, G 0.0067)] [G loss: 5.9870]\n",
      "4464 (5, 1) [D loss: (-1.4936)(R 5.2462, F -6.8340, G 0.0094)] [G loss: 7.8633]\n",
      "4465 (5, 1) [D loss: (-1.9505)(R 7.4318, F -9.4870, G 0.0105)] [G loss: 9.7583]\n",
      "4466 (5, 1) [D loss: (-1.8175)(R 9.4834, F -11.4504, G 0.0149)] [G loss: 11.9119]\n",
      "4467 (5, 1) [D loss: (-2.6318)(R 10.9923, F -13.7706, G 0.0147)] [G loss: 13.9185]\n",
      "4468 (5, 1) [D loss: (-2.0889)(R 12.7681, F -15.0459, G 0.0189)] [G loss: 15.2811]\n",
      "4469 (5, 1) [D loss: (-1.7983)(R 14.8230, F -16.8293, G 0.0208)] [G loss: 16.7213]\n",
      "4470 (5, 1) [D loss: (-2.2248)(R 16.1894, F -18.6267, G 0.0213)] [G loss: 17.9662]\n",
      "4471 (5, 1) [D loss: (-1.5005)(R 16.6744, F -18.3727, G 0.0198)] [G loss: 17.9169]\n",
      "4472 (5, 1) [D loss: (-1.6620)(R 17.2975, F -19.1418, G 0.0182)] [G loss: 18.6844]\n",
      "4473 (5, 1) [D loss: (-2.0926)(R 18.4021, F -20.6581, G 0.0163)] [G loss: 19.2394]\n",
      "4474 (5, 1) [D loss: (-2.3160)(R 17.8315, F -20.2968, G 0.0149)] [G loss: 19.2684]\n",
      "4475 (5, 1) [D loss: (-1.5979)(R 18.8545, F -20.6176, G 0.0165)] [G loss: 19.2856]\n",
      "4476 (5, 1) [D loss: (-1.9768)(R 17.1756, F -19.2411, G 0.0089)] [G loss: 17.8652]\n",
      "4477 (5, 1) [D loss: (-2.2454)(R 17.4362, F -19.7902, G 0.0109)] [G loss: 17.7612]\n",
      "4478 (5, 1) [D loss: (-2.1282)(R 18.0453, F -20.3341, G 0.0161)] [G loss: 18.4535]\n",
      "4479 (5, 1) [D loss: (-1.9069)(R 17.4986, F -19.5322, G 0.0127)] [G loss: 18.0326]\n",
      "4480 (5, 1) [D loss: (-0.6827)(R 18.2122, F -18.9907, G 0.0096)] [G loss: 17.1578]\n",
      "4481 (5, 1) [D loss: (-0.6679)(R 16.2945, F -17.0126, G 0.0050)] [G loss: 15.2652]\n",
      "4482 (5, 1) [D loss: (-0.9738)(R 15.9117, F -16.9197, G 0.0034)] [G loss: 14.8051]\n",
      "4483 (5, 1) [D loss: (-0.1400)(R 14.6359, F -14.7990, G 0.0023)] [G loss: 13.3565]\n",
      "4484 (5, 1) [D loss: (-0.9841)(R 13.4636, F -14.4665, G 0.0019)] [G loss: 12.7530]\n",
      "4485 (5, 1) [D loss: (-1.1207)(R 12.2655, F -13.4068, G 0.0021)] [G loss: 11.6476]\n",
      "4486 (5, 1) [D loss: (-1.1276)(R 10.3650, F -11.5201, G 0.0027)] [G loss: 10.5105]\n",
      "4487 (5, 1) [D loss: (-0.9206)(R 9.9671, F -10.9169, G 0.0029)] [G loss: 9.5846]\n",
      "4488 (5, 1) [D loss: (-1.0947)(R 8.1030, F -9.2233, G 0.0026)] [G loss: 8.2942]\n",
      "4489 (5, 1) [D loss: (-1.2027)(R 5.1405, F -6.3681, G 0.0025)] [G loss: 5.2676]\n",
      "4490 (5, 1) [D loss: (-1.2392)(R 2.1494, F -3.4158, G 0.0027)] [G loss: 2.8271]\n",
      "4491 (5, 1) [D loss: (-1.1142)(R -0.5652, F -0.5760, G 0.0027)] [G loss: -0.1984]\n",
      "4492 (5, 1) [D loss: (-1.4338)(R -4.0878, F 2.6244, G 0.0030)] [G loss: -3.2165]\n",
      "4493 (5, 1) [D loss: (-1.1537)(R -8.7889, F 7.5825, G 0.0053)] [G loss: -7.7178]\n",
      "4494 (5, 1) [D loss: (-1.5458)(R -11.5849, F 9.9421, G 0.0097)] [G loss: -9.6987]\n",
      "4495 (5, 1) [D loss: (-1.8014)(R -13.5069, F 11.6065, G 0.0099)] [G loss: -11.5988]\n",
      "4496 (5, 1) [D loss: (-1.2754)(R -14.8330, F 13.4538, G 0.0104)] [G loss: -12.2198]\n",
      "4497 (5, 1) [D loss: (-1.4035)(R -14.6277, F 13.1186, G 0.0106)] [G loss: -12.5128]\n",
      "4498 (5, 1) [D loss: (-2.0377)(R -15.9270, F 13.7882, G 0.0101)] [G loss: -13.6798]\n",
      "4499 (5, 1) [D loss: (-1.9082)(R -17.4246, F 15.3378, G 0.0179)] [G loss: -14.9669]\n",
      "4500 (5, 1) [D loss: (-2.3772)(R -18.1200, F 15.5397, G 0.0203)] [G loss: -15.0828]\n",
      "4501 (5, 1) [D loss: (-2.8582)(R -18.0109, F 14.9564, G 0.0196)] [G loss: -15.3707]\n",
      "4502 (5, 1) [D loss: (-3.4207)(R -19.5457, F 15.8595, G 0.0265)] [G loss: -17.2474]\n",
      "4503 (5, 1) [D loss: (-3.2926)(R -21.6117, F 17.9168, G 0.0402)] [G loss: -19.6789]\n",
      "4504 (5, 1) [D loss: (-3.3091)(R -23.8197, F 20.0669, G 0.0444)] [G loss: -22.2690]\n",
      "4505 (5, 1) [D loss: (-2.5866)(R -24.2476, F 21.2396, G 0.0421)] [G loss: -22.9126]\n",
      "4506 (5, 1) [D loss: (-2.2383)(R -25.5506, F 22.8988, G 0.0413)] [G loss: -24.0397]\n",
      "4507 (5, 1) [D loss: (-2.6718)(R -24.7457, F 21.8094, G 0.0265)] [G loss: -23.4140]\n",
      "4508 (5, 1) [D loss: (-1.2851)(R -23.6449, F 22.1733, G 0.0187)] [G loss: -22.6668]\n",
      "4509 (5, 1) [D loss: (-1.8899)(R -21.8639, F 19.8927, G 0.0081)] [G loss: -21.1813]\n",
      "4510 (5, 1) [D loss: (-1.8368)(R -21.4313, F 19.5169, G 0.0078)] [G loss: -20.2780]\n",
      "4511 (5, 1) [D loss: (-1.6464)(R -19.6264, F 17.9283, G 0.0052)] [G loss: -18.4098]\n",
      "4512 (5, 1) [D loss: (-1.1560)(R -16.9605, F 15.7654, G 0.0039)] [G loss: -15.6462]\n",
      "4513 (5, 1) [D loss: (-1.0245)(R -14.5542, F 13.5030, G 0.0027)] [G loss: -13.1152]\n",
      "4514 (5, 1) [D loss: (-1.0001)(R -12.3444, F 11.3190, G 0.0025)] [G loss: -11.2724]\n",
      "4515 (5, 1) [D loss: (-0.8668)(R -11.1912, F 10.2919, G 0.0032)] [G loss: -10.5088]\n",
      "4516 (5, 1) [D loss: (-0.9708)(R -10.9725, F 9.9714, G 0.0030)] [G loss: -10.0578]\n",
      "4517 (5, 1) [D loss: (-0.4036)(R -10.4245, F 9.9902, G 0.0031)] [G loss: -9.9604]\n",
      "4518 (5, 1) [D loss: (-0.2338)(R -10.5143, F 10.2436, G 0.0037)] [G loss: -10.5015]\n",
      "4519 (5, 1) [D loss: (-0.7770)(R -11.0382, F 10.2229, G 0.0038)] [G loss: -10.6122]\n",
      "4520 (5, 1) [D loss: (-0.5262)(R -10.7908, F 10.2271, G 0.0038)] [G loss: -10.1808]\n",
      "4521 (5, 1) [D loss: (-0.6458)(R -9.8973, F 9.2124, G 0.0039)] [G loss: -9.0269]\n",
      "4522 (5, 1) [D loss: (-0.8224)(R -8.9578, F 8.0923, G 0.0043)] [G loss: -8.0701]\n",
      "4523 (5, 1) [D loss: (-0.8244)(R -7.9948, F 7.1269, G 0.0043)] [G loss: -7.1551]\n",
      "4524 (5, 1) [D loss: (-1.0985)(R -6.9833, F 5.8384, G 0.0046)] [G loss: -5.5814]\n",
      "4525 (5, 1) [D loss: (-0.6386)(R -5.2741, F 4.5812, G 0.0054)] [G loss: -4.1127]\n",
      "4526 (5, 1) [D loss: (-1.0983)(R -4.0413, F 2.8913, G 0.0052)] [G loss: -2.6509]\n",
      "4527 (5, 1) [D loss: (-1.2145)(R -2.8324, F 1.5554, G 0.0063)] [G loss: -1.4638]\n",
      "4528 (5, 1) [D loss: (-1.0050)(R -1.9914, F 0.9170, G 0.0069)] [G loss: -0.8775]\n",
      "4529 (5, 1) [D loss: (-1.2464)(R -1.5566, F 0.2492, G 0.0061)] [G loss: -0.0323]\n",
      "4530 (5, 1) [D loss: (-0.8055)(R -1.1589, F 0.2854, G 0.0068)] [G loss: -0.0739]\n",
      "4531 (5, 1) [D loss: (-1.1999)(R -1.6336, F 0.3602, G 0.0074)] [G loss: -0.3555]\n",
      "4532 (5, 1) [D loss: (-0.9141)(R -1.5004, F 0.5240, G 0.0062)] [G loss: -0.7983]\n",
      "4533 (5, 1) [D loss: (-1.1454)(R -2.3011, F 1.1091, G 0.0047)] [G loss: -1.6081]\n",
      "4534 (5, 1) [D loss: (-0.7705)(R -2.7131, F 1.8923, G 0.0050)] [G loss: -1.8673]\n",
      "4535 (5, 1) [D loss: (-1.0965)(R -3.4824, F 2.3396, G 0.0046)] [G loss: -2.8004]\n",
      "4536 (5, 1) [D loss: (-1.0115)(R -3.3631, F 2.2836, G 0.0068)] [G loss: -2.4837]\n",
      "4537 (5, 1) [D loss: (-1.0699)(R -2.6244, F 1.4983, G 0.0056)] [G loss: -1.6415]\n",
      "4538 (5, 1) [D loss: (-1.2252)(R -2.0353, F 0.7556, G 0.0055)] [G loss: -0.8595]\n",
      "4539 (5, 1) [D loss: (-1.2913)(R -0.8740, F -0.4716, G 0.0054)] [G loss: 0.4448]\n",
      "4540 (5, 1) [D loss: (-1.1505)(R 0.8261, F -2.0351, G 0.0059)] [G loss: 2.5383]\n",
      "4541 (5, 1) [D loss: (-1.5752)(R 3.7122, F -5.3580, G 0.0071)] [G loss: 5.8726]\n",
      "4542 (5, 1) [D loss: (-1.5008)(R 6.0918, F -7.7155, G 0.0123)] [G loss: 8.5357]\n",
      "4543 (5, 1) [D loss: (-1.8519)(R 8.1529, F -10.1387, G 0.0134)] [G loss: 10.4825]\n",
      "4544 (5, 1) [D loss: (-1.8473)(R 10.4840, F -12.4938, G 0.0162)] [G loss: 12.8149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4545 (5, 1) [D loss: (-2.1545)(R 11.3132, F -13.6349, G 0.0167)] [G loss: 13.7398]\n",
      "4546 (5, 1) [D loss: (-2.0013)(R 12.7447, F -14.9128, G 0.0167)] [G loss: 14.6320]\n",
      "4547 (5, 1) [D loss: (-1.5282)(R 13.2390, F -14.9102, G 0.0143)] [G loss: 14.5642]\n",
      "4548 (5, 1) [D loss: (-1.7120)(R 13.4469, F -15.2923, G 0.0133)] [G loss: 14.6074]\n",
      "4549 (5, 1) [D loss: (-1.4628)(R 13.6816, F -15.2447, G 0.0100)] [G loss: 14.7375]\n",
      "4550 (5, 1) [D loss: (-1.7647)(R 14.3393, F -16.2111, G 0.0107)] [G loss: 16.0954]\n",
      "4551 (5, 1) [D loss: (-1.3634)(R 15.8351, F -17.3457, G 0.0147)] [G loss: 16.8655]\n",
      "4552 (5, 1) [D loss: (-2.0930)(R 15.6335, F -17.8694, G 0.0143)] [G loss: 17.0558]\n",
      "4553 (5, 1) [D loss: (-2.0386)(R 16.9475, F -19.1710, G 0.0185)] [G loss: 18.1557]\n",
      "4554 (5, 1) [D loss: (-3.2908)(R 17.7818, F -21.3018, G 0.0229)] [G loss: 19.5127]\n",
      "4555 (5, 1) [D loss: (-2.1513)(R 19.4520, F -21.8833, G 0.0280)] [G loss: 20.3810]\n",
      "4556 (5, 1) [D loss: (-2.5541)(R 20.7545, F -23.5988, G 0.0290)] [G loss: 21.5155]\n",
      "4557 (5, 1) [D loss: (-2.1744)(R 21.0777, F -23.4860, G 0.0234)] [G loss: 21.2379]\n",
      "4558 (5, 1) [D loss: (-1.9992)(R 21.4909, F -23.7051, G 0.0215)] [G loss: 21.0176]\n",
      "4559 (5, 1) [D loss: (-1.6211)(R 21.5661, F -23.3333, G 0.0146)] [G loss: 20.7798]\n",
      "4560 (5, 1) [D loss: (-1.6446)(R 20.2142, F -21.9447, G 0.0086)] [G loss: 19.2416]\n",
      "4561 (5, 1) [D loss: (-1.1865)(R 18.1965, F -19.4137, G 0.0031)] [G loss: 17.4803]\n",
      "4562 (5, 1) [D loss: (-0.3217)(R 15.5192, F -15.8564, G 0.0016)] [G loss: 14.4384]\n",
      "4563 (5, 1) [D loss: (-0.4804)(R 12.9337, F -13.4515, G 0.0037)] [G loss: 12.0049]\n",
      "4564 (5, 1) [D loss: (-0.8780)(R 10.0655, F -10.9937, G 0.0050)] [G loss: 10.0326]\n",
      "4565 (5, 1) [D loss: (-0.8815)(R 6.3487, F -7.3075, G 0.0077)] [G loss: 6.3305]\n",
      "4566 (5, 1) [D loss: (-1.4525)(R 2.4895, F -3.9972, G 0.0055)] [G loss: 3.0241]\n",
      "4567 (5, 1) [D loss: (-1.3547)(R -0.9360, F -0.4425, G 0.0024)] [G loss: -0.9298]\n",
      "4568 (5, 1) [D loss: (-1.5439)(R -5.9586, F 4.3956, G 0.0019)] [G loss: -5.1654]\n",
      "4569 (5, 1) [D loss: (-0.5269)(R -9.1346, F 8.5666, G 0.0041)] [G loss: -8.0317]\n",
      "4570 (5, 1) [D loss: (-0.6886)(R -10.5360, F 9.7961, G 0.0051)] [G loss: -8.9022]\n",
      "4571 (5, 1) [D loss: (-1.2817)(R -10.3455, F 9.0264, G 0.0038)] [G loss: -8.6505]\n",
      "4572 (5, 1) [D loss: (-1.2771)(R -9.2433, F 7.9278, G 0.0038)] [G loss: -7.2601]\n",
      "4573 (5, 1) [D loss: (-1.6037)(R -7.3686, F 5.7159, G 0.0049)] [G loss: -5.3557]\n",
      "4574 (5, 1) [D loss: (-1.4450)(R -6.2191, F 4.7044, G 0.0070)] [G loss: -4.4380]\n",
      "4575 (5, 1) [D loss: (-1.0715)(R -6.1931, F 5.0392, G 0.0082)] [G loss: -5.0808]\n",
      "4576 (5, 1) [D loss: (-1.7380)(R -7.3668, F 5.5304, G 0.0098)] [G loss: -6.4080]\n",
      "4577 (5, 1) [D loss: (-1.3971)(R -9.7883, F 8.2900, G 0.0101)] [G loss: -9.1459]\n",
      "4578 (5, 1) [D loss: (-2.4570)(R -13.4852, F 10.9089, G 0.0119)] [G loss: -12.3329]\n",
      "4579 (5, 1) [D loss: (-2.5479)(R -17.5998, F 14.8246, G 0.0227)] [G loss: -16.0731]\n",
      "4580 (5, 1) [D loss: (-3.2373)(R -20.5821, F 17.0073, G 0.0338)] [G loss: -18.7477]\n",
      "4581 (5, 1) [D loss: (-2.5609)(R -21.2319, F 18.3525, G 0.0318)] [G loss: -19.1191]\n",
      "4582 (5, 1) [D loss: (-2.3841)(R -20.0207, F 17.4165, G 0.0220)] [G loss: -18.6756]\n",
      "4583 (5, 1) [D loss: (-1.3308)(R -19.4931, F 18.0032, G 0.0159)] [G loss: -18.4464]\n",
      "4584 (5, 1) [D loss: (-1.4056)(R -17.1394, F 15.6741, G 0.0060)] [G loss: -16.1538]\n",
      "4585 (5, 1) [D loss: (-1.1422)(R -15.3867, F 14.1977, G 0.0047)] [G loss: -13.2561]\n",
      "4586 (5, 1) [D loss: (-0.8246)(R -13.3503, F 12.4772, G 0.0049)] [G loss: -11.8794]\n",
      "4587 (5, 1) [D loss: (-1.1621)(R -11.3246, F 10.1165, G 0.0046)] [G loss: -10.0136]\n",
      "4588 (5, 1) [D loss: (-1.4847)(R -10.3041, F 8.7569, G 0.0063)] [G loss: -8.4909]\n",
      "4589 (5, 1) [D loss: (-1.6616)(R -9.2859, F 7.5567, G 0.0068)] [G loss: -8.1623]\n",
      "4590 (5, 1) [D loss: (-1.6643)(R -10.3981, F 8.6610, G 0.0073)] [G loss: -9.5488]\n",
      "4591 (5, 1) [D loss: (-1.4145)(R -10.8804, F 9.3938, G 0.0072)] [G loss: -9.8405]\n",
      "4592 (5, 1) [D loss: (-1.5324)(R -10.4328, F 8.8508, G 0.0050)] [G loss: -9.4052]\n",
      "4593 (5, 1) [D loss: (-0.7212)(R -9.9754, F 9.2082, G 0.0046)] [G loss: -9.1838]\n",
      "4594 (5, 1) [D loss: (-1.3706)(R -9.7567, F 8.3424, G 0.0044)] [G loss: -8.2224]\n",
      "4595 (5, 1) [D loss: (-0.3324)(R -7.0741, F 6.7057, G 0.0036)] [G loss: -6.1650]\n",
      "4596 (5, 1) [D loss: (-0.6246)(R -4.9595, F 4.2926, G 0.0042)] [G loss: -4.1437]\n",
      "4597 (5, 1) [D loss: (-0.6711)(R -3.5510, F 2.8509, G 0.0029)] [G loss: -2.8427]\n",
      "4598 (5, 1) [D loss: (-0.8978)(R -1.9948, F 1.0467, G 0.0050)] [G loss: -1.1368]\n",
      "4599 (5, 1) [D loss: (-0.7831)(R -0.8281, F -0.0031, G 0.0048)] [G loss: 0.1224]\n",
      "4600 (5, 1) [D loss: (-0.9529)(R -0.1795, F -0.8341, G 0.0061)] [G loss: 0.6233]\n",
      "4601 (5, 1) [D loss: (-1.2342)(R -0.8728, F -0.4250, G 0.0064)] [G loss: 0.4938]\n",
      "4602 (5, 1) [D loss: (-0.9873)(R -1.0209, F -0.0298, G 0.0063)] [G loss: -0.4154]\n",
      "4603 (5, 1) [D loss: (-1.0902)(R -1.8833, F 0.7309, G 0.0062)] [G loss: -0.8864]\n",
      "4604 (5, 1) [D loss: (-1.1210)(R -2.5650, F 1.3893, G 0.0055)] [G loss: -1.5731]\n",
      "4605 (5, 1) [D loss: (-1.1430)(R -2.3290, F 1.1190, G 0.0067)] [G loss: -1.0408]\n",
      "4606 (5, 1) [D loss: (-1.1276)(R -2.6219, F 1.4242, G 0.0070)] [G loss: -1.6957]\n",
      "4607 (5, 1) [D loss: (-1.2341)(R -3.4116, F 2.1093, G 0.0068)] [G loss: -2.1221]\n",
      "4608 (5, 1) [D loss: (-0.9541)(R -2.7451, F 1.7281, G 0.0063)] [G loss: -1.4161]\n",
      "4609 (5, 1) [D loss: (-0.8701)(R -2.1659, F 1.2263, G 0.0070)] [G loss: -1.0526]\n",
      "4610 (5, 1) [D loss: (-1.4699)(R -1.7347, F 0.1951, G 0.0070)] [G loss: -0.3248]\n",
      "4611 (5, 1) [D loss: (-0.8006)(R -0.6513, F -0.2001, G 0.0051)] [G loss: 0.5991]\n",
      "4612 (5, 1) [D loss: (-1.3459)(R 0.2318, F -1.6302, G 0.0052)] [G loss: 1.6473]\n",
      "4613 (5, 1) [D loss: (-1.0546)(R 0.8831, F -2.0033, G 0.0066)] [G loss: 2.4983]\n",
      "4614 (5, 1) [D loss: (-1.3491)(R 1.4202, F -2.8394, G 0.0070)] [G loss: 2.7494]\n",
      "4615 (5, 1) [D loss: (-1.1012)(R 2.2211, F -3.3986, G 0.0076)] [G loss: 3.4733]\n",
      "4616 (5, 1) [D loss: (-0.9892)(R 2.6701, F -3.7267, G 0.0067)] [G loss: 3.9105]\n",
      "4617 (5, 1) [D loss: (-1.2072)(R 2.6398, F -3.9170, G 0.0070)] [G loss: 4.1556]\n",
      "4618 (5, 1) [D loss: (-1.0975)(R 3.0311, F -4.1877, G 0.0059)] [G loss: 4.3401]\n",
      "4619 (5, 1) [D loss: (-1.4858)(R 2.9702, F -4.5281, G 0.0072)] [G loss: 4.4017]\n",
      "4620 (5, 1) [D loss: (-1.6984)(R 3.4459, F -5.2216, G 0.0077)] [G loss: 5.0579]\n",
      "4621 (5, 1) [D loss: (-0.9886)(R 4.4320, F -5.4952, G 0.0075)] [G loss: 5.4081]\n",
      "4622 (5, 1) [D loss: (-1.3597)(R 5.0195, F -6.4525, G 0.0073)] [G loss: 6.2730]\n",
      "4623 (5, 1) [D loss: (-1.2588)(R 5.6116, F -6.9476, G 0.0077)] [G loss: 7.3127]\n",
      "4624 (5, 1) [D loss: (-1.1072)(R 7.3349, F -8.5249, G 0.0083)] [G loss: 8.5380]\n",
      "4625 (5, 1) [D loss: (-0.9419)(R 8.1595, F -9.1938, G 0.0092)] [G loss: 9.3887]\n",
      "4626 (5, 1) [D loss: (-1.2818)(R 9.1084, F -10.4642, G 0.0074)] [G loss: 10.4332]\n",
      "4627 (5, 1) [D loss: (-1.0212)(R 9.9696, F -11.0962, G 0.0105)] [G loss: 10.4981]\n",
      "4628 (5, 1) [D loss: (-1.1094)(R 9.3253, F -10.5007, G 0.0066)] [G loss: 9.9109]\n",
      "4629 (5, 1) [D loss: (-1.5237)(R 8.6436, F -10.2329, G 0.0066)] [G loss: 9.7258]\n",
      "4630 (5, 1) [D loss: (-1.3387)(R 9.7673, F -11.1833, G 0.0077)] [G loss: 10.7215]\n",
      "4631 (5, 1) [D loss: (-1.2006)(R 9.8269, F -11.0978, G 0.0070)] [G loss: 10.6137]\n",
      "4632 (5, 1) [D loss: (-1.0993)(R 9.8516, F -11.0450, G 0.0094)] [G loss: 10.4737]\n",
      "4633 (5, 1) [D loss: (-1.0621)(R 8.9217, F -10.0330, G 0.0049)] [G loss: 9.4471]\n",
      "4634 (5, 1) [D loss: (-1.3904)(R 8.4034, F -9.8448, G 0.0051)] [G loss: 8.9108]\n",
      "4635 (5, 1) [D loss: (-1.2860)(R 8.2577, F -9.5931, G 0.0049)] [G loss: 8.7810]\n",
      "4636 (5, 1) [D loss: (-0.8669)(R 7.9642, F -8.8837, G 0.0053)] [G loss: 8.5216]\n",
      "4637 (5, 1) [D loss: (-1.0606)(R 5.4522, F -6.5416, G 0.0029)] [G loss: 6.1775]\n",
      "4638 (5, 1) [D loss: (-0.5771)(R 4.6623, F -5.2733, G 0.0034)] [G loss: 5.0145]\n",
      "4639 (5, 1) [D loss: (-0.3762)(R 2.9576, F -3.3651, G 0.0031)] [G loss: 2.6946]\n",
      "4640 (5, 1) [D loss: (-1.0665)(R -0.4008, F -0.6909, G 0.0025)] [G loss: -0.1484]\n",
      "4641 (5, 1) [D loss: (-0.5945)(R -2.3469, F 1.7174, G 0.0035)] [G loss: -1.9041]\n",
      "4642 (5, 1) [D loss: (-1.1527)(R -5.4511, F 4.2685, G 0.0030)] [G loss: -4.6783]\n",
      "4643 (5, 1) [D loss: (-1.2383)(R -7.8364, F 6.5456, G 0.0053)] [G loss: -7.0507]\n",
      "4644 (5, 1) [D loss: (-1.6413)(R -10.3770, F 8.6709, G 0.0065)] [G loss: -8.9954]\n",
      "4645 (5, 1) [D loss: (-1.1563)(R -11.7851, F 10.5320, G 0.0097)] [G loss: -10.2437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4646 (5, 1) [D loss: (-1.6277)(R -12.9094, F 11.1861, G 0.0096)] [G loss: -11.7963]\n",
      "4647 (5, 1) [D loss: (-1.9228)(R -13.6138, F 11.5916, G 0.0099)] [G loss: -11.9756]\n",
      "4648 (5, 1) [D loss: (-1.0082)(R -12.6172, F 11.5355, G 0.0073)] [G loss: -10.9448]\n",
      "4649 (5, 1) [D loss: (-1.4450)(R -12.4904, F 10.9589, G 0.0087)] [G loss: -10.9269]\n",
      "4650 (5, 1) [D loss: (-1.5113)(R -12.8486, F 11.2499, G 0.0087)] [G loss: -10.9620]\n",
      "4651 (5, 1) [D loss: (-1.5859)(R -12.8397, F 11.1346, G 0.0119)] [G loss: -12.1667]\n",
      "4652 (5, 1) [D loss: (-1.6510)(R -14.2348, F 12.4650, G 0.0119)] [G loss: -13.2193]\n",
      "4653 (5, 1) [D loss: (-2.0651)(R -14.7574, F 12.5770, G 0.0115)] [G loss: -13.6777]\n",
      "4654 (5, 1) [D loss: (-1.4872)(R -14.3961, F 12.8099, G 0.0099)] [G loss: -13.7649]\n",
      "4655 (5, 1) [D loss: (-1.6510)(R -14.9323, F 13.1714, G 0.0110)] [G loss: -14.1593]\n",
      "4656 (5, 1) [D loss: (-1.6959)(R -16.4254, F 14.5754, G 0.0154)] [G loss: -15.7796]\n",
      "4657 (5, 1) [D loss: (-1.5535)(R -16.9853, F 15.2695, G 0.0162)] [G loss: -16.1615]\n",
      "4658 (5, 1) [D loss: (-1.9936)(R -16.6652, F 14.5508, G 0.0121)] [G loss: -15.5042]\n",
      "4659 (5, 1) [D loss: (-1.2453)(R -15.8359, F 14.5027, G 0.0088)] [G loss: -15.0536]\n",
      "4660 (5, 1) [D loss: (-1.3632)(R -14.6198, F 13.2014, G 0.0055)] [G loss: -12.8184]\n",
      "4661 (5, 1) [D loss: (-1.6174)(R -12.8788, F 11.2096, G 0.0052)] [G loss: -12.6205]\n",
      "4662 (5, 1) [D loss: (-1.1108)(R -11.9538, F 10.8032, G 0.0040)] [G loss: -10.8119]\n",
      "4663 (5, 1) [D loss: (-0.8619)(R -9.7667, F 8.8660, G 0.0039)] [G loss: -8.7093]\n",
      "4664 (5, 1) [D loss: (-0.8087)(R -8.4702, F 7.6203, G 0.0041)] [G loss: -7.3397]\n",
      "4665 (5, 1) [D loss: (-0.7688)(R -7.0821, F 6.2782, G 0.0035)] [G loss: -5.9955]\n",
      "4666 (5, 1) [D loss: (-0.5904)(R -5.5544, F 4.9287, G 0.0035)] [G loss: -4.8511]\n",
      "4667 (5, 1) [D loss: (-0.9592)(R -4.5723, F 3.5656, G 0.0047)] [G loss: -3.7480]\n",
      "4668 (5, 1) [D loss: (-0.9302)(R -3.9247, F 2.9486, G 0.0046)] [G loss: -2.8264]\n",
      "4669 (5, 1) [D loss: (-1.0604)(R -2.9053, F 1.8022, G 0.0043)] [G loss: -1.4932]\n",
      "4670 (5, 1) [D loss: (-0.9949)(R -1.7107, F 0.6648, G 0.0051)] [G loss: -0.3609]\n",
      "4671 (5, 1) [D loss: (-0.8276)(R -0.4674, F -0.4132, G 0.0053)] [G loss: 0.8893]\n",
      "4672 (5, 1) [D loss: (-1.2740)(R 0.6699, F -2.0027, G 0.0059)] [G loss: 2.4709]\n",
      "4673 (5, 1) [D loss: (-1.3596)(R 2.0516, F -3.4715, G 0.0060)] [G loss: 3.8386]\n",
      "4674 (5, 1) [D loss: (-1.4821)(R 3.7417, F -5.2985, G 0.0075)] [G loss: 6.1614]\n",
      "4675 (5, 1) [D loss: (-1.5186)(R 6.6896, F -8.3075, G 0.0099)] [G loss: 8.9459]\n",
      "4676 (5, 1) [D loss: (-1.9101)(R 9.8196, F -11.8421, G 0.0112)] [G loss: 12.3712]\n",
      "4677 (5, 1) [D loss: (-2.0344)(R 12.0394, F -14.2461, G 0.0172)] [G loss: 13.9453]\n",
      "4678 (5, 1) [D loss: (-1.3390)(R 13.9818, F -15.4724, G 0.0152)] [G loss: 15.5205]\n",
      "4679 (5, 1) [D loss: (-1.7435)(R 14.1845, F -16.0646, G 0.0137)] [G loss: 16.0084]\n",
      "4680 (5, 1) [D loss: (-2.1761)(R 13.1143, F -15.3600, G 0.0070)] [G loss: 14.7216]\n",
      "4681 (5, 1) [D loss: (-1.7655)(R 13.9987, F -15.8641, G 0.0100)] [G loss: 15.2033]\n",
      "4682 (5, 1) [D loss: (-1.6420)(R 14.0342, F -15.7721, G 0.0096)] [G loss: 15.1232]\n",
      "4683 (5, 1) [D loss: (-1.7633)(R 14.0223, F -15.8912, G 0.0106)] [G loss: 15.0775]\n",
      "4684 (5, 1) [D loss: (-1.3983)(R 13.8795, F -15.3738, G 0.0096)] [G loss: 14.6622]\n",
      "4685 (5, 1) [D loss: (-1.1458)(R 13.7244, F -14.9539, G 0.0084)] [G loss: 14.2017]\n",
      "4686 (5, 1) [D loss: (-1.2733)(R 13.7866, F -15.1407, G 0.0081)] [G loss: 14.4967]\n",
      "4687 (5, 1) [D loss: (-1.3756)(R 14.6859, F -16.1469, G 0.0085)] [G loss: 15.1883]\n",
      "4688 (5, 1) [D loss: (-1.8268)(R 13.9148, F -15.8074, G 0.0066)] [G loss: 14.8981]\n",
      "4689 (5, 1) [D loss: (-1.5188)(R 14.3496, F -15.9332, G 0.0065)] [G loss: 15.5563]\n",
      "4690 (5, 1) [D loss: (-1.9261)(R 14.1544, F -16.1383, G 0.0058)] [G loss: 15.2391]\n",
      "4691 (5, 1) [D loss: (-0.7754)(R 14.9501, F -15.7895, G 0.0064)] [G loss: 15.0114]\n",
      "4692 (5, 1) [D loss: (-1.0582)(R 13.8818, F -14.9902, G 0.0050)] [G loss: 14.1790]\n",
      "4693 (5, 1) [D loss: (-1.3440)(R 12.0162, F -13.3974, G 0.0037)] [G loss: 12.5127]\n",
      "4694 (5, 1) [D loss: (-0.6970)(R 10.1164, F -10.8312, G 0.0018)] [G loss: 9.8939]\n",
      "4695 (5, 1) [D loss: (-1.1049)(R 7.4896, F -8.6139, G 0.0019)] [G loss: 8.0666]\n",
      "4696 (5, 1) [D loss: (-1.4553)(R 5.6102, F -7.0869, G 0.0021)] [G loss: 6.2456]\n",
      "4697 (5, 1) [D loss: (-1.0345)(R 3.9788, F -5.0339, G 0.0021)] [G loss: 4.2780]\n",
      "4698 (5, 1) [D loss: (-0.9617)(R 2.1278, F -3.1132, G 0.0024)] [G loss: 2.3729]\n",
      "4699 (5, 1) [D loss: (-1.0198)(R 0.1483, F -1.1984, G 0.0030)] [G loss: 0.7686]\n",
      "4700 (5, 1) [D loss: (-1.2274)(R -1.5361, F 0.2743, G 0.0034)] [G loss: -0.3708]\n",
      "4701 (5, 1) [D loss: (-0.9386)(R -1.4226, F 0.4521, G 0.0032)] [G loss: -0.6827]\n",
      "4702 (5, 1) [D loss: (-0.8942)(R -1.7408, F 0.8064, G 0.0040)] [G loss: -0.7981]\n",
      "4703 (5, 1) [D loss: (-1.0308)(R -2.5614, F 1.4938, G 0.0037)] [G loss: -1.2848]\n",
      "4704 (5, 1) [D loss: (-1.0365)(R -2.1934, F 1.1019, G 0.0055)] [G loss: -1.0310]\n",
      "4705 (5, 1) [D loss: (-1.2217)(R -2.5476, F 1.2749, G 0.0051)] [G loss: -1.2421]\n",
      "4706 (5, 1) [D loss: (-1.4262)(R -3.5913, F 2.0846, G 0.0080)] [G loss: -2.3864]\n",
      "4707 (5, 1) [D loss: (-1.4457)(R -4.9803, F 3.4396, G 0.0095)] [G loss: -3.7677]\n",
      "4708 (5, 1) [D loss: (-1.4438)(R -7.0269, F 5.4898, G 0.0093)] [G loss: -6.0221]\n",
      "4709 (5, 1) [D loss: (-1.8765)(R -9.1521, F 7.1948, G 0.0081)] [G loss: -7.9757]\n",
      "4710 (5, 1) [D loss: (-1.7907)(R -12.9171, F 11.0027, G 0.0124)] [G loss: -11.1113]\n",
      "4711 (5, 1) [D loss: (-2.2434)(R -15.2637, F 12.8518, G 0.0169)] [G loss: -13.9092]\n",
      "4712 (5, 1) [D loss: (-2.3580)(R -16.5429, F 14.0012, G 0.0184)] [G loss: -15.3264]\n",
      "4713 (5, 1) [D loss: (-2.3492)(R -16.5604, F 14.0822, G 0.0129)] [G loss: -14.6189]\n",
      "4714 (5, 1) [D loss: (-1.4409)(R -14.8024, F 13.2792, G 0.0082)] [G loss: -12.5982]\n",
      "4715 (5, 1) [D loss: (-1.1704)(R -13.1272, F 11.8840, G 0.0073)] [G loss: -11.8097]\n",
      "4716 (5, 1) [D loss: (-1.9006)(R -12.8436, F 10.8712, G 0.0072)] [G loss: -11.1559]\n",
      "4717 (5, 1) [D loss: (-1.6659)(R -11.4618, F 9.7241, G 0.0072)] [G loss: -9.6712]\n",
      "4718 (5, 1) [D loss: (-1.9551)(R -10.2445, F 8.2218, G 0.0068)] [G loss: -9.0503]\n",
      "4719 (5, 1) [D loss: (-1.2220)(R -9.4014, F 8.1016, G 0.0078)] [G loss: -8.0316]\n",
      "4720 (5, 1) [D loss: (-1.5346)(R -10.1917, F 8.5705, G 0.0087)] [G loss: -9.8749]\n",
      "4721 (5, 1) [D loss: (-1.4594)(R -11.5488, F 9.9841, G 0.0105)] [G loss: -11.3319]\n",
      "4722 (5, 1) [D loss: (-1.6971)(R -13.9145, F 12.0776, G 0.0140)] [G loss: -13.8107]\n",
      "4723 (5, 1) [D loss: (-1.5825)(R -14.7006, F 13.0311, G 0.0087)] [G loss: -13.8677]\n",
      "4724 (5, 1) [D loss: (-1.0946)(R -14.5593, F 13.3512, G 0.0113)] [G loss: -14.3455]\n",
      "4725 (5, 1) [D loss: (-0.8682)(R -13.4888, F 12.5653, G 0.0055)] [G loss: -13.2371]\n",
      "4726 (5, 1) [D loss: (-1.1774)(R -12.6471, F 11.4292, G 0.0041)] [G loss: -11.5336]\n",
      "4727 (5, 1) [D loss: (-1.3487)(R -11.9229, F 10.5428, G 0.0031)] [G loss: -11.2768]\n",
      "4728 (5, 1) [D loss: (-0.5062)(R -10.3183, F 9.7832, G 0.0029)] [G loss: -9.4092]\n",
      "4729 (5, 1) [D loss: (-0.8855)(R -8.3098, F 7.3883, G 0.0036)] [G loss: -7.3327]\n",
      "4730 (5, 1) [D loss: (-0.6543)(R -5.9473, F 5.2626, G 0.0030)] [G loss: -4.6702]\n",
      "4731 (5, 1) [D loss: (-0.8204)(R -4.5070, F 3.6469, G 0.0040)] [G loss: -3.4429]\n",
      "4732 (5, 1) [D loss: (-1.0084)(R -4.1317, F 3.0767, G 0.0047)] [G loss: -2.9751]\n",
      "4733 (5, 1) [D loss: (-0.9055)(R -3.5611, F 2.6077, G 0.0048)] [G loss: -2.4004]\n",
      "4734 (5, 1) [D loss: (-0.7312)(R -3.7892, F 3.0049, G 0.0053)] [G loss: -3.0207]\n",
      "4735 (5, 1) [D loss: (-0.9853)(R -3.6597, F 2.6233, G 0.0051)] [G loss: -2.5185]\n",
      "4736 (5, 1) [D loss: (-1.2114)(R -3.6076, F 2.3592, G 0.0037)] [G loss: -2.3012]\n",
      "4737 (5, 1) [D loss: (-0.9694)(R -3.0765, F 2.0558, G 0.0051)] [G loss: -2.0866]\n",
      "4738 (5, 1) [D loss: (-0.9665)(R -2.3265, F 1.3105, G 0.0050)] [G loss: -1.1126]\n",
      "4739 (5, 1) [D loss: (-1.3838)(R -1.9658, F 0.5190, G 0.0063)] [G loss: -0.4980]\n",
      "4740 (5, 1) [D loss: (-0.9715)(R -0.4613, F -0.5633, G 0.0053)] [G loss: 0.8026]\n",
      "4741 (5, 1) [D loss: (-1.4431)(R 0.6437, F -2.1459, G 0.0059)] [G loss: 2.1892]\n",
      "4742 (5, 1) [D loss: (-1.4423)(R 2.4817, F -3.9863, G 0.0062)] [G loss: 4.4050]\n",
      "4743 (5, 1) [D loss: (-1.3832)(R 4.3831, F -5.8484, G 0.0082)] [G loss: 6.0481]\n",
      "4744 (5, 1) [D loss: (-1.6814)(R 6.1547, F -7.9320, G 0.0096)] [G loss: 8.1595]\n",
      "4745 (5, 1) [D loss: (-1.2914)(R 8.2149, F -9.6200, G 0.0114)] [G loss: 9.8802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4746 (5, 1) [D loss: (-1.6256)(R 9.4668, F -11.2091, G 0.0117)] [G loss: 11.3783]\n",
      "4747 (5, 1) [D loss: (-1.1898)(R 10.3691, F -11.6726, G 0.0114)] [G loss: 11.6891]\n",
      "4748 (5, 1) [D loss: (-1.4934)(R 10.3347, F -11.9308, G 0.0103)] [G loss: 11.7430]\n",
      "4749 (5, 1) [D loss: (-1.3655)(R 9.9827, F -11.4221, G 0.0074)] [G loss: 10.9504]\n",
      "4750 (5, 1) [D loss: (-1.5479)(R 9.1127, F -10.7287, G 0.0068)] [G loss: 10.3104]\n",
      "4751 (5, 1) [D loss: (-1.4715)(R 8.6815, F -10.2066, G 0.0054)] [G loss: 9.3957]\n",
      "4752 (5, 1) [D loss: (-1.7104)(R 7.8596, F -9.6192, G 0.0049)] [G loss: 9.0343]\n",
      "4753 (5, 1) [D loss: (-1.4470)(R 8.1580, F -9.6726, G 0.0068)] [G loss: 9.3395]\n",
      "4754 (5, 1) [D loss: (-1.7715)(R 8.4778, F -10.3176, G 0.0068)] [G loss: 9.4879]\n",
      "4755 (5, 1) [D loss: (-1.5684)(R 9.5972, F -11.2737, G 0.0108)] [G loss: 10.6927]\n",
      "4756 (5, 1) [D loss: (-1.4344)(R 9.7294, F -11.2567, G 0.0093)] [G loss: 10.4907]\n",
      "4757 (5, 1) [D loss: (-1.8184)(R 10.6823, F -12.6032, G 0.0103)] [G loss: 11.8583]\n",
      "4758 (5, 1) [D loss: (-0.9837)(R 13.5082, F -14.6273, G 0.0135)] [G loss: 13.5718]\n",
      "4759 (5, 1) [D loss: (-1.5720)(R 13.5563, F -15.2561, G 0.0128)] [G loss: 14.1754]\n",
      "4760 (5, 1) [D loss: (-1.6237)(R 14.8691, F -16.6088, G 0.0116)] [G loss: 14.9826]\n",
      "4761 (5, 1) [D loss: (-1.0747)(R 15.7584, F -16.9731, G 0.0140)] [G loss: 15.5408]\n",
      "4762 (5, 1) [D loss: (-1.7292)(R 14.4859, F -16.3190, G 0.0104)] [G loss: 15.0579]\n",
      "4763 (5, 1) [D loss: (-0.6848)(R 14.5242, F -15.2852, G 0.0076)] [G loss: 14.0392]\n",
      "4764 (5, 1) [D loss: (-0.6972)(R 13.3888, F -14.1280, G 0.0042)] [G loss: 12.9125]\n",
      "4765 (5, 1) [D loss: (-0.8120)(R 10.8486, F -11.6812, G 0.0021)] [G loss: 10.5006]\n",
      "4766 (5, 1) [D loss: (-0.7040)(R 8.9114, F -9.6365, G 0.0021)] [G loss: 8.8407]\n",
      "4767 (5, 1) [D loss: (-0.6608)(R 6.5587, F -7.2424, G 0.0023)] [G loss: 6.4045]\n",
      "4768 (5, 1) [D loss: (-0.8236)(R 3.8763, F -4.7214, G 0.0022)] [G loss: 3.9111]\n",
      "4769 (5, 1) [D loss: (-1.0780)(R 1.1289, F -2.2244, G 0.0018)] [G loss: 1.5466]\n",
      "4770 (5, 1) [D loss: (-1.1266)(R -0.8640, F -0.2880, G 0.0025)] [G loss: -0.3422]\n",
      "4771 (5, 1) [D loss: (-0.9045)(R -1.9874, F 1.0391, G 0.0044)] [G loss: -1.2746]\n",
      "4772 (5, 1) [D loss: (-0.6021)(R -2.6997, F 2.0592, G 0.0038)] [G loss: -1.9683]\n",
      "4773 (5, 1) [D loss: (-0.9421)(R -3.0243, F 2.0436, G 0.0039)] [G loss: -2.3387]\n",
      "4774 (5, 1) [D loss: (-0.7525)(R -3.4535, F 2.6615, G 0.0040)] [G loss: -2.2482]\n",
      "4775 (5, 1) [D loss: (-1.0973)(R -3.5077, F 2.3518, G 0.0059)] [G loss: -2.0499]\n",
      "4776 (5, 1) [D loss: (-1.4578)(R -4.1523, F 2.6224, G 0.0072)] [G loss: -2.5976]\n",
      "4777 (5, 1) [D loss: (-1.0735)(R -4.2337, F 3.0774, G 0.0083)] [G loss: -2.8901]\n",
      "4778 (5, 1) [D loss: (-1.4392)(R -5.7928, F 4.2727, G 0.0081)] [G loss: -4.3533]\n",
      "4779 (5, 1) [D loss: (-1.9142)(R -8.6496, F 6.6297, G 0.0106)] [G loss: -7.5390]\n",
      "4780 (5, 1) [D loss: (-1.7909)(R -12.1304, F 10.2094, G 0.0130)] [G loss: -11.4409]\n",
      "4781 (5, 1) [D loss: (-1.9673)(R -15.7304, F 13.5919, G 0.0171)] [G loss: -14.4032]\n",
      "4782 (5, 1) [D loss: (-2.2291)(R -18.9675, F 16.4639, G 0.0275)] [G loss: -17.3751]\n",
      "4783 (5, 1) [D loss: (-2.2212)(R -19.5415, F 17.0920, G 0.0228)] [G loss: -18.0391]\n",
      "4784 (5, 1) [D loss: (-2.4398)(R -19.0323, F 16.4329, G 0.0160)] [G loss: -17.5910]\n",
      "4785 (5, 1) [D loss: (-1.7904)(R -17.8679, F 15.9647, G 0.0113)] [G loss: -16.7244]\n",
      "4786 (5, 1) [D loss: (-2.2925)(R -17.3104, F 14.9239, G 0.0094)] [G loss: -16.4496]\n",
      "4787 (5, 1) [D loss: (-1.9323)(R -16.7643, F 14.7300, G 0.0102)] [G loss: -15.4536]\n",
      "4788 (5, 1) [D loss: (-2.3847)(R -17.0582, F 14.5474, G 0.0126)] [G loss: -16.1815]\n",
      "4789 (5, 1) [D loss: (-1.7784)(R -17.3004, F 15.3635, G 0.0159)] [G loss: -16.3757]\n",
      "4790 (5, 1) [D loss: (-2.9657)(R -18.0018, F 14.8754, G 0.0161)] [G loss: -17.1149]\n",
      "4791 (5, 1) [D loss: (-1.6778)(R -17.8801, F 16.0354, G 0.0167)] [G loss: -17.5747]\n",
      "4792 (5, 1) [D loss: (-1.3350)(R -18.8556, F 17.3544, G 0.0166)] [G loss: -18.8746]\n",
      "4793 (5, 1) [D loss: (-1.9352)(R -19.6946, F 17.6111, G 0.0148)] [G loss: -19.4578]\n",
      "4794 (5, 1) [D loss: (-1.5401)(R -20.1038, F 18.4172, G 0.0147)] [G loss: -19.8502]\n",
      "4795 (5, 1) [D loss: (-1.5724)(R -18.6575, F 17.0055, G 0.0080)] [G loss: -18.9600]\n",
      "4796 (5, 1) [D loss: (-0.5639)(R -17.3733, F 16.7663, G 0.0043)] [G loss: -16.5625]\n",
      "4797 (5, 1) [D loss: (-0.4277)(R -14.2012, F 13.7476, G 0.0026)] [G loss: -13.8736]\n",
      "4798 (5, 1) [D loss: (-0.9150)(R -11.7744, F 10.8336, G 0.0026)] [G loss: -10.8896]\n",
      "4799 (5, 1) [D loss: (-0.9332)(R -9.7209, F 8.7669, G 0.0021)] [G loss: -8.8101]\n",
      "4800 (5, 1) [D loss: (-0.7771)(R -7.4268, F 6.6227, G 0.0027)] [G loss: -6.4971]\n",
      "4801 (5, 1) [D loss: (-0.8002)(R -5.6720, F 4.8322, G 0.0040)] [G loss: -4.8624]\n",
      "4802 (5, 1) [D loss: (-0.6087)(R -4.4924, F 3.8365, G 0.0047)] [G loss: -3.8403]\n",
      "4803 (5, 1) [D loss: (-0.7713)(R -3.9903, F 3.1783, G 0.0041)] [G loss: -3.3425]\n",
      "4804 (5, 1) [D loss: (-1.1915)(R -4.1796, F 2.9424, G 0.0046)] [G loss: -3.1811]\n",
      "4805 (5, 1) [D loss: (-0.7052)(R -3.2704, F 2.5248, G 0.0040)] [G loss: -2.1180]\n",
      "4806 (5, 1) [D loss: (-1.0268)(R -2.3919, F 1.3034, G 0.0062)] [G loss: -1.0651]\n",
      "4807 (5, 1) [D loss: (-1.1188)(R -1.1490, F -0.0175, G 0.0048)] [G loss: 0.2913]\n",
      "4808 (5, 1) [D loss: (-0.9568)(R 1.2769, F -2.2893, G 0.0056)] [G loss: 3.0762]\n",
      "4809 (5, 1) [D loss: (-1.2100)(R 3.1810, F -4.4518, G 0.0061)] [G loss: 5.1370]\n",
      "4810 (5, 1) [D loss: (-1.5808)(R 4.7413, F -6.3931, G 0.0071)] [G loss: 6.7426]\n",
      "4811 (5, 1) [D loss: (-1.9762)(R 6.9879, F -9.0655, G 0.0101)] [G loss: 9.5296]\n",
      "4812 (5, 1) [D loss: (-1.5571)(R 9.6381, F -11.3197, G 0.0125)] [G loss: 11.6296]\n",
      "4813 (5, 1) [D loss: (-1.8688)(R 10.7404, F -12.7403, G 0.0131)] [G loss: 12.5408]\n",
      "4814 (5, 1) [D loss: (-1.4973)(R 11.6190, F -13.2273, G 0.0111)] [G loss: 13.4042]\n",
      "4815 (5, 1) [D loss: (-1.7317)(R 11.9740, F -13.7907, G 0.0085)] [G loss: 13.4546]\n",
      "4816 (5, 1) [D loss: (-1.3060)(R 11.8137, F -13.1994, G 0.0080)] [G loss: 12.9942]\n",
      "4817 (5, 1) [D loss: (-1.9007)(R 11.2441, F -13.2242, G 0.0079)] [G loss: 12.8090]\n",
      "4818 (5, 1) [D loss: (-1.7384)(R 10.7330, F -12.5442, G 0.0073)] [G loss: 11.7819]\n",
      "4819 (5, 1) [D loss: (-1.9013)(R 10.0455, F -12.0205, G 0.0074)] [G loss: 11.6666]\n",
      "4820 (5, 1) [D loss: (-1.4468)(R 10.4806, F -11.9980, G 0.0071)] [G loss: 11.6600]\n",
      "4821 (5, 1) [D loss: (-2.2917)(R 11.1868, F -13.5660, G 0.0087)] [G loss: 12.6119]\n",
      "4822 (5, 1) [D loss: (-2.2180)(R 12.0433, F -14.3603, G 0.0099)] [G loss: 13.4959]\n",
      "4823 (5, 1) [D loss: (-1.8245)(R 12.7064, F -14.6501, G 0.0119)] [G loss: 13.7423]\n",
      "4824 (5, 1) [D loss: (-2.2712)(R 13.4405, F -15.8232, G 0.0112)] [G loss: 14.4545]\n",
      "4825 (5, 1) [D loss: (-1.6712)(R 13.6307, F -15.4000, G 0.0098)] [G loss: 14.3176]\n",
      "4826 (5, 1) [D loss: (-1.0625)(R 13.5465, F -14.6933, G 0.0084)] [G loss: 13.9492]\n",
      "4827 (5, 1) [D loss: (-1.7737)(R 14.2525, F -16.1156, G 0.0089)] [G loss: 14.5261]\n",
      "4828 (5, 1) [D loss: (-1.7772)(R 14.9141, F -16.7846, G 0.0093)] [G loss: 15.0979]\n",
      "4829 (5, 1) [D loss: (-1.8630)(R 15.1475, F -17.0994, G 0.0089)] [G loss: 15.6914]\n",
      "4830 (5, 1) [D loss: (-1.3212)(R 15.0950, F -16.5149, G 0.0099)] [G loss: 15.2912]\n",
      "4831 (5, 1) [D loss: (-1.1091)(R 13.7114, F -14.8661, G 0.0046)] [G loss: 13.8027]\n",
      "4832 (5, 1) [D loss: (-1.4283)(R 12.7735, F -14.2450, G 0.0043)] [G loss: 13.1654]\n",
      "4833 (5, 1) [D loss: (-0.8528)(R 10.7556, F -11.6333, G 0.0025)] [G loss: 10.5582]\n",
      "4834 (5, 1) [D loss: (-1.1774)(R 10.2797, F -11.4805, G 0.0023)] [G loss: 10.1660]\n",
      "4835 (5, 1) [D loss: (-1.0985)(R 9.8944, F -11.0247, G 0.0032)] [G loss: 10.3623]\n",
      "4836 (5, 1) [D loss: (-1.4734)(R 9.2152, F -10.7153, G 0.0027)] [G loss: 9.4805]\n",
      "4837 (5, 1) [D loss: (-1.3144)(R 8.9621, F -10.3098, G 0.0033)] [G loss: 9.5535]\n",
      "4838 (5, 1) [D loss: (-0.8761)(R 8.0963, F -9.0006, G 0.0028)] [G loss: 8.1285]\n",
      "4839 (5, 1) [D loss: (-0.3937)(R 6.1961, F -6.6123, G 0.0022)] [G loss: 5.4181]\n",
      "4840 (5, 1) [D loss: (-0.5204)(R 3.8685, F -4.4139, G 0.0025)] [G loss: 3.9742]\n",
      "4841 (5, 1) [D loss: (-0.8870)(R 1.1979, F -2.1105, G 0.0026)] [G loss: 1.1636]\n",
      "4842 (5, 1) [D loss: (-1.2724)(R -1.9556, F 0.6571, G 0.0026)] [G loss: -1.4470]\n",
      "4843 (5, 1) [D loss: (-1.2644)(R -4.9769, F 3.6778, G 0.0035)] [G loss: -3.9459]\n",
      "4844 (5, 1) [D loss: (-1.3580)(R -7.3005, F 5.8778, G 0.0065)] [G loss: -6.1818]\n",
      "4845 (5, 1) [D loss: (-1.7889)(R -9.6819, F 7.8092, G 0.0084)] [G loss: -8.0624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4846 (5, 1) [D loss: (-1.2012)(R -11.5157, F 10.2088, G 0.0106)] [G loss: -9.7598]\n",
      "4847 (5, 1) [D loss: (-1.3687)(R -11.9013, F 10.4415, G 0.0091)] [G loss: -10.1465]\n",
      "4848 (5, 1) [D loss: (-2.0317)(R -13.5465, F 11.4256, G 0.0089)] [G loss: -11.9819]\n",
      "4849 (5, 1) [D loss: (-1.4577)(R -13.2770, F 11.7210, G 0.0098)] [G loss: -11.4715]\n",
      "4850 (5, 1) [D loss: (-2.0024)(R -13.4032, F 11.3179, G 0.0083)] [G loss: -11.7202]\n",
      "4851 (5, 1) [D loss: (-1.6880)(R -13.3798, F 11.5917, G 0.0100)] [G loss: -12.3730]\n",
      "4852 (5, 1) [D loss: (-2.1666)(R -15.2895, F 12.9974, G 0.0125)] [G loss: -13.8658]\n",
      "4853 (5, 1) [D loss: (-1.9643)(R -16.1530, F 14.0130, G 0.0176)] [G loss: -14.3998]\n",
      "4854 (5, 1) [D loss: (-2.9321)(R -18.0506, F 14.8942, G 0.0224)] [G loss: -16.9488]\n",
      "4855 (5, 1) [D loss: (-3.2576)(R -21.3225, F 17.7465, G 0.0318)] [G loss: -20.0888]\n",
      "4856 (5, 1) [D loss: (-2.5827)(R -22.4295, F 19.4742, G 0.0373)] [G loss: -20.9899]\n",
      "4857 (5, 1) [D loss: (-2.7182)(R -22.3674, F 19.3636, G 0.0286)] [G loss: -21.2676]\n",
      "4858 (5, 1) [D loss: (-2.4526)(R -23.8606, F 21.0553, G 0.0353)] [G loss: -23.5791]\n",
      "4859 (5, 1) [D loss: (-4.0304)(R -25.2150, F 20.8251, G 0.0360)] [G loss: -24.9725]\n",
      "4860 (5, 1) [D loss: (-3.1497)(R -24.7544, F 21.3495, G 0.0255)] [G loss: -23.7798]\n",
      "4861 (5, 1) [D loss: (-2.2392)(R -23.9682, F 21.4981, G 0.0231)] [G loss: -22.8506]\n",
      "4862 (5, 1) [D loss: (-1.4740)(R -20.8674, F 19.3014, G 0.0092)] [G loss: -20.3832]\n",
      "4863 (5, 1) [D loss: (-1.5086)(R -18.5563, F 17.0048, G 0.0043)] [G loss: -18.3408]\n",
      "4864 (5, 1) [D loss: (-1.3826)(R -17.5877, F 16.1673, G 0.0038)] [G loss: -17.0955]\n",
      "4865 (5, 1) [D loss: (-1.5023)(R -16.5444, F 14.9933, G 0.0049)] [G loss: -16.3188]\n",
      "4866 (5, 1) [D loss: (-1.1951)(R -15.6080, F 14.3857, G 0.0027)] [G loss: -14.9460]\n",
      "4867 (5, 1) [D loss: (-0.4386)(R -13.1331, F 12.6686, G 0.0026)] [G loss: -13.0116]\n",
      "4868 (5, 1) [D loss: (-0.8965)(R -12.0507, F 11.1235, G 0.0031)] [G loss: -11.2351]\n",
      "4869 (5, 1) [D loss: (-0.3923)(R -9.1011, F 8.6798, G 0.0029)] [G loss: -8.3937]\n",
      "4870 (5, 1) [D loss: (-0.6316)(R -6.8785, F 6.2138, G 0.0033)] [G loss: -5.7406]\n",
      "4871 (5, 1) [D loss: (-0.7572)(R -3.9108, F 3.1113, G 0.0042)] [G loss: -2.3845]\n",
      "4872 (5, 1) [D loss: (-0.7878)(R -1.0457, F 0.2166, G 0.0041)] [G loss: 0.2523]\n",
      "4873 (5, 1) [D loss: (-0.9939)(R 0.7248, F -1.7747, G 0.0056)] [G loss: 2.1304]\n",
      "4874 (5, 1) [D loss: (-1.0131)(R 1.7569, F -2.8297, G 0.0060)] [G loss: 2.9144]\n",
      "4875 (5, 1) [D loss: (-0.9123)(R 2.1518, F -3.1070, G 0.0043)] [G loss: 3.3498]\n",
      "4876 (5, 1) [D loss: (-0.9468)(R 2.7857, F -3.7897, G 0.0057)] [G loss: 3.6097]\n",
      "4877 (5, 1) [D loss: (-0.9778)(R 2.6857, F -3.7072, G 0.0044)] [G loss: 3.8446]\n",
      "4878 (5, 1) [D loss: (-1.4060)(R 2.5731, F -4.0373, G 0.0058)] [G loss: 4.0410]\n",
      "4879 (5, 1) [D loss: (-1.6019)(R 2.8872, F -4.5468, G 0.0058)] [G loss: 4.7494]\n",
      "4880 (5, 1) [D loss: (-1.4469)(R 3.7880, F -5.2980, G 0.0063)] [G loss: 5.3370]\n",
      "4881 (5, 1) [D loss: (-1.6985)(R 5.9279, F -7.7196, G 0.0093)] [G loss: 8.0249]\n",
      "4882 (5, 1) [D loss: (-2.0861)(R 8.6128, F -10.8436, G 0.0145)] [G loss: 10.9493]\n",
      "4883 (5, 1) [D loss: (-1.8775)(R 11.6968, F -13.7832, G 0.0209)] [G loss: 14.2609]\n",
      "4884 (5, 1) [D loss: (-1.8440)(R 13.3777, F -15.4064, G 0.0185)] [G loss: 14.8504]\n",
      "4885 (5, 1) [D loss: (-1.7692)(R 13.7002, F -15.6440, G 0.0175)] [G loss: 14.4104]\n",
      "4886 (5, 1) [D loss: (-1.7207)(R 13.3029, F -15.1491, G 0.0125)] [G loss: 13.9813]\n",
      "4887 (5, 1) [D loss: (-2.0441)(R 11.7672, F -13.8825, G 0.0071)] [G loss: 12.8833]\n",
      "4888 (5, 1) [D loss: (-1.9007)(R 9.8883, F -11.8323, G 0.0043)] [G loss: 10.7090]\n",
      "4889 (5, 1) [D loss: (-1.4135)(R 8.3913, F -9.8391, G 0.0034)] [G loss: 8.9000]\n",
      "4890 (5, 1) [D loss: (-1.2514)(R 6.8430, F -8.1259, G 0.0031)] [G loss: 7.2186]\n",
      "4891 (5, 1) [D loss: (-1.5226)(R 5.5657, F -7.1274, G 0.0039)] [G loss: 6.4519]\n",
      "4892 (5, 1) [D loss: (-1.6002)(R 4.9720, F -6.6184, G 0.0046)] [G loss: 5.7792]\n",
      "4893 (5, 1) [D loss: (-1.1656)(R 4.6962, F -5.9171, G 0.0055)] [G loss: 5.6351]\n",
      "4894 (5, 1) [D loss: (-0.9499)(R 5.8100, F -6.8319, G 0.0072)] [G loss: 6.3769]\n",
      "4895 (5, 1) [D loss: (-1.0619)(R 6.7987, F -7.9138, G 0.0053)] [G loss: 7.2129]\n",
      "4896 (5, 1) [D loss: (-0.9089)(R 7.9677, F -8.9488, G 0.0072)] [G loss: 8.4339]\n",
      "4897 (5, 1) [D loss: (-0.8570)(R 9.1583, F -10.0942, G 0.0079)] [G loss: 9.7820]\n",
      "4898 (5, 1) [D loss: (-0.7300)(R 9.7707, F -10.5721, G 0.0071)] [G loss: 10.0019]\n",
      "4899 (5, 1) [D loss: (-0.6845)(R 9.2610, F -9.9826, G 0.0037)] [G loss: 9.1724]\n",
      "4900 (5, 1) [D loss: (-1.8120)(R 7.9758, F -9.8295, G 0.0042)] [G loss: 9.1357]\n",
      "4901 (5, 1) [D loss: (-1.1981)(R 8.1132, F -9.3611, G 0.0050)] [G loss: 8.7850]\n",
      "4902 (5, 1) [D loss: (-1.0695)(R 7.2418, F -8.3514, G 0.0040)] [G loss: 7.8168]\n",
      "4903 (5, 1) [D loss: (-1.3681)(R 5.4453, F -6.8516, G 0.0038)] [G loss: 6.1377]\n",
      "4904 (5, 1) [D loss: (-1.1850)(R 3.3535, F -4.5707, G 0.0032)] [G loss: 3.8520]\n",
      "4905 (5, 1) [D loss: (-1.0760)(R 0.4253, F -1.5269, G 0.0026)] [G loss: 1.2965]\n",
      "4906 (5, 1) [D loss: (-1.0496)(R -1.0220, F -0.0579, G 0.0030)] [G loss: -0.1376]\n",
      "4907 (5, 1) [D loss: (-1.0253)(R -3.0415, F 1.9858, G 0.0030)] [G loss: -2.4848]\n",
      "4908 (5, 1) [D loss: (-0.4523)(R -3.8046, F 3.3252, G 0.0027)] [G loss: -3.3344]\n",
      "4909 (5, 1) [D loss: (-0.4074)(R -5.1247, F 4.6832, G 0.0034)] [G loss: -4.5771]\n",
      "4910 (5, 1) [D loss: (-1.0037)(R -5.9296, F 4.8966, G 0.0029)] [G loss: -5.0742]\n",
      "4911 (5, 1) [D loss: (-0.9866)(R -7.4097, F 6.3684, G 0.0055)] [G loss: -6.2047]\n",
      "4912 (5, 1) [D loss: (-1.3604)(R -8.5786, F 7.1550, G 0.0063)] [G loss: -7.1738]\n",
      "4913 (5, 1) [D loss: (-1.7310)(R -9.9232, F 8.1152, G 0.0077)] [G loss: -8.6432]\n",
      "4914 (5, 1) [D loss: (-1.9162)(R -12.8506, F 10.8246, G 0.0110)] [G loss: -11.5821]\n",
      "4915 (5, 1) [D loss: (-1.7633)(R -15.2986, F 13.3920, G 0.0143)] [G loss: -13.6214]\n",
      "4916 (5, 1) [D loss: (-2.4190)(R -17.2768, F 14.6741, G 0.0184)] [G loss: -16.1012]\n",
      "4917 (5, 1) [D loss: (-2.3205)(R -19.5530, F 16.9901, G 0.0242)] [G loss: -18.4602]\n",
      "4918 (5, 1) [D loss: (-2.2777)(R -20.2529, F 17.7724, G 0.0203)] [G loss: -18.9652]\n",
      "4919 (5, 1) [D loss: (-2.0802)(R -19.4238, F 17.2020, G 0.0142)] [G loss: -18.5383]\n",
      "4920 (5, 1) [D loss: (-2.0504)(R -18.3596, F 16.1924, G 0.0117)] [G loss: -18.2470]\n",
      "4921 (5, 1) [D loss: (-1.5289)(R -16.4968, F 14.8951, G 0.0073)] [G loss: -15.8089]\n",
      "4922 (5, 1) [D loss: (-1.4497)(R -16.8407, F 15.2811, G 0.0110)] [G loss: -16.4294]\n",
      "4923 (5, 1) [D loss: (-1.5654)(R -15.6479, F 13.9882, G 0.0094)] [G loss: -14.5879]\n",
      "4924 (5, 1) [D loss: (-1.3162)(R -12.7735, F 11.3884, G 0.0069)] [G loss: -12.0675]\n",
      "4925 (5, 1) [D loss: (-1.5642)(R -12.1338, F 10.4674, G 0.0102)] [G loss: -10.9357]\n",
      "4926 (5, 1) [D loss: (-1.5691)(R -10.4930, F 8.8356, G 0.0088)] [G loss: -9.6929]\n",
      "4927 (5, 1) [D loss: (-1.2451)(R -10.7195, F 9.3957, G 0.0079)] [G loss: -9.6081]\n",
      "4928 (5, 1) [D loss: (-1.3998)(R -10.7905, F 9.3275, G 0.0063)] [G loss: -9.4362]\n",
      "4929 (5, 1) [D loss: (-0.6655)(R -9.7198, F 9.0003, G 0.0054)] [G loss: -8.9726]\n",
      "4930 (5, 1) [D loss: (-1.0373)(R -9.6375, F 8.5588, G 0.0041)] [G loss: -9.4232]\n",
      "4931 (5, 1) [D loss: (-0.8443)(R -8.9994, F 8.1174, G 0.0038)] [G loss: -8.4879]\n",
      "4932 (5, 1) [D loss: (-1.0760)(R -7.9474, F 6.8319, G 0.0039)] [G loss: -7.1504]\n",
      "4933 (5, 1) [D loss: (-1.1217)(R -5.8352, F 4.6859, G 0.0028)] [G loss: -4.6154]\n",
      "4934 (5, 1) [D loss: (-0.8216)(R -3.8483, F 2.9833, G 0.0043)] [G loss: -2.5656]\n",
      "4935 (5, 1) [D loss: (-1.3064)(R -1.7743, F 0.4186, G 0.0049)] [G loss: -0.5669]\n",
      "4936 (5, 1) [D loss: (-1.0313)(R -0.1403, F -0.9471, G 0.0056)] [G loss: 1.5649]\n",
      "4937 (5, 1) [D loss: (-1.2176)(R 1.7484, F -3.0160, G 0.0050)] [G loss: 3.6480]\n",
      "4938 (5, 1) [D loss: (-1.0742)(R 2.4398, F -3.5729, G 0.0059)] [G loss: 3.4813]\n",
      "4939 (5, 1) [D loss: (-1.1338)(R 1.9551, F -3.1437, G 0.0055)] [G loss: 3.3802]\n",
      "4940 (5, 1) [D loss: (-1.0818)(R 2.3701, F -3.4996, G 0.0048)] [G loss: 3.7162]\n",
      "4941 (5, 1) [D loss: (-1.0191)(R 2.4515, F -3.5294, G 0.0059)] [G loss: 3.7844]\n",
      "4942 (5, 1) [D loss: (-1.3763)(R 1.9841, F -3.4244, G 0.0064)] [G loss: 3.6953]\n",
      "4943 (5, 1) [D loss: (-1.4561)(R 2.5889, F -4.0966, G 0.0052)] [G loss: 4.2729]\n",
      "4944 (5, 1) [D loss: (-1.1754)(R 3.8179, F -5.0449, G 0.0052)] [G loss: 5.3437]\n",
      "4945 (5, 1) [D loss: (-1.9925)(R 5.1495, F -7.2193, G 0.0077)] [G loss: 7.1557]\n",
      "4946 (5, 1) [D loss: (-1.6898)(R 7.9888, F -9.7838, G 0.0105)] [G loss: 9.9265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4947 (5, 1) [D loss: (-1.7719)(R 10.2821, F -12.2038, G 0.0150)] [G loss: 11.7427]\n",
      "4948 (5, 1) [D loss: (-1.8888)(R 12.6303, F -14.7010, G 0.0182)] [G loss: 14.6299]\n",
      "4949 (5, 1) [D loss: (-1.7567)(R 13.2843, F -15.2116, G 0.0171)] [G loss: 14.2812]\n",
      "4950 (5, 1) [D loss: (-1.2015)(R 13.7576, F -15.1075, G 0.0148)] [G loss: 14.3046]\n",
      "4951 (5, 1) [D loss: (-1.4542)(R 12.8649, F -14.4217, G 0.0103)] [G loss: 13.4021]\n",
      "4952 (5, 1) [D loss: (-0.9233)(R 11.4453, F -12.4189, G 0.0050)] [G loss: 11.1386]\n",
      "4953 (5, 1) [D loss: (-1.5592)(R 9.0075, F -10.6004, G 0.0034)] [G loss: 9.7687]\n",
      "4954 (5, 1) [D loss: (-1.7193)(R 7.5043, F -9.2523, G 0.0029)] [G loss: 7.9320]\n",
      "4955 (5, 1) [D loss: (-1.6394)(R 6.7408, F -8.4100, G 0.0030)] [G loss: 7.4885]\n",
      "4956 (5, 1) [D loss: (-1.5720)(R 6.0144, F -7.6181, G 0.0032)] [G loss: 6.8161]\n",
      "4957 (5, 1) [D loss: (-1.8151)(R 6.3192, F -8.1856, G 0.0051)] [G loss: 6.8205]\n",
      "4958 (5, 1) [D loss: (-1.5648)(R 7.1571, F -8.7849, G 0.0063)] [G loss: 8.3642]\n",
      "4959 (5, 1) [D loss: (-1.8596)(R 8.6097, F -10.5687, G 0.0099)] [G loss: 9.8453]\n",
      "4960 (5, 1) [D loss: (-1.5086)(R 10.3782, F -11.9931, G 0.0106)] [G loss: 11.2342]\n",
      "4961 (5, 1) [D loss: (-2.3608)(R 12.5858, F -15.1112, G 0.0165)] [G loss: 13.6601]\n",
      "4962 (5, 1) [D loss: (-2.5978)(R 14.8636, F -17.6842, G 0.0223)] [G loss: 15.6448]\n",
      "4963 (5, 1) [D loss: (-1.8340)(R 16.9774, F -19.0459, G 0.0234)] [G loss: 16.5909]\n",
      "4964 (5, 1) [D loss: (-1.6471)(R 16.7117, F -18.5500, G 0.0191)] [G loss: 15.9173]\n",
      "4965 (5, 1) [D loss: (-2.2778)(R 14.5556, F -16.9284, G 0.0095)] [G loss: 14.6818]\n",
      "4966 (5, 1) [D loss: (-1.9329)(R 12.7881, F -14.7673, G 0.0046)] [G loss: 12.8153]\n",
      "4967 (5, 1) [D loss: (-0.5389)(R 11.2025, F -11.7608, G 0.0019)] [G loss: 10.4401]\n",
      "4968 (5, 1) [D loss: (-0.4262)(R 8.4986, F -8.9423, G 0.0018)] [G loss: 8.0463]\n",
      "4969 (5, 1) [D loss: (-0.7780)(R 7.0576, F -7.8558, G 0.0020)] [G loss: 7.0890]\n",
      "4970 (5, 1) [D loss: (-1.1172)(R 5.1893, F -6.3272, G 0.0021)] [G loss: 5.4133]\n",
      "4971 (5, 1) [D loss: (-1.0631)(R 3.8262, F -4.9079, G 0.0019)] [G loss: 3.9367]\n",
      "4972 (5, 1) [D loss: (-1.2048)(R 2.2602, F -3.4910, G 0.0026)] [G loss: 2.9171]\n",
      "4973 (5, 1) [D loss: (-1.5292)(R 1.4812, F -3.0435, G 0.0033)] [G loss: 2.5921]\n",
      "4974 (5, 1) [D loss: (-0.8347)(R 1.4766, F -2.3515, G 0.0040)] [G loss: 1.8400]\n",
      "4975 (5, 1) [D loss: (-0.7267)(R 0.0662, F -0.8363, G 0.0043)] [G loss: 0.5454]\n",
      "4976 (5, 1) [D loss: (-1.1526)(R -2.5383, F 1.3423, G 0.0043)] [G loss: -1.4063]\n",
      "4977 (5, 1) [D loss: (-1.3391)(R -5.0130, F 3.6258, G 0.0048)] [G loss: -4.0010]\n",
      "4978 (5, 1) [D loss: (-1.7620)(R -8.9848, F 7.1469, G 0.0076)] [G loss: -8.0216]\n",
      "4979 (5, 1) [D loss: (-1.9289)(R -13.9805, F 11.9094, G 0.0142)] [G loss: -12.6695]\n",
      "4980 (5, 1) [D loss: (-2.1520)(R -17.3779, F 15.0286, G 0.0197)] [G loss: -15.7181]\n",
      "4981 (5, 1) [D loss: (-2.4637)(R -20.0021, F 17.3517, G 0.0187)] [G loss: -17.7236]\n",
      "4982 (5, 1) [D loss: (-2.5509)(R -20.9923, F 18.2438, G 0.0198)] [G loss: -19.4253]\n",
      "4983 (5, 1) [D loss: (-2.5491)(R -21.1640, F 18.4774, G 0.0137)] [G loss: -18.7847]\n",
      "4984 (5, 1) [D loss: (-1.1518)(R -20.1747, F 18.8977, G 0.0125)] [G loss: -18.3359]\n",
      "4985 (5, 1) [D loss: (-2.7190)(R -19.4022, F 16.5843, G 0.0099)] [G loss: -17.4972]\n",
      "4986 (5, 1) [D loss: (-3.2388)(R -21.5437, F 18.1002, G 0.0205)] [G loss: -19.5259]\n",
      "4987 (5, 1) [D loss: (-2.6186)(R -22.3319, F 19.4583, G 0.0255)] [G loss: -20.9821]\n",
      "4988 (5, 1) [D loss: (-2.3986)(R -22.3202, F 19.6571, G 0.0264)] [G loss: -20.1644]\n",
      "4989 (5, 1) [D loss: (-2.6855)(R -23.5898, F 20.5560, G 0.0348)] [G loss: -23.1969]\n",
      "4990 (5, 1) [D loss: (-3.3689)(R -24.9001, F 21.1395, G 0.0392)] [G loss: -24.6745]\n",
      "4991 (5, 1) [D loss: (-3.1823)(R -24.6676, F 21.1706, G 0.0315)] [G loss: -24.0017]\n",
      "4992 (5, 1) [D loss: (-2.5388)(R -23.7038, F 20.8894, G 0.0276)] [G loss: -23.4503]\n",
      "4993 (5, 1) [D loss: (-2.6281)(R -22.9321, F 20.1063, G 0.0198)] [G loss: -23.5338]\n",
      "4994 (5, 1) [D loss: (-1.7703)(R -23.5718, F 21.6098, G 0.0192)] [G loss: -24.0238]\n",
      "4995 (5, 1) [D loss: (-1.9885)(R -22.8580, F 20.7288, G 0.0141)] [G loss: -22.8926]\n",
      "4996 (5, 1) [D loss: (-1.3730)(R -21.1401, F 19.6921, G 0.0075)] [G loss: -21.0930]\n",
      "4997 (5, 1) [D loss: (-1.4521)(R -19.1698, F 17.6844, G 0.0033)] [G loss: -18.7285]\n",
      "4998 (5, 1) [D loss: (-1.1251)(R -17.8540, F 16.6893, G 0.0040)] [G loss: -17.5147]\n",
      "4999 (5, 1) [D loss: (-1.0213)(R -15.1964, F 14.1490, G 0.0026)] [G loss: -14.4751]\n",
      "5000 (5, 1) [D loss: (-1.1124)(R -14.0749, F 12.9350, G 0.0028)] [G loss: -13.3753]\n",
      "5001 (5, 1) [D loss: (-0.8839)(R -12.1600, F 11.2464, G 0.0030)] [G loss: -11.8655]\n",
      "5002 (5, 1) [D loss: (-0.9941)(R -10.5131, F 9.4901, G 0.0029)] [G loss: -9.5557]\n",
      "5003 (5, 1) [D loss: (-0.7486)(R -9.1667, F 8.3852, G 0.0033)] [G loss: -7.9822]\n",
      "5004 (5, 1) [D loss: (-0.4124)(R -6.6778, F 6.2306, G 0.0035)] [G loss: -5.8653]\n",
      "5005 (5, 1) [D loss: (-0.8244)(R -3.9448, F 3.0821, G 0.0038)] [G loss: -2.4887]\n",
      "5006 (5, 1) [D loss: (-0.8648)(R -1.2517, F 0.3439, G 0.0043)] [G loss: 0.1881]\n",
      "5007 (5, 1) [D loss: (-1.1681)(R 1.2327, F -2.4524, G 0.0052)] [G loss: 2.7769]\n",
      "5008 (5, 1) [D loss: (-1.2206)(R 4.4902, F -5.7661, G 0.0055)] [G loss: 6.3532]\n",
      "5009 (5, 1) [D loss: (-1.4009)(R 6.6526, F -8.1263, G 0.0073)] [G loss: 8.7694]\n",
      "5010 (5, 1) [D loss: (-1.7747)(R 8.8235, F -10.6825, G 0.0084)] [G loss: 10.7414]\n",
      "5011 (5, 1) [D loss: (-2.2530)(R 10.4229, F -12.7918, G 0.0116)] [G loss: 13.0788]\n",
      "5012 (5, 1) [D loss: (-1.9307)(R 12.8151, F -14.8593, G 0.0114)] [G loss: 14.3979]\n",
      "5013 (5, 1) [D loss: (-2.2233)(R 13.1530, F -15.5043, G 0.0128)] [G loss: 14.6915]\n",
      "5014 (5, 1) [D loss: (-2.7566)(R 14.0361, F -16.9336, G 0.0141)] [G loss: 16.4898]\n",
      "5015 (5, 1) [D loss: (-2.3347)(R 14.9951, F -17.5105, G 0.0181)] [G loss: 16.3210]\n",
      "5016 (5, 1) [D loss: (-2.7666)(R 16.8479, F -19.8684, G 0.0254)] [G loss: 18.3032]\n",
      "5017 (5, 1) [D loss: (-3.5416)(R 17.1507, F -20.9389, G 0.0247)] [G loss: 18.5870]\n",
      "5018 (5, 1) [D loss: (-2.8175)(R 18.7994, F -21.9654, G 0.0348)] [G loss: 19.1770]\n",
      "5019 (5, 1) [D loss: (-3.2705)(R 19.0666, F -22.7108, G 0.0374)] [G loss: 19.6711]\n",
      "5020 (5, 1) [D loss: (-3.2717)(R 18.8560, F -22.4127, G 0.0285)] [G loss: 19.0167]\n",
      "5021 (5, 1) [D loss: (-2.9383)(R 18.1406, F -21.3606, G 0.0282)] [G loss: 18.4395]\n",
      "5022 (5, 1) [D loss: (-2.5577)(R 16.4609, F -19.1642, G 0.0146)] [G loss: 16.6805]\n",
      "5023 (5, 1) [D loss: (-2.8540)(R 15.3240, F -18.2851, G 0.0107)] [G loss: 15.5224]\n",
      "5024 (5, 1) [D loss: (-2.7249)(R 14.0663, F -16.8757, G 0.0085)] [G loss: 14.1591]\n",
      "5025 (5, 1) [D loss: (-2.2338)(R 13.6525, F -15.9397, G 0.0053)] [G loss: 13.5258]\n",
      "5026 (5, 1) [D loss: (-3.1211)(R 13.9986, F -17.2133, G 0.0094)] [G loss: 14.3020]\n",
      "5027 (5, 1) [D loss: (-1.3179)(R 15.8265, F -17.2722, G 0.0128)] [G loss: 14.6621]\n",
      "5028 (5, 1) [D loss: (-2.4495)(R 15.0677, F -17.6236, G 0.0106)] [G loss: 14.8467]\n",
      "5029 (5, 1) [D loss: (-1.8729)(R 15.8322, F -17.8124, G 0.0107)] [G loss: 15.0187]\n",
      "5030 (5, 1) [D loss: (-2.1309)(R 15.5669, F -17.8095, G 0.0112)] [G loss: 15.0472]\n",
      "5031 (5, 1) [D loss: (-2.4212)(R 16.1377, F -18.6914, G 0.0132)] [G loss: 15.5051]\n",
      "5032 (5, 1) [D loss: (-2.6927)(R 16.4624, F -19.3216, G 0.0166)] [G loss: 16.3847]\n",
      "5033 (5, 1) [D loss: (-2.2801)(R 17.6251, F -20.1137, G 0.0208)] [G loss: 16.2016]\n",
      "5034 (5, 1) [D loss: (-2.4996)(R 16.4739, F -19.1165, G 0.0143)] [G loss: 15.3087]\n",
      "5035 (5, 1) [D loss: (-0.9719)(R 16.0300, F -17.1041, G 0.0102)] [G loss: 13.9657]\n",
      "5036 (5, 1) [D loss: (-1.6328)(R 13.6618, F -15.3388, G 0.0044)] [G loss: 12.2739]\n",
      "5037 (5, 1) [D loss: (-1.4959)(R 12.0522, F -13.5811, G 0.0033)] [G loss: 10.7851]\n",
      "5038 (5, 1) [D loss: (-1.1578)(R 10.4466, F -11.6285, G 0.0024)] [G loss: 9.4437]\n",
      "5039 (5, 1) [D loss: (-1.0212)(R 8.9100, F -9.9640, G 0.0033)] [G loss: 8.2584]\n",
      "5040 (5, 1) [D loss: (-0.8348)(R 5.5844, F -6.4641, G 0.0045)] [G loss: 4.8638]\n",
      "5041 (5, 1) [D loss: (-0.7937)(R 3.6146, F -4.4447, G 0.0037)] [G loss: 3.4902]\n",
      "5042 (5, 1) [D loss: (-1.1018)(R 1.1988, F -2.3361, G 0.0035)] [G loss: 1.5944]\n",
      "5043 (5, 1) [D loss: (-1.4919)(R -2.1018, F 0.5857, G 0.0024)] [G loss: -0.5975]\n",
      "5044 (5, 1) [D loss: (-1.7861)(R -3.2622, F 1.4336, G 0.0043)] [G loss: -1.5768]\n",
      "5045 (5, 1) [D loss: (-1.5807)(R -4.5021, F 2.8506, G 0.0071)] [G loss: -2.7739]\n",
      "5046 (5, 1) [D loss: (-1.0488)(R -5.8775, F 4.7492, G 0.0080)] [G loss: -4.2541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5047 (5, 1) [D loss: (-1.8248)(R -7.1853, F 5.2519, G 0.0109)] [G loss: -5.2712]\n",
      "5048 (5, 1) [D loss: (-2.1433)(R -8.9506, F 6.7058, G 0.0102)] [G loss: -6.6053]\n",
      "5049 (5, 1) [D loss: (-2.4618)(R -10.9118, F 8.3123, G 0.0138)] [G loss: -8.5900]\n",
      "5050 (5, 1) [D loss: (-1.7963)(R -11.6691, F 9.7115, G 0.0161)] [G loss: -10.0942]\n",
      "5051 (5, 1) [D loss: (-1.3982)(R -12.6180, F 11.0916, G 0.0128)] [G loss: -10.0330]\n",
      "5052 (5, 1) [D loss: (-1.9288)(R -13.3086, F 11.2384, G 0.0141)] [G loss: -11.5235]\n",
      "5053 (5, 1) [D loss: (-2.1010)(R -13.9030, F 11.6684, G 0.0134)] [G loss: -11.7340]\n",
      "5054 (5, 1) [D loss: (-2.8174)(R -14.6668, F 11.6743, G 0.0175)] [G loss: -12.7531]\n",
      "5055 (5, 1) [D loss: (-2.3869)(R -15.0490, F 12.4638, G 0.0198)] [G loss: -13.1049]\n",
      "5056 (5, 1) [D loss: (-1.9951)(R -14.3823, F 12.2124, G 0.0175)] [G loss: -12.6032]\n",
      "5057 (5, 1) [D loss: (-3.6570)(R -15.4842, F 11.6019, G 0.0225)] [G loss: -13.2526]\n",
      "5058 (5, 1) [D loss: (-2.6247)(R -15.1272, F 12.2218, G 0.0281)] [G loss: -13.6523]\n",
      "5059 (5, 1) [D loss: (-3.1636)(R -16.2580, F 12.7353, G 0.0359)] [G loss: -14.9276]\n",
      "5060 (5, 1) [D loss: (-3.2778)(R -16.9246, F 13.3074, G 0.0339)] [G loss: -15.9243]\n",
      "5061 (5, 1) [D loss: (-4.2037)(R -17.5746, F 13.0500, G 0.0321)] [G loss: -16.6871]\n",
      "5062 (5, 1) [D loss: (-3.7580)(R -18.5965, F 14.5198, G 0.0319)] [G loss: -18.3311]\n",
      "5063 (5, 1) [D loss: (-3.4901)(R -19.4130, F 15.5946, G 0.0328)] [G loss: -18.6972]\n",
      "5064 (5, 1) [D loss: (-2.7933)(R -20.2742, F 17.1722, G 0.0309)] [G loss: -19.7532]\n",
      "5065 (5, 1) [D loss: (-3.5356)(R -20.7538, F 16.9148, G 0.0303)] [G loss: -20.3041]\n",
      "5066 (5, 1) [D loss: (-2.9110)(R -19.8259, F 16.6462, G 0.0269)] [G loss: -20.0763]\n",
      "5067 (5, 1) [D loss: (-2.6418)(R -19.4528, F 16.6280, G 0.0183)] [G loss: -19.4377]\n",
      "5068 (5, 1) [D loss: (-1.1889)(R -18.7145, F 17.3629, G 0.0163)] [G loss: -18.3909]\n",
      "5069 (5, 1) [D loss: (-2.1016)(R -16.8310, F 14.6626, G 0.0067)] [G loss: -16.3573]\n",
      "5070 (5, 1) [D loss: (-0.9152)(R -16.0155, F 15.0166, G 0.0084)] [G loss: -15.9101]\n",
      "5071 (5, 1) [D loss: (-1.3609)(R -14.0636, F 12.6729, G 0.0030)] [G loss: -14.0282]\n",
      "5072 (5, 1) [D loss: (-0.9244)(R -13.4221, F 12.4606, G 0.0037)] [G loss: -13.4762]\n",
      "5073 (5, 1) [D loss: (-0.7234)(R -11.7528, F 10.9987, G 0.0031)] [G loss: -12.0508]\n",
      "5074 (5, 1) [D loss: (-1.0625)(R -9.7205, F 8.6393, G 0.0019)] [G loss: -8.9207]\n",
      "5075 (5, 1) [D loss: (-0.8170)(R -6.6777, F 5.8418, G 0.0019)] [G loss: -5.9984]\n",
      "5076 (5, 1) [D loss: (-0.9766)(R -3.5769, F 2.5790, G 0.0021)] [G loss: -2.2365]\n",
      "5077 (5, 1) [D loss: (-0.9522)(R 0.7695, F -1.7396, G 0.0018)] [G loss: 2.2497]\n",
      "5078 (5, 1) [D loss: (-1.2042)(R 3.8435, F -5.0792, G 0.0032)] [G loss: 5.5405]\n",
      "5079 (5, 1) [D loss: (-0.9602)(R 7.0400, F -8.0242, G 0.0024)] [G loss: 8.9759]\n",
      "5080 (5, 1) [D loss: (-0.8113)(R 8.5789, F -9.4289, G 0.0039)] [G loss: 9.8738]\n",
      "5081 (5, 1) [D loss: (-0.7482)(R 8.9847, F -9.7685, G 0.0036)] [G loss: 9.8642]\n",
      "5082 (5, 1) [D loss: (-0.9204)(R 8.6387, F -9.5955, G 0.0036)] [G loss: 9.7083]\n",
      "5083 (5, 1) [D loss: (-1.5595)(R 8.5336, F -10.1281, G 0.0035)] [G loss: 10.0346]\n",
      "5084 (5, 1) [D loss: (-1.2929)(R 10.9409, F -12.2852, G 0.0051)] [G loss: 12.8187]\n",
      "5085 (5, 1) [D loss: (-1.7520)(R 14.7705, F -16.6017, G 0.0079)] [G loss: 16.6780]\n",
      "5086 (5, 1) [D loss: (-2.0729)(R 18.3224, F -20.5578, G 0.0163)] [G loss: 20.4769]\n",
      "5087 (5, 1) [D loss: (-2.1651)(R 22.4555, F -24.8924, G 0.0272)] [G loss: 23.8937]\n",
      "5088 (5, 1) [D loss: (-2.9172)(R 22.4882, F -25.6891, G 0.0284)] [G loss: 24.4453]\n",
      "5089 (5, 1) [D loss: (-2.6699)(R 21.5920, F -24.4733, G 0.0211)] [G loss: 22.2913]\n",
      "5090 (5, 1) [D loss: (-1.3515)(R 19.7696, F -21.2525, G 0.0131)] [G loss: 19.9498]\n",
      "5091 (5, 1) [D loss: (-1.5702)(R 17.0105, F -18.6450, G 0.0064)] [G loss: 17.0379]\n",
      "5092 (5, 1) [D loss: (-2.2827)(R 14.0384, F -16.3564, G 0.0035)] [G loss: 15.0178]\n",
      "5093 (5, 1) [D loss: (-2.2067)(R 12.8091, F -15.0511, G 0.0035)] [G loss: 13.6940]\n",
      "5094 (5, 1) [D loss: (-2.5652)(R 12.4519, F -15.0737, G 0.0057)] [G loss: 13.7624]\n",
      "5095 (5, 1) [D loss: (-2.1961)(R 14.9647, F -17.2886, G 0.0128)] [G loss: 16.1986]\n",
      "5096 (5, 1) [D loss: (-2.8606)(R 15.9810, F -19.0109, G 0.0169)] [G loss: 17.0415]\n",
      "5097 (5, 1) [D loss: (-2.6650)(R 16.9854, F -19.8550, G 0.0205)] [G loss: 17.4754]\n",
      "5098 (5, 1) [D loss: (-1.9220)(R 17.4446, F -19.5322, G 0.0166)] [G loss: 17.6339]\n",
      "5099 (5, 1) [D loss: (-1.8837)(R 17.0570, F -19.0767, G 0.0136)] [G loss: 17.1990]\n",
      "5100 (5, 1) [D loss: (-2.3844)(R 15.5069, F -17.9773, G 0.0086)] [G loss: 16.2435]\n",
      "5101 (5, 1) [D loss: (-1.3602)(R 14.0648, F -15.4861, G 0.0061)] [G loss: 14.2587]\n",
      "5102 (5, 1) [D loss: (-1.7932)(R 10.8162, F -12.6346, G 0.0025)] [G loss: 11.2383]\n",
      "5103 (5, 1) [D loss: (-1.6338)(R 7.6049, F -9.2610, G 0.0022)] [G loss: 8.7834]\n",
      "5104 (5, 1) [D loss: (-1.9328)(R 5.4416, F -7.4071, G 0.0033)] [G loss: 6.5722]\n",
      "5105 (5, 1) [D loss: (-0.9702)(R 4.8636, F -5.8666, G 0.0033)] [G loss: 5.8367]\n",
      "5106 (5, 1) [D loss: (-0.8561)(R 4.9763, F -5.8714, G 0.0039)] [G loss: 5.9679]\n",
      "5107 (5, 1) [D loss: (-1.1668)(R 6.1937, F -7.4018, G 0.0041)] [G loss: 7.2232]\n",
      "5108 (5, 1) [D loss: (-0.8681)(R 7.6461, F -8.5619, G 0.0048)] [G loss: 8.0947]\n",
      "5109 (5, 1) [D loss: (-1.2711)(R 8.8171, F -10.1457, G 0.0057)] [G loss: 9.5726]\n",
      "5110 (5, 1) [D loss: (-1.5506)(R 8.9430, F -10.5581, G 0.0065)] [G loss: 9.8487]\n",
      "5111 (5, 1) [D loss: (-1.1309)(R 9.0002, F -10.1739, G 0.0043)] [G loss: 9.4764]\n",
      "5112 (5, 1) [D loss: (-1.2631)(R 7.1256, F -8.4219, G 0.0033)] [G loss: 7.8621]\n",
      "5113 (5, 1) [D loss: (-1.0642)(R 5.2074, F -6.3100, G 0.0038)] [G loss: 6.0941]\n",
      "5114 (5, 1) [D loss: (-1.4342)(R 3.2356, F -4.6965, G 0.0027)] [G loss: 4.4569]\n",
      "5115 (5, 1) [D loss: (-1.7143)(R 0.5566, F -2.3190, G 0.0048)] [G loss: 2.0751]\n",
      "5116 (5, 1) [D loss: (-1.5749)(R -1.1529, F -0.4907, G 0.0069)] [G loss: 0.1371]\n",
      "5117 (5, 1) [D loss: (-1.4329)(R -2.1111, F 0.5947, G 0.0083)] [G loss: -0.7599]\n",
      "5118 (5, 1) [D loss: (-1.6763)(R -2.6816, F 0.9341, G 0.0071)] [G loss: -0.9712]\n",
      "5119 (5, 1) [D loss: (-1.3716)(R -3.1439, F 1.7091, G 0.0063)] [G loss: -1.4857]\n",
      "5120 (5, 1) [D loss: (-1.6746)(R -2.7137, F 0.9846, G 0.0054)] [G loss: -1.4025]\n",
      "5121 (5, 1) [D loss: (-1.1592)(R -3.1561, F 1.9114, G 0.0085)] [G loss: -2.0676]\n",
      "5122 (5, 1) [D loss: (-1.9983)(R -3.4184, F 1.3497, G 0.0070)] [G loss: -1.7112]\n",
      "5123 (5, 1) [D loss: (-1.5665)(R -3.4879, F 1.8395, G 0.0082)] [G loss: -2.3218]\n",
      "5124 (5, 1) [D loss: (-2.2385)(R -4.1587, F 1.8227, G 0.0098)] [G loss: -3.0012]\n",
      "5125 (5, 1) [D loss: (-1.5930)(R -5.1096, F 3.3970, G 0.0120)] [G loss: -4.0744]\n",
      "5126 (5, 1) [D loss: (-2.1054)(R -6.0673, F 3.8280, G 0.0134)] [G loss: -5.0440]\n",
      "5127 (5, 1) [D loss: (-2.0456)(R -6.8734, F 4.6838, G 0.0144)] [G loss: -5.9599]\n",
      "5128 (5, 1) [D loss: (-1.9975)(R -7.2698, F 5.1114, G 0.0161)] [G loss: -6.3855]\n",
      "5129 (5, 1) [D loss: (-1.5518)(R -6.4632, F 4.7896, G 0.0122)] [G loss: -6.2445]\n",
      "5130 (5, 1) [D loss: (-1.4381)(R -6.1917, F 4.6524, G 0.0101)] [G loss: -6.2688]\n",
      "5131 (5, 1) [D loss: (-1.6081)(R -6.3904, F 4.6748, G 0.0108)] [G loss: -6.1781]\n",
      "5132 (5, 1) [D loss: (-1.9816)(R -6.4781, F 4.3895, G 0.0107)] [G loss: -6.2679]\n",
      "5133 (5, 1) [D loss: (-1.5829)(R -5.2771, F 3.6239, G 0.0070)] [G loss: -5.3187]\n",
      "5134 (5, 1) [D loss: (-1.8022)(R -5.4658, F 3.5904, G 0.0073)] [G loss: -5.1856]\n",
      "5135 (5, 1) [D loss: (-1.7560)(R -5.2192, F 3.3780, G 0.0085)] [G loss: -4.9554]\n",
      "5136 (5, 1) [D loss: (-1.4149)(R -4.5752, F 3.0928, G 0.0067)] [G loss: -4.4661]\n",
      "5137 (5, 1) [D loss: (-1.4596)(R -3.7796, F 2.2581, G 0.0062)] [G loss: -3.7526]\n",
      "5138 (5, 1) [D loss: (-1.0285)(R -2.9569, F 1.8696, G 0.0059)] [G loss: -2.6832]\n",
      "5139 (5, 1) [D loss: (-1.4923)(R -2.0374, F 0.4998, G 0.0045)] [G loss: -1.0252]\n",
      "5140 (5, 1) [D loss: (-0.8730)(R -0.4319, F -0.4899, G 0.0049)] [G loss: 0.0657]\n",
      "5141 (5, 1) [D loss: (-1.0858)(R 0.8802, F -2.0120, G 0.0046)] [G loss: 1.8377]\n",
      "5142 (5, 1) [D loss: (-1.5998)(R 2.8268, F -4.4837, G 0.0057)] [G loss: 3.7753]\n",
      "5143 (5, 1) [D loss: (-1.3536)(R 4.8047, F -6.2083, G 0.0050)] [G loss: 6.2262]\n",
      "5144 (5, 1) [D loss: (-1.3314)(R 7.6588, F -9.0381, G 0.0048)] [G loss: 8.9523]\n",
      "5145 (5, 1) [D loss: (-0.9710)(R 9.6912, F -10.7112, G 0.0049)] [G loss: 11.1396]\n",
      "5146 (5, 1) [D loss: (-1.0291)(R 10.8852, F -11.9748, G 0.0061)] [G loss: 12.0052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5147 (5, 1) [D loss: (-0.7818)(R 12.2159, F -13.0447, G 0.0047)] [G loss: 13.3207]\n",
      "5148 (5, 1) [D loss: (-1.2269)(R 12.9256, F -14.2055, G 0.0053)] [G loss: 14.5119]\n",
      "5149 (5, 1) [D loss: (-1.1051)(R 14.4089, F -15.5683, G 0.0054)] [G loss: 16.3036]\n",
      "5150 (5, 1) [D loss: (-1.6736)(R 15.2951, F -17.0288, G 0.0060)] [G loss: 17.4070]\n",
      "5151 (5, 1) [D loss: (-1.7053)(R 17.6013, F -19.3623, G 0.0056)] [G loss: 20.5093]\n",
      "5152 (5, 1) [D loss: (-1.0173)(R 22.1481, F -23.2826, G 0.0117)] [G loss: 23.8674]\n",
      "5153 (5, 1) [D loss: (-1.6182)(R 24.9024, F -26.6778, G 0.0157)] [G loss: 26.9640]\n",
      "5154 (5, 1) [D loss: (-1.8873)(R 27.2658, F -29.3809, G 0.0228)] [G loss: 29.2477]\n",
      "5155 (5, 1) [D loss: (-3.0549)(R 30.2561, F -33.5955, G 0.0285)] [G loss: 32.4052]\n",
      "5156 (5, 1) [D loss: (-2.0526)(R 29.5420, F -31.7925, G 0.0198)] [G loss: 29.8686]\n",
      "5157 (5, 1) [D loss: (-1.2316)(R 29.5881, F -31.0060, G 0.0186)] [G loss: 29.0478]\n",
      "5158 (5, 1) [D loss: (-1.8924)(R 26.9484, F -28.9451, G 0.0104)] [G loss: 26.9568]\n",
      "5159 (5, 1) [D loss: (-1.9072)(R 24.4429, F -26.4196, G 0.0070)] [G loss: 25.1705]\n",
      "5160 (5, 1) [D loss: (-2.1536)(R 23.2929, F -25.5107, G 0.0064)] [G loss: 23.1628]\n",
      "5161 (5, 1) [D loss: (-1.3240)(R 22.6620, F -24.0754, G 0.0089)] [G loss: 22.5287]\n",
      "5162 (5, 1) [D loss: (-2.5537)(R 24.5312, F -27.2705, G 0.0186)] [G loss: 25.0929]\n",
      "5163 (5, 1) [D loss: (-3.5879)(R 27.6995, F -31.6759, G 0.0389)] [G loss: 28.7997]\n",
      "5164 (5, 1) [D loss: (-4.7443)(R 33.2888, F -39.0859, G 0.1053)] [G loss: 33.3116]\n",
      "5165 (5, 1) [D loss: (-4.4425)(R 36.6100, F -42.5026, G 0.1450)] [G loss: 34.0658]\n",
      "5166 (5, 1) [D loss: (-5.0894)(R 32.6150, F -38.5254, G 0.0821)] [G loss: 31.4022]\n",
      "5167 (5, 1) [D loss: (-3.5429)(R 32.0565, F -36.2699, G 0.0671)] [G loss: 29.2201]\n",
      "5168 (5, 1) [D loss: (-3.8654)(R 31.1625, F -35.5283, G 0.0500)] [G loss: 28.5012]\n",
      "5169 (5, 1) [D loss: (-4.3376)(R 31.7232, F -36.6937, G 0.0633)] [G loss: 29.6558]\n",
      "5170 (5, 1) [D loss: (-4.0273)(R 30.0519, F -34.4695, G 0.0390)] [G loss: 27.3746]\n",
      "5171 (5, 1) [D loss: (-3.8169)(R 28.9417, F -33.1931, G 0.0434)] [G loss: 27.3204]\n",
      "5172 (5, 1) [D loss: (-4.3364)(R 28.6542, F -33.3984, G 0.0408)] [G loss: 26.1418]\n",
      "5173 (5, 1) [D loss: (-3.4045)(R 28.2745, F -32.1160, G 0.0437)] [G loss: 24.9999]\n",
      "5174 (5, 1) [D loss: (-3.2739)(R 26.8475, F -30.4444, G 0.0323)] [G loss: 22.7064]\n",
      "5175 (5, 1) [D loss: (-3.6810)(R 25.4893, F -29.4828, G 0.0313)] [G loss: 22.4153]\n",
      "5176 (5, 1) [D loss: (-4.3984)(R 23.1327, F -27.8087, G 0.0278)] [G loss: 21.1328]\n",
      "5177 (5, 1) [D loss: (-3.2699)(R 21.0457, F -24.5167, G 0.0201)] [G loss: 19.2538]\n",
      "5178 (5, 1) [D loss: (-2.1681)(R 18.1036, F -20.4424, G 0.0171)] [G loss: 15.9474]\n",
      "5179 (5, 1) [D loss: (-1.4525)(R 14.2394, F -15.9261, G 0.0234)] [G loss: 13.2379]\n",
      "5180 (5, 1) [D loss: (-2.2460)(R 12.4881, F -14.9262, G 0.0192)] [G loss: 12.5586]\n",
      "5181 (5, 1) [D loss: (-1.7197)(R 9.8616, F -11.7431, G 0.0162)] [G loss: 10.1027]\n",
      "5182 (5, 1) [D loss: (-2.7538)(R 5.4648, F -8.3163, G 0.0098)] [G loss: 7.5165]\n",
      "5183 (5, 1) [D loss: (-2.9495)(R 0.9948, F -3.9613, G 0.0017)] [G loss: 3.7902]\n",
      "5184 (5, 1) [D loss: (-4.1106)(R -5.5171, F 1.2650, G 0.0142)] [G loss: -0.9039]\n",
      "5185 (5, 1) [D loss: (-3.6677)(R -8.0538, F 3.8554, G 0.0531)] [G loss: -2.5285]\n",
      "5186 (5, 1) [D loss: (-3.6912)(R -6.2813, F 2.1991, G 0.0391)] [G loss: -1.3011]\n",
      "5187 (5, 1) [D loss: (-3.6374)(R -5.4354, F 1.4984, G 0.0300)] [G loss: -1.3550]\n",
      "5188 (5, 1) [D loss: (-3.7884)(R -6.4121, F 2.3109, G 0.0313)] [G loss: -2.9646]\n",
      "5189 (5, 1) [D loss: (-4.1681)(R -6.8751, F 2.2896, G 0.0417)] [G loss: -3.5865]\n",
      "5190 (5, 1) [D loss: (-3.4398)(R -5.3258, F 1.5820, G 0.0304)] [G loss: -2.9171]\n",
      "5191 (5, 1) [D loss: (-2.6042)(R -4.5300, F 1.7035, G 0.0222)] [G loss: -2.8758]\n",
      "5192 (5, 1) [D loss: (-2.8068)(R -4.4464, F 1.4733, G 0.0166)] [G loss: -3.2028]\n",
      "5193 (5, 1) [D loss: (-3.0128)(R -4.5229, F 1.3757, G 0.0134)] [G loss: -3.2797]\n",
      "5194 (5, 1) [D loss: (-2.6209)(R -3.9679, F 1.2563, G 0.0091)] [G loss: -2.9396]\n",
      "5195 (5, 1) [D loss: (-1.7844)(R -3.3991, F 1.5272, G 0.0087)] [G loss: -2.8108]\n",
      "5196 (5, 1) [D loss: (-2.5769)(R -3.7737, F 1.1147, G 0.0082)] [G loss: -3.1003]\n",
      "5197 (5, 1) [D loss: (-1.9154)(R -2.9913, F 1.0182, G 0.0058)] [G loss: -2.3560]\n",
      "5198 (5, 1) [D loss: (-1.8349)(R -2.5386, F 0.6432, G 0.0060)] [G loss: -2.3494]\n",
      "5199 (5, 1) [D loss: (-2.3849)(R -3.0522, F 0.5873, G 0.0080)] [G loss: -2.6912]\n",
      "5200 (5, 1) [D loss: (-2.9555)(R -3.0507, F 0.0100, G 0.0085)] [G loss: -2.5022]\n",
      "5201 (5, 1) [D loss: (-1.6098)(R -1.6957, F 0.0244, G 0.0062)] [G loss: -1.7305]\n",
      "5202 (5, 1) [D loss: (-0.9060)(R -0.8975, F -0.0607, G 0.0052)] [G loss: -1.1462]\n",
      "5203 (5, 1) [D loss: (-0.9638)(R -0.8928, F -0.1248, G 0.0054)] [G loss: -1.1500]\n",
      "5204 (5, 1) [D loss: (-1.7184)(R -0.8164, F -0.9458, G 0.0044)] [G loss: -0.4157]\n",
      "5205 (5, 1) [D loss: (-0.9973)(R 0.7270, F -1.7541, G 0.0030)] [G loss: 0.1187]\n",
      "5206 (5, 1) [D loss: (-1.4200)(R 1.2367, F -2.6791, G 0.0022)] [G loss: 1.1695]\n",
      "5207 (5, 1) [D loss: (-1.1778)(R 1.6829, F -2.8935, G 0.0033)] [G loss: 1.6061]\n",
      "5208 (5, 1) [D loss: (-1.2688)(R 2.6648, F -3.9556, G 0.0022)] [G loss: 2.9430]\n",
      "5209 (5, 1) [D loss: (-1.5890)(R 3.2405, F -4.8544, G 0.0025)] [G loss: 4.0545]\n",
      "5210 (5, 1) [D loss: (-1.3995)(R 5.1430, F -6.5608, G 0.0018)] [G loss: 6.0870]\n",
      "5211 (5, 1) [D loss: (-1.3337)(R 7.5451, F -8.9011, G 0.0022)] [G loss: 8.3334]\n",
      "5212 (5, 1) [D loss: (-1.3700)(R 8.7767, F -10.1759, G 0.0029)] [G loss: 9.6828]\n",
      "5213 (5, 1) [D loss: (-1.1168)(R 10.7489, F -11.9048, G 0.0039)] [G loss: 12.0679]\n",
      "5214 (5, 1) [D loss: (-1.0718)(R 12.5777, F -13.6918, G 0.0042)] [G loss: 13.8359]\n",
      "5215 (5, 1) [D loss: (-1.3154)(R 13.8440, F -15.2151, G 0.0056)] [G loss: 15.2710]\n",
      "5216 (5, 1) [D loss: (-0.7272)(R 15.4737, F -16.2626, G 0.0062)] [G loss: 16.5614]\n",
      "5217 (5, 1) [D loss: (-1.3686)(R 15.2846, F -16.7208, G 0.0068)] [G loss: 16.6280]\n",
      "5218 (5, 1) [D loss: (-1.4182)(R 15.8934, F -17.3771, G 0.0065)] [G loss: 16.7052]\n",
      "5219 (5, 1) [D loss: (-1.1317)(R 14.7369, F -15.9294, G 0.0061)] [G loss: 15.6785]\n",
      "5220 (5, 1) [D loss: (-1.0386)(R 13.9773, F -15.0775, G 0.0062)] [G loss: 14.5573]\n",
      "5221 (5, 1) [D loss: (-1.0123)(R 12.1737, F -13.2505, G 0.0064)] [G loss: 12.9497]\n",
      "5222 (5, 1) [D loss: (-1.0533)(R 11.5141, F -12.6220, G 0.0055)] [G loss: 12.4823]\n",
      "5223 (5, 1) [D loss: (-1.2416)(R 11.1496, F -12.4423, G 0.0051)] [G loss: 12.7324]\n",
      "5224 (5, 1) [D loss: (-0.4749)(R 13.3643, F -13.8868, G 0.0048)] [G loss: 13.2860]\n",
      "5225 (5, 1) [D loss: (-0.6205)(R 14.1893, F -14.8474, G 0.0038)] [G loss: 14.8395]\n",
      "5226 (5, 1) [D loss: (-0.8889)(R 16.0715, F -17.0078, G 0.0047)] [G loss: 17.2471]\n",
      "5227 (5, 1) [D loss: (-1.0663)(R 16.7336, F -17.8421, G 0.0042)] [G loss: 17.9960]\n",
      "5228 (5, 1) [D loss: (-0.9591)(R 17.8720, F -18.8788, G 0.0048)] [G loss: 19.0113]\n",
      "5229 (5, 1) [D loss: (-0.6945)(R 17.5984, F -18.3405, G 0.0048)] [G loss: 18.4898]\n",
      "5230 (5, 1) [D loss: (-1.0851)(R 16.1797, F -17.3087, G 0.0044)] [G loss: 16.6781]\n",
      "5231 (5, 1) [D loss: (-1.4723)(R 14.7403, F -16.2657, G 0.0053)] [G loss: 15.9947]\n",
      "5232 (5, 1) [D loss: (-1.3211)(R 13.9345, F -15.3055, G 0.0050)] [G loss: 14.8146]\n",
      "5233 (5, 1) [D loss: (-1.0054)(R 12.4554, F -13.5286, G 0.0068)] [G loss: 13.1761]\n",
      "5234 (5, 1) [D loss: (-1.2265)(R 12.1691, F -13.4604, G 0.0065)] [G loss: 13.5952]\n",
      "5235 (5, 1) [D loss: (-1.3173)(R 13.3259, F -14.7203, G 0.0077)] [G loss: 14.4539]\n",
      "5236 (5, 1) [D loss: (-1.2871)(R 13.8911, F -15.2413, G 0.0063)] [G loss: 15.3443]\n",
      "5237 (5, 1) [D loss: (-2.2099)(R 15.2101, F -17.5013, G 0.0081)] [G loss: 16.9803]\n",
      "5238 (5, 1) [D loss: (-1.1257)(R 16.9821, F -18.2234, G 0.0116)] [G loss: 18.2824]\n",
      "5239 (5, 1) [D loss: (-1.2634)(R 16.2235, F -17.5907, G 0.0104)] [G loss: 17.5094]\n",
      "5240 (5, 1) [D loss: (-1.4705)(R 15.0892, F -16.6647, G 0.0105)] [G loss: 16.6322]\n",
      "5241 (5, 1) [D loss: (-1.4869)(R 13.0325, F -14.5805, G 0.0061)] [G loss: 13.8730]\n",
      "5242 (5, 1) [D loss: (-1.0573)(R 11.1780, F -12.2976, G 0.0062)] [G loss: 11.8561]\n",
      "5243 (5, 1) [D loss: (-1.5580)(R 10.4490, F -12.0545, G 0.0047)] [G loss: 11.9213]\n",
      "5244 (5, 1) [D loss: (-0.7929)(R 12.4238, F -13.2725, G 0.0056)] [G loss: 14.4141]\n",
      "5245 (5, 1) [D loss: (-1.2224)(R 16.7015, F -18.0388, G 0.0115)] [G loss: 18.7952]\n",
      "5246 (5, 1) [D loss: (-1.4861)(R 21.8057, F -23.6447, G 0.0353)] [G loss: 24.7832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5247 (5, 1) [D loss: (-2.1089)(R 25.0477, F -27.7464, G 0.0590)] [G loss: 27.5036]\n",
      "5248 (5, 1) [D loss: (-1.6359)(R 25.5511, F -27.6725, G 0.0486)] [G loss: 27.0293]\n",
      "5249 (5, 1) [D loss: (-2.0710)(R 25.3938, F -27.8202, G 0.0355)] [G loss: 27.0566]\n",
      "5250 (5, 1) [D loss: (-2.4505)(R 24.3224, F -26.9880, G 0.0215)] [G loss: 26.1905]\n",
      "5251 (5, 1) [D loss: (-2.1324)(R 24.1218, F -26.4276, G 0.0173)] [G loss: 25.9431]\n",
      "5252 (5, 1) [D loss: (-2.8225)(R 23.6751, F -26.6843, G 0.0187)] [G loss: 25.9347]\n",
      "5253 (5, 1) [D loss: (-2.7818)(R 23.6026, F -26.6237, G 0.0239)] [G loss: 25.6045]\n",
      "5254 (5, 1) [D loss: (-2.4484)(R 23.9137, F -26.6320, G 0.0270)] [G loss: 25.1607]\n",
      "5255 (5, 1) [D loss: (-2.8628)(R 23.3817, F -26.5138, G 0.0269)] [G loss: 25.3497]\n",
      "5256 (5, 1) [D loss: (-1.5969)(R 24.8634, F -26.8080, G 0.0348)] [G loss: 25.4759]\n",
      "5257 (5, 1) [D loss: (-1.7653)(R 23.7537, F -25.7590, G 0.0240)] [G loss: 24.1588]\n",
      "5258 (5, 1) [D loss: (-1.9940)(R 23.7367, F -25.9936, G 0.0263)] [G loss: 23.8499]\n",
      "5259 (5, 1) [D loss: (-0.9436)(R 22.6177, F -23.7037, G 0.0142)] [G loss: 22.1499]\n",
      "5260 (5, 1) [D loss: (-1.9562)(R 20.3571, F -22.3726, G 0.0059)] [G loss: 20.6233]\n",
      "5261 (5, 1) [D loss: (-0.9089)(R 20.9158, F -21.8813, G 0.0057)] [G loss: 20.2040]\n",
      "5262 (5, 1) [D loss: (-1.2430)(R 18.1041, F -19.3701, G 0.0023)] [G loss: 18.9935]\n",
      "5263 (5, 1) [D loss: (-1.8788)(R 18.2509, F -20.1554, G 0.0026)] [G loss: 19.1176]\n",
      "5264 (5, 1) [D loss: (-0.6385)(R 17.1218, F -17.7862, G 0.0026)] [G loss: 17.0938]\n",
      "5265 (5, 1) [D loss: (-0.9078)(R 15.6039, F -16.5356, G 0.0024)] [G loss: 15.4273]\n",
      "5266 (5, 1) [D loss: (-1.0727)(R 13.4050, F -14.5002, G 0.0022)] [G loss: 13.6148]\n",
      "5267 (5, 1) [D loss: (-1.3120)(R 11.8198, F -13.1510, G 0.0019)] [G loss: 13.1057]\n",
      "5268 (5, 1) [D loss: (-1.4457)(R 9.6965, F -11.1692, G 0.0027)] [G loss: 10.4360]\n",
      "5269 (5, 1) [D loss: (-1.5455)(R 8.2661, F -9.8545, G 0.0043)] [G loss: 10.0292]\n",
      "5270 (5, 1) [D loss: (-1.2716)(R 7.5301, F -8.8733, G 0.0072)] [G loss: 8.1143]\n",
      "5271 (5, 1) [D loss: (-1.6126)(R 5.7855, F -7.4864, G 0.0088)] [G loss: 7.2674]\n",
      "5272 (5, 1) [D loss: (-2.0625)(R 3.5805, F -5.7420, G 0.0099)] [G loss: 5.1718]\n",
      "5273 (5, 1) [D loss: (-1.9032)(R 2.5415, F -4.5429, G 0.0098)] [G loss: 3.7202]\n",
      "5274 (5, 1) [D loss: (-1.9377)(R 0.7200, F -2.7857, G 0.0128)] [G loss: 1.8930]\n",
      "5275 (5, 1) [D loss: (-2.2595)(R -0.9238, F -1.4825, G 0.0147)] [G loss: 0.1733]\n",
      "5276 (5, 1) [D loss: (-1.9677)(R -1.9530, F -0.1855, G 0.0171)] [G loss: -0.8286]\n",
      "5277 (5, 1) [D loss: (-1.9444)(R -2.7269, F 0.5882, G 0.0194)] [G loss: -1.5495]\n",
      "5278 (5, 1) [D loss: (-1.7588)(R -1.7985, F -0.0673, G 0.0107)] [G loss: -0.9071]\n",
      "5279 (5, 1) [D loss: (-1.9422)(R -2.0463, F 0.0247, G 0.0079)] [G loss: -0.8057]\n",
      "5280 (5, 1) [D loss: (-1.7202)(R -2.0340, F 0.2406, G 0.0073)] [G loss: -0.7371]\n",
      "5281 (5, 1) [D loss: (-1.1791)(R -0.9948, F -0.2198, G 0.0036)] [G loss: 0.0121]\n",
      "5282 (5, 1) [D loss: (-0.8774)(R 0.0513, F -0.9545, G 0.0026)] [G loss: 1.0162]\n",
      "5283 (5, 1) [D loss: (-0.9353)(R 1.3317, F -2.2904, G 0.0023)] [G loss: 1.7962]\n",
      "5284 (5, 1) [D loss: (-0.8413)(R 2.3899, F -3.2520, G 0.0021)] [G loss: 3.3519]\n",
      "5285 (5, 1) [D loss: (-0.8893)(R 4.0301, F -4.9483, G 0.0029)] [G loss: 4.8859]\n",
      "5286 (5, 1) [D loss: (-0.8430)(R 5.4503, F -6.3224, G 0.0029)] [G loss: 6.5196]\n",
      "5287 (5, 1) [D loss: (-1.0986)(R 6.8504, F -7.9883, G 0.0039)] [G loss: 8.4492]\n",
      "5288 (5, 1) [D loss: (-1.4767)(R 8.0792, F -9.5936, G 0.0038)] [G loss: 9.4900]\n",
      "5289 (5, 1) [D loss: (-0.9387)(R 9.6715, F -10.6443, G 0.0034)] [G loss: 10.6484]\n",
      "5290 (5, 1) [D loss: (-1.4453)(R 10.3997, F -11.8861, G 0.0041)] [G loss: 11.9137]\n",
      "5291 (5, 1) [D loss: (-1.3219)(R 11.5810, F -12.9532, G 0.0050)] [G loss: 13.2110]\n",
      "5292 (5, 1) [D loss: (-1.6670)(R 12.2674, F -13.9960, G 0.0062)] [G loss: 14.4842]\n",
      "5293 (5, 1) [D loss: (-2.0345)(R 13.5142, F -15.5973, G 0.0049)] [G loss: 15.5135]\n",
      "5294 (5, 1) [D loss: (-1.5097)(R 14.8304, F -16.4317, G 0.0092)] [G loss: 16.9190]\n",
      "5295 (5, 1) [D loss: (-1.6349)(R 16.6203, F -18.3315, G 0.0076)] [G loss: 18.2542]\n",
      "5296 (5, 1) [D loss: (-1.8135)(R 17.9604, F -19.8864, G 0.0112)] [G loss: 20.0413]\n",
      "5297 (5, 1) [D loss: (-1.6119)(R 19.7774, F -21.4751, G 0.0086)] [G loss: 21.8078]\n",
      "5298 (5, 1) [D loss: (-1.4828)(R 21.6295, F -23.2117, G 0.0099)] [G loss: 23.2665]\n",
      "5299 (5, 1) [D loss: (-1.1586)(R 23.5056, F -24.7692, G 0.0105)] [G loss: 25.4396]\n",
      "5300 (5, 1) [D loss: (-1.1148)(R 25.3194, F -26.5355, G 0.0101)] [G loss: 26.0392]\n",
      "5301 (5, 1) [D loss: (-1.3910)(R 24.0482, F -25.5359, G 0.0097)] [G loss: 25.3245]\n",
      "5302 (5, 1) [D loss: (-1.0687)(R 23.6038, F -24.7563, G 0.0084)] [G loss: 24.5937]\n",
      "5303 (5, 1) [D loss: (-1.1346)(R 22.6890, F -23.8873, G 0.0064)] [G loss: 23.7369]\n",
      "5304 (5, 1) [D loss: (-0.8982)(R 21.3133, F -22.2578, G 0.0046)] [G loss: 21.8006]\n",
      "5305 (5, 1) [D loss: (-1.2297)(R 20.4157, F -21.7011, G 0.0056)] [G loss: 21.3829]\n",
      "5306 (5, 1) [D loss: (-0.8849)(R 18.2611, F -19.1963, G 0.0050)] [G loss: 18.9378]\n",
      "5307 (5, 1) [D loss: (-0.8119)(R 16.0997, F -16.9574, G 0.0046)] [G loss: 16.4741]\n",
      "5308 (5, 1) [D loss: (-0.6972)(R 14.4126, F -15.1626, G 0.0053)] [G loss: 14.4476]\n",
      "5309 (5, 1) [D loss: (-1.3432)(R 12.1143, F -13.5163, G 0.0059)] [G loss: 12.8029]\n",
      "5310 (5, 1) [D loss: (-1.2018)(R 10.5956, F -11.8632, G 0.0066)] [G loss: 11.8130]\n",
      "5311 (5, 1) [D loss: (-0.7610)(R 10.3829, F -11.2222, G 0.0078)] [G loss: 11.6952]\n",
      "5312 (5, 1) [D loss: (-1.3017)(R 10.0120, F -11.3613, G 0.0048)] [G loss: 11.3783]\n",
      "5313 (5, 1) [D loss: (-1.0180)(R 8.4154, F -9.5023, G 0.0069)] [G loss: 9.8299]\n",
      "5314 (5, 1) [D loss: (-1.2191)(R 7.6317, F -8.9280, G 0.0077)] [G loss: 8.7598]\n",
      "5315 (5, 1) [D loss: (-1.5119)(R 5.4197, F -7.0239, G 0.0092)] [G loss: 6.5586]\n",
      "5316 (5, 1) [D loss: (-1.7351)(R 3.4441, F -5.3182, G 0.0139)] [G loss: 4.3238]\n",
      "5317 (5, 1) [D loss: (-1.7600)(R 1.8278, F -3.7634, G 0.0176)] [G loss: 2.3698]\n",
      "5318 (5, 1) [D loss: (-1.6279)(R 0.6088, F -2.4050, G 0.0168)] [G loss: 1.0303]\n",
      "5319 (5, 1) [D loss: (-1.4861)(R 0.4779, F -2.0881, G 0.0124)] [G loss: 0.6418]\n",
      "5320 (5, 1) [D loss: (-1.4451)(R 0.1305, F -1.6697, G 0.0094)] [G loss: 0.2608]\n",
      "5321 (5, 1) [D loss: (-1.2262)(R 0.6731, F -1.9349, G 0.0036)] [G loss: 1.5296]\n",
      "5322 (5, 1) [D loss: (-0.8202)(R 2.2536, F -3.0972, G 0.0023)] [G loss: 2.7981]\n",
      "5323 (5, 1) [D loss: (-0.6604)(R 4.2728, F -4.9542, G 0.0021)] [G loss: 5.1610]\n",
      "5324 (5, 1) [D loss: (-0.7818)(R 6.6417, F -7.4467, G 0.0023)] [G loss: 7.0542]\n",
      "5325 (5, 1) [D loss: (-0.8928)(R 8.6437, F -9.5567, G 0.0020)] [G loss: 9.8362]\n",
      "5326 (5, 1) [D loss: (-1.1276)(R 11.1807, F -12.3316, G 0.0023)] [G loss: 12.5874]\n",
      "5327 (5, 1) [D loss: (-1.3933)(R 12.2968, F -13.7108, G 0.0021)] [G loss: 13.6343]\n",
      "5328 (5, 1) [D loss: (-0.5196)(R 13.7691, F -14.3192, G 0.0031)] [G loss: 14.6438]\n",
      "5329 (5, 1) [D loss: (-1.3144)(R 14.5232, F -15.8667, G 0.0029)] [G loss: 16.3123]\n",
      "5330 (5, 1) [D loss: (-1.8622)(R 15.7272, F -17.6290, G 0.0040)] [G loss: 18.1220]\n",
      "5331 (5, 1) [D loss: (-1.8408)(R 17.3764, F -19.2794, G 0.0062)] [G loss: 19.9117]\n",
      "5332 (5, 1) [D loss: (-1.4980)(R 19.4596, F -21.0324, G 0.0075)] [G loss: 21.6657]\n",
      "5333 (5, 1) [D loss: (-1.5640)(R 22.0671, F -23.7153, G 0.0084)] [G loss: 24.7119]\n",
      "5334 (5, 1) [D loss: (-2.2538)(R 26.1864, F -28.6101, G 0.0170)] [G loss: 28.7215]\n",
      "5335 (5, 1) [D loss: (-3.2143)(R 29.3742, F -32.9394, G 0.0351)] [G loss: 32.7829]\n",
      "5336 (5, 1) [D loss: (-2.9041)(R 32.1821, F -35.5451, G 0.0459)] [G loss: 34.4064]\n",
      "5337 (5, 1) [D loss: (-3.4076)(R 32.1604, F -36.0452, G 0.0477)] [G loss: 34.0908]\n",
      "5338 (5, 1) [D loss: (-2.8847)(R 31.3912, F -34.5929, G 0.0317)] [G loss: 32.5646]\n",
      "5339 (5, 1) [D loss: (-2.2204)(R 30.7460, F -33.1667, G 0.0200)] [G loss: 31.5654]\n",
      "5340 (5, 1) [D loss: (-2.4096)(R 30.4623, F -33.0081, G 0.0136)] [G loss: 31.6034]\n",
      "5341 (5, 1) [D loss: (-2.4003)(R 30.6382, F -33.1504, G 0.0112)] [G loss: 31.7260]\n",
      "5342 (5, 1) [D loss: (-3.2470)(R 31.1929, F -34.5761, G 0.0136)] [G loss: 31.8772]\n",
      "5343 (5, 1) [D loss: (-2.2397)(R 30.9160, F -33.3112, G 0.0156)] [G loss: 31.9735]\n",
      "5344 (5, 1) [D loss: (-4.9669)(R 29.4057, F -34.6217, G 0.0249)] [G loss: 32.7469]\n",
      "5345 (5, 1) [D loss: (-3.3248)(R 34.1882, F -37.9905, G 0.0477)] [G loss: 34.1446]\n",
      "5346 (5, 1) [D loss: (-2.0207)(R 37.0148, F -39.6356, G 0.0600)] [G loss: 34.6453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5347 (5, 1) [D loss: (-3.7814)(R 34.7773, F -39.0273, G 0.0469)] [G loss: 33.9887]\n",
      "5348 (5, 1) [D loss: (-2.7574)(R 34.2006, F -37.4570, G 0.0499)] [G loss: 31.5847]\n",
      "5349 (5, 1) [D loss: (-3.8712)(R 30.5120, F -34.6944, G 0.0311)] [G loss: 29.8518]\n",
      "5350 (5, 1) [D loss: (-2.4240)(R 27.6542, F -30.2145, G 0.0136)] [G loss: 26.1097]\n",
      "5351 (5, 1) [D loss: (-2.5566)(R 24.8232, F -27.4796, G 0.0100)] [G loss: 24.3137]\n",
      "5352 (5, 1) [D loss: (-1.9671)(R 21.6056, F -23.6345, G 0.0062)] [G loss: 20.9793]\n",
      "5353 (5, 1) [D loss: (-1.0784)(R 17.6793, F -18.7971, G 0.0039)] [G loss: 17.3626]\n",
      "5354 (5, 1) [D loss: (-1.7513)(R 14.0551, F -15.8416, G 0.0035)] [G loss: 14.8117]\n",
      "5355 (5, 1) [D loss: (-2.4303)(R 13.5165, F -15.9782, G 0.0031)] [G loss: 14.2772]\n",
      "5356 (5, 1) [D loss: (-1.3916)(R 15.3336, F -16.7706, G 0.0045)] [G loss: 15.0480]\n",
      "5357 (5, 1) [D loss: (-2.1876)(R 16.5220, F -18.7654, G 0.0056)] [G loss: 16.6531]\n",
      "5358 (5, 1) [D loss: (-2.4013)(R 19.1172, F -21.6493, G 0.0131)] [G loss: 18.9597]\n",
      "5359 (5, 1) [D loss: (-2.8785)(R 20.7106, F -23.8478, G 0.0259)] [G loss: 20.1459]\n",
      "5360 (5, 1) [D loss: (-3.1749)(R 19.1196, F -22.4992, G 0.0205)] [G loss: 18.2670]\n",
      "5361 (5, 1) [D loss: (-1.5706)(R 16.2532, F -17.9124, G 0.0089)] [G loss: 15.6427]\n",
      "5362 (5, 1) [D loss: (-2.2060)(R 12.3712, F -14.6378, G 0.0061)] [G loss: 12.8151]\n",
      "5363 (5, 1) [D loss: (-2.0845)(R 10.3536, F -12.4928, G 0.0055)] [G loss: 11.0357]\n",
      "5364 (5, 1) [D loss: (-1.8844)(R 6.8890, F -8.8015, G 0.0028)] [G loss: 7.8242]\n",
      "5365 (5, 1) [D loss: (-2.0022)(R 2.4066, F -4.4390, G 0.0030)] [G loss: 4.2525]\n",
      "5366 (5, 1) [D loss: (-2.6286)(R -2.1842, F -0.5638, G 0.0119)] [G loss: 0.0598]\n",
      "5367 (5, 1) [D loss: (-3.2017)(R -5.1305, F 1.6614, G 0.0267)] [G loss: -2.4513]\n",
      "5368 (5, 1) [D loss: (-3.8419)(R -7.6106, F 3.3568, G 0.0412)] [G loss: -4.4352]\n",
      "5369 (5, 1) [D loss: (-3.1364)(R -7.1208, F 3.6536, G 0.0331)] [G loss: -4.2175]\n",
      "5370 (5, 1) [D loss: (-3.6662)(R -7.7646, F 3.7275, G 0.0371)] [G loss: -4.6960]\n",
      "5371 (5, 1) [D loss: (-3.8959)(R -8.0509, F 3.8809, G 0.0274)] [G loss: -4.6518]\n",
      "5372 (5, 1) [D loss: (-2.5291)(R -6.2184, F 3.4857, G 0.0204)] [G loss: -4.1676]\n",
      "5373 (5, 1) [D loss: (-2.3465)(R -6.7472, F 4.1593, G 0.0241)] [G loss: -4.7044]\n",
      "5374 (5, 1) [D loss: (-2.1018)(R -6.1239, F 3.8565, G 0.0166)] [G loss: -4.5627]\n",
      "5375 (5, 1) [D loss: (-3.1002)(R -6.5015, F 3.2488, G 0.0153)] [G loss: -5.0742]\n",
      "5376 (5, 1) [D loss: (-1.6818)(R -5.9386, F 4.1065, G 0.0150)] [G loss: -5.0639]\n",
      "5377 (5, 1) [D loss: (-2.2278)(R -5.9906, F 3.6492, G 0.0114)] [G loss: -4.9317]\n",
      "5378 (5, 1) [D loss: (-1.9177)(R -5.3727, F 3.3896, G 0.0065)] [G loss: -4.4371]\n",
      "5379 (5, 1) [D loss: (-0.9431)(R -3.9202, F 2.9309, G 0.0046)] [G loss: -3.7583]\n",
      "5380 (5, 1) [D loss: (-1.2242)(R -3.3943, F 2.1495, G 0.0021)] [G loss: -2.5954]\n",
      "5381 (5, 1) [D loss: (-0.8625)(R -2.3335, F 1.4541, G 0.0017)] [G loss: -1.8445]\n",
      "5382 (5, 1) [D loss: (-1.0874)(R -1.3922, F 0.2848, G 0.0020)] [G loss: -0.5111]\n",
      "5383 (5, 1) [D loss: (-1.3760)(R -0.5062, F -0.8850, G 0.0015)] [G loss: 0.1354]\n",
      "5384 (5, 1) [D loss: (-1.7112)(R -0.0787, F -1.6588, G 0.0026)] [G loss: 0.9507]\n",
      "5385 (5, 1) [D loss: (-1.2365)(R 1.0342, F -2.2924, G 0.0022)] [G loss: 2.1011]\n",
      "5386 (5, 1) [D loss: (-1.5929)(R 1.4161, F -3.0346, G 0.0026)] [G loss: 2.4074]\n",
      "5387 (5, 1) [D loss: (-1.4554)(R 2.3216, F -3.8158, G 0.0039)] [G loss: 3.1713]\n",
      "5388 (5, 1) [D loss: (-1.3408)(R 2.5071, F -3.8947, G 0.0047)] [G loss: 3.3713]\n",
      "5389 (5, 1) [D loss: (-1.9201)(R 2.3855, F -4.3675, G 0.0062)] [G loss: 2.9661]\n",
      "5390 (5, 1) [D loss: (-1.4829)(R 1.7612, F -3.3364, G 0.0092)] [G loss: 2.2944]\n",
      "5391 (5, 1) [D loss: (-1.2011)(R 1.3909, F -2.6840, G 0.0092)] [G loss: 1.5370]\n",
      "5392 (5, 1) [D loss: (-1.6246)(R 0.7592, F -2.4769, G 0.0093)] [G loss: 1.2724]\n",
      "5393 (5, 1) [D loss: (-1.8320)(R 0.1148, F -2.0366, G 0.0090)] [G loss: 0.7414]\n",
      "5394 (5, 1) [D loss: (-1.4824)(R 0.2864, F -1.8534, G 0.0085)] [G loss: 0.5290]\n",
      "5395 (5, 1) [D loss: (-1.1926)(R 0.4694, F -1.7305, G 0.0069)] [G loss: 0.8488]\n",
      "5396 (5, 1) [D loss: (-1.4754)(R 0.8068, F -2.3283, G 0.0046)] [G loss: 1.4427]\n",
      "5397 (5, 1) [D loss: (-1.3632)(R 1.5695, F -2.9688, G 0.0036)] [G loss: 2.3403]\n",
      "5398 (5, 1) [D loss: (-1.0477)(R 2.6694, F -3.7484, G 0.0031)] [G loss: 3.5149]\n",
      "5399 (5, 1) [D loss: (-0.6228)(R 5.0303, F -5.6825, G 0.0029)] [G loss: 6.0835]\n",
      "5400 (5, 1) [D loss: (-1.2143)(R 6.9843, F -8.2268, G 0.0028)] [G loss: 7.9586]\n",
      "5401 (5, 1) [D loss: (-0.9405)(R 8.8528, F -9.8206, G 0.0027)] [G loss: 10.3560]\n",
      "5402 (5, 1) [D loss: (-1.0330)(R 10.9599, F -12.0317, G 0.0039)] [G loss: 12.7244]\n",
      "5403 (5, 1) [D loss: (-1.7011)(R 12.3203, F -14.0612, G 0.0040)] [G loss: 14.6190]\n",
      "5404 (5, 1) [D loss: (-1.2840)(R 14.2966, F -15.6335, G 0.0053)] [G loss: 15.9371]\n",
      "5405 (5, 1) [D loss: (-1.1909)(R 15.1192, F -16.3585, G 0.0048)] [G loss: 16.4118]\n",
      "5406 (5, 1) [D loss: (-1.5789)(R 15.9414, F -17.5666, G 0.0046)] [G loss: 17.6090]\n",
      "5407 (5, 1) [D loss: (-0.9004)(R 17.5161, F -18.4640, G 0.0048)] [G loss: 18.8425]\n",
      "5408 (5, 1) [D loss: (-0.8600)(R 17.9001, F -18.8173, G 0.0057)] [G loss: 19.1809]\n",
      "5409 (5, 1) [D loss: (-0.7802)(R 18.2425, F -19.0717, G 0.0049)] [G loss: 19.4153]\n",
      "5410 (5, 1) [D loss: (-1.8007)(R 18.0205, F -19.8770, G 0.0056)] [G loss: 19.2765]\n",
      "5411 (5, 1) [D loss: (-0.7850)(R 18.2876, F -19.1316, G 0.0059)] [G loss: 19.8446]\n",
      "5412 (5, 1) [D loss: (-0.9929)(R 18.1010, F -19.1439, G 0.0050)] [G loss: 19.8931]\n",
      "5413 (5, 1) [D loss: (-1.5604)(R 18.6907, F -20.3064, G 0.0055)] [G loss: 20.2668]\n",
      "5414 (5, 1) [D loss: (-1.8772)(R 20.5274, F -22.4707, G 0.0066)] [G loss: 22.9592]\n",
      "5415 (5, 1) [D loss: (-1.5704)(R 22.8313, F -24.4998, G 0.0098)] [G loss: 24.6931]\n",
      "5416 (5, 1) [D loss: (-1.8624)(R 24.5244, F -26.5147, G 0.0128)] [G loss: 26.6581]\n",
      "5417 (5, 1) [D loss: (-1.9653)(R 24.5944, F -26.7088, G 0.0149)] [G loss: 26.2567]\n",
      "5418 (5, 1) [D loss: (-1.0016)(R 26.1738, F -27.3313, G 0.0156)] [G loss: 26.3425]\n",
      "5419 (5, 1) [D loss: (-1.8709)(R 24.0981, F -26.1161, G 0.0147)] [G loss: 25.4969]\n",
      "5420 (5, 1) [D loss: (-1.5341)(R 22.4829, F -24.1229, G 0.0106)] [G loss: 22.8362]\n",
      "5421 (5, 1) [D loss: (-1.1559)(R 18.4291, F -19.6259, G 0.0041)] [G loss: 18.6913]\n",
      "5422 (5, 1) [D loss: (-1.5734)(R 14.9987, F -16.6081, G 0.0036)] [G loss: 15.6423]\n",
      "5423 (5, 1) [D loss: (-1.4930)(R 12.3395, F -13.8649, G 0.0032)] [G loss: 12.9320]\n",
      "5424 (5, 1) [D loss: (-1.1962)(R 9.9197, F -11.1506, G 0.0035)] [G loss: 10.4715]\n",
      "5425 (5, 1) [D loss: (-1.7423)(R 7.4523, F -9.2624, G 0.0068)] [G loss: 8.2404]\n",
      "5426 (5, 1) [D loss: (-1.5874)(R 7.2838, F -8.9658, G 0.0095)] [G loss: 8.5989]\n",
      "5427 (5, 1) [D loss: (-1.8801)(R 7.7528, F -9.7494, G 0.0117)] [G loss: 9.3611]\n",
      "5428 (5, 1) [D loss: (-2.0596)(R 9.0092, F -11.2429, G 0.0174)] [G loss: 10.2458]\n",
      "5429 (5, 1) [D loss: (-1.9966)(R 9.1487, F -11.3130, G 0.0168)] [G loss: 10.1824]\n",
      "5430 (5, 1) [D loss: (-1.6956)(R 8.8704, F -10.7047, G 0.0139)] [G loss: 9.4047]\n",
      "5431 (5, 1) [D loss: (-1.8027)(R 6.3394, F -8.2165, G 0.0074)] [G loss: 6.5604]\n",
      "5432 (5, 1) [D loss: (-0.8745)(R 3.9062, F -4.8165, G 0.0036)] [G loss: 3.7221]\n",
      "5433 (5, 1) [D loss: (-1.0998)(R 1.2322, F -2.3647, G 0.0033)] [G loss: 1.7481]\n",
      "5434 (5, 1) [D loss: (-0.9717)(R -1.5987, F 0.5724, G 0.0055)] [G loss: -0.8827]\n",
      "5435 (5, 1) [D loss: (-0.5973)(R -3.0410, F 2.3937, G 0.0050)] [G loss: -2.5533]\n",
      "5436 (5, 1) [D loss: (-0.9205)(R -4.7876, F 3.8057, G 0.0061)] [G loss: -4.2855]\n",
      "5437 (5, 1) [D loss: (-1.0170)(R -4.8731, F 3.8107, G 0.0045)] [G loss: -4.1664]\n",
      "5438 (5, 1) [D loss: (-0.7429)(R -3.0541, F 2.2848, G 0.0026)] [G loss: -1.6318]\n",
      "5439 (5, 1) [D loss: (-1.1532)(R -0.9757, F -0.2046, G 0.0027)] [G loss: 0.4001]\n",
      "5440 (5, 1) [D loss: (-0.7817)(R 0.3946, F -1.2192, G 0.0043)] [G loss: 1.3761]\n",
      "5441 (5, 1) [D loss: (-1.6137)(R 1.0437, F -2.7140, G 0.0057)] [G loss: 2.2349]\n",
      "5442 (5, 1) [D loss: (-1.1875)(R 1.9331, F -3.1567, G 0.0036)] [G loss: 3.1034]\n",
      "5443 (5, 1) [D loss: (-0.5993)(R 2.2810, F -2.9187, G 0.0038)] [G loss: 2.9202]\n",
      "5444 (5, 1) [D loss: (-1.2350)(R 1.4572, F -2.7288, G 0.0037)] [G loss: 2.4893]\n",
      "5445 (5, 1) [D loss: (-0.9069)(R 1.0862, F -2.0319, G 0.0039)] [G loss: 1.9038]\n",
      "5446 (5, 1) [D loss: (-1.2480)(R 1.1197, F -2.4009, G 0.0033)] [G loss: 2.0661]\n",
      "5447 (5, 1) [D loss: (-1.5497)(R 0.6158, F -2.2128, G 0.0047)] [G loss: 1.9050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5448 (5, 1) [D loss: (-0.6883)(R 0.8049, F -1.5391, G 0.0046)] [G loss: 1.6941]\n",
      "5449 (5, 1) [D loss: (-0.9265)(R 0.7039, F -1.6890, G 0.0059)] [G loss: 1.9115]\n",
      "5450 (5, 1) [D loss: (-1.1758)(R 0.9201, F -2.1519, G 0.0056)] [G loss: 1.9619]\n",
      "5451 (5, 1) [D loss: (-1.2492)(R 1.1358, F -2.4287, G 0.0044)] [G loss: 1.8960]\n",
      "5452 (5, 1) [D loss: (-0.4492)(R 1.6574, F -2.1577, G 0.0051)] [G loss: 2.5772]\n",
      "5453 (5, 1) [D loss: (-1.1288)(R 2.4168, F -3.5913, G 0.0046)] [G loss: 3.2628]\n",
      "5454 (5, 1) [D loss: (-1.2501)(R 2.1202, F -3.4321, G 0.0062)] [G loss: 3.2479]\n",
      "5455 (5, 1) [D loss: (-0.9621)(R 1.9251, F -2.9502, G 0.0063)] [G loss: 3.1306]\n",
      "5456 (5, 1) [D loss: (-1.4446)(R 1.5807, F -3.0964, G 0.0071)] [G loss: 2.5316]\n",
      "5457 (5, 1) [D loss: (-1.4646)(R 1.0004, F -2.5346, G 0.0070)] [G loss: 1.4930]\n",
      "5458 (5, 1) [D loss: (-1.3855)(R -0.1644, F -1.2971, G 0.0076)] [G loss: 0.5340]\n",
      "5459 (5, 1) [D loss: (-1.6735)(R -1.9737, F 0.2011, G 0.0099)] [G loss: -1.0148]\n",
      "5460 (5, 1) [D loss: (-1.7075)(R -3.2659, F 1.4567, G 0.0102)] [G loss: -2.3191]\n",
      "5461 (5, 1) [D loss: (-1.0838)(R -3.1079, F 1.9207, G 0.0103)] [G loss: -2.6122]\n",
      "5462 (5, 1) [D loss: (-1.1204)(R -3.7221, F 2.5089, G 0.0093)] [G loss: -3.5812]\n",
      "5463 (5, 1) [D loss: (-0.5631)(R -3.5189, F 2.8773, G 0.0079)] [G loss: -2.7631]\n",
      "5464 (5, 1) [D loss: (-1.4430)(R -3.4527, F 1.9524, G 0.0057)] [G loss: -2.3840]\n",
      "5465 (5, 1) [D loss: (-1.0101)(R -2.2147, F 1.1686, G 0.0036)] [G loss: -1.6185]\n",
      "5466 (5, 1) [D loss: (-0.7471)(R -1.4899, F 0.7139, G 0.0029)] [G loss: -0.5718]\n",
      "5467 (5, 1) [D loss: (-1.2109)(R -0.5309, F -0.7122, G 0.0032)] [G loss: 0.2264]\n",
      "5468 (5, 1) [D loss: (-0.8847)(R 0.9452, F -1.8548, G 0.0025)] [G loss: 1.8340]\n",
      "5469 (5, 1) [D loss: (-1.0015)(R 1.9497, F -2.9819, G 0.0031)] [G loss: 2.9566]\n",
      "5470 (5, 1) [D loss: (-0.9523)(R 3.0133, F -3.9948, G 0.0029)] [G loss: 4.1300]\n",
      "5471 (5, 1) [D loss: (-1.1858)(R 3.9018, F -5.1252, G 0.0038)] [G loss: 5.3515]\n",
      "5472 (5, 1) [D loss: (-1.1866)(R 4.2525, F -5.4833, G 0.0044)] [G loss: 5.2434]\n",
      "5473 (5, 1) [D loss: (-1.1306)(R 4.1214, F -5.3039, G 0.0052)] [G loss: 5.5959]\n",
      "5474 (5, 1) [D loss: (-0.9454)(R 4.4653, F -5.4641, G 0.0053)] [G loss: 5.3880]\n",
      "5475 (5, 1) [D loss: (-0.7272)(R 4.7357, F -5.5273, G 0.0064)] [G loss: 5.1862]\n",
      "5476 (5, 1) [D loss: (-0.9813)(R 4.1839, F -5.2272, G 0.0062)] [G loss: 5.5455]\n",
      "5477 (5, 1) [D loss: (-1.1338)(R 5.4809, F -6.6597, G 0.0045)] [G loss: 6.8799]\n",
      "5478 (5, 1) [D loss: (-0.7015)(R 7.0853, F -7.8363, G 0.0050)] [G loss: 7.8553]\n",
      "5479 (5, 1) [D loss: (-0.4521)(R 8.5966, F -9.0989, G 0.0050)] [G loss: 9.6224]\n",
      "5480 (5, 1) [D loss: (-0.8153)(R 10.2526, F -11.1142, G 0.0046)] [G loss: 11.6649]\n",
      "5481 (5, 1) [D loss: (-1.2520)(R 12.3744, F -13.6880, G 0.0062)] [G loss: 13.8431]\n",
      "5482 (5, 1) [D loss: (-1.3340)(R 15.0064, F -16.4161, G 0.0076)] [G loss: 16.9311]\n",
      "5483 (5, 1) [D loss: (-1.6508)(R 16.9421, F -18.7048, G 0.0112)] [G loss: 19.1096]\n",
      "5484 (5, 1) [D loss: (-1.7269)(R 17.2175, F -19.0631, G 0.0119)] [G loss: 19.4946]\n",
      "5485 (5, 1) [D loss: (-1.2896)(R 18.4256, F -19.8136, G 0.0098)] [G loss: 19.2646]\n",
      "5486 (5, 1) [D loss: (-1.4826)(R 17.9071, F -19.4759, G 0.0086)] [G loss: 19.1481]\n",
      "5487 (5, 1) [D loss: (-1.5149)(R 17.5822, F -19.1769, G 0.0080)] [G loss: 19.0908]\n",
      "5488 (5, 1) [D loss: (-1.0792)(R 16.8015, F -17.9357, G 0.0055)] [G loss: 17.6979]\n",
      "5489 (5, 1) [D loss: (-1.6740)(R 16.5269, F -18.2747, G 0.0074)] [G loss: 17.6789]\n",
      "5490 (5, 1) [D loss: (-2.2839)(R 17.1838, F -19.5849, G 0.0117)] [G loss: 18.0373]\n",
      "5491 (5, 1) [D loss: (-1.0026)(R 18.1540, F -19.3243, G 0.0168)] [G loss: 18.3849]\n",
      "5492 (5, 1) [D loss: (-1.6364)(R 17.0777, F -18.9077, G 0.0194)] [G loss: 17.5697]\n",
      "5493 (5, 1) [D loss: (-1.8592)(R 15.3634, F -17.3797, G 0.0157)] [G loss: 15.8121]\n",
      "5494 (5, 1) [D loss: (-2.1041)(R 14.1020, F -16.3520, G 0.0146)] [G loss: 15.1796]\n",
      "5495 (5, 1) [D loss: (-2.0256)(R 13.6893, F -15.8441, G 0.0129)] [G loss: 14.8969]\n",
      "5496 (5, 1) [D loss: (-2.1189)(R 12.8282, F -15.0659, G 0.0119)] [G loss: 14.0381]\n",
      "5497 (5, 1) [D loss: (-1.1797)(R 12.6275, F -13.9173, G 0.0110)] [G loss: 12.6290]\n",
      "5498 (5, 1) [D loss: (-1.9738)(R 12.1495, F -14.2120, G 0.0089)] [G loss: 12.8997]\n",
      "5499 (5, 1) [D loss: (-0.9760)(R 11.1536, F -12.1830, G 0.0053)] [G loss: 11.1954]\n",
      "5500 (5, 1) [D loss: (-1.1470)(R 10.5083, F -11.7008, G 0.0046)] [G loss: 11.4018]\n",
      "5501 (5, 1) [D loss: (-1.1379)(R 11.5119, F -12.7176, G 0.0068)] [G loss: 11.7808]\n",
      "5502 (5, 1) [D loss: (-1.2186)(R 11.8860, F -13.1859, G 0.0081)] [G loss: 12.7529]\n",
      "5503 (5, 1) [D loss: (-0.7578)(R 11.7074, F -12.5238, G 0.0059)] [G loss: 11.4202]\n",
      "5504 (5, 1) [D loss: (-0.0991)(R 10.8761, F -11.0131, G 0.0038)] [G loss: 10.7854]\n",
      "5505 (5, 1) [D loss: (-1.0286)(R 8.9370, F -9.9950, G 0.0029)] [G loss: 9.3845]\n",
      "5506 (5, 1) [D loss: (-0.5531)(R 7.3769, F -7.9586, G 0.0029)] [G loss: 7.2134]\n",
      "5507 (5, 1) [D loss: (-1.3278)(R 4.7917, F -6.1443, G 0.0025)] [G loss: 5.6010]\n",
      "5508 (5, 1) [D loss: (-0.7390)(R 3.4449, F -4.2114, G 0.0028)] [G loss: 3.1805]\n",
      "5509 (5, 1) [D loss: (-1.2832)(R 0.2191, F -1.5352, G 0.0033)] [G loss: 0.8935]\n",
      "5510 (5, 1) [D loss: (-0.9326)(R -1.8596, F 0.8732, G 0.0054)] [G loss: -0.8082]\n",
      "5511 (5, 1) [D loss: (-0.7664)(R -4.2089, F 3.3726, G 0.0070)] [G loss: -3.1009]\n",
      "5512 (5, 1) [D loss: (-1.3633)(R -6.6392, F 5.1806, G 0.0095)] [G loss: -5.5663]\n",
      "5513 (5, 1) [D loss: (-1.4698)(R -8.0271, F 6.4420, G 0.0115)] [G loss: -7.2951]\n",
      "5514 (5, 1) [D loss: (-2.1774)(R -9.6018, F 7.3125, G 0.0112)] [G loss: -8.1185]\n",
      "5515 (5, 1) [D loss: (-1.2001)(R -10.0498, F 8.7326, G 0.0117)] [G loss: -8.5655]\n",
      "5516 (5, 1) [D loss: (-2.6631)(R -10.7343, F 7.9611, G 0.0110)] [G loss: -9.1825]\n",
      "5517 (5, 1) [D loss: (-1.5331)(R -9.7460, F 8.1279, G 0.0085)] [G loss: -8.6676]\n",
      "5518 (5, 1) [D loss: (-2.1491)(R -10.9559, F 8.7027, G 0.0104)] [G loss: -9.7720]\n",
      "5519 (5, 1) [D loss: (-2.3364)(R -11.1655, F 8.7099, G 0.0119)] [G loss: -9.3072]\n",
      "5520 (5, 1) [D loss: (-2.1303)(R -11.7113, F 9.4477, G 0.0133)] [G loss: -10.1352]\n",
      "5521 (5, 1) [D loss: (-2.2402)(R -12.2861, F 9.8782, G 0.0168)] [G loss: -10.8566]\n",
      "5522 (5, 1) [D loss: (-1.3739)(R -10.9973, F 9.5239, G 0.0099)] [G loss: -10.5147]\n",
      "5523 (5, 1) [D loss: (-1.7093)(R -11.2008, F 9.4029, G 0.0089)] [G loss: -10.5158]\n",
      "5524 (5, 1) [D loss: (-1.7075)(R -10.9434, F 9.1571, G 0.0079)] [G loss: -10.5188]\n",
      "5525 (5, 1) [D loss: (-1.4265)(R -10.8230, F 9.3101, G 0.0086)] [G loss: -10.5574]\n",
      "5526 (5, 1) [D loss: (-1.1209)(R -10.5740, F 9.3863, G 0.0067)] [G loss: -10.0639]\n",
      "5527 (5, 1) [D loss: (-1.6766)(R -9.6266, F 7.9099, G 0.0040)] [G loss: -9.5341]\n",
      "5528 (5, 1) [D loss: (-0.8667)(R -9.2437, F 8.3383, G 0.0039)] [G loss: -8.6808]\n",
      "5529 (5, 1) [D loss: (-1.3125)(R -9.1552, F 7.7973, G 0.0045)] [G loss: -8.5110]\n",
      "5530 (5, 1) [D loss: (-1.2878)(R -8.3295, F 7.0029, G 0.0039)] [G loss: -8.2042]\n",
      "5531 (5, 1) [D loss: (-1.2219)(R -7.0219, F 5.7735, G 0.0026)] [G loss: -6.6619]\n",
      "5532 (5, 1) [D loss: (-1.4116)(R -6.2982, F 4.8588, G 0.0028)] [G loss: -5.8780]\n",
      "5533 (5, 1) [D loss: (-0.6503)(R -5.3920, F 4.7129, G 0.0029)] [G loss: -5.2540]\n",
      "5534 (5, 1) [D loss: (-1.1831)(R -4.7252, F 3.5123, G 0.0030)] [G loss: -4.1785]\n",
      "5535 (5, 1) [D loss: (-0.6734)(R -2.8781, F 2.1817, G 0.0023)] [G loss: -2.5344]\n",
      "5536 (5, 1) [D loss: (-1.2549)(R -1.8705, F 0.5869, G 0.0029)] [G loss: -1.0119]\n",
      "5537 (5, 1) [D loss: (-1.1592)(R -1.1902, F 0.0029, G 0.0028)] [G loss: -0.4664]\n",
      "5538 (5, 1) [D loss: (-0.8083)(R -0.0329, F -0.8125, G 0.0037)] [G loss: 0.7296]\n",
      "5539 (5, 1) [D loss: (-0.8730)(R 0.7177, F -1.6233, G 0.0033)] [G loss: 1.8064]\n",
      "5540 (5, 1) [D loss: (-1.5373)(R 1.5036, F -3.0773, G 0.0036)] [G loss: 2.7629]\n",
      "5541 (5, 1) [D loss: (-1.0631)(R 2.7870, F -3.8870, G 0.0037)] [G loss: 4.0489]\n",
      "5542 (5, 1) [D loss: (-1.1887)(R 3.1676, F -4.4011, G 0.0045)] [G loss: 4.4497]\n",
      "5543 (5, 1) [D loss: (-1.2073)(R 3.8426, F -5.0979, G 0.0048)] [G loss: 4.7239]\n",
      "5544 (5, 1) [D loss: (-1.0839)(R 4.8102, F -5.9348, G 0.0041)] [G loss: 6.1220]\n",
      "5545 (5, 1) [D loss: (-1.1305)(R 6.2299, F -7.4054, G 0.0045)] [G loss: 7.9218]\n",
      "5546 (5, 1) [D loss: (-1.3713)(R 7.6891, F -9.1118, G 0.0051)] [G loss: 9.7693]\n",
      "5547 (5, 1) [D loss: (-1.1810)(R 9.4075, F -10.6388, G 0.0050)] [G loss: 10.5038]\n",
      "5548 (5, 1) [D loss: (-1.4763)(R 10.4658, F -12.0040, G 0.0062)] [G loss: 12.5320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5549 (5, 1) [D loss: (-2.1051)(R 12.1509, F -14.3314, G 0.0075)] [G loss: 14.8577]\n",
      "5550 (5, 1) [D loss: (-1.9804)(R 14.2696, F -16.3428, G 0.0093)] [G loss: 16.2222]\n",
      "5551 (5, 1) [D loss: (-2.3662)(R 15.2743, F -17.7413, G 0.0101)] [G loss: 18.2896]\n",
      "5552 (5, 1) [D loss: (-2.2599)(R 17.0581, F -19.4570, G 0.0139)] [G loss: 19.4438]\n",
      "5553 (5, 1) [D loss: (-1.7560)(R 17.7463, F -19.6420, G 0.0140)] [G loss: 19.2614]\n",
      "5554 (5, 1) [D loss: (-1.5199)(R 17.8268, F -19.4543, G 0.0108)] [G loss: 19.0874]\n",
      "5555 (5, 1) [D loss: (-1.1193)(R 18.7288, F -19.9534, G 0.0105)] [G loss: 19.5686]\n",
      "5556 (5, 1) [D loss: (-2.3051)(R 19.0036, F -21.4229, G 0.0114)] [G loss: 20.7206]\n",
      "5557 (5, 1) [D loss: (-2.0030)(R 18.2061, F -20.2804, G 0.0071)] [G loss: 19.6404]\n",
      "5558 (5, 1) [D loss: (-1.5287)(R 17.7744, F -19.3758, G 0.0073)] [G loss: 18.7818]\n",
      "5559 (5, 1) [D loss: (-1.5144)(R 17.2380, F -18.8152, G 0.0063)] [G loss: 17.7568]\n",
      "5560 (5, 1) [D loss: (-2.2927)(R 16.7847, F -19.1415, G 0.0064)] [G loss: 18.2290]\n",
      "5561 (5, 1) [D loss: (-2.0940)(R 17.2990, F -19.4691, G 0.0076)] [G loss: 18.4505]\n",
      "5562 (5, 1) [D loss: (-1.2354)(R 19.8488, F -21.2091, G 0.0125)] [G loss: 20.1744]\n",
      "5563 (5, 1) [D loss: (-1.5635)(R 20.5529, F -22.2484, G 0.0132)] [G loss: 20.5557]\n",
      "5564 (5, 1) [D loss: (-1.9748)(R 20.9996, F -23.1267, G 0.0152)] [G loss: 20.6142]\n",
      "5565 (5, 1) [D loss: (-1.8771)(R 20.7646, F -22.7576, G 0.0116)] [G loss: 20.3476]\n",
      "5566 (5, 1) [D loss: (-1.7135)(R 19.6919, F -21.5063, G 0.0101)] [G loss: 19.6022]\n",
      "5567 (5, 1) [D loss: (-0.7035)(R 21.3285, F -22.1796, G 0.0148)] [G loss: 18.9154]\n",
      "5568 (5, 1) [D loss: (-0.9112)(R 18.1026, F -19.0863, G 0.0073)] [G loss: 16.7595]\n",
      "5569 (5, 1) [D loss: (-3.2066)(R 15.7759, F -19.0495, G 0.0067)] [G loss: 15.9634]\n",
      "5570 (5, 1) [D loss: (-1.5234)(R 15.4272, F -17.0161, G 0.0065)] [G loss: 14.1224]\n",
      "5571 (5, 1) [D loss: (-0.8154)(R 16.8438, F -17.7675, G 0.0108)] [G loss: 15.4081]\n",
      "5572 (5, 1) [D loss: (-1.1330)(R 16.0111, F -17.2331, G 0.0089)] [G loss: 15.2342]\n",
      "5573 (5, 1) [D loss: (-2.1407)(R 17.0241, F -19.2727, G 0.0108)] [G loss: 15.6944]\n",
      "5574 (5, 1) [D loss: (-1.6063)(R 18.4699, F -20.2487, G 0.0172)] [G loss: 16.1801]\n",
      "5575 (5, 1) [D loss: (-3.2269)(R 19.0230, F -22.5083, G 0.0258)] [G loss: 17.9438]\n",
      "5576 (5, 1) [D loss: (-2.6111)(R 18.8327, F -21.6741, G 0.0230)] [G loss: 16.7887]\n",
      "5577 (5, 1) [D loss: (-3.0419)(R 18.1436, F -21.3993, G 0.0214)] [G loss: 16.8296]\n",
      "5578 (5, 1) [D loss: (-1.9898)(R 17.0242, F -19.1851, G 0.0171)] [G loss: 14.4399]\n",
      "5579 (5, 1) [D loss: (-2.0170)(R 15.8638, F -18.0225, G 0.0142)] [G loss: 13.4079]\n",
      "5580 (5, 1) [D loss: (-1.8495)(R 12.2797, F -14.2097, G 0.0080)] [G loss: 11.0287]\n",
      "5581 (5, 1) [D loss: (-1.1996)(R 8.9471, F -10.2305, G 0.0084)] [G loss: 7.3681]\n",
      "5582 (5, 1) [D loss: (-2.0443)(R 6.4242, F -8.5252, G 0.0057)] [G loss: 6.2589]\n",
      "5583 (5, 1) [D loss: (-2.1208)(R 3.9102, F -6.1090, G 0.0078)] [G loss: 4.1409]\n",
      "5584 (5, 1) [D loss: (-2.6217)(R 0.9753, F -3.6439, G 0.0047)] [G loss: 1.8576]\n",
      "5585 (5, 1) [D loss: (-1.3705)(R -1.7882, F 0.3735, G 0.0044)] [G loss: -1.3963]\n",
      "5586 (5, 1) [D loss: (-1.9067)(R -5.1055, F 3.1462, G 0.0053)] [G loss: -4.4988]\n",
      "5587 (5, 1) [D loss: (-2.3032)(R -10.1009, F 7.7532, G 0.0044)] [G loss: -8.2783]\n",
      "5588 (5, 1) [D loss: (-2.4303)(R -14.1932, F 11.7016, G 0.0061)] [G loss: -11.7334]\n",
      "5589 (5, 1) [D loss: (-2.5475)(R -18.1881, F 15.5629, G 0.0078)] [G loss: -16.6095]\n",
      "5590 (5, 1) [D loss: (-3.2721)(R -22.8908, F 19.5266, G 0.0092)] [G loss: -20.9198]\n",
      "5591 (5, 1) [D loss: (-3.0122)(R -26.2515, F 23.1031, G 0.0136)] [G loss: -23.9517]\n",
      "5592 (5, 1) [D loss: (-2.8722)(R -31.5226, F 28.3318, G 0.0319)] [G loss: -28.1369]\n",
      "5593 (5, 1) [D loss: (-4.9551)(R -34.2158, F 28.8201, G 0.0441)] [G loss: -31.6469]\n",
      "5594 (5, 1) [D loss: (-4.7616)(R -35.6803, F 30.3587, G 0.0560)] [G loss: -33.2382]\n",
      "5595 (5, 1) [D loss: (-4.1194)(R -35.8613, F 31.1339, G 0.0608)] [G loss: -33.6493]\n",
      "5596 (5, 1) [D loss: (-4.4218)(R -35.6686, F 30.7265, G 0.0520)] [G loss: -33.7404]\n",
      "5597 (5, 1) [D loss: (-4.4749)(R -34.3739, F 29.4567, G 0.0442)] [G loss: -32.7685]\n",
      "5598 (5, 1) [D loss: (-3.5117)(R -33.9279, F 29.9890, G 0.0427)] [G loss: -32.3458]\n",
      "5599 (5, 1) [D loss: (-2.9733)(R -31.8843, F 28.6023, G 0.0309)] [G loss: -30.4593]\n",
      "5600 (5, 1) [D loss: (-2.8304)(R -30.8930, F 27.8415, G 0.0221)] [G loss: -30.6448]\n",
      "5601 (5, 1) [D loss: (-2.0386)(R -30.3786, F 28.1541, G 0.0186)] [G loss: -30.2319]\n",
      "5602 (5, 1) [D loss: (-2.3865)(R -28.9587, F 26.4753, G 0.0097)] [G loss: -29.0585]\n",
      "5603 (5, 1) [D loss: (-1.7263)(R -27.2187, F 25.4457, G 0.0047)] [G loss: -27.7463]\n",
      "5604 (5, 1) [D loss: (-1.1971)(R -26.4401, F 25.2106, G 0.0032)] [G loss: -26.7069]\n",
      "5605 (5, 1) [D loss: (-1.5921)(R -26.4275, F 24.8014, G 0.0034)] [G loss: -26.1835]\n",
      "5606 (5, 1) [D loss: (-1.5674)(R -25.6682, F 24.0737, G 0.0027)] [G loss: -25.6279]\n",
      "5607 (5, 1) [D loss: (-1.0762)(R -23.5486, F 22.4556, G 0.0017)] [G loss: -23.7169]\n",
      "5608 (5, 1) [D loss: (-1.5651)(R -22.7831, F 21.2016, G 0.0016)] [G loss: -22.6688]\n",
      "5609 (5, 1) [D loss: (-0.5635)(R -20.8914, F 20.3139, G 0.0014)] [G loss: -20.3325]\n",
      "5610 (5, 1) [D loss: (-1.2449)(R -20.0079, F 18.7510, G 0.0012)] [G loss: -20.1430]\n",
      "5611 (5, 1) [D loss: (-0.4190)(R -18.4385, F 18.0052, G 0.0014)] [G loss: -18.1392]\n",
      "5612 (5, 1) [D loss: (-1.2824)(R -17.3465, F 16.0488, G 0.0015)] [G loss: -16.7598]\n",
      "5613 (5, 1) [D loss: (-0.8936)(R -16.2580, F 15.3395, G 0.0025)] [G loss: -15.8355]\n",
      "5614 (5, 1) [D loss: (-0.9903)(R -14.7050, F 13.6912, G 0.0024)] [G loss: -13.9264]\n",
      "5615 (5, 1) [D loss: (-0.8901)(R -13.5417, F 12.6336, G 0.0018)] [G loss: -13.1231]\n",
      "5616 (5, 1) [D loss: (-0.6152)(R -12.5232, F 11.8761, G 0.0032)] [G loss: -11.4107]\n",
      "5617 (5, 1) [D loss: (-1.2743)(R -11.0953, F 9.7875, G 0.0033)] [G loss: -9.8870]\n",
      "5618 (5, 1) [D loss: (-1.2652)(R -9.8381, F 8.5394, G 0.0034)] [G loss: -8.8899]\n",
      "5619 (5, 1) [D loss: (-1.3114)(R -9.3306, F 7.9751, G 0.0044)] [G loss: -8.3097]\n",
      "5620 (5, 1) [D loss: (-1.0315)(R -8.8443, F 7.7635, G 0.0049)] [G loss: -7.3952]\n",
      "5621 (5, 1) [D loss: (-1.8251)(R -8.3261, F 6.4451, G 0.0056)] [G loss: -6.7802]\n",
      "5622 (5, 1) [D loss: (-1.3733)(R -6.4284, F 5.0048, G 0.0050)] [G loss: -5.0834]\n",
      "5623 (5, 1) [D loss: (-1.2100)(R -5.6707, F 4.3910, G 0.0070)] [G loss: -4.3057]\n",
      "5624 (5, 1) [D loss: (-0.8393)(R -4.2192, F 3.3183, G 0.0062)] [G loss: -2.7338]\n",
      "5625 (5, 1) [D loss: (-1.6344)(R -3.0534, F 1.3566, G 0.0062)] [G loss: -0.9455]\n",
      "5626 (5, 1) [D loss: (-1.5402)(R -1.6685, F 0.0425, G 0.0086)] [G loss: -0.1342]\n",
      "5627 (5, 1) [D loss: (-1.2761)(R -1.0117, F -0.3462, G 0.0082)] [G loss: 0.4711]\n",
      "5628 (5, 1) [D loss: (-1.2543)(R -0.8486, F -0.4764, G 0.0071)] [G loss: 0.3019]\n",
      "5629 (5, 1) [D loss: (-0.8876)(R -0.3349, F -0.6045, G 0.0052)] [G loss: 0.7049]\n",
      "5630 (5, 1) [D loss: (-1.0205)(R 0.1345, F -1.2135, G 0.0059)] [G loss: 1.5627]\n",
      "5631 (5, 1) [D loss: (-0.9253)(R 0.4484, F -1.4277, G 0.0054)] [G loss: 1.6113]\n",
      "5632 (5, 1) [D loss: (-0.8521)(R 0.6302, F -1.5246, G 0.0042)] [G loss: 1.5652]\n",
      "5633 (5, 1) [D loss: (-1.2475)(R 0.7116, F -2.0226, G 0.0063)] [G loss: 2.0824]\n",
      "5634 (5, 1) [D loss: (-0.9303)(R 1.6457, F -2.6523, G 0.0076)] [G loss: 3.3909]\n",
      "5635 (5, 1) [D loss: (-1.0220)(R 1.6799, F -2.7543, G 0.0052)] [G loss: 2.8704]\n",
      "5636 (5, 1) [D loss: (-0.8938)(R 0.9249, F -1.8644, G 0.0046)] [G loss: 1.7169]\n",
      "5637 (5, 1) [D loss: (-1.3242)(R -0.0217, F -1.3510, G 0.0049)] [G loss: 1.6192]\n",
      "5638 (5, 1) [D loss: (-1.0141)(R -0.6348, F -0.4197, G 0.0040)] [G loss: 0.4379]\n",
      "5639 (5, 1) [D loss: (-1.3113)(R -2.2996, F 0.9450, G 0.0043)] [G loss: -1.3172]\n",
      "5640 (5, 1) [D loss: (-1.0927)(R -2.7211, F 1.5849, G 0.0043)] [G loss: -1.6211]\n",
      "5641 (5, 1) [D loss: (-1.3529)(R -4.2834, F 2.8804, G 0.0050)] [G loss: -2.8751]\n",
      "5642 (5, 1) [D loss: (-1.7166)(R -5.1673, F 3.4058, G 0.0045)] [G loss: -3.6130]\n",
      "5643 (5, 1) [D loss: (-0.9797)(R -5.3615, F 4.3319, G 0.0050)] [G loss: -4.4070]\n",
      "5644 (5, 1) [D loss: (-0.9046)(R -5.6836, F 4.7257, G 0.0053)] [G loss: -4.4311]\n",
      "5645 (5, 1) [D loss: (-1.4447)(R -6.1181, F 4.6156, G 0.0058)] [G loss: -4.9459]\n",
      "5646 (5, 1) [D loss: (-1.5162)(R -6.7161, F 5.1389, G 0.0061)] [G loss: -5.2371]\n",
      "5647 (5, 1) [D loss: (-1.1162)(R -6.4485, F 5.2836, G 0.0049)] [G loss: -5.4193]\n",
      "5648 (5, 1) [D loss: (-1.5199)(R -6.6675, F 5.1055, G 0.0042)] [G loss: -5.5147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5649 (5, 1) [D loss: (-1.1512)(R -6.3680, F 5.1696, G 0.0047)] [G loss: -4.8408]\n",
      "5650 (5, 1) [D loss: (-1.2665)(R -4.9254, F 3.6140, G 0.0045)] [G loss: -3.4854]\n",
      "5651 (5, 1) [D loss: (-1.1224)(R -3.9445, F 2.7778, G 0.0044)] [G loss: -2.5776]\n",
      "5652 (5, 1) [D loss: (-1.4477)(R -2.1540, F 0.6525, G 0.0054)] [G loss: -0.5635]\n",
      "5653 (5, 1) [D loss: (-1.5171)(R -1.0480, F -0.5244, G 0.0055)] [G loss: 0.8447]\n",
      "5654 (5, 1) [D loss: (-1.3675)(R 1.7556, F -3.2004, G 0.0077)] [G loss: 3.0963]\n",
      "5655 (5, 1) [D loss: (-1.1957)(R 3.1183, F -4.4215, G 0.0107)] [G loss: 4.5562]\n",
      "5656 (5, 1) [D loss: (-1.1231)(R 3.9032, F -5.1165, G 0.0090)] [G loss: 4.8380]\n",
      "5657 (5, 1) [D loss: (-1.6809)(R 3.9029, F -5.6568, G 0.0073)] [G loss: 5.6676]\n",
      "5658 (5, 1) [D loss: (-1.4363)(R 5.3406, F -6.8859, G 0.0109)] [G loss: 6.5575]\n",
      "5659 (5, 1) [D loss: (-1.5276)(R 5.0973, F -6.6982, G 0.0073)] [G loss: 6.8764]\n",
      "5660 (5, 1) [D loss: (-1.4653)(R 6.0029, F -7.5700, G 0.0102)] [G loss: 6.9254]\n",
      "5661 (5, 1) [D loss: (-0.8574)(R 6.0433, F -6.9908, G 0.0090)] [G loss: 6.9454]\n",
      "5662 (5, 1) [D loss: (-1.0543)(R 5.8224, F -6.9316, G 0.0055)] [G loss: 6.6739]\n",
      "5663 (5, 1) [D loss: (-1.3913)(R 6.1293, F -7.5988, G 0.0078)] [G loss: 6.8754]\n",
      "5664 (5, 1) [D loss: (-1.4850)(R 6.6170, F -8.2138, G 0.0112)] [G loss: 6.9912]\n",
      "5665 (5, 1) [D loss: (-1.3808)(R 6.6830, F -8.1729, G 0.0109)] [G loss: 7.0639]\n",
      "5666 (5, 1) [D loss: (-0.8592)(R 6.5205, F -7.4915, G 0.0112)] [G loss: 6.2011]\n",
      "5667 (5, 1) [D loss: (-0.8778)(R 5.5568, F -6.5104, G 0.0076)] [G loss: 5.3667]\n",
      "5668 (5, 1) [D loss: (-0.9131)(R 5.6424, F -6.6327, G 0.0077)] [G loss: 5.4827]\n",
      "5669 (5, 1) [D loss: (-1.5589)(R 5.0722, F -6.6931, G 0.0062)] [G loss: 5.5266]\n",
      "5670 (5, 1) [D loss: (-1.5608)(R 4.4378, F -6.0477, G 0.0049)] [G loss: 5.2391]\n",
      "5671 (5, 1) [D loss: (-1.1277)(R 2.7297, F -3.8882, G 0.0031)] [G loss: 3.1402]\n",
      "5672 (5, 1) [D loss: (-0.7754)(R 1.8748, F -2.6774, G 0.0027)] [G loss: 2.4316]\n",
      "5673 (5, 1) [D loss: (-1.0098)(R 0.1857, F -1.2205, G 0.0025)] [G loss: 0.5781]\n",
      "5674 (5, 1) [D loss: (-1.0917)(R -2.3915, F 1.2751, G 0.0025)] [G loss: -1.8977]\n",
      "5675 (5, 1) [D loss: (-0.9751)(R -4.9063, F 3.8984, G 0.0033)] [G loss: -4.0282]\n",
      "5676 (5, 1) [D loss: (-1.0557)(R -6.1101, F 5.0161, G 0.0038)] [G loss: -4.6641]\n",
      "5677 (5, 1) [D loss: (-1.1320)(R -8.1342, F 6.9455, G 0.0057)] [G loss: -7.6538]\n",
      "5678 (5, 1) [D loss: (-1.0594)(R -11.2861, F 10.1144, G 0.0112)] [G loss: -9.9642]\n",
      "5679 (5, 1) [D loss: (-1.6271)(R -13.2689, F 11.4899, G 0.0152)] [G loss: -11.6572]\n",
      "5680 (5, 1) [D loss: (-1.5851)(R -16.4186, F 14.6365, G 0.0197)] [G loss: -14.7443]\n",
      "5681 (5, 1) [D loss: (-1.6038)(R -17.1481, F 15.3481, G 0.0196)] [G loss: -15.6818]\n",
      "5682 (5, 1) [D loss: (-2.2672)(R -19.6989, F 17.1784, G 0.0253)] [G loss: -18.5365]\n",
      "5683 (5, 1) [D loss: (-2.2039)(R -20.5761, F 18.1522, G 0.0220)] [G loss: -18.4384]\n",
      "5684 (5, 1) [D loss: (-2.4682)(R -20.0135, F 17.3985, G 0.0147)] [G loss: -18.8238]\n",
      "5685 (5, 1) [D loss: (-1.5250)(R -20.0600, F 18.3945, G 0.0141)] [G loss: -19.1930]\n",
      "5686 (5, 1) [D loss: (-2.1412)(R -20.8668, F 18.5950, G 0.0131)] [G loss: -19.5609]\n",
      "5687 (5, 1) [D loss: (-1.7769)(R -19.5339, F 17.6820, G 0.0075)] [G loss: -18.8184]\n",
      "5688 (5, 1) [D loss: (-1.6429)(R -18.8437, F 17.1425, G 0.0058)] [G loss: -18.3843]\n",
      "5689 (5, 1) [D loss: (-1.6477)(R -18.3235, F 16.6290, G 0.0047)] [G loss: -17.2737]\n",
      "5690 (5, 1) [D loss: (-0.9625)(R -17.4512, F 16.4490, G 0.0040)] [G loss: -16.4638]\n",
      "5691 (5, 1) [D loss: (-1.1340)(R -16.1285, F 14.9655, G 0.0029)] [G loss: -16.2967]\n",
      "5692 (5, 1) [D loss: (-1.0638)(R -15.3948, F 14.3083, G 0.0023)] [G loss: -14.5514]\n",
      "5693 (5, 1) [D loss: (-0.6046)(R -13.9665, F 13.3377, G 0.0024)] [G loss: -13.1384]\n",
      "5694 (5, 1) [D loss: (-1.6094)(R -12.9718, F 11.3283, G 0.0034)] [G loss: -11.6656]\n",
      "5695 (5, 1) [D loss: (-1.4992)(R -11.4252, F 9.9026, G 0.0023)] [G loss: -10.5559]\n",
      "5696 (5, 1) [D loss: (-1.6018)(R -10.2161, F 8.5906, G 0.0024)] [G loss: -8.8056]\n",
      "5697 (5, 1) [D loss: (-0.6450)(R -8.6591, F 7.9824, G 0.0032)] [G loss: -7.5083]\n",
      "5698 (5, 1) [D loss: (-1.1105)(R -7.1083, F 5.9624, G 0.0035)] [G loss: -5.6843]\n",
      "5699 (5, 1) [D loss: (-0.7529)(R -4.6679, F 3.8870, G 0.0028)] [G loss: -3.9269]\n",
      "5700 (5, 1) [D loss: (-0.9884)(R -3.9235, F 2.9059, G 0.0029)] [G loss: -2.2297]\n",
      "5701 (5, 1) [D loss: (-1.1386)(R -2.7550, F 1.5831, G 0.0033)] [G loss: -1.1513]\n",
      "5702 (5, 1) [D loss: (-1.6521)(R -1.9873, F 0.2856, G 0.0050)] [G loss: 0.2501]\n",
      "5703 (5, 1) [D loss: (-1.6019)(R -1.0745, F -0.5897, G 0.0062)] [G loss: 0.7448]\n",
      "5704 (5, 1) [D loss: (-0.8573)(R 0.3605, F -1.2920, G 0.0074)] [G loss: 1.8857]\n",
      "5705 (5, 1) [D loss: (-1.9974)(R 1.6180, F -3.7048, G 0.0089)] [G loss: 3.9996]\n",
      "5706 (5, 1) [D loss: (-1.3932)(R 3.7800, F -5.3141, G 0.0141)] [G loss: 5.7692]\n",
      "5707 (5, 1) [D loss: (-1.5580)(R 5.8851, F -7.6204, G 0.0177)] [G loss: 7.4990]\n",
      "5708 (5, 1) [D loss: (-1.4961)(R 6.8185, F -8.5287, G 0.0214)] [G loss: 8.1798]\n",
      "5709 (5, 1) [D loss: (-1.2096)(R 7.0393, F -8.4921, G 0.0243)] [G loss: 8.2697]\n",
      "5710 (5, 1) [D loss: (-1.3886)(R 5.8138, F -7.3446, G 0.0142)] [G loss: 6.2597]\n",
      "5711 (5, 1) [D loss: (-0.8700)(R 3.2737, F -4.1877, G 0.0044)] [G loss: 3.8896]\n",
      "5712 (5, 1) [D loss: (-1.5512)(R -0.2660, F -1.3120, G 0.0027)] [G loss: 0.6188]\n",
      "5713 (5, 1) [D loss: (-1.9560)(R -2.1673, F 0.1734, G 0.0038)] [G loss: -1.1515]\n",
      "5714 (5, 1) [D loss: (-2.0568)(R -4.9539, F 2.8315, G 0.0066)] [G loss: -3.8894]\n",
      "5715 (5, 1) [D loss: (-1.6800)(R -7.6111, F 5.8444, G 0.0087)] [G loss: -6.5192]\n",
      "5716 (5, 1) [D loss: (-1.0595)(R -8.0493, F 6.9098, G 0.0080)] [G loss: -6.6147]\n",
      "5717 (5, 1) [D loss: (-1.0965)(R -5.2665, F 4.0983, G 0.0072)] [G loss: -3.7428]\n",
      "5718 (5, 1) [D loss: (-0.9705)(R -1.2379, F 0.1164, G 0.0151)] [G loss: 0.7235]\n",
      "5719 (5, 1) [D loss: (-2.1619)(R 1.6467, F -4.1580, G 0.0349)] [G loss: 3.0993]\n",
      "5720 (5, 1) [D loss: (-1.4059)(R 1.6224, F -3.2792, G 0.0251)] [G loss: 2.1801]\n",
      "5721 (5, 1) [D loss: (-0.6529)(R 0.3570, F -1.1305, G 0.0121)] [G loss: 0.3250]\n",
      "5722 (5, 1) [D loss: (-1.2417)(R -4.3733, F 3.1057, G 0.0026)] [G loss: -3.5666]\n",
      "5723 (5, 1) [D loss: (-1.3433)(R -8.6860, F 7.3272, G 0.0015)] [G loss: -8.2863]\n",
      "5724 (5, 1) [D loss: (-1.1423)(R -10.8868, F 9.7214, G 0.0023)] [G loss: -9.7350]\n",
      "5725 (5, 1) [D loss: (-1.2387)(R -11.9827, F 10.7065, G 0.0037)] [G loss: -10.7190]\n",
      "5726 (5, 1) [D loss: (-1.1093)(R -11.1403, F 10.0040, G 0.0027)] [G loss: -10.6461]\n",
      "5727 (5, 1) [D loss: (-0.7905)(R -10.1836, F 9.3681, G 0.0025)] [G loss: -8.9379]\n",
      "5728 (5, 1) [D loss: (-1.3541)(R -9.0340, F 7.6495, G 0.0030)] [G loss: -8.1925]\n",
      "5729 (5, 1) [D loss: (-0.6973)(R -8.2746, F 7.5419, G 0.0035)] [G loss: -6.7393]\n",
      "5730 (5, 1) [D loss: (-1.0951)(R -6.9850, F 5.8450, G 0.0045)] [G loss: -5.6742]\n",
      "5731 (5, 1) [D loss: (-1.0071)(R -6.4883, F 5.4457, G 0.0035)] [G loss: -5.1124]\n",
      "5732 (5, 1) [D loss: (-0.7337)(R -6.6663, F 5.8942, G 0.0038)] [G loss: -5.7632]\n",
      "5733 (5, 1) [D loss: (-0.8717)(R -7.8707, F 6.9719, G 0.0027)] [G loss: -7.1295]\n",
      "5734 (5, 1) [D loss: (-0.7020)(R -9.4129, F 8.6756, G 0.0035)] [G loss: -8.6816]\n",
      "5735 (5, 1) [D loss: (-1.2020)(R -10.8012, F 9.5410, G 0.0058)] [G loss: -9.9509]\n",
      "5736 (5, 1) [D loss: (-1.3436)(R -12.8162, F 11.3839, G 0.0089)] [G loss: -11.4251]\n",
      "5737 (5, 1) [D loss: (-1.5374)(R -12.5762, F 10.9468, G 0.0092)] [G loss: -10.9881]\n",
      "5738 (5, 1) [D loss: (-1.6968)(R -12.4623, F 10.6844, G 0.0081)] [G loss: -10.8153]\n",
      "5739 (5, 1) [D loss: (-1.6300)(R -11.0920, F 9.4151, G 0.0047)] [G loss: -9.9700]\n",
      "5740 (5, 1) [D loss: (-1.7907)(R -8.6542, F 6.8306, G 0.0033)] [G loss: -6.8358]\n",
      "5741 (5, 1) [D loss: (-1.2078)(R -5.8092, F 4.5724, G 0.0029)] [G loss: -4.2487]\n",
      "5742 (5, 1) [D loss: (-1.4747)(R -4.6049, F 3.0755, G 0.0055)] [G loss: -2.7177]\n",
      "5743 (5, 1) [D loss: (-0.8456)(R -2.4098, F 1.5117, G 0.0052)] [G loss: -1.0551]\n",
      "5744 (5, 1) [D loss: (-1.1862)(R -2.1866, F 0.9479, G 0.0053)] [G loss: -0.5485]\n",
      "5745 (5, 1) [D loss: (-0.9128)(R -1.7141, F 0.7473, G 0.0054)] [G loss: -0.8994]\n",
      "5746 (5, 1) [D loss: (-1.1285)(R -1.7608, F 0.5898, G 0.0043)] [G loss: -0.7036]\n",
      "5747 (5, 1) [D loss: (-0.9303)(R -2.0262, F 1.0525, G 0.0043)] [G loss: -1.0354]\n",
      "5748 (5, 1) [D loss: (-1.7062)(R -4.2328, F 2.4789, G 0.0048)] [G loss: -3.0503]\n",
      "5749 (5, 1) [D loss: (-1.5287)(R -5.0277, F 3.4140, G 0.0085)] [G loss: -3.6511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5750 (5, 1) [D loss: (-1.7319)(R -6.6182, F 4.7826, G 0.0104)] [G loss: -4.9255]\n",
      "5751 (5, 1) [D loss: (-1.4237)(R -5.9985, F 4.4615, G 0.0113)] [G loss: -4.4763]\n",
      "5752 (5, 1) [D loss: (-0.9350)(R -5.4962, F 4.4905, G 0.0071)] [G loss: -4.0843]\n",
      "5753 (5, 1) [D loss: (-1.0103)(R -4.7047, F 3.6465, G 0.0048)] [G loss: -3.8892]\n",
      "5754 (5, 1) [D loss: (-0.7825)(R -4.1094, F 3.2904, G 0.0036)] [G loss: -2.9332]\n",
      "5755 (5, 1) [D loss: (-0.6754)(R -2.8787, F 2.1788, G 0.0025)] [G loss: -2.0725]\n",
      "5756 (5, 1) [D loss: (-0.7591)(R -2.4000, F 1.6037, G 0.0037)] [G loss: -1.5504]\n",
      "5757 (5, 1) [D loss: (-0.5759)(R -1.2553, F 0.6401, G 0.0039)] [G loss: -0.1856]\n",
      "5758 (5, 1) [D loss: (-1.3927)(R -0.7646, F -0.6809, G 0.0053)] [G loss: 0.9903]\n",
      "5759 (5, 1) [D loss: (-1.3222)(R 0.0284, F -1.4032, G 0.0053)] [G loss: 1.3978]\n",
      "5760 (5, 1) [D loss: (-1.3692)(R -0.5327, F -0.8985, G 0.0062)] [G loss: 0.7258]\n",
      "5761 (5, 1) [D loss: (-0.7673)(R -0.3826, F -0.4311, G 0.0046)] [G loss: 0.6126]\n",
      "5762 (5, 1) [D loss: (-1.2281)(R -1.6351, F 0.3580, G 0.0049)] [G loss: -0.3584]\n",
      "5763 (5, 1) [D loss: (-1.1561)(R -2.2861, F 1.0899, G 0.0040)] [G loss: -1.3934]\n",
      "5764 (5, 1) [D loss: (-0.9674)(R -3.2900, F 2.2603, G 0.0062)] [G loss: -2.9159]\n",
      "5765 (5, 1) [D loss: (-1.5519)(R -4.7691, F 3.1450, G 0.0072)] [G loss: -4.0599]\n",
      "5766 (5, 1) [D loss: (-0.8937)(R -6.0139, F 5.0285, G 0.0092)] [G loss: -5.1821]\n",
      "5767 (5, 1) [D loss: (-0.7247)(R -5.0045, F 4.2198, G 0.0060)] [G loss: -3.4457]\n",
      "5768 (5, 1) [D loss: (-0.7932)(R -3.8334, F 2.9749, G 0.0065)] [G loss: -2.6752]\n",
      "5769 (5, 1) [D loss: (-0.9181)(R -3.4187, F 2.4395, G 0.0061)] [G loss: -2.1183]\n",
      "5770 (5, 1) [D loss: (-1.0590)(R -2.6687, F 1.5366, G 0.0073)] [G loss: -1.2439]\n",
      "5771 (5, 1) [D loss: (-0.8128)(R -2.0085, F 1.1442, G 0.0052)] [G loss: -1.1278]\n",
      "5772 (5, 1) [D loss: (-0.8826)(R -1.5697, F 0.6197, G 0.0067)] [G loss: -0.4717]\n",
      "5773 (5, 1) [D loss: (-0.5883)(R -2.5896, F 1.9520, G 0.0049)] [G loss: -2.1334]\n",
      "5774 (5, 1) [D loss: (-0.8516)(R -4.0974, F 3.1991, G 0.0047)] [G loss: -3.3474]\n",
      "5775 (5, 1) [D loss: (-1.3806)(R -5.2066, F 3.7840, G 0.0042)] [G loss: -4.4533]\n",
      "5776 (5, 1) [D loss: (-0.8592)(R -5.9088, F 5.0069, G 0.0043)] [G loss: -5.2252]\n",
      "5777 (5, 1) [D loss: (-1.2648)(R -5.5965, F 4.2954, G 0.0036)] [G loss: -4.5519]\n",
      "5778 (5, 1) [D loss: (-1.0904)(R -5.2198, F 4.0974, G 0.0032)] [G loss: -3.9360]\n",
      "5779 (5, 1) [D loss: (-1.0171)(R -3.9701, F 2.9191, G 0.0034)] [G loss: -2.6440]\n",
      "5780 (5, 1) [D loss: (-1.4056)(R -2.5904, F 1.1527, G 0.0032)] [G loss: -0.7032]\n",
      "5781 (5, 1) [D loss: (-1.4988)(R -0.7624, F -0.7769, G 0.0041)] [G loss: 0.7868]\n",
      "5782 (5, 1) [D loss: (-1.5148)(R 1.4399, F -2.9923, G 0.0038)] [G loss: 3.2159]\n",
      "5783 (5, 1) [D loss: (-1.2902)(R 3.1938, F -4.5357, G 0.0052)] [G loss: 5.0704]\n",
      "5784 (5, 1) [D loss: (-1.9176)(R 4.1778, F -6.1806, G 0.0085)] [G loss: 5.7538]\n",
      "5785 (5, 1) [D loss: (-1.5322)(R 4.9823, F -6.6149, G 0.0100)] [G loss: 6.5549]\n",
      "5786 (5, 1) [D loss: (-0.8245)(R 5.8604, F -6.7661, G 0.0081)] [G loss: 6.6925]\n",
      "5787 (5, 1) [D loss: (-1.3864)(R 5.3866, F -6.8539, G 0.0081)] [G loss: 6.2211]\n",
      "5788 (5, 1) [D loss: (-0.8105)(R 5.2837, F -6.1599, G 0.0066)] [G loss: 5.5827]\n",
      "5789 (5, 1) [D loss: (-1.2294)(R 3.9232, F -5.1910, G 0.0038)] [G loss: 4.8029]\n",
      "5790 (5, 1) [D loss: (-1.2070)(R 2.9638, F -4.2057, G 0.0035)] [G loss: 3.5768]\n",
      "5791 (5, 1) [D loss: (-0.9460)(R 1.3808, F -2.3654, G 0.0039)] [G loss: 2.3087]\n",
      "5792 (5, 1) [D loss: (-1.4860)(R -0.0613, F -1.4736, G 0.0049)] [G loss: 1.0860]\n",
      "5793 (5, 1) [D loss: (-0.9302)(R -0.1556, F -0.8516, G 0.0077)] [G loss: 1.1163]\n",
      "5794 (5, 1) [D loss: (-1.0857)(R -0.0794, F -1.0820, G 0.0076)] [G loss: 0.9324]\n",
      "5795 (5, 1) [D loss: (-1.4191)(R 1.2450, F -2.7543, G 0.0090)] [G loss: 2.4796]\n",
      "5796 (5, 1) [D loss: (-0.8278)(R 3.5335, F -4.4748, G 0.0113)] [G loss: 4.8094]\n",
      "5797 (5, 1) [D loss: (-1.3736)(R 4.7516, F -6.2838, G 0.0159)] [G loss: 5.8862]\n",
      "5798 (5, 1) [D loss: (-0.4698)(R 5.2338, F -5.8510, G 0.0147)] [G loss: 5.3593]\n",
      "5799 (5, 1) [D loss: (-0.7027)(R 4.3394, F -5.1357, G 0.0094)] [G loss: 4.5747]\n",
      "5800 (5, 1) [D loss: (-0.5183)(R 2.8687, F -3.4212, G 0.0034)] [G loss: 3.5362]\n",
      "5801 (5, 1) [D loss: (-0.9852)(R 0.5345, F -1.5443, G 0.0025)] [G loss: 1.4533]\n",
      "5802 (5, 1) [D loss: (-0.8901)(R -1.7737, F 0.8642, G 0.0019)] [G loss: -0.8106]\n",
      "5803 (5, 1) [D loss: (-1.1767)(R -4.4620, F 3.2656, G 0.0020)] [G loss: -3.4109]\n",
      "5804 (5, 1) [D loss: (-1.2013)(R -5.7710, F 4.5292, G 0.0041)] [G loss: -5.0008]\n",
      "5805 (5, 1) [D loss: (-0.9732)(R -7.1770, F 6.1434, G 0.0060)] [G loss: -6.5897]\n",
      "5806 (5, 1) [D loss: (-1.0105)(R -8.3442, F 7.2513, G 0.0082)] [G loss: -7.3108]\n",
      "5807 (5, 1) [D loss: (-1.2269)(R -7.9208, F 6.6540, G 0.0040)] [G loss: -6.5956]\n",
      "5808 (5, 1) [D loss: (-1.1468)(R -7.2832, F 6.0961, G 0.0040)] [G loss: -6.1725]\n",
      "5809 (5, 1) [D loss: (-1.0449)(R -7.3365, F 6.2512, G 0.0040)] [G loss: -5.7815]\n",
      "5810 (5, 1) [D loss: (-1.2099)(R -7.0318, F 5.7743, G 0.0048)] [G loss: -6.0580]\n",
      "5811 (5, 1) [D loss: (-1.1142)(R -7.8189, F 6.6464, G 0.0058)] [G loss: -6.6103]\n",
      "5812 (5, 1) [D loss: (-1.1559)(R -8.0362, F 6.8221, G 0.0058)] [G loss: -7.1624]\n",
      "5813 (5, 1) [D loss: (-1.5971)(R -8.9658, F 7.3143, G 0.0054)] [G loss: -8.4376]\n",
      "5814 (5, 1) [D loss: (-1.5743)(R -10.2814, F 8.6275, G 0.0079)] [G loss: -9.6388]\n",
      "5815 (5, 1) [D loss: (-0.9168)(R -10.3522, F 9.3612, G 0.0074)] [G loss: -9.4748]\n",
      "5816 (5, 1) [D loss: (-1.4692)(R -11.1569, F 9.6113, G 0.0076)] [G loss: -10.7105]\n",
      "5817 (5, 1) [D loss: (-1.4852)(R -11.0654, F 9.5006, G 0.0080)] [G loss: -10.3028]\n",
      "5818 (5, 1) [D loss: (-0.8451)(R -10.3362, F 9.4220, G 0.0069)] [G loss: -9.7735]\n",
      "5819 (5, 1) [D loss: (-1.3424)(R -10.3210, F 8.9315, G 0.0047)] [G loss: -9.3037]\n",
      "5820 (5, 1) [D loss: (-1.2379)(R -9.8277, F 8.5526, G 0.0037)] [G loss: -9.0385]\n",
      "5821 (5, 1) [D loss: (-0.5738)(R -8.3332, F 7.7309, G 0.0029)] [G loss: -7.5025]\n",
      "5822 (5, 1) [D loss: (-0.9180)(R -7.8694, F 6.9231, G 0.0028)] [G loss: -6.8793]\n",
      "5823 (5, 1) [D loss: (-1.0271)(R -6.8400, F 5.7834, G 0.0030)] [G loss: -5.7270]\n",
      "5824 (5, 1) [D loss: (-1.3874)(R -6.1498, F 4.7291, G 0.0033)] [G loss: -5.0810]\n",
      "5825 (5, 1) [D loss: (-1.4999)(R -5.3043, F 3.7747, G 0.0030)] [G loss: -4.0117]\n",
      "5826 (5, 1) [D loss: (-0.8390)(R -4.4730, F 3.5865, G 0.0048)] [G loss: -3.7459]\n",
      "5827 (5, 1) [D loss: (-1.3440)(R -4.4773, F 3.0903, G 0.0043)] [G loss: -3.1661]\n",
      "5828 (5, 1) [D loss: (-1.0214)(R -4.1305, F 3.0596, G 0.0050)] [G loss: -3.3414]\n",
      "5829 (5, 1) [D loss: (-0.7970)(R -3.7997, F 2.9483, G 0.0054)] [G loss: -2.7054]\n",
      "5830 (5, 1) [D loss: (-1.2882)(R -3.9644, F 2.6252, G 0.0051)] [G loss: -2.9271]\n",
      "5831 (5, 1) [D loss: (-0.9085)(R -3.7760, F 2.8294, G 0.0038)] [G loss: -2.8338]\n",
      "5832 (5, 1) [D loss: (-1.4003)(R -3.5576, F 2.1106, G 0.0047)] [G loss: -2.5910]\n",
      "5833 (5, 1) [D loss: (-1.4506)(R -3.6390, F 2.1311, G 0.0057)] [G loss: -2.4205]\n",
      "5834 (5, 1) [D loss: (-1.1399)(R -2.4667, F 1.2797, G 0.0047)] [G loss: -0.8969]\n",
      "5835 (5, 1) [D loss: (-1.5408)(R -1.1446, F -0.4475, G 0.0051)] [G loss: 0.7950]\n",
      "5836 (5, 1) [D loss: (-1.5548)(R 1.4848, F -3.0914, G 0.0052)] [G loss: 3.2234]\n",
      "5837 (5, 1) [D loss: (-1.0951)(R 3.8041, F -5.0034, G 0.0104)] [G loss: 5.4678]\n",
      "5838 (5, 1) [D loss: (-1.8442)(R 5.0685, F -7.0772, G 0.0165)] [G loss: 6.7100]\n",
      "5839 (5, 1) [D loss: (-1.3644)(R 6.2444, F -7.8259, G 0.0217)] [G loss: 7.5382]\n",
      "5840 (5, 1) [D loss: (-1.9414)(R 5.9378, F -8.0446, G 0.0165)] [G loss: 7.1007]\n",
      "5841 (5, 1) [D loss: (-1.9520)(R 5.4998, F -7.5931, G 0.0141)] [G loss: 6.5398]\n",
      "5842 (5, 1) [D loss: (-0.9804)(R 5.0298, F -6.1149, G 0.0105)] [G loss: 5.5428]\n",
      "5843 (5, 1) [D loss: (-0.7977)(R 3.3490, F -4.1839, G 0.0037)] [G loss: 4.0751]\n",
      "5844 (5, 1) [D loss: (-0.7699)(R 3.1050, F -3.9156, G 0.0041)] [G loss: 3.0913]\n",
      "5845 (5, 1) [D loss: (-1.3449)(R 1.8456, F -3.2175, G 0.0027)] [G loss: 2.5314]\n",
      "5846 (5, 1) [D loss: (-1.3817)(R 1.1406, F -2.5691, G 0.0047)] [G loss: 1.8590]\n",
      "5847 (5, 1) [D loss: (-1.1510)(R 0.3894, F -1.5802, G 0.0040)] [G loss: 0.9637]\n",
      "5848 (5, 1) [D loss: (-0.8715)(R 0.1888, F -1.1197, G 0.0059)] [G loss: 1.0597]\n",
      "5849 (5, 1) [D loss: (-1.5108)(R 0.6756, F -2.2769, G 0.0091)] [G loss: 1.9051]\n",
      "5850 (5, 1) [D loss: (-0.9282)(R 1.9012, F -2.9555, G 0.0126)] [G loss: 2.4643]\n",
      "5851 (5, 1) [D loss: (-1.1877)(R 2.7382, F -4.0772, G 0.0151)] [G loss: 3.2522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5852 (5, 1) [D loss: (-1.1255)(R 3.3048, F -4.5860, G 0.0156)] [G loss: 3.6744]\n",
      "5853 (5, 1) [D loss: (-0.9817)(R 2.4820, F -3.5682, G 0.0104)] [G loss: 2.6754]\n",
      "5854 (5, 1) [D loss: (-0.3203)(R 2.4397, F -2.8220, G 0.0062)] [G loss: 2.0504]\n",
      "5855 (5, 1) [D loss: (-0.6765)(R 0.4407, F -1.1513, G 0.0034)] [G loss: 0.2914]\n",
      "5856 (5, 1) [D loss: (-1.0253)(R -1.6140, F 0.5525, G 0.0036)] [G loss: -0.9910]\n",
      "5857 (5, 1) [D loss: (-1.3166)(R -3.6420, F 2.2938, G 0.0032)] [G loss: -3.0747]\n",
      "5858 (5, 1) [D loss: (-0.9992)(R -5.0557, F 4.0320, G 0.0025)] [G loss: -4.3855]\n",
      "5859 (5, 1) [D loss: (-0.7553)(R -6.4956, F 5.7201, G 0.0020)] [G loss: -6.2404]\n",
      "5860 (5, 1) [D loss: (-0.6668)(R -8.6812, F 7.9789, G 0.0035)] [G loss: -7.9470]\n",
      "5861 (5, 1) [D loss: (-0.7419)(R -9.5427, F 8.7498, G 0.0051)] [G loss: -8.6422]\n",
      "5862 (5, 1) [D loss: (-0.9855)(R -10.4522, F 9.4095, G 0.0057)] [G loss: -9.3060]\n",
      "5863 (5, 1) [D loss: (-0.8056)(R -10.8441, F 9.9898, G 0.0049)] [G loss: -9.5946]\n",
      "5864 (5, 1) [D loss: (-1.1318)(R -11.1247, F 9.9439, G 0.0049)] [G loss: -9.8850]\n",
      "5865 (5, 1) [D loss: (-0.6002)(R -10.4647, F 9.8154, G 0.0049)] [G loss: -9.8270]\n",
      "5866 (5, 1) [D loss: (-1.4808)(R -11.1522, F 9.6173, G 0.0054)] [G loss: -9.9606]\n",
      "5867 (5, 1) [D loss: (-1.0889)(R -11.4038, F 10.2521, G 0.0063)] [G loss: -10.0598]\n",
      "5868 (5, 1) [D loss: (-1.1741)(R -12.1290, F 10.8887, G 0.0066)] [G loss: -11.3217]\n",
      "5869 (5, 1) [D loss: (-1.2220)(R -12.6808, F 11.3914, G 0.0067)] [G loss: -11.0445]\n",
      "5870 (5, 1) [D loss: (-1.4307)(R -13.8570, F 12.3443, G 0.0082)] [G loss: -12.6320]\n",
      "5871 (5, 1) [D loss: (-1.2975)(R -13.6501, F 12.2899, G 0.0063)] [G loss: -12.8920]\n",
      "5872 (5, 1) [D loss: (-1.1060)(R -14.2802, F 13.1080, G 0.0066)] [G loss: -13.6087]\n",
      "5873 (5, 1) [D loss: (-1.6387)(R -15.0601, F 13.3570, G 0.0064)] [G loss: -14.1536]\n",
      "5874 (5, 1) [D loss: (-0.9306)(R -15.5899, F 14.5674, G 0.0092)] [G loss: -14.8715]\n",
      "5875 (5, 1) [D loss: (-1.2945)(R -15.5725, F 14.2152, G 0.0063)] [G loss: -14.4769]\n",
      "5876 (5, 1) [D loss: (-1.4693)(R -15.7338, F 14.2075, G 0.0057)] [G loss: -14.7606]\n",
      "5877 (5, 1) [D loss: (-0.8392)(R -15.7230, F 14.8227, G 0.0061)] [G loss: -14.8605]\n",
      "5878 (5, 1) [D loss: (-1.2108)(R -14.9997, F 13.7472, G 0.0042)] [G loss: -14.2458]\n",
      "5879 (5, 1) [D loss: (-0.9232)(R -14.5643, F 13.6078, G 0.0033)] [G loss: -13.4717]\n",
      "5880 (5, 1) [D loss: (-1.2938)(R -13.7870, F 12.4560, G 0.0037)] [G loss: -12.5338]\n",
      "5881 (5, 1) [D loss: (-0.6136)(R -12.3827, F 11.7329, G 0.0036)] [G loss: -11.5303]\n",
      "5882 (5, 1) [D loss: (-0.9833)(R -11.2949, F 10.2736, G 0.0038)] [G loss: -10.2502]\n",
      "5883 (5, 1) [D loss: (-0.8134)(R -10.2307, F 9.3786, G 0.0039)] [G loss: -9.5592]\n",
      "5884 (5, 1) [D loss: (-1.3473)(R -10.4822, F 9.0962, G 0.0039)] [G loss: -9.4434]\n",
      "5885 (5, 1) [D loss: (-1.3611)(R -9.8939, F 8.4928, G 0.0040)] [G loss: -8.8390]\n",
      "5886 (5, 1) [D loss: (-1.3614)(R -9.4904, F 8.0934, G 0.0036)] [G loss: -8.6008]\n",
      "5887 (5, 1) [D loss: (-1.3912)(R -8.9673, F 7.5369, G 0.0039)] [G loss: -8.0750]\n",
      "5888 (5, 1) [D loss: (-0.7305)(R -8.6953, F 7.9129, G 0.0052)] [G loss: -8.3327]\n",
      "5889 (5, 1) [D loss: (-1.0486)(R -8.9421, F 7.8380, G 0.0056)] [G loss: -8.4681]\n",
      "5890 (5, 1) [D loss: (-1.0233)(R -9.0165, F 7.9480, G 0.0045)] [G loss: -8.3675]\n",
      "5891 (5, 1) [D loss: (-1.2174)(R -9.1047, F 7.8430, G 0.0044)] [G loss: -8.3390]\n",
      "5892 (5, 1) [D loss: (-1.2164)(R -9.6963, F 8.4188, G 0.0061)] [G loss: -8.8215]\n",
      "5893 (5, 1) [D loss: (-1.3233)(R -8.9337, F 7.5705, G 0.0040)] [G loss: -7.9095]\n",
      "5894 (5, 1) [D loss: (-0.8198)(R -8.6458, F 7.7889, G 0.0037)] [G loss: -7.9802]\n",
      "5895 (5, 1) [D loss: (-0.9945)(R -7.8445, F 6.8081, G 0.0042)] [G loss: -6.6887]\n",
      "5896 (5, 1) [D loss: (-0.7945)(R -6.5716, F 5.7394, G 0.0038)] [G loss: -5.6611]\n",
      "5897 (5, 1) [D loss: (-0.7828)(R -5.5325, F 4.7144, G 0.0035)] [G loss: -4.6312]\n",
      "5898 (5, 1) [D loss: (-0.7474)(R -4.5243, F 3.7326, G 0.0044)] [G loss: -3.3244]\n",
      "5899 (5, 1) [D loss: (-1.0172)(R -3.1942, F 2.1427, G 0.0034)] [G loss: -1.8375]\n",
      "5900 (5, 1) [D loss: (-0.9138)(R -2.0599, F 1.1057, G 0.0040)] [G loss: -1.0724]\n",
      "5901 (5, 1) [D loss: (-0.7300)(R -0.9265, F 0.1546, G 0.0042)] [G loss: 0.2967]\n",
      "5902 (5, 1) [D loss: (-1.0024)(R -0.4081, F -0.6480, G 0.0054)] [G loss: 1.3690]\n",
      "5903 (5, 1) [D loss: (-1.4763)(R 0.2924, F -1.8183, G 0.0050)] [G loss: 2.0986]\n",
      "5904 (5, 1) [D loss: (-1.3472)(R 1.0726, F -2.4796, G 0.0060)] [G loss: 2.8471]\n",
      "5905 (5, 1) [D loss: (-0.8929)(R 1.7388, F -2.6922, G 0.0060)] [G loss: 3.0338]\n",
      "5906 (5, 1) [D loss: (-1.5244)(R 1.9535, F -3.5348, G 0.0057)] [G loss: 3.4400]\n",
      "5907 (5, 1) [D loss: (-0.8273)(R 2.6941, F -3.5952, G 0.0074)] [G loss: 3.7607]\n",
      "5908 (5, 1) [D loss: (-1.3766)(R 2.4026, F -3.8516, G 0.0072)] [G loss: 3.9818]\n",
      "5909 (5, 1) [D loss: (-1.2272)(R 3.0090, F -4.3127, G 0.0077)] [G loss: 4.2193]\n",
      "5910 (5, 1) [D loss: (-1.5090)(R 3.1620, F -4.7532, G 0.0082)] [G loss: 4.4795]\n",
      "5911 (5, 1) [D loss: (-1.2368)(R 4.5108, F -5.8639, G 0.0116)] [G loss: 5.7757]\n",
      "5912 (5, 1) [D loss: (-1.4692)(R 4.7468, F -6.3797, G 0.0164)] [G loss: 6.3489]\n",
      "5913 (5, 1) [D loss: (-2.0317)(R 4.1733, F -6.3289, G 0.0124)] [G loss: 5.4470]\n",
      "5914 (5, 1) [D loss: (-1.6945)(R 4.6931, F -6.5228, G 0.0135)] [G loss: 6.1427]\n",
      "5915 (5, 1) [D loss: (-1.4127)(R 5.8768, F -7.4542, G 0.0165)] [G loss: 6.6373]\n",
      "5916 (5, 1) [D loss: (-1.6980)(R 5.3781, F -7.2132, G 0.0137)] [G loss: 6.1713]\n",
      "5917 (5, 1) [D loss: (-1.7561)(R 4.5638, F -6.4254, G 0.0106)] [G loss: 5.4031]\n",
      "5918 (5, 1) [D loss: (-0.8902)(R 4.9604, F -5.9374, G 0.0087)] [G loss: 5.3166]\n",
      "5919 (5, 1) [D loss: (-1.4247)(R 3.6434, F -5.1254, G 0.0057)] [G loss: 4.4509]\n",
      "5920 (5, 1) [D loss: (-1.6491)(R 3.3543, F -5.0477, G 0.0044)] [G loss: 3.7081]\n",
      "5921 (5, 1) [D loss: (-1.7853)(R 3.0705, F -4.9012, G 0.0045)] [G loss: 3.6284]\n",
      "5922 (5, 1) [D loss: (-0.9834)(R 2.3309, F -3.3471, G 0.0033)] [G loss: 2.6464]\n",
      "5923 (5, 1) [D loss: (-0.8302)(R 3.3966, F -4.2733, G 0.0046)] [G loss: 3.3510]\n",
      "5924 (5, 1) [D loss: (-1.0410)(R 3.0123, F -4.1076, G 0.0054)] [G loss: 3.6109]\n",
      "5925 (5, 1) [D loss: (-0.7566)(R 3.2171, F -4.0339, G 0.0060)] [G loss: 3.4074]\n",
      "5926 (5, 1) [D loss: (-0.8792)(R 2.0286, F -2.9382, G 0.0030)] [G loss: 2.4504]\n",
      "5927 (5, 1) [D loss: (-0.1088)(R 0.8094, F -0.9420, G 0.0024)] [G loss: 0.8053]\n",
      "5928 (5, 1) [D loss: (-0.8160)(R 0.4647, F -1.3068, G 0.0026)] [G loss: 0.9191]\n",
      "5929 (5, 1) [D loss: (-0.4153)(R -0.0377, F -0.4033, G 0.0026)] [G loss: 0.0193]\n",
      "5930 (5, 1) [D loss: (-0.8111)(R -1.4613, F 0.6296, G 0.0021)] [G loss: -0.8778]\n",
      "5931 (5, 1) [D loss: (-0.9176)(R -1.8837, F 0.9367, G 0.0029)] [G loss: -1.2697]\n",
      "5932 (5, 1) [D loss: (-0.6999)(R -2.2746, F 1.5451, G 0.0030)] [G loss: -1.9084]\n",
      "5933 (5, 1) [D loss: (-0.7999)(R -3.4670, F 2.6340, G 0.0033)] [G loss: -2.8057]\n",
      "5934 (5, 1) [D loss: (-0.7305)(R -3.9806, F 3.2184, G 0.0032)] [G loss: -2.5602]\n",
      "5935 (5, 1) [D loss: (-0.6026)(R -4.6798, F 4.0287, G 0.0049)] [G loss: -3.9425]\n",
      "5936 (5, 1) [D loss: (-1.0019)(R -5.8762, F 4.8188, G 0.0055)] [G loss: -4.5666]\n",
      "5937 (5, 1) [D loss: (-0.9019)(R -6.0305, F 5.0823, G 0.0046)] [G loss: -5.4267]\n",
      "5938 (5, 1) [D loss: (-0.9834)(R -8.2071, F 7.1566, G 0.0067)] [G loss: -7.1839]\n",
      "5939 (5, 1) [D loss: (-1.6271)(R -9.6971, F 7.9969, G 0.0073)] [G loss: -8.0291]\n",
      "5940 (5, 1) [D loss: (-0.9667)(R -9.9546, F 8.9041, G 0.0084)] [G loss: -9.1074]\n",
      "5941 (5, 1) [D loss: (-1.3450)(R -11.0296, F 9.5939, G 0.0091)] [G loss: -9.7883]\n",
      "5942 (5, 1) [D loss: (-1.0758)(R -12.6589, F 11.4609, G 0.0122)] [G loss: -11.4498]\n",
      "5943 (5, 1) [D loss: (-1.1808)(R -13.8611, F 12.5329, G 0.0147)] [G loss: -12.6136]\n",
      "5944 (5, 1) [D loss: (-1.2441)(R -15.1495, F 13.7587, G 0.0147)] [G loss: -13.2513]\n",
      "5945 (5, 1) [D loss: (-1.6710)(R -15.3215, F 13.5330, G 0.0117)] [G loss: -14.1477]\n",
      "5946 (5, 1) [D loss: (-1.6441)(R -15.2376, F 13.4909, G 0.0103)] [G loss: -14.1961]\n",
      "5947 (5, 1) [D loss: (-1.1860)(R -15.3080, F 14.0214, G 0.0101)] [G loss: -14.4688]\n",
      "5948 (5, 1) [D loss: (-1.9219)(R -15.5881, F 13.5709, G 0.0095)] [G loss: -14.8948]\n",
      "5949 (5, 1) [D loss: (-1.2342)(R -14.8828, F 13.5739, G 0.0075)] [G loss: -14.1519]\n",
      "5950 (5, 1) [D loss: (-1.8136)(R -14.6092, F 12.7398, G 0.0056)] [G loss: -14.0537]\n",
      "5951 (5, 1) [D loss: (-1.4198)(R -15.1605, F 13.6361, G 0.0105)] [G loss: -14.7422]\n",
      "5952 (5, 1) [D loss: (-1.8400)(R -15.0506, F 13.1425, G 0.0068)] [G loss: -14.1422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5953 (5, 1) [D loss: (-1.5162)(R -14.4862, F 12.9041, G 0.0066)] [G loss: -14.0253]\n",
      "5954 (5, 1) [D loss: (-1.3863)(R -14.8676, F 13.4064, G 0.0075)] [G loss: -13.9705]\n",
      "5955 (5, 1) [D loss: (-1.3051)(R -14.3392, F 12.9706, G 0.0063)] [G loss: -14.0341]\n",
      "5956 (5, 1) [D loss: (-1.6786)(R -13.8991, F 12.1689, G 0.0052)] [G loss: -13.2104]\n",
      "5957 (5, 1) [D loss: (-1.2991)(R -12.8608, F 11.5218, G 0.0040)] [G loss: -12.0118]\n",
      "5958 (5, 1) [D loss: (-1.4588)(R -12.5049, F 11.0023, G 0.0044)] [G loss: -12.2281]\n",
      "5959 (5, 1) [D loss: (-1.2952)(R -11.8862, F 10.5575, G 0.0033)] [G loss: -11.0600]\n",
      "5960 (5, 1) [D loss: (-1.2991)(R -11.4387, F 10.1014, G 0.0038)] [G loss: -10.9858]\n",
      "5961 (5, 1) [D loss: (-0.8877)(R -10.5090, F 9.5830, G 0.0038)] [G loss: -10.1443]\n",
      "5962 (5, 1) [D loss: (-0.6900)(R -9.7227, F 8.9992, G 0.0034)] [G loss: -9.1926]\n",
      "5963 (5, 1) [D loss: (-0.4110)(R -8.9294, F 8.4864, G 0.0032)] [G loss: -8.3546]\n",
      "5964 (5, 1) [D loss: (-0.3398)(R -8.0834, F 7.7128, G 0.0031)] [G loss: -7.4837]\n",
      "5965 (5, 1) [D loss: (-0.5173)(R -7.4297, F 6.8791, G 0.0033)] [G loss: -7.0595]\n",
      "5966 (5, 1) [D loss: (-1.0250)(R -6.6605, F 5.6049, G 0.0031)] [G loss: -6.0042]\n",
      "5967 (5, 1) [D loss: (-0.9976)(R -5.7926, F 4.7648, G 0.0030)] [G loss: -4.7319]\n",
      "5968 (5, 1) [D loss: (-1.1212)(R -5.3861, F 4.2209, G 0.0044)] [G loss: -4.2904]\n",
      "5969 (5, 1) [D loss: (-0.7952)(R -4.3096, F 3.4734, G 0.0041)] [G loss: -3.5160]\n",
      "5970 (5, 1) [D loss: (-1.1300)(R -4.0223, F 2.8528, G 0.0039)] [G loss: -2.6440]\n",
      "5971 (5, 1) [D loss: (-1.0962)(R -3.1019, F 1.9679, G 0.0038)] [G loss: -1.6882]\n",
      "5972 (5, 1) [D loss: (-1.3839)(R -2.1104, F 0.6839, G 0.0043)] [G loss: -0.4395]\n",
      "5973 (5, 1) [D loss: (-1.2152)(R -1.3461, F 0.0855, G 0.0045)] [G loss: 0.3193]\n",
      "5974 (5, 1) [D loss: (-0.9946)(R -0.5969, F -0.4497, G 0.0052)] [G loss: 0.8887]\n",
      "5975 (5, 1) [D loss: (-1.0325)(R 0.1376, F -1.2235, G 0.0053)] [G loss: 1.6058]\n",
      "5976 (5, 1) [D loss: (-1.5101)(R 0.6850, F -2.2402, G 0.0045)] [G loss: 2.5938]\n",
      "5977 (5, 1) [D loss: (-1.2400)(R 1.7281, F -3.0279, G 0.0060)] [G loss: 3.2952]\n",
      "5978 (5, 1) [D loss: (-1.3775)(R 2.4006, F -3.8414, G 0.0063)] [G loss: 4.3501]\n",
      "5979 (5, 1) [D loss: (-1.2509)(R 3.2300, F -4.5703, G 0.0089)] [G loss: 4.8323]\n",
      "5980 (5, 1) [D loss: (-1.5513)(R 3.6404, F -5.2684, G 0.0077)] [G loss: 5.1102]\n",
      "5981 (5, 1) [D loss: (-1.5994)(R 3.8521, F -5.5340, G 0.0083)] [G loss: 5.1172]\n",
      "5982 (5, 1) [D loss: (-1.8155)(R 4.2936, F -6.2072, G 0.0098)] [G loss: 6.0317]\n",
      "5983 (5, 1) [D loss: (-1.9341)(R 5.2689, F -7.3478, G 0.0145)] [G loss: 6.7149]\n",
      "5984 (5, 1) [D loss: (-2.0588)(R 5.4967, F -7.7016, G 0.0146)] [G loss: 6.8300]\n",
      "5985 (5, 1) [D loss: (-1.6475)(R 5.9735, F -7.7694, G 0.0148)] [G loss: 6.7319]\n",
      "5986 (5, 1) [D loss: (-1.9104)(R 5.7972, F -7.8697, G 0.0162)] [G loss: 6.9405]\n",
      "5987 (5, 1) [D loss: (-1.9924)(R 5.9798, F -8.1535, G 0.0181)] [G loss: 6.8780]\n",
      "5988 (5, 1) [D loss: (-1.6730)(R 5.9341, F -7.7598, G 0.0153)] [G loss: 6.3504]\n",
      "5989 (5, 1) [D loss: (-2.0182)(R 5.4819, F -7.6108, G 0.0111)] [G loss: 6.3447]\n",
      "5990 (5, 1) [D loss: (-1.8168)(R 5.2865, F -7.2220, G 0.0119)] [G loss: 6.0651]\n",
      "5991 (5, 1) [D loss: (-1.4461)(R 5.5085, F -7.0686, G 0.0114)] [G loss: 5.1604]\n",
      "5992 (5, 1) [D loss: (-0.1668)(R 4.6770, F -4.8905, G 0.0047)] [G loss: 4.0283]\n",
      "5993 (5, 1) [D loss: (-1.4655)(R 2.8831, F -4.3762, G 0.0028)] [G loss: 3.0516]\n",
      "5994 (5, 1) [D loss: (-1.1271)(R 2.5942, F -3.7470, G 0.0026)] [G loss: 2.2016]\n",
      "5995 (5, 1) [D loss: (-1.0186)(R 1.9026, F -2.9550, G 0.0034)] [G loss: 1.9563]\n",
      "5996 (5, 1) [D loss: (-0.9236)(R 2.1967, F -3.1603, G 0.0040)] [G loss: 2.1218]\n",
      "5997 (5, 1) [D loss: (-0.9059)(R 1.7137, F -2.6647, G 0.0045)] [G loss: 1.5467]\n",
      "5998 (5, 1) [D loss: (-1.2181)(R 1.3885, F -2.6504, G 0.0044)] [G loss: 1.3862]\n",
      "5999 (5, 1) [D loss: (-0.4488)(R 1.7158, F -2.2110, G 0.0046)] [G loss: 0.9352]\n",
      "6000 (5, 1) [D loss: (0.0769)(R 1.7633, F -1.7316, G 0.0045)] [G loss: 0.9233]\n",
      "6001 (5, 1) [D loss: (-0.9739)(R 0.4588, F -1.4593, G 0.0027)] [G loss: 0.6443]\n",
      "6002 (5, 1) [D loss: (-0.8000)(R -0.9949, F 0.1675, G 0.0027)] [G loss: -1.0219]\n",
      "6003 (5, 1) [D loss: (-0.8988)(R -2.4074, F 1.4862, G 0.0022)] [G loss: -2.1022]\n",
      "6004 (5, 1) [D loss: (-0.7910)(R -3.5926, F 2.7759, G 0.0026)] [G loss: -3.5122]\n",
      "6005 (5, 1) [D loss: (-1.3573)(R -4.8238, F 3.4354, G 0.0031)] [G loss: -4.1471]\n",
      "6006 (5, 1) [D loss: (-0.3734)(R -6.5254, F 6.1183, G 0.0034)] [G loss: -6.2187]\n",
      "6007 (5, 1) [D loss: (-0.9952)(R -8.6478, F 7.6133, G 0.0039)] [G loss: -8.2023]\n",
      "6008 (5, 1) [D loss: (-1.2954)(R -11.0246, F 9.6707, G 0.0059)] [G loss: -10.5027]\n",
      "6009 (5, 1) [D loss: (-1.1793)(R -14.5923, F 13.3339, G 0.0079)] [G loss: -13.3189]\n",
      "6010 (5, 1) [D loss: (-1.1257)(R -16.4893, F 15.2776, G 0.0086)] [G loss: -15.1081]\n",
      "6011 (5, 1) [D loss: (-2.1870)(R -18.5596, F 16.2807, G 0.0092)] [G loss: -16.9599]\n",
      "6012 (5, 1) [D loss: (-1.4028)(R -20.4460, F 18.8671, G 0.0176)] [G loss: -18.7565]\n",
      "6013 (5, 1) [D loss: (-1.4940)(R -21.7666, F 20.1080, G 0.0165)] [G loss: -19.4711]\n",
      "6014 (5, 1) [D loss: (-1.3958)(R -21.5020, F 19.9461, G 0.0160)] [G loss: -19.9552]\n",
      "6015 (5, 1) [D loss: (-1.9823)(R -23.0792, F 20.8896, G 0.0207)] [G loss: -21.3989]\n",
      "6016 (5, 1) [D loss: (-1.7263)(R -23.8748, F 21.9201, G 0.0228)] [G loss: -22.2504]\n",
      "6017 (5, 1) [D loss: (-1.1442)(R -24.1575, F 22.8210, G 0.0192)] [G loss: -22.8357]\n",
      "6018 (5, 1) [D loss: (-1.4398)(R -24.5248, F 22.9066, G 0.0178)] [G loss: -23.3500]\n",
      "6019 (5, 1) [D loss: (-1.2755)(R -23.5489, F 22.1433, G 0.0130)] [G loss: -22.7340]\n",
      "6020 (5, 1) [D loss: (-1.5184)(R -23.4402, F 21.8112, G 0.0111)] [G loss: -23.0791]\n",
      "6021 (5, 1) [D loss: (-1.8565)(R -23.9162, F 21.9264, G 0.0133)] [G loss: -23.0398]\n",
      "6022 (5, 1) [D loss: (-1.8974)(R -23.6971, F 21.7014, G 0.0098)] [G loss: -22.4273]\n",
      "6023 (5, 1) [D loss: (-1.1179)(R -22.2783, F 21.0617, G 0.0099)] [G loss: -21.8009]\n",
      "6024 (5, 1) [D loss: (-1.1109)(R -20.7462, F 19.5824, G 0.0053)] [G loss: -20.7802]\n",
      "6025 (5, 1) [D loss: (-1.9090)(R -20.4491, F 18.5051, G 0.0035)] [G loss: -20.5109]\n",
      "6026 (5, 1) [D loss: (-1.2012)(R -19.5481, F 18.2992, G 0.0048)] [G loss: -19.2397]\n",
      "6027 (5, 1) [D loss: (-2.0031)(R -19.5949, F 17.5544, G 0.0037)] [G loss: -19.1991]\n",
      "6028 (5, 1) [D loss: (-1.6097)(R -19.4389, F 17.7744, G 0.0055)] [G loss: -18.8280]\n",
      "6029 (5, 1) [D loss: (-1.3660)(R -18.9310, F 17.5189, G 0.0046)] [G loss: -18.6455]\n",
      "6030 (5, 1) [D loss: (-0.9195)(R -17.7556, F 16.7994, G 0.0037)] [G loss: -17.3019]\n",
      "6031 (5, 1) [D loss: (-1.3707)(R -16.2541, F 14.8585, G 0.0025)] [G loss: -16.1169]\n",
      "6032 (5, 1) [D loss: (-0.6324)(R -14.9858, F 14.3303, G 0.0023)] [G loss: -14.7839]\n",
      "6033 (5, 1) [D loss: (-1.1261)(R -13.5386, F 12.3909, G 0.0022)] [G loss: -13.1703]\n",
      "6034 (5, 1) [D loss: (-1.0124)(R -12.8268, F 11.7962, G 0.0018)] [G loss: -12.2826]\n",
      "6035 (5, 1) [D loss: (-1.2824)(R -12.2908, F 10.9844, G 0.0024)] [G loss: -11.2244]\n",
      "6036 (5, 1) [D loss: (-0.4652)(R -10.6984, F 10.2084, G 0.0025)] [G loss: -9.9945]\n",
      "6037 (5, 1) [D loss: (-0.6737)(R -9.7129, F 9.0071, G 0.0032)] [G loss: -8.8150]\n",
      "6038 (5, 1) [D loss: (-1.1695)(R -8.9331, F 7.7375, G 0.0026)] [G loss: -7.7648]\n",
      "6039 (5, 1) [D loss: (-1.0465)(R -8.1919, F 7.1131, G 0.0032)] [G loss: -7.0549]\n",
      "6040 (5, 1) [D loss: (-0.9469)(R -7.2096, F 6.2291, G 0.0034)] [G loss: -5.9007]\n",
      "6041 (5, 1) [D loss: (-0.9128)(R -6.0402, F 5.0812, G 0.0046)] [G loss: -4.8099]\n",
      "6042 (5, 1) [D loss: (-1.0723)(R -5.6129, F 4.4845, G 0.0056)] [G loss: -4.5575]\n",
      "6043 (5, 1) [D loss: (-0.9094)(R -4.9980, F 4.0435, G 0.0045)] [G loss: -3.7378]\n",
      "6044 (5, 1) [D loss: (-1.2484)(R -4.8615, F 3.5697, G 0.0043)] [G loss: -3.6277]\n",
      "6045 (5, 1) [D loss: (-1.4568)(R -4.6532, F 3.1525, G 0.0044)] [G loss: -3.0905]\n",
      "6046 (5, 1) [D loss: (-1.3370)(R -4.0280, F 2.6394, G 0.0051)] [G loss: -2.3060]\n",
      "6047 (5, 1) [D loss: (-1.5976)(R -2.7295, F 1.0748, G 0.0057)] [G loss: -0.6727]\n",
      "6048 (5, 1) [D loss: (-1.1597)(R -1.6653, F 0.4345, G 0.0071)] [G loss: -0.1438]\n",
      "6049 (5, 1) [D loss: (-1.6644)(R -1.3812, F -0.3408, G 0.0058)] [G loss: 0.3528]\n",
      "6050 (5, 1) [D loss: (-1.2055)(R -0.0395, F -1.2267, G 0.0061)] [G loss: 1.5945]\n",
      "6051 (5, 1) [D loss: (-1.4539)(R 0.2849, F -1.8009, G 0.0062)] [G loss: 1.8291]\n",
      "6052 (5, 1) [D loss: (-0.9246)(R 0.5144, F -1.4890, G 0.0050)] [G loss: 1.4016]\n",
      "6053 (5, 1) [D loss: (-1.3520)(R 1.0192, F -2.4136, G 0.0042)] [G loss: 2.5684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6054 (5, 1) [D loss: (-1.6249)(R 1.3346, F -3.0215, G 0.0062)] [G loss: 3.0865]\n",
      "6055 (5, 1) [D loss: (-2.0305)(R 2.1644, F -4.2976, G 0.0103)] [G loss: 4.3260]\n",
      "6056 (5, 1) [D loss: (-2.2351)(R 3.9932, F -6.4389, G 0.0211)] [G loss: 5.9129]\n",
      "6057 (5, 1) [D loss: (-2.9745)(R 4.4706, F -7.7375, G 0.0292)] [G loss: 6.8295]\n",
      "6058 (5, 1) [D loss: (-3.3848)(R 4.0264, F -7.6880, G 0.0277)] [G loss: 6.3666]\n",
      "6059 (5, 1) [D loss: (-1.8724)(R 4.7284, F -6.8782, G 0.0277)] [G loss: 6.0561]\n",
      "6060 (5, 1) [D loss: (-1.7178)(R 4.8755, F -6.8291, G 0.0236)] [G loss: 5.3026]\n",
      "6061 (5, 1) [D loss: (-1.7355)(R 4.2216, F -6.1080, G 0.0151)] [G loss: 4.4642]\n",
      "6062 (5, 1) [D loss: (-1.4722)(R 4.0238, F -5.6201, G 0.0124)] [G loss: 4.1635]\n",
      "6063 (5, 1) [D loss: (-0.6700)(R 3.2759, F -4.0077, G 0.0062)] [G loss: 2.9977]\n",
      "6064 (5, 1) [D loss: (-1.7119)(R 1.5143, F -3.2544, G 0.0028)] [G loss: 2.0962]\n",
      "6065 (5, 1) [D loss: (-2.0905)(R 1.6592, F -3.7980, G 0.0048)] [G loss: 2.4195]\n",
      "6066 (5, 1) [D loss: (-2.3069)(R 3.0994, F -5.5296, G 0.0123)] [G loss: 3.8558]\n",
      "6067 (5, 1) [D loss: (-2.1428)(R 2.4439, F -4.7104, G 0.0124)] [G loss: 3.3093]\n",
      "6068 (5, 1) [D loss: (-1.6750)(R 2.4946, F -4.2936, G 0.0124)] [G loss: 2.8417]\n",
      "6069 (5, 1) [D loss: (-1.6747)(R 0.9883, F -2.7584, G 0.0095)] [G loss: 1.4007]\n",
      "6070 (5, 1) [D loss: (-0.9631)(R 1.3661, F -2.4189, G 0.0090)] [G loss: 1.2338]\n",
      "6071 (5, 1) [D loss: (-0.8699)(R 0.3795, F -1.3078, G 0.0058)] [G loss: 0.1632]\n",
      "6072 (5, 1) [D loss: (-0.8988)(R -1.2447, F 0.3216, G 0.0024)] [G loss: -1.3539]\n",
      "6073 (5, 1) [D loss: (-0.2626)(R -0.2062, F -0.0896, G 0.0033)] [G loss: -0.7257]\n",
      "6074 (5, 1) [D loss: (-0.6146)(R -0.4289, F -0.2122, G 0.0027)] [G loss: -0.2338]\n",
      "6075 (5, 1) [D loss: (-0.4280)(R 0.5600, F -1.0253, G 0.0037)] [G loss: 0.2040]\n",
      "6076 (5, 1) [D loss: (-0.6677)(R -0.1874, F -0.5157, G 0.0035)] [G loss: -0.0651]\n",
      "6077 (5, 1) [D loss: (-1.4078)(R -2.0094, F 0.5814, G 0.0020)] [G loss: -1.4378]\n",
      "6078 (5, 1) [D loss: (-1.2624)(R -3.4757, F 2.1870, G 0.0026)] [G loss: -2.7634]\n",
      "6079 (5, 1) [D loss: (-1.1776)(R -5.6293, F 4.4267, G 0.0025)] [G loss: -5.1984]\n",
      "6080 (5, 1) [D loss: (-1.2415)(R -7.7354, F 6.4670, G 0.0027)] [G loss: -7.0277]\n",
      "6081 (5, 1) [D loss: (-1.0913)(R -9.9408, F 8.8213, G 0.0028)] [G loss: -9.1710]\n",
      "6082 (5, 1) [D loss: (-0.9421)(R -13.8241, F 12.8491, G 0.0033)] [G loss: -12.9808]\n",
      "6083 (5, 1) [D loss: (-1.7121)(R -17.3710, F 15.6003, G 0.0059)] [G loss: -15.6782]\n",
      "6084 (5, 1) [D loss: (-1.5731)(R -19.9789, F 18.3182, G 0.0088)] [G loss: -18.4387]\n",
      "6085 (5, 1) [D loss: (-2.4853)(R -22.4663, F 19.8695, G 0.0111)] [G loss: -20.7863]\n",
      "6086 (5, 1) [D loss: (-2.1514)(R -23.7805, F 21.5061, G 0.0123)] [G loss: -21.1317]\n",
      "6087 (5, 1) [D loss: (-1.4831)(R -23.0974, F 21.4963, G 0.0118)] [G loss: -21.2555]\n",
      "6088 (5, 1) [D loss: (-1.4635)(R -24.5429, F 22.9377, G 0.0142)] [G loss: -22.6878]\n",
      "6089 (5, 1) [D loss: (-1.2644)(R -24.0172, F 22.5935, G 0.0159)] [G loss: -21.7986]\n",
      "6090 (5, 1) [D loss: (-1.5101)(R -25.1894, F 23.5042, G 0.0175)] [G loss: -23.4794]\n",
      "6091 (5, 1) [D loss: (-2.5877)(R -26.0034, F 23.2374, G 0.0178)] [G loss: -24.0561]\n",
      "6092 (5, 1) [D loss: (-2.2418)(R -25.7498, F 23.3583, G 0.0150)] [G loss: -24.6629]\n",
      "6093 (5, 1) [D loss: (-2.0873)(R -26.5541, F 24.2881, G 0.0179)] [G loss: -25.8794]\n",
      "6094 (5, 1) [D loss: (-1.8246)(R -25.9083, F 23.9550, G 0.0129)] [G loss: -25.0173]\n",
      "6095 (5, 1) [D loss: (-2.2786)(R -25.5076, F 23.1254, G 0.0104)] [G loss: -24.4875]\n",
      "6096 (5, 1) [D loss: (-1.8272)(R -23.1460, F 21.2662, G 0.0053)] [G loss: -22.4146]\n",
      "6097 (5, 1) [D loss: (-1.0428)(R -21.3981, F 20.3268, G 0.0028)] [G loss: -20.6991]\n",
      "6098 (5, 1) [D loss: (-1.4021)(R -18.5888, F 17.1751, G 0.0012)] [G loss: -17.1743]\n",
      "6099 (5, 1) [D loss: (-0.3296)(R -15.5041, F 15.1558, G 0.0019)] [G loss: -14.3611]\n",
      "6100 (5, 1) [D loss: (-1.3010)(R -13.2583, F 11.9420, G 0.0015)] [G loss: -11.6146]\n",
      "6101 (5, 1) [D loss: (-1.2442)(R -11.5805, F 10.3087, G 0.0028)] [G loss: -9.7544]\n",
      "6102 (5, 1) [D loss: (-1.7875)(R -10.7164, F 8.8912, G 0.0038)] [G loss: -9.1613]\n",
      "6103 (5, 1) [D loss: (-0.9873)(R -10.6635, F 9.6429, G 0.0033)] [G loss: -9.6221]\n",
      "6104 (5, 1) [D loss: (-1.2302)(R -11.1337, F 9.8662, G 0.0037)] [G loss: -10.4262]\n",
      "6105 (5, 1) [D loss: (-1.1172)(R -12.8790, F 11.7248, G 0.0037)] [G loss: -12.4512]\n",
      "6106 (5, 1) [D loss: (-1.1247)(R -14.0086, F 12.8270, G 0.0057)] [G loss: -13.6316]\n",
      "6107 (5, 1) [D loss: (-2.2354)(R -15.6138, F 13.3008, G 0.0078)] [G loss: -15.2217]\n",
      "6108 (5, 1) [D loss: (-1.5776)(R -16.4680, F 14.7947, G 0.0096)] [G loss: -15.7819]\n",
      "6109 (5, 1) [D loss: (-1.3568)(R -16.3979, F 14.9636, G 0.0077)] [G loss: -15.8596]\n",
      "6110 (5, 1) [D loss: (-0.9386)(R -15.6939, F 14.7012, G 0.0054)] [G loss: -15.1007]\n",
      "6111 (5, 1) [D loss: (-1.2392)(R -14.2738, F 13.0074, G 0.0027)] [G loss: -13.5147]\n",
      "6112 (5, 1) [D loss: (-1.1929)(R -11.8054, F 10.5867, G 0.0026)] [G loss: -10.4972]\n",
      "6113 (5, 1) [D loss: (-1.1596)(R -8.8080, F 7.6211, G 0.0027)] [G loss: -7.5718]\n",
      "6114 (5, 1) [D loss: (-1.6906)(R -6.8624, F 5.1381, G 0.0034)] [G loss: -5.0534]\n",
      "6115 (5, 1) [D loss: (-1.0509)(R -5.0760, F 3.9759, G 0.0049)] [G loss: -2.7129]\n",
      "6116 (5, 1) [D loss: (-1.4043)(R -2.6580, F 1.1776, G 0.0076)] [G loss: -0.4914]\n",
      "6117 (5, 1) [D loss: (-1.4122)(R -1.8938, F 0.3913, G 0.0090)] [G loss: -0.2077]\n",
      "6118 (5, 1) [D loss: (-1.3512)(R -1.7479, F 0.3314, G 0.0065)] [G loss: 0.5602]\n",
      "6119 (5, 1) [D loss: (-0.6541)(R -1.5929, F 0.8992, G 0.0040)] [G loss: -0.2407]\n",
      "6120 (5, 1) [D loss: (-0.5541)(R -2.6241, F 2.0389, G 0.0031)] [G loss: -1.7577]\n",
      "6121 (5, 1) [D loss: (-0.6382)(R -3.9447, F 3.2787, G 0.0028)] [G loss: -3.4971]\n",
      "6122 (5, 1) [D loss: (-1.1080)(R -5.3789, F 4.2402, G 0.0031)] [G loss: -4.8331]\n",
      "6123 (5, 1) [D loss: (-1.5311)(R -6.8537, F 5.2863, G 0.0036)] [G loss: -5.7969]\n",
      "6124 (5, 1) [D loss: (-1.3492)(R -6.9715, F 5.5776, G 0.0045)] [G loss: -5.6402]\n",
      "6125 (5, 1) [D loss: (-1.1221)(R -5.9695, F 4.8072, G 0.0040)] [G loss: -4.4578]\n",
      "6126 (5, 1) [D loss: (-0.9463)(R -4.1633, F 3.1773, G 0.0040)] [G loss: -2.3805]\n",
      "6127 (5, 1) [D loss: (-1.4152)(R -1.4577, F -0.0362, G 0.0079)] [G loss: 0.9201]\n",
      "6128 (5, 1) [D loss: (-1.7659)(R 2.4715, F -4.5117, G 0.0274)] [G loss: 4.6796]\n",
      "6129 (5, 1) [D loss: (-3.2350)(R 4.6179, F -8.3520, G 0.0499)] [G loss: 7.4154]\n",
      "6130 (5, 1) [D loss: (-2.7346)(R 5.2734, F -8.5734, G 0.0565)] [G loss: 6.8898]\n",
      "6131 (5, 1) [D loss: (-2.1718)(R 4.4060, F -6.9004, G 0.0323)] [G loss: 5.6652]\n",
      "6132 (5, 1) [D loss: (-1.3438)(R 3.0937, F -4.6101, G 0.0173)] [G loss: 3.6326]\n",
      "6133 (5, 1) [D loss: (-1.7280)(R 0.6076, F -2.3740, G 0.0038)] [G loss: 1.3082]\n",
      "6134 (5, 1) [D loss: (-1.3045)(R -1.2428, F -0.0805, G 0.0019)] [G loss: -1.0044]\n",
      "6135 (5, 1) [D loss: (-1.1572)(R -3.4729, F 2.2676, G 0.0048)] [G loss: -3.1431]\n",
      "6136 (5, 1) [D loss: (-1.2702)(R -5.3570, F 4.0494, G 0.0037)] [G loss: -4.6944]\n",
      "6137 (5, 1) [D loss: (-1.4479)(R -6.9260, F 5.4576, G 0.0021)] [G loss: -6.0165]\n",
      "6138 (5, 1) [D loss: (-1.8490)(R -7.4576, F 5.5848, G 0.0024)] [G loss: -5.6189]\n",
      "6139 (5, 1) [D loss: (-1.0715)(R -6.3241, F 5.2153, G 0.0037)] [G loss: -5.0193]\n",
      "6140 (5, 1) [D loss: (-1.4112)(R -4.9073, F 3.4396, G 0.0056)] [G loss: -3.7353]\n",
      "6141 (5, 1) [D loss: (-1.5401)(R -2.2493, F 0.6003, G 0.0109)] [G loss: -0.7780]\n",
      "6142 (5, 1) [D loss: (-0.8777)(R 0.2441, F -1.2803, G 0.0159)] [G loss: 0.8003]\n",
      "6143 (5, 1) [D loss: (-0.9107)(R 1.1721, F -2.2436, G 0.0161)] [G loss: 1.6023]\n",
      "6144 (5, 1) [D loss: (-0.7329)(R 2.2554, F -3.1605, G 0.0172)] [G loss: 1.9183]\n",
      "6145 (5, 1) [D loss: (-1.0399)(R 0.9249, F -2.0377, G 0.0073)] [G loss: 0.4896]\n",
      "6146 (5, 1) [D loss: (-1.0223)(R -0.6869, F -0.3780, G 0.0043)] [G loss: -0.6471]\n",
      "6147 (5, 1) [D loss: (-0.5049)(R -2.8867, F 2.3561, G 0.0026)] [G loss: -3.3550]\n",
      "6148 (5, 1) [D loss: (-1.2082)(R -6.0115, F 4.7747, G 0.0029)] [G loss: -5.7501]\n",
      "6149 (5, 1) [D loss: (-0.7574)(R -8.0653, F 7.2811, G 0.0027)] [G loss: -7.1700]\n",
      "6150 (5, 1) [D loss: (-1.0512)(R -10.3275, F 9.2513, G 0.0025)] [G loss: -9.2791]\n",
      "6151 (5, 1) [D loss: (-0.8770)(R -12.4256, F 11.5114, G 0.0037)] [G loss: -11.9434]\n",
      "6152 (5, 1) [D loss: (-0.9308)(R -13.2944, F 12.3148, G 0.0049)] [G loss: -12.2462]\n",
      "6153 (5, 1) [D loss: (-1.1867)(R -12.8741, F 11.6431, G 0.0044)] [G loss: -11.4238]\n",
      "6154 (5, 1) [D loss: (-1.0060)(R -11.5121, F 10.4559, G 0.0050)] [G loss: -10.3820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155 (5, 1) [D loss: (-1.4352)(R -10.1163, F 8.6385, G 0.0043)] [G loss: -8.5114]\n",
      "6156 (5, 1) [D loss: (-0.8963)(R -8.3872, F 7.4336, G 0.0057)] [G loss: -7.3482]\n",
      "6157 (5, 1) [D loss: (-0.9680)(R -7.5470, F 6.5187, G 0.0060)] [G loss: -6.2598]\n",
      "6158 (5, 1) [D loss: (-1.5751)(R -7.3261, F 5.6828, G 0.0068)] [G loss: -6.2786]\n",
      "6159 (5, 1) [D loss: (-1.1601)(R -9.2549, F 8.0306, G 0.0064)] [G loss: -8.3060]\n",
      "6160 (5, 1) [D loss: (-1.1958)(R -12.2858, F 11.0342, G 0.0056)] [G loss: -11.7172]\n",
      "6161 (5, 1) [D loss: (-1.6346)(R -16.0070, F 14.2805, G 0.0092)] [G loss: -15.2545]\n",
      "6162 (5, 1) [D loss: (-2.3247)(R -20.8345, F 18.3195, G 0.0190)] [G loss: -19.5910]\n",
      "6163 (5, 1) [D loss: (-1.4730)(R -22.8364, F 21.0736, G 0.0290)] [G loss: -22.2520]\n",
      "6164 (5, 1) [D loss: (-2.3394)(R -23.0505, F 20.4778, G 0.0233)] [G loss: -21.6560]\n",
      "6165 (5, 1) [D loss: (-1.2601)(R -21.6291, F 20.1977, G 0.0171)] [G loss: -20.7667]\n",
      "6166 (5, 1) [D loss: (-1.9751)(R -20.7155, F 18.6357, G 0.0105)] [G loss: -20.0284]\n",
      "6167 (5, 1) [D loss: (-1.9862)(R -20.5767, F 18.4900, G 0.0101)] [G loss: -19.5517]\n",
      "6168 (5, 1) [D loss: (-1.2880)(R -19.1098, F 17.7569, G 0.0065)] [G loss: -17.8880]\n",
      "6169 (5, 1) [D loss: (-1.1081)(R -16.7439, F 15.5911, G 0.0045)] [G loss: -15.6809]\n",
      "6170 (5, 1) [D loss: (-1.7148)(R -16.6528, F 14.8877, G 0.0050)] [G loss: -16.4586]\n",
      "6171 (5, 1) [D loss: (-2.6683)(R -18.3271, F 15.5679, G 0.0091)] [G loss: -18.3541]\n",
      "6172 (5, 1) [D loss: (-2.0543)(R -19.3778, F 17.1992, G 0.0124)] [G loss: -19.6988]\n",
      "6173 (5, 1) [D loss: (-1.7824)(R -20.6648, F 18.7164, G 0.0166)] [G loss: -20.8809]\n",
      "6174 (5, 1) [D loss: (-2.2348)(R -21.1484, F 18.7819, G 0.0132)] [G loss: -21.4767]\n",
      "6175 (5, 1) [D loss: (-0.6102)(R -19.5241, F 18.8289, G 0.0085)] [G loss: -19.4554]\n",
      "6176 (5, 1) [D loss: (-1.5582)(R -18.5591, F 16.9428, G 0.0058)] [G loss: -18.9395]\n",
      "6177 (5, 1) [D loss: (-0.7795)(R -16.2691, F 15.4686, G 0.0021)] [G loss: -16.5483]\n",
      "6178 (5, 1) [D loss: (-0.2085)(R -13.8942, F 13.6691, G 0.0017)] [G loss: -13.0787]\n",
      "6179 (5, 1) [D loss: (-0.6324)(R -11.5427, F 10.8950, G 0.0015)] [G loss: -10.6184]\n",
      "6180 (5, 1) [D loss: (-0.8249)(R -9.2111, F 8.3687, G 0.0017)] [G loss: -8.1769]\n",
      "6181 (5, 1) [D loss: (-1.0392)(R -6.7873, F 5.7277, G 0.0020)] [G loss: -5.6742]\n",
      "6182 (5, 1) [D loss: (-0.9792)(R -4.4353, F 3.4296, G 0.0026)] [G loss: -2.8865]\n",
      "6183 (5, 1) [D loss: (-1.2981)(R -2.9252, F 1.5973, G 0.0030)] [G loss: -0.9090]\n",
      "6184 (5, 1) [D loss: (-0.8935)(R -1.2989, F 0.3751, G 0.0030)] [G loss: -0.4348]\n",
      "6185 (5, 1) [D loss: (-0.8554)(R -0.5926, F -0.2955, G 0.0033)] [G loss: 0.7015]\n",
      "6186 (5, 1) [D loss: (-0.5964)(R 0.0525, F -0.6785, G 0.0030)] [G loss: 1.1674]\n",
      "6187 (5, 1) [D loss: (-1.0593)(R -0.0857, F -1.0072, G 0.0034)] [G loss: 1.5483]\n",
      "6188 (5, 1) [D loss: (-1.8608)(R -0.1585, F -1.7395, G 0.0037)] [G loss: 2.0811]\n",
      "6189 (5, 1) [D loss: (-1.4307)(R 1.2082, F -2.6834, G 0.0044)] [G loss: 2.8974]\n",
      "6190 (5, 1) [D loss: (-2.2059)(R 2.0208, F -4.2907, G 0.0064)] [G loss: 4.4803]\n",
      "6191 (5, 1) [D loss: (-1.9458)(R 4.2064, F -6.2592, G 0.0107)] [G loss: 6.7553]\n",
      "6192 (5, 1) [D loss: (-1.7083)(R 6.0657, F -7.9146, G 0.0141)] [G loss: 7.8950]\n",
      "6193 (5, 1) [D loss: (-1.7809)(R 7.8526, F -9.8414, G 0.0208)] [G loss: 9.8180]\n",
      "6194 (5, 1) [D loss: (-1.8620)(R 9.2909, F -11.3975, G 0.0245)] [G loss: 10.9104]\n",
      "6195 (5, 1) [D loss: (-1.8884)(R 10.1916, F -12.3783, G 0.0298)] [G loss: 11.3443]\n",
      "6196 (5, 1) [D loss: (-1.5454)(R 9.2849, F -11.0586, G 0.0228)] [G loss: 10.8151]\n",
      "6197 (5, 1) [D loss: (-1.7398)(R 9.9334, F -11.8947, G 0.0221)] [G loss: 10.2151]\n",
      "6198 (5, 1) [D loss: (-1.0126)(R 8.4175, F -9.5715, G 0.0141)] [G loss: 8.5218]\n",
      "6199 (5, 1) [D loss: (-2.3122)(R 6.7826, F -9.2019, G 0.0107)] [G loss: 8.3731]\n",
      "6200 (5, 1) [D loss: (-1.3328)(R 7.2286, F -8.6536, G 0.0092)] [G loss: 7.6899]\n",
      "6201 (5, 1) [D loss: (-2.2604)(R 5.9964, F -8.3571, G 0.0100)] [G loss: 6.9986]\n",
      "6202 (5, 1) [D loss: (-1.9411)(R 6.0089, F -8.0400, G 0.0090)] [G loss: 6.2471]\n",
      "6203 (5, 1) [D loss: (-1.5013)(R 6.1263, F -7.7186, G 0.0091)] [G loss: 5.9473]\n",
      "6204 (5, 1) [D loss: (-1.2781)(R 5.7742, F -7.1386, G 0.0086)] [G loss: 6.3505]\n",
      "6205 (5, 1) [D loss: (-1.4561)(R 6.1467, F -7.7108, G 0.0108)] [G loss: 6.1784]\n",
      "6206 (5, 1) [D loss: (-2.2435)(R 6.1297, F -8.4528, G 0.0080)] [G loss: 6.0258]\n",
      "6207 (5, 1) [D loss: (-1.8515)(R 6.1958, F -8.1296, G 0.0082)] [G loss: 6.3614]\n",
      "6208 (5, 1) [D loss: (-0.9406)(R 6.6163, F -7.6430, G 0.0086)] [G loss: 6.0506]\n",
      "6209 (5, 1) [D loss: (-2.0600)(R 5.8322, F -7.9612, G 0.0069)] [G loss: 5.8410]\n",
      "6210 (5, 1) [D loss: (-1.3594)(R 5.4167, F -6.8373, G 0.0061)] [G loss: 5.2596]\n",
      "6211 (5, 1) [D loss: (-1.9056)(R 3.9489, F -5.8909, G 0.0036)] [G loss: 4.1728]\n",
      "6212 (5, 1) [D loss: (-0.5236)(R 3.8638, F -4.4249, G 0.0038)] [G loss: 3.3516]\n",
      "6213 (5, 1) [D loss: (-0.9968)(R 2.6213, F -3.6449, G 0.0027)] [G loss: 1.9147]\n",
      "6214 (5, 1) [D loss: (-0.1970)(R 1.6094, F -1.8330, G 0.0027)] [G loss: 1.0989]\n",
      "6215 (5, 1) [D loss: (-0.6058)(R -0.7293, F 0.0980, G 0.0026)] [G loss: -0.7096]\n",
      "6216 (5, 1) [D loss: (-0.8275)(R -2.6706, F 1.8138, G 0.0029)] [G loss: -2.7361]\n",
      "6217 (5, 1) [D loss: (-0.6369)(R -4.8081, F 4.1422, G 0.0029)] [G loss: -4.4139]\n",
      "6218 (5, 1) [D loss: (-0.7021)(R -6.7963, F 6.0721, G 0.0022)] [G loss: -6.2899]\n",
      "6219 (5, 1) [D loss: (-0.7116)(R -8.7148, F 7.9660, G 0.0037)] [G loss: -8.2894]\n",
      "6220 (5, 1) [D loss: (-0.6465)(R -9.5450, F 8.8490, G 0.0050)] [G loss: -9.2903]\n",
      "6221 (5, 1) [D loss: (-1.2078)(R -10.8501, F 9.5905, G 0.0052)] [G loss: -10.0437]\n",
      "6222 (5, 1) [D loss: (-0.8482)(R -11.3298, F 10.4112, G 0.0070)] [G loss: -9.6397]\n",
      "6223 (5, 1) [D loss: (-1.3326)(R -10.3302, F 8.9362, G 0.0061)] [G loss: -9.0872]\n",
      "6224 (5, 1) [D loss: (-1.6253)(R -9.9166, F 8.2110, G 0.0080)] [G loss: -8.4390]\n",
      "6225 (5, 1) [D loss: (-1.5770)(R -10.4684, F 8.7988, G 0.0093)] [G loss: -8.6573]\n",
      "6226 (5, 1) [D loss: (-1.6557)(R -10.3439, F 8.6121, G 0.0076)] [G loss: -8.8459]\n",
      "6227 (5, 1) [D loss: (-1.4432)(R -11.8406, F 10.3078, G 0.0090)] [G loss: -11.1227]\n",
      "6228 (5, 1) [D loss: (-1.1691)(R -13.8622, F 12.5954, G 0.0098)] [G loss: -12.4699]\n",
      "6229 (5, 1) [D loss: (-1.6161)(R -16.3904, F 14.6821, G 0.0092)] [G loss: -14.7768]\n",
      "6230 (5, 1) [D loss: (-0.8908)(R -17.5156, F 16.5199, G 0.0105)] [G loss: -16.3198]\n",
      "6231 (5, 1) [D loss: (-1.7989)(R -19.9614, F 18.0446, G 0.0118)] [G loss: -18.0796]\n",
      "6232 (5, 1) [D loss: (-2.1229)(R -21.3328, F 19.0623, G 0.0148)] [G loss: -19.4373]\n",
      "6233 (5, 1) [D loss: (-1.6818)(R -21.8833, F 20.0606, G 0.0141)] [G loss: -19.7498]\n",
      "6234 (5, 1) [D loss: (-1.9496)(R -20.5923, F 18.5595, G 0.0083)] [G loss: -18.5971]\n",
      "6235 (5, 1) [D loss: (-2.5416)(R -21.0418, F 18.3643, G 0.0136)] [G loss: -19.8246]\n",
      "6236 (5, 1) [D loss: (-2.2734)(R -21.2175, F 18.8060, G 0.0138)] [G loss: -19.8328]\n",
      "6237 (5, 1) [D loss: (-2.1734)(R -22.6151, F 20.1872, G 0.0254)] [G loss: -22.0302]\n",
      "6238 (5, 1) [D loss: (-1.3742)(R -22.2702, F 20.6695, G 0.0226)] [G loss: -22.2459]\n",
      "6239 (5, 1) [D loss: (-2.6025)(R -24.4142, F 21.5411, G 0.0271)] [G loss: -24.3513]\n",
      "6240 (5, 1) [D loss: (-2.9122)(R -25.5208, F 22.2771, G 0.0332)] [G loss: -25.9920]\n",
      "6241 (5, 1) [D loss: (-2.2867)(R -24.4150, F 21.8895, G 0.0239)] [G loss: -25.4137]\n",
      "6242 (5, 1) [D loss: (-1.9783)(R -24.0210, F 21.8410, G 0.0202)] [G loss: -24.6673]\n",
      "6243 (5, 1) [D loss: (-1.4386)(R -23.5215, F 21.9480, G 0.0135)] [G loss: -24.3278]\n",
      "6244 (5, 1) [D loss: (-1.8487)(R -22.5810, F 20.6404, G 0.0092)] [G loss: -22.6941]\n",
      "6245 (5, 1) [D loss: (-1.1866)(R -20.8372, F 19.6091, G 0.0042)] [G loss: -21.0371]\n",
      "6246 (5, 1) [D loss: (-1.3895)(R -18.4207, F 17.0136, G 0.0018)] [G loss: -18.2241]\n",
      "6247 (5, 1) [D loss: (-0.7264)(R -16.3588, F 15.6185, G 0.0014)] [G loss: -15.8710]\n",
      "6248 (5, 1) [D loss: (-0.9378)(R -13.3364, F 12.3813, G 0.0017)] [G loss: -12.8202]\n",
      "6249 (5, 1) [D loss: (-1.6886)(R -9.9466, F 8.2380, G 0.0020)] [G loss: -8.6853]\n",
      "6250 (5, 1) [D loss: (-1.0760)(R -6.1001, F 5.0083, G 0.0016)] [G loss: -4.3838]\n",
      "6251 (5, 1) [D loss: (-1.1215)(R -3.3217, F 2.1772, G 0.0023)] [G loss: -1.6248]\n",
      "6252 (5, 1) [D loss: (-1.6041)(R -0.9512, F -0.6788, G 0.0026)] [G loss: 0.2551]\n",
      "6253 (5, 1) [D loss: (-0.8921)(R 0.8222, F -1.7422, G 0.0028)] [G loss: 2.1933]\n",
      "6254 (5, 1) [D loss: (-0.9037)(R 1.4033, F -2.3336, G 0.0027)] [G loss: 3.0274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6255 (5, 1) [D loss: (-1.9171)(R 1.5953, F -3.5355, G 0.0023)] [G loss: 3.8058]\n",
      "6256 (5, 1) [D loss: (-1.4987)(R 2.8095, F -4.3460, G 0.0038)] [G loss: 4.5705]\n",
      "6257 (5, 1) [D loss: (-2.2871)(R 3.2289, F -5.5772, G 0.0061)] [G loss: 6.0412]\n",
      "6258 (5, 1) [D loss: (-2.0274)(R 4.9670, F -7.0798, G 0.0085)] [G loss: 7.0329]\n",
      "6259 (5, 1) [D loss: (-2.0945)(R 7.3812, F -9.6106, G 0.0135)] [G loss: 9.6511]\n",
      "6260 (5, 1) [D loss: (-1.1288)(R 9.9876, F -11.3022, G 0.0186)] [G loss: 11.7653]\n",
      "6261 (5, 1) [D loss: (-1.9216)(R 11.6751, F -13.8473, G 0.0251)] [G loss: 13.8947]\n",
      "6262 (5, 1) [D loss: (-2.0010)(R 13.0686, F -15.4364, G 0.0367)] [G loss: 14.9531]\n",
      "6263 (5, 1) [D loss: (-2.1217)(R 14.6235, F -17.1531, G 0.0408)] [G loss: 15.2032]\n",
      "6264 (5, 1) [D loss: (-2.0512)(R 13.7519, F -16.2115, G 0.0408)] [G loss: 14.2008]\n",
      "6265 (5, 1) [D loss: (-2.6083)(R 11.7708, F -14.7050, G 0.0326)] [G loss: 12.7798]\n",
      "6266 (5, 1) [D loss: (-2.0549)(R 10.5233, F -12.7854, G 0.0207)] [G loss: 10.6144]\n",
      "6267 (5, 1) [D loss: (-1.3510)(R 8.3282, F -9.7587, G 0.0079)] [G loss: 7.4249]\n",
      "6268 (5, 1) [D loss: (-1.2812)(R 5.4991, F -6.8068, G 0.0027)] [G loss: 5.0054]\n",
      "6269 (5, 1) [D loss: (-1.0466)(R 2.8910, F -3.9542, G 0.0017)] [G loss: 2.9736]\n",
      "6270 (5, 1) [D loss: (-1.5505)(R 0.3537, F -1.9293, G 0.0025)] [G loss: 0.1554]\n",
      "6271 (5, 1) [D loss: (-1.2482)(R -3.0176, F 1.7440, G 0.0025)] [G loss: -3.3216]\n",
      "6272 (5, 1) [D loss: (-2.2663)(R -7.5879, F 5.3055, G 0.0016)] [G loss: -7.0613]\n",
      "6273 (5, 1) [D loss: (-2.4167)(R -11.1581, F 8.6958, G 0.0046)] [G loss: -10.1752]\n",
      "6274 (5, 1) [D loss: (-2.1659)(R -13.3791, F 11.1040, G 0.0109)] [G loss: -12.1823]\n",
      "6275 (5, 1) [D loss: (-0.9179)(R -13.0298, F 12.0016, G 0.0110)] [G loss: -11.9551]\n",
      "6276 (5, 1) [D loss: (-1.2242)(R -11.2934, F 10.0074, G 0.0062)] [G loss: -9.8185]\n",
      "6277 (5, 1) [D loss: (-0.7613)(R -8.6627, F 7.8649, G 0.0036)] [G loss: -7.4270]\n",
      "6278 (5, 1) [D loss: (-1.0906)(R -5.1254, F 3.9978, G 0.0037)] [G loss: -3.9139]\n",
      "6279 (5, 1) [D loss: (-1.5754)(R -2.0278, F 0.3950, G 0.0057)] [G loss: 0.2320]\n",
      "6280 (5, 1) [D loss: (-1.1213)(R 1.8120, F -3.0635, G 0.0130)] [G loss: 3.1730]\n",
      "6281 (5, 1) [D loss: (-2.0223)(R 2.6495, F -4.8402, G 0.0168)] [G loss: 4.6859]\n",
      "6282 (5, 1) [D loss: (-1.0632)(R 3.0098, F -4.1927, G 0.0120)] [G loss: 3.1794]\n",
      "6283 (5, 1) [D loss: (-0.8014)(R 0.8616, F -1.7099, G 0.0047)] [G loss: 0.9502]\n",
      "6284 (5, 1) [D loss: (-0.9398)(R -2.7084, F 1.7440, G 0.0025)] [G loss: -2.4949]\n",
      "6285 (5, 1) [D loss: (-0.7968)(R -5.4851, F 4.6626, G 0.0026)] [G loss: -4.9845]\n",
      "6286 (5, 1) [D loss: (-1.1970)(R -7.9467, F 6.7255, G 0.0024)] [G loss: -7.1659]\n",
      "6287 (5, 1) [D loss: (-1.8729)(R -10.6539, F 8.7379, G 0.0043)] [G loss: -9.3123]\n",
      "6288 (5, 1) [D loss: (-1.4770)(R -12.3043, F 10.7556, G 0.0072)] [G loss: -11.5401]\n",
      "6289 (5, 1) [D loss: (-0.9816)(R -12.5333, F 11.4884, G 0.0063)] [G loss: -11.2861]\n",
      "6290 (5, 1) [D loss: (-0.4909)(R -11.3597, F 10.8351, G 0.0034)] [G loss: -10.0042]\n",
      "6291 (5, 1) [D loss: (-0.7955)(R -9.0353, F 8.2131, G 0.0027)] [G loss: -7.9168]\n",
      "6292 (5, 1) [D loss: (-0.8549)(R -6.8107, F 5.9358, G 0.0020)] [G loss: -5.8781]\n",
      "6293 (5, 1) [D loss: (-0.9991)(R -4.9555, F 3.9268, G 0.0030)] [G loss: -3.5761]\n",
      "6294 (5, 1) [D loss: (-1.2349)(R -2.1263, F 0.8535, G 0.0038)] [G loss: -0.1564]\n",
      "6295 (5, 1) [D loss: (-1.0714)(R -0.5997, F -0.5282, G 0.0057)] [G loss: 0.1734]\n",
      "6296 (5, 1) [D loss: (-1.5328)(R -0.6519, F -0.9414, G 0.0060)] [G loss: 0.8752]\n",
      "6297 (5, 1) [D loss: (-0.7932)(R -1.1083, F 0.2520, G 0.0063)] [G loss: -0.5456]\n",
      "6298 (5, 1) [D loss: (-1.3597)(R -3.4055, F 2.0075, G 0.0038)] [G loss: -2.4898]\n",
      "6299 (5, 1) [D loss: (-1.4917)(R -6.4573, F 4.9174, G 0.0048)] [G loss: -5.8568]\n",
      "6300 (5, 1) [D loss: (-2.9951)(R -11.0424, F 7.9629, G 0.0084)] [G loss: -10.1565]\n",
      "6301 (5, 1) [D loss: (-2.0919)(R -13.3739, F 11.1539, G 0.0128)] [G loss: -12.9275]\n",
      "6302 (5, 1) [D loss: (-2.1540)(R -15.1543, F 12.8579, G 0.0142)] [G loss: -14.1003]\n",
      "6303 (5, 1) [D loss: (-1.8550)(R -14.9866, F 13.0131, G 0.0119)] [G loss: -14.0540]\n",
      "6304 (5, 1) [D loss: (-1.2939)(R -13.2943, F 11.9315, G 0.0069)] [G loss: -11.7581]\n",
      "6305 (5, 1) [D loss: (-0.9516)(R -11.6312, F 10.6454, G 0.0034)] [G loss: -10.8257]\n",
      "6306 (5, 1) [D loss: (-1.3032)(R -10.7634, F 9.4334, G 0.0027)] [G loss: -9.5734]\n",
      "6307 (5, 1) [D loss: (-1.1817)(R -8.6679, F 7.4593, G 0.0027)] [G loss: -7.4335]\n",
      "6308 (5, 1) [D loss: (-1.0417)(R -6.6914, F 5.6246, G 0.0025)] [G loss: -6.1670]\n",
      "6309 (5, 1) [D loss: (-1.1643)(R -5.8259, F 4.6284, G 0.0033)] [G loss: -5.5695]\n",
      "6310 (5, 1) [D loss: (-1.0766)(R -7.0123, F 5.8882, G 0.0048)] [G loss: -6.5095]\n",
      "6311 (5, 1) [D loss: (-0.8474)(R -7.4181, F 6.5157, G 0.0055)] [G loss: -7.0993]\n",
      "6312 (5, 1) [D loss: (-1.7435)(R -9.8891, F 8.0577, G 0.0088)] [G loss: -9.8342]\n",
      "6313 (5, 1) [D loss: (-2.3231)(R -12.3146, F 9.8683, G 0.0123)] [G loss: -11.4071]\n",
      "6314 (5, 1) [D loss: (-1.4566)(R -13.0274, F 11.4103, G 0.0161)] [G loss: -12.8698]\n",
      "6315 (5, 1) [D loss: (-1.4334)(R -13.4662, F 11.8896, G 0.0143)] [G loss: -13.0361]\n",
      "6316 (5, 1) [D loss: (-1.4191)(R -12.9051, F 11.4152, G 0.0071)] [G loss: -12.7321]\n",
      "6317 (5, 1) [D loss: (-1.0636)(R -11.8620, F 10.7600, G 0.0038)] [G loss: -12.1538]\n",
      "6318 (5, 1) [D loss: (-0.5588)(R -10.4981, F 9.9177, G 0.0022)] [G loss: -10.2148]\n",
      "6319 (5, 1) [D loss: (-0.6321)(R -8.6717, F 8.0235, G 0.0016)] [G loss: -7.9668]\n",
      "6320 (5, 1) [D loss: (-0.7341)(R -7.1805, F 6.4279, G 0.0018)] [G loss: -6.4481]\n",
      "6321 (5, 1) [D loss: (-0.8340)(R -5.4619, F 4.6091, G 0.0019)] [G loss: -4.5664]\n",
      "6322 (5, 1) [D loss: (-1.7216)(R -3.6859, F 1.9431, G 0.0021)] [G loss: -2.0341]\n",
      "6323 (5, 1) [D loss: (-1.6383)(R -1.4042, F -0.2648, G 0.0031)] [G loss: 0.8196]\n",
      "6324 (5, 1) [D loss: (-1.6276)(R 1.3344, F -3.0120, G 0.0050)] [G loss: 3.7937]\n",
      "6325 (5, 1) [D loss: (-2.0456)(R 3.8666, F -6.0181, G 0.0106)] [G loss: 6.3941]\n",
      "6326 (5, 1) [D loss: (-2.0861)(R 6.8585, F -9.0956, G 0.0151)] [G loss: 9.3030]\n",
      "6327 (5, 1) [D loss: (-1.4808)(R 9.8147, F -11.5070, G 0.0212)] [G loss: 11.7983]\n",
      "6328 (5, 1) [D loss: (-2.4573)(R 11.0503, F -13.7099, G 0.0202)] [G loss: 13.6040]\n",
      "6329 (5, 1) [D loss: (-2.6550)(R 12.6230, F -15.5071, G 0.0229)] [G loss: 14.8238]\n",
      "6330 (5, 1) [D loss: (-2.6265)(R 13.8181, F -16.7153, G 0.0271)] [G loss: 15.6752]\n",
      "6331 (5, 1) [D loss: (-2.4114)(R 14.3800, F -17.0714, G 0.0280)] [G loss: 16.0674]\n",
      "6332 (5, 1) [D loss: (-3.2247)(R 15.2060, F -18.7174, G 0.0287)] [G loss: 16.7245]\n",
      "6333 (5, 1) [D loss: (-2.9563)(R 15.0206, F -18.2849, G 0.0308)] [G loss: 16.4017]\n",
      "6334 (5, 1) [D loss: (-2.8992)(R 14.2727, F -17.4133, G 0.0241)] [G loss: 15.9418]\n",
      "6335 (5, 1) [D loss: (-2.1266)(R 14.2347, F -16.5728, G 0.0212)] [G loss: 15.1418]\n",
      "6336 (5, 1) [D loss: (-3.1068)(R 12.1969, F -15.4404, G 0.0137)] [G loss: 13.8000]\n",
      "6337 (5, 1) [D loss: (-1.7151)(R 11.6093, F -13.4405, G 0.0116)] [G loss: 12.7182]\n",
      "6338 (5, 1) [D loss: (-1.4794)(R 10.7241, F -12.2920, G 0.0089)] [G loss: 11.1158]\n",
      "6339 (5, 1) [D loss: (-1.8739)(R 8.9314, F -10.8462, G 0.0041)] [G loss: 9.5951]\n",
      "6340 (5, 1) [D loss: (-2.0641)(R 8.1374, F -10.2307, G 0.0029)] [G loss: 8.8809]\n",
      "6341 (5, 1) [D loss: (-1.6163)(R 6.9269, F -8.5763, G 0.0033)] [G loss: 7.9506]\n",
      "6342 (5, 1) [D loss: (-1.3012)(R 5.8445, F -7.1702, G 0.0025)] [G loss: 6.2482]\n",
      "6343 (5, 1) [D loss: (-1.3344)(R 4.5778, F -5.9292, G 0.0017)] [G loss: 5.0245]\n",
      "6344 (5, 1) [D loss: (-0.8959)(R 3.4901, F -4.4069, G 0.0021)] [G loss: 3.8897]\n",
      "6345 (5, 1) [D loss: (-0.3440)(R 2.7439, F -3.1115, G 0.0024)] [G loss: 2.7365]\n",
      "6346 (5, 1) [D loss: (-0.8001)(R 1.9241, F -2.7528, G 0.0029)] [G loss: 2.0294]\n",
      "6347 (5, 1) [D loss: (-0.8880)(R 1.1094, F -2.0364, G 0.0039)] [G loss: 1.7233]\n",
      "6348 (5, 1) [D loss: (-1.0698)(R 1.8510, F -2.9437, G 0.0023)] [G loss: 2.1186]\n",
      "6349 (5, 1) [D loss: (-1.1969)(R 2.2008, F -3.4312, G 0.0034)] [G loss: 2.8998]\n",
      "6350 (5, 1) [D loss: (-1.1331)(R 1.7898, F -2.9704, G 0.0047)] [G loss: 2.5599]\n",
      "6351 (5, 1) [D loss: (-1.5695)(R 1.2798, F -2.8989, G 0.0050)] [G loss: 2.0018]\n",
      "6352 (5, 1) [D loss: (-1.5417)(R 1.0476, F -2.6337, G 0.0044)] [G loss: 2.1344]\n",
      "6353 (5, 1) [D loss: (-0.9914)(R 1.5012, F -2.5696, G 0.0077)] [G loss: 2.0524]\n",
      "6354 (5, 1) [D loss: (-0.9377)(R 1.1966, F -2.1942, G 0.0060)] [G loss: 1.7213]\n",
      "6355 (5, 1) [D loss: (-0.8747)(R -0.2785, F -0.6521, G 0.0056)] [G loss: -0.0422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6356 (5, 1) [D loss: (-0.7896)(R -1.9952, F 1.1743, G 0.0031)] [G loss: -1.6596]\n",
      "6357 (5, 1) [D loss: (-0.3795)(R -2.9899, F 2.5808, G 0.0030)] [G loss: -3.2016]\n",
      "6358 (5, 1) [D loss: (-1.0729)(R -5.4527, F 4.3538, G 0.0026)] [G loss: -4.4817]\n",
      "6359 (5, 1) [D loss: (-0.9264)(R -7.4165, F 6.4587, G 0.0031)] [G loss: -6.6125]\n",
      "6360 (5, 1) [D loss: (-1.2689)(R -9.8078, F 8.4944, G 0.0045)] [G loss: -8.8611]\n",
      "6361 (5, 1) [D loss: (-1.2603)(R -11.8435, F 10.5128, G 0.0070)] [G loss: -10.5393]\n",
      "6362 (5, 1) [D loss: (-1.1593)(R -13.3049, F 12.0300, G 0.0116)] [G loss: -11.9176]\n",
      "6363 (5, 1) [D loss: (-1.3899)(R -14.0707, F 12.5813, G 0.0100)] [G loss: -12.4874]\n",
      "6364 (5, 1) [D loss: (-1.4363)(R -14.1229, F 12.6020, G 0.0085)] [G loss: -12.8188]\n",
      "6365 (5, 1) [D loss: (-0.6175)(R -13.6616, F 12.9771, G 0.0067)] [G loss: -12.2090]\n",
      "6366 (5, 1) [D loss: (-1.4768)(R -12.8020, F 11.2788, G 0.0046)] [G loss: -11.1620]\n",
      "6367 (5, 1) [D loss: (-1.1604)(R -11.0359, F 9.8390, G 0.0036)] [G loss: -10.5282]\n",
      "6368 (5, 1) [D loss: (-1.4772)(R -10.5665, F 9.0397, G 0.0050)] [G loss: -9.2594]\n",
      "6369 (5, 1) [D loss: (-1.8434)(R -10.2734, F 8.3900, G 0.0040)] [G loss: -8.1709]\n",
      "6370 (5, 1) [D loss: (-1.7307)(R -9.7747, F 7.9769, G 0.0067)] [G loss: -9.1128]\n",
      "6371 (5, 1) [D loss: (-1.8492)(R -11.1279, F 9.1846, G 0.0094)] [G loss: -10.5458]\n",
      "6372 (5, 1) [D loss: (-1.5139)(R -13.1240, F 11.4636, G 0.0147)] [G loss: -12.3970]\n",
      "6373 (5, 1) [D loss: (-1.3638)(R -13.3100, F 11.8283, G 0.0118)] [G loss: -12.4161]\n",
      "6374 (5, 1) [D loss: (-1.4179)(R -14.5277, F 12.9709, G 0.0139)] [G loss: -13.6179]\n",
      "6375 (5, 1) [D loss: (-1.5191)(R -14.6839, F 13.0496, G 0.0115)] [G loss: -13.5638]\n",
      "6376 (5, 1) [D loss: (-0.4109)(R -13.6054, F 13.1028, G 0.0092)] [G loss: -13.3341]\n",
      "6377 (5, 1) [D loss: (-1.5224)(R -13.8668, F 12.2574, G 0.0087)] [G loss: -13.3102]\n",
      "6378 (5, 1) [D loss: (-1.0438)(R -12.9273, F 11.8216, G 0.0062)] [G loss: -12.2223]\n",
      "6379 (5, 1) [D loss: (-0.6916)(R -10.9771, F 10.2481, G 0.0037)] [G loss: -10.5722]\n",
      "6380 (5, 1) [D loss: (-1.1467)(R -9.3401, F 8.1642, G 0.0029)] [G loss: -8.3436]\n",
      "6381 (5, 1) [D loss: (-1.0907)(R -8.0414, F 6.9241, G 0.0027)] [G loss: -7.4571]\n",
      "6382 (5, 1) [D loss: (-0.9190)(R -7.6012, F 6.6543, G 0.0028)] [G loss: -6.6438]\n",
      "6383 (5, 1) [D loss: (-1.4053)(R -6.9742, F 5.5383, G 0.0031)] [G loss: -5.6326]\n",
      "6384 (5, 1) [D loss: (-1.2322)(R -6.1821, F 4.9198, G 0.0030)] [G loss: -5.0381]\n",
      "6385 (5, 1) [D loss: (-1.8044)(R -5.1480, F 3.3103, G 0.0033)] [G loss: -4.1470]\n",
      "6386 (5, 1) [D loss: (-1.4425)(R -4.8255, F 3.3453, G 0.0038)] [G loss: -4.2910]\n",
      "6387 (5, 1) [D loss: (-0.7965)(R -4.7227, F 3.8827, G 0.0044)] [G loss: -4.3189]\n",
      "6388 (5, 1) [D loss: (-0.8630)(R -4.4142, F 3.5121, G 0.0039)] [G loss: -3.5765]\n",
      "6389 (5, 1) [D loss: (-0.7705)(R -3.3281, F 2.5245, G 0.0033)] [G loss: -2.3154]\n",
      "6390 (5, 1) [D loss: (-0.8221)(R -3.3874, F 2.5225, G 0.0043)] [G loss: -2.4270]\n",
      "6391 (5, 1) [D loss: (-0.7693)(R -2.7574, F 1.9560, G 0.0032)] [G loss: -2.0456]\n",
      "6392 (5, 1) [D loss: (-0.7209)(R -2.4550, F 1.7037, G 0.0030)] [G loss: -1.4136]\n",
      "6393 (5, 1) [D loss: (-0.2515)(R -1.9315, F 1.6491, G 0.0031)] [G loss: -1.0873]\n",
      "6394 (5, 1) [D loss: (-1.0456)(R -1.5035, F 0.4272, G 0.0031)] [G loss: -0.5870]\n",
      "6395 (5, 1) [D loss: (-0.7723)(R -0.6889, F -0.1138, G 0.0030)] [G loss: -0.1638]\n",
      "6396 (5, 1) [D loss: (-1.1096)(R -0.6533, F -0.4891, G 0.0033)] [G loss: 0.3019]\n",
      "6397 (5, 1) [D loss: (-1.0322)(R 0.0757, F -1.1399, G 0.0032)] [G loss: 0.8907]\n",
      "6398 (5, 1) [D loss: (-0.8908)(R 0.5691, F -1.4992, G 0.0039)] [G loss: 1.9039]\n",
      "6399 (5, 1) [D loss: (-0.7735)(R 1.4750, F -2.2899, G 0.0041)] [G loss: 2.6126]\n",
      "6400 (5, 1) [D loss: (-1.2580)(R 2.6075, F -3.9089, G 0.0043)] [G loss: 4.2173]\n",
      "6401 (5, 1) [D loss: (-1.5105)(R 4.0608, F -5.6208, G 0.0049)] [G loss: 6.0781]\n",
      "6402 (5, 1) [D loss: (-1.2845)(R 5.9502, F -7.3101, G 0.0075)] [G loss: 7.7501]\n",
      "6403 (5, 1) [D loss: (-2.3514)(R 6.8175, F -9.2574, G 0.0089)] [G loss: 9.0799]\n",
      "6404 (5, 1) [D loss: (-1.4971)(R 8.2669, F -9.8590, G 0.0095)] [G loss: 10.3558]\n",
      "6405 (5, 1) [D loss: (-1.4030)(R 10.0694, F -11.5568, G 0.0084)] [G loss: 12.1334]\n",
      "6406 (5, 1) [D loss: (-0.9325)(R 11.2100, F -12.2526, G 0.0110)] [G loss: 12.0652]\n",
      "6407 (5, 1) [D loss: (-1.4249)(R 11.0482, F -12.5719, G 0.0099)] [G loss: 12.0734]\n",
      "6408 (5, 1) [D loss: (-1.5348)(R 11.3899, F -13.0382, G 0.0114)] [G loss: 12.5518]\n",
      "6409 (5, 1) [D loss: (-1.7816)(R 12.2512, F -14.1575, G 0.0125)] [G loss: 12.4578]\n",
      "6410 (5, 1) [D loss: (-1.7635)(R 11.7945, F -13.6573, G 0.0099)] [G loss: 12.6540]\n",
      "6411 (5, 1) [D loss: (-1.4410)(R 11.7274, F -13.2706, G 0.0102)] [G loss: 12.4857]\n",
      "6412 (5, 1) [D loss: (-1.9309)(R 11.7781, F -13.8106, G 0.0102)] [G loss: 12.8329]\n",
      "6413 (5, 1) [D loss: (-1.7471)(R 11.7479, F -13.6218, G 0.0127)] [G loss: 12.8497]\n",
      "6414 (5, 1) [D loss: (-1.3752)(R 12.3080, F -13.8166, G 0.0133)] [G loss: 12.9393]\n",
      "6415 (5, 1) [D loss: (-1.8980)(R 11.5787, F -13.5839, G 0.0107)] [G loss: 12.3810]\n",
      "6416 (5, 1) [D loss: (-1.7313)(R 11.4472, F -13.2757, G 0.0097)] [G loss: 12.0358]\n",
      "6417 (5, 1) [D loss: (-1.5283)(R 11.5040, F -13.1175, G 0.0085)] [G loss: 11.5214]\n",
      "6418 (5, 1) [D loss: (-1.0360)(R 12.3348, F -13.4676, G 0.0097)] [G loss: 11.9202]\n",
      "6419 (5, 1) [D loss: (-1.1378)(R 12.4529, F -13.7155, G 0.0125)] [G loss: 11.7683]\n",
      "6420 (5, 1) [D loss: (-1.0648)(R 11.1744, F -12.3149, G 0.0076)] [G loss: 10.8121]\n",
      "6421 (5, 1) [D loss: (-1.2515)(R 10.9686, F -12.2775, G 0.0057)] [G loss: 10.6020]\n",
      "6422 (5, 1) [D loss: (-1.3395)(R 10.9257, F -12.3413, G 0.0076)] [G loss: 11.3827]\n",
      "6423 (5, 1) [D loss: (-1.3667)(R 11.1889, F -12.6444, G 0.0089)] [G loss: 10.6673]\n",
      "6424 (5, 1) [D loss: (-0.1850)(R 10.0922, F -10.3206, G 0.0043)] [G loss: 9.0621]\n",
      "6425 (5, 1) [D loss: (-0.7782)(R 7.8488, F -8.6488, G 0.0022)] [G loss: 7.4607]\n",
      "6426 (5, 1) [D loss: (-0.5856)(R 6.3809, F -6.9962, G 0.0030)] [G loss: 6.0071]\n",
      "6427 (5, 1) [D loss: (-0.6539)(R 4.8717, F -5.5541, G 0.0028)] [G loss: 4.2127]\n",
      "6428 (5, 1) [D loss: (-0.4472)(R 3.2337, F -3.7063, G 0.0025)] [G loss: 3.2419]\n",
      "6429 (5, 1) [D loss: (-0.2658)(R 1.7256, F -2.0233, G 0.0032)] [G loss: 1.5887]\n",
      "6430 (5, 1) [D loss: (-0.9441)(R -0.4773, F -0.4893, G 0.0022)] [G loss: 0.0035]\n",
      "6431 (5, 1) [D loss: (-0.6678)(R -1.3043, F 0.6158, G 0.0021)] [G loss: -0.9909]\n",
      "6432 (5, 1) [D loss: (-0.9776)(R -3.4585, F 2.4613, G 0.0020)] [G loss: -2.6340]\n",
      "6433 (5, 1) [D loss: (-1.0130)(R -5.4431, F 4.4040, G 0.0026)] [G loss: -4.6999]\n",
      "6434 (5, 1) [D loss: (-1.5987)(R -7.4075, F 5.7614, G 0.0047)] [G loss: -6.2413]\n",
      "6435 (5, 1) [D loss: (-1.6503)(R -8.8454, F 7.1270, G 0.0068)] [G loss: -7.7143]\n",
      "6436 (5, 1) [D loss: (-2.1188)(R -10.3147, F 8.1222, G 0.0074)] [G loss: -9.0065]\n",
      "6437 (5, 1) [D loss: (-1.5286)(R -12.5488, F 10.9164, G 0.0104)] [G loss: -10.5794]\n",
      "6438 (5, 1) [D loss: (-1.5660)(R -13.5882, F 11.8987, G 0.0124)] [G loss: -12.2602]\n",
      "6439 (5, 1) [D loss: (-1.9247)(R -15.6866, F 13.6107, G 0.0151)] [G loss: -14.3375]\n",
      "6440 (5, 1) [D loss: (-2.4085)(R -17.0985, F 14.5064, G 0.0184)] [G loss: -15.5416]\n",
      "6441 (5, 1) [D loss: (-2.6284)(R -18.2223, F 15.4189, G 0.0175)] [G loss: -15.8290]\n",
      "6442 (5, 1) [D loss: (-0.9525)(R -17.2186, F 16.0921, G 0.0174)] [G loss: -15.6979]\n",
      "6443 (5, 1) [D loss: (-1.9447)(R -18.0906, F 15.9889, G 0.0157)] [G loss: -16.0052]\n",
      "6444 (5, 1) [D loss: (-1.1968)(R -16.5022, F 15.2055, G 0.0100)] [G loss: -14.9810]\n",
      "6445 (5, 1) [D loss: (-1.5976)(R -16.5006, F 14.8075, G 0.0096)] [G loss: -15.8232]\n",
      "6446 (5, 1) [D loss: (-0.8576)(R -15.8646, F 14.9171, G 0.0090)] [G loss: -15.8763]\n",
      "6447 (5, 1) [D loss: (-0.6500)(R -16.5510, F 15.8183, G 0.0083)] [G loss: -15.9183]\n",
      "6448 (5, 1) [D loss: (-1.5460)(R -16.1538, F 14.5606, G 0.0047)] [G loss: -15.9674]\n",
      "6449 (5, 1) [D loss: (-1.3439)(R -15.8813, F 14.4935, G 0.0044)] [G loss: -15.3709]\n",
      "6450 (5, 1) [D loss: (-0.5015)(R -15.1812, F 14.6349, G 0.0045)] [G loss: -15.4261]\n",
      "6451 (5, 1) [D loss: (-1.5493)(R -15.0181, F 13.4368, G 0.0032)] [G loss: -14.3304]\n",
      "6452 (5, 1) [D loss: (-1.3461)(R -14.5307, F 13.1572, G 0.0027)] [G loss: -13.1014]\n",
      "6453 (5, 1) [D loss: (-1.1441)(R -11.9000, F 10.7368, G 0.0019)] [G loss: -10.9320]\n",
      "6454 (5, 1) [D loss: (-0.8875)(R -9.9934, F 9.0885, G 0.0017)] [G loss: -8.9331]\n",
      "6455 (5, 1) [D loss: (-1.1403)(R -8.5543, F 7.3922, G 0.0022)] [G loss: -7.8156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6456 (5, 1) [D loss: (-0.6740)(R -7.0769, F 6.3808, G 0.0022)] [G loss: -6.2104]\n",
      "6457 (5, 1) [D loss: (-1.2162)(R -5.5987, F 4.3555, G 0.0027)] [G loss: -4.8398]\n",
      "6458 (5, 1) [D loss: (-1.1662)(R -5.1417, F 3.9389, G 0.0037)] [G loss: -4.4313]\n",
      "6459 (5, 1) [D loss: (-1.1919)(R -4.2121, F 2.9765, G 0.0044)] [G loss: -3.9704]\n",
      "6460 (5, 1) [D loss: (-0.5882)(R -4.5507, F 3.9231, G 0.0039)] [G loss: -4.5882]\n",
      "6461 (5, 1) [D loss: (-1.2795)(R -4.9699, F 3.6436, G 0.0047)] [G loss: -4.1924]\n",
      "6462 (5, 1) [D loss: (-0.5509)(R -5.6241, F 5.0264, G 0.0047)] [G loss: -5.4120]\n",
      "6463 (5, 1) [D loss: (-0.8744)(R -5.0609, F 4.1505, G 0.0036)] [G loss: -5.1231]\n",
      "6464 (5, 1) [D loss: (-0.5592)(R -5.2607, F 4.6639, G 0.0038)] [G loss: -4.6114]\n",
      "6465 (5, 1) [D loss: (-0.6698)(R -4.7389, F 4.0401, G 0.0029)] [G loss: -3.7350]\n",
      "6466 (5, 1) [D loss: (-0.7107)(R -3.2634, F 2.5178, G 0.0035)] [G loss: -2.5216]\n",
      "6467 (5, 1) [D loss: (-0.7134)(R -1.7181, F 0.9676, G 0.0037)] [G loss: -0.5030]\n",
      "6468 (5, 1) [D loss: (-0.9052)(R 0.1842, F -1.1213, G 0.0032)] [G loss: 1.5014]\n",
      "6469 (5, 1) [D loss: (-1.0727)(R 2.8104, F -3.9220, G 0.0039)] [G loss: 5.1717]\n",
      "6470 (5, 1) [D loss: (-1.4708)(R 6.3242, F -7.8463, G 0.0051)] [G loss: 8.4482]\n",
      "6471 (5, 1) [D loss: (-1.7029)(R 9.8265, F -11.6345, G 0.0105)] [G loss: 12.3137]\n",
      "6472 (5, 1) [D loss: (-0.8532)(R 12.6051, F -13.6062, G 0.0148)] [G loss: 13.9801]\n",
      "6473 (5, 1) [D loss: (-1.0981)(R 12.8662, F -14.0822, G 0.0118)] [G loss: 14.6370]\n",
      "6474 (5, 1) [D loss: (-1.6422)(R 12.9202, F -14.6705, G 0.0108)] [G loss: 15.1336]\n",
      "6475 (5, 1) [D loss: (-1.3610)(R 12.8996, F -14.3412, G 0.0081)] [G loss: 14.8569]\n",
      "6476 (5, 1) [D loss: (-0.5622)(R 12.3704, F -12.9819, G 0.0049)] [G loss: 12.6022]\n",
      "6477 (5, 1) [D loss: (-0.7916)(R 10.5147, F -11.3408, G 0.0034)] [G loss: 11.3008]\n",
      "6478 (5, 1) [D loss: (-1.4244)(R 9.0737, F -10.5308, G 0.0033)] [G loss: 10.1990]\n",
      "6479 (5, 1) [D loss: (-0.8945)(R 7.8201, F -8.7403, G 0.0026)] [G loss: 8.5960]\n",
      "6480 (5, 1) [D loss: (-1.1795)(R 6.8607, F -8.0660, G 0.0026)] [G loss: 7.6981]\n",
      "6481 (5, 1) [D loss: (-1.1139)(R 6.9242, F -8.0783, G 0.0040)] [G loss: 8.1802]\n",
      "6482 (5, 1) [D loss: (-1.2366)(R 7.1301, F -8.4203, G 0.0054)] [G loss: 8.2984]\n",
      "6483 (5, 1) [D loss: (-1.1409)(R 7.7290, F -8.9291, G 0.0059)] [G loss: 8.9900]\n",
      "6484 (5, 1) [D loss: (-1.1817)(R 8.5963, F -9.8470, G 0.0069)] [G loss: 9.4608]\n",
      "6485 (5, 1) [D loss: (-1.3069)(R 9.4118, F -10.8037, G 0.0085)] [G loss: 10.9449]\n",
      "6486 (5, 1) [D loss: (-1.7663)(R 10.5273, F -12.4265, G 0.0133)] [G loss: 11.7109]\n",
      "6487 (5, 1) [D loss: (-0.7615)(R 12.6531, F -13.5930, G 0.0178)] [G loss: 12.6752]\n",
      "6488 (5, 1) [D loss: (-1.1892)(R 11.7741, F -13.0804, G 0.0117)] [G loss: 12.3568]\n",
      "6489 (5, 1) [D loss: (-1.1576)(R 11.2488, F -12.5193, G 0.0113)] [G loss: 11.1290]\n",
      "6490 (5, 1) [D loss: (-1.3232)(R 9.5805, F -10.9590, G 0.0055)] [G loss: 10.3187]\n",
      "6491 (5, 1) [D loss: (-0.5053)(R 9.5834, F -10.1188, G 0.0030)] [G loss: 9.7238]\n",
      "6492 (5, 1) [D loss: (-0.8674)(R 8.6921, F -9.5930, G 0.0034)] [G loss: 8.2538]\n",
      "6493 (5, 1) [D loss: (-1.1751)(R 6.6307, F -7.8234, G 0.0018)] [G loss: 6.9056]\n",
      "6494 (5, 1) [D loss: (-1.0636)(R 6.0163, F -7.1033, G 0.0023)] [G loss: 6.2789]\n",
      "6495 (5, 1) [D loss: (-0.7986)(R 4.9651, F -5.7815, G 0.0018)] [G loss: 5.3896]\n",
      "6496 (5, 1) [D loss: (-0.3053)(R 5.0905, F -5.4239, G 0.0028)] [G loss: 5.3932]\n",
      "6497 (5, 1) [D loss: (-0.9298)(R 4.1057, F -5.0632, G 0.0028)] [G loss: 4.2999]\n",
      "6498 (5, 1) [D loss: (-1.0232)(R 3.6256, F -4.6778, G 0.0029)] [G loss: 3.9576]\n",
      "6499 (5, 1) [D loss: (-1.1878)(R 2.6344, F -3.8467, G 0.0025)] [G loss: 3.6219]\n",
      "6500 (5, 1) [D loss: (-0.4948)(R 2.3428, F -2.8717, G 0.0034)] [G loss: 2.8353]\n",
      "6501 (5, 1) [D loss: (-0.4774)(R 2.1588, F -2.6658, G 0.0030)] [G loss: 2.6599]\n",
      "6502 (5, 1) [D loss: (-1.0151)(R 1.6060, F -2.6525, G 0.0031)] [G loss: 2.5622]\n",
      "6503 (5, 1) [D loss: (-0.5181)(R 1.5627, F -2.1147, G 0.0034)] [G loss: 2.2920]\n",
      "6504 (5, 1) [D loss: (-0.9736)(R 1.3853, F -2.3961, G 0.0037)] [G loss: 2.0676]\n",
      "6505 (5, 1) [D loss: (-0.9514)(R 0.6437, F -1.6356, G 0.0040)] [G loss: 1.5208]\n",
      "6506 (5, 1) [D loss: (-1.0822)(R 0.2901, F -1.4092, G 0.0037)] [G loss: 1.0245]\n",
      "6507 (5, 1) [D loss: (-0.7723)(R -1.1189, F 0.2961, G 0.0051)] [G loss: -0.4081]\n",
      "6508 (5, 1) [D loss: (-1.0164)(R -2.6078, F 1.5392, G 0.0052)] [G loss: -1.4023]\n",
      "6509 (5, 1) [D loss: (-1.1164)(R -4.2840, F 3.1028, G 0.0065)] [G loss: -3.1432]\n",
      "6510 (5, 1) [D loss: (-1.1737)(R -6.6050, F 5.3562, G 0.0075)] [G loss: -5.3947]\n",
      "6511 (5, 1) [D loss: (-1.3792)(R -8.1548, F 6.6808, G 0.0095)] [G loss: -7.3570]\n",
      "6512 (5, 1) [D loss: (-1.7899)(R -10.1703, F 8.2734, G 0.0107)] [G loss: -9.1121]\n",
      "6513 (5, 1) [D loss: (-1.8071)(R -11.9182, F 9.9612, G 0.0150)] [G loss: -10.7357]\n",
      "6514 (5, 1) [D loss: (-1.3187)(R -12.0421, F 10.5719, G 0.0151)] [G loss: -11.3327]\n",
      "6515 (5, 1) [D loss: (-1.3851)(R -12.1534, F 10.6558, G 0.0113)] [G loss: -10.9422]\n",
      "6516 (5, 1) [D loss: (-1.2367)(R -12.4972, F 11.1429, G 0.0118)] [G loss: -11.3657]\n",
      "6517 (5, 1) [D loss: (-1.7288)(R -12.9954, F 11.1675, G 0.0099)] [G loss: -11.4219]\n",
      "6518 (5, 1) [D loss: (-1.2907)(R -11.6380, F 10.2844, G 0.0063)] [G loss: -10.9454]\n",
      "6519 (5, 1) [D loss: (-1.2941)(R -10.6118, F 9.2778, G 0.0040)] [G loss: -10.0710]\n",
      "6520 (5, 1) [D loss: (-1.0110)(R -10.9366, F 9.8781, G 0.0047)] [G loss: -10.3584]\n",
      "6521 (5, 1) [D loss: (-1.2560)(R -9.7914, F 8.5072, G 0.0028)] [G loss: -9.1062]\n",
      "6522 (5, 1) [D loss: (-0.8734)(R -9.0450, F 8.1383, G 0.0033)] [G loss: -8.7713]\n",
      "6523 (5, 1) [D loss: (-1.4278)(R -9.4251, F 7.9682, G 0.0029)] [G loss: -8.7972]\n",
      "6524 (5, 1) [D loss: (-0.4618)(R -8.1615, F 7.6734, G 0.0026)] [G loss: -7.7595]\n",
      "6525 (5, 1) [D loss: (-0.7054)(R -7.3206, F 6.5963, G 0.0019)] [G loss: -6.6656]\n",
      "6526 (5, 1) [D loss: (-0.9397)(R -6.4391, F 5.4713, G 0.0028)] [G loss: -6.5490]\n",
      "6527 (5, 1) [D loss: (-1.0101)(R -6.3718, F 5.3340, G 0.0028)] [G loss: -6.2113]\n",
      "6528 (5, 1) [D loss: (-1.2214)(R -5.7668, F 4.5155, G 0.0030)] [G loss: -4.9285]\n",
      "6529 (5, 1) [D loss: (-1.2576)(R -4.6660, F 3.3843, G 0.0024)] [G loss: -3.9047]\n",
      "6530 (5, 1) [D loss: (-0.6864)(R -2.5744, F 1.8571, G 0.0031)] [G loss: -2.2279]\n",
      "6531 (5, 1) [D loss: (-0.8428)(R -1.0215, F 0.1549, G 0.0024)] [G loss: 0.0543]\n",
      "6532 (5, 1) [D loss: (-1.2203)(R 0.2129, F -1.4571, G 0.0024)] [G loss: 2.0942]\n",
      "6533 (5, 1) [D loss: (-0.5595)(R 2.8642, F -3.4514, G 0.0028)] [G loss: 4.0353]\n",
      "6534 (5, 1) [D loss: (-1.3228)(R 4.0896, F -5.4523, G 0.0040)] [G loss: 5.4207]\n",
      "6535 (5, 1) [D loss: (-0.8990)(R 5.5606, F -6.5134, G 0.0054)] [G loss: 6.9337]\n",
      "6536 (5, 1) [D loss: (-1.0176)(R 6.8464, F -7.9109, G 0.0047)] [G loss: 8.3079]\n",
      "6537 (5, 1) [D loss: (-0.9510)(R 7.5251, F -8.5210, G 0.0045)] [G loss: 9.0234]\n",
      "6538 (5, 1) [D loss: (-0.3483)(R 7.9024, F -8.2964, G 0.0046)] [G loss: 9.0141]\n",
      "6539 (5, 1) [D loss: (-1.1219)(R 7.3705, F -8.5430, G 0.0051)] [G loss: 8.7143]\n",
      "6540 (5, 1) [D loss: (-1.2520)(R 6.9205, F -8.2169, G 0.0044)] [G loss: 8.4577]\n",
      "6541 (5, 1) [D loss: (-0.8488)(R 6.9276, F -7.8239, G 0.0048)] [G loss: 8.4861]\n",
      "6542 (5, 1) [D loss: (-0.7045)(R 6.8085, F -7.5458, G 0.0033)] [G loss: 8.0171]\n",
      "6543 (5, 1) [D loss: (-0.4104)(R 7.6797, F -8.1221, G 0.0032)] [G loss: 8.8027]\n",
      "6544 (5, 1) [D loss: (-0.4748)(R 8.5028, F -9.0333, G 0.0056)] [G loss: 9.8083]\n",
      "6545 (5, 1) [D loss: (-1.1665)(R 9.6000, F -10.8164, G 0.0050)] [G loss: 11.0914]\n",
      "6546 (5, 1) [D loss: (-1.1437)(R 10.6344, F -11.8406, G 0.0063)] [G loss: 11.9255]\n",
      "6547 (5, 1) [D loss: (-1.4404)(R 11.5443, F -13.0586, G 0.0074)] [G loss: 13.0471]\n",
      "6548 (5, 1) [D loss: (-2.1756)(R 12.0431, F -14.3156, G 0.0097)] [G loss: 14.2908]\n",
      "6549 (5, 1) [D loss: (-1.7351)(R 13.4675, F -15.3328, G 0.0130)] [G loss: 15.2398]\n",
      "6550 (5, 1) [D loss: (-1.2937)(R 13.8837, F -15.2985, G 0.0121)] [G loss: 14.1816]\n",
      "6551 (5, 1) [D loss: (-1.6008)(R 13.8766, F -15.5854, G 0.0108)] [G loss: 14.5392]\n",
      "6552 (5, 1) [D loss: (-1.7329)(R 13.7312, F -15.5671, G 0.0103)] [G loss: 14.5465]\n",
      "6553 (5, 1) [D loss: (-1.4970)(R 12.2615, F -13.8239, G 0.0065)] [G loss: 13.2749]\n",
      "6554 (5, 1) [D loss: (-0.9180)(R 11.2556, F -12.2049, G 0.0031)] [G loss: 11.4077]\n",
      "6555 (5, 1) [D loss: (-0.5661)(R 10.3872, F -10.9910, G 0.0038)] [G loss: 10.0077]\n",
      "6556 (5, 1) [D loss: (-1.1436)(R 8.9152, F -10.0855, G 0.0027)] [G loss: 9.8180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6557 (5, 1) [D loss: (-1.1283)(R 8.6243, F -9.7852, G 0.0033)] [G loss: 9.0174]\n",
      "6558 (5, 1) [D loss: (-0.9711)(R 8.9005, F -9.9078, G 0.0036)] [G loss: 9.4592]\n",
      "6559 (5, 1) [D loss: (-1.3397)(R 9.3432, F -10.7445, G 0.0062)] [G loss: 9.6580]\n",
      "6560 (5, 1) [D loss: (-1.0183)(R 9.5836, F -10.6653, G 0.0063)] [G loss: 9.9723]\n",
      "6561 (5, 1) [D loss: (-1.0157)(R 9.5836, F -10.6570, G 0.0058)] [G loss: 9.4254]\n",
      "6562 (5, 1) [D loss: (-1.1254)(R 9.0431, F -10.2110, G 0.0042)] [G loss: 9.3754]\n",
      "6563 (5, 1) [D loss: (-1.3523)(R 9.5860, F -10.9921, G 0.0054)] [G loss: 10.3098]\n",
      "6564 (5, 1) [D loss: (-0.3964)(R 10.8091, F -11.2869, G 0.0081)] [G loss: 10.4865]\n",
      "6565 (5, 1) [D loss: (-0.7910)(R 9.8008, F -10.6522, G 0.0060)] [G loss: 9.9486]\n",
      "6566 (5, 1) [D loss: (-1.0598)(R 9.1880, F -10.2982, G 0.0050)] [G loss: 9.3768]\n",
      "6567 (5, 1) [D loss: (-0.9410)(R 9.2218, F -10.2108, G 0.0048)] [G loss: 9.0423]\n",
      "6568 (5, 1) [D loss: (-0.7075)(R 8.3936, F -9.1334, G 0.0032)] [G loss: 8.3401]\n",
      "6569 (5, 1) [D loss: (-0.5558)(R 7.4672, F -8.0462, G 0.0023)] [G loss: 7.4919]\n",
      "6570 (5, 1) [D loss: (-1.0224)(R 5.6920, F -6.7387, G 0.0024)] [G loss: 5.8692]\n",
      "6571 (5, 1) [D loss: (-1.3718)(R 3.9576, F -5.3542, G 0.0025)] [G loss: 4.5726]\n",
      "6572 (5, 1) [D loss: (-1.0396)(R 2.7698, F -3.8346, G 0.0025)] [G loss: 3.1689]\n",
      "6573 (5, 1) [D loss: (-1.2998)(R 1.1117, F -2.4346, G 0.0023)] [G loss: 1.8210]\n",
      "6574 (5, 1) [D loss: (-1.1697)(R -0.8503, F -0.3479, G 0.0029)] [G loss: 0.6491]\n",
      "6575 (5, 1) [D loss: (-0.8370)(R -2.2844, F 1.4141, G 0.0033)] [G loss: -1.2520]\n",
      "6576 (5, 1) [D loss: (-1.2435)(R -3.5715, F 2.2717, G 0.0056)] [G loss: -2.3980]\n",
      "6577 (5, 1) [D loss: (-1.3410)(R -5.1596, F 3.7442, G 0.0074)] [G loss: -3.9629]\n",
      "6578 (5, 1) [D loss: (-1.5009)(R -5.7173, F 4.1521, G 0.0064)] [G loss: -4.4829]\n",
      "6579 (5, 1) [D loss: (-1.3321)(R -6.0921, F 4.6827, G 0.0077)] [G loss: -4.4914]\n",
      "6580 (5, 1) [D loss: (-1.8474)(R -6.4964, F 4.5647, G 0.0084)] [G loss: -5.4217]\n",
      "6581 (5, 1) [D loss: (-1.8436)(R -7.2848, F 5.3460, G 0.0095)] [G loss: -5.8280]\n",
      "6582 (5, 1) [D loss: (-2.5319)(R -7.6439, F 5.0267, G 0.0085)] [G loss: -5.6311]\n",
      "6583 (5, 1) [D loss: (-1.8903)(R -7.7652, F 5.7616, G 0.0113)] [G loss: -6.6746]\n",
      "6584 (5, 1) [D loss: (-1.3203)(R -8.0018, F 6.5726, G 0.0109)] [G loss: -6.6325]\n",
      "6585 (5, 1) [D loss: (-1.6284)(R -8.3460, F 6.6277, G 0.0090)] [G loss: -7.2059]\n",
      "6586 (5, 1) [D loss: (-2.2590)(R -9.3198, F 6.9538, G 0.0107)] [G loss: -7.9063]\n",
      "6587 (5, 1) [D loss: (-1.1875)(R -8.6666, F 7.3738, G 0.0105)] [G loss: -7.9010]\n",
      "6588 (5, 1) [D loss: (-1.3957)(R -9.2318, F 7.7547, G 0.0081)] [G loss: -8.2531]\n",
      "6589 (5, 1) [D loss: (-1.1407)(R -9.5406, F 8.2854, G 0.0114)] [G loss: -8.7495]\n",
      "6590 (5, 1) [D loss: (-1.6567)(R -9.3501, F 7.6243, G 0.0069)] [G loss: -8.6618]\n",
      "6591 (5, 1) [D loss: (-1.0600)(R -8.7214, F 7.6082, G 0.0053)] [G loss: -8.2610]\n",
      "6592 (5, 1) [D loss: (-1.1251)(R -8.1928, F 7.0350, G 0.0033)] [G loss: -7.4351]\n",
      "6593 (5, 1) [D loss: (-0.8800)(R -6.9336, F 6.0322, G 0.0021)] [G loss: -6.4890]\n",
      "6594 (5, 1) [D loss: (-0.5868)(R -5.7001, F 5.0959, G 0.0017)] [G loss: -4.8664]\n",
      "6595 (5, 1) [D loss: (-0.5542)(R -3.8770, F 3.3035, G 0.0019)] [G loss: -3.2588]\n",
      "6596 (5, 1) [D loss: (-0.8009)(R -2.6409, F 1.8191, G 0.0021)] [G loss: -2.4052]\n",
      "6597 (5, 1) [D loss: (-0.9462)(R -1.6657, F 0.6997, G 0.0020)] [G loss: -0.9436]\n",
      "6598 (5, 1) [D loss: (-0.8925)(R -1.0779, F 0.1560, G 0.0029)] [G loss: -0.7183]\n",
      "6599 (5, 1) [D loss: (-0.6506)(R -0.4380, F -0.2479, G 0.0035)] [G loss: 0.1480]\n",
      "6600 (5, 1) [D loss: (-1.0603)(R 0.0482, F -1.1462, G 0.0038)] [G loss: 0.7622]\n",
      "6601 (5, 1) [D loss: (-1.0008)(R 0.7160, F -1.7718, G 0.0055)] [G loss: 1.3360]\n",
      "6602 (5, 1) [D loss: (-0.6330)(R 0.6629, F -1.3472, G 0.0051)] [G loss: 1.1426]\n",
      "6603 (5, 1) [D loss: (-0.9437)(R 0.8198, F -1.8121, G 0.0049)] [G loss: 1.3500]\n",
      "6604 (5, 1) [D loss: (-1.2086)(R 0.4272, F -1.6784, G 0.0043)] [G loss: 0.7061]\n",
      "6605 (5, 1) [D loss: (-0.7310)(R 0.1515, F -0.9228, G 0.0040)] [G loss: 0.7635]\n",
      "6606 (5, 1) [D loss: (-1.1929)(R 0.3090, F -1.5369, G 0.0035)] [G loss: 0.9682]\n",
      "6607 (5, 1) [D loss: (-0.9936)(R 0.2639, F -1.2935, G 0.0036)] [G loss: 0.9026]\n",
      "6608 (5, 1) [D loss: (-0.9786)(R 0.5668, F -1.5910, G 0.0046)] [G loss: 1.2423]\n",
      "6609 (5, 1) [D loss: (-0.8234)(R 1.2110, F -2.0654, G 0.0031)] [G loss: 1.9898]\n",
      "6610 (5, 1) [D loss: (-1.3945)(R 2.3504, F -3.7717, G 0.0027)] [G loss: 3.6175]\n",
      "6611 (5, 1) [D loss: (-0.9519)(R 4.5186, F -5.5019, G 0.0031)] [G loss: 5.6591]\n",
      "6612 (5, 1) [D loss: (-1.2756)(R 7.1771, F -8.4903, G 0.0038)] [G loss: 8.8592]\n",
      "6613 (5, 1) [D loss: (-1.6015)(R 9.1849, F -10.8326, G 0.0046)] [G loss: 11.3424]\n",
      "6614 (5, 1) [D loss: (-1.2217)(R 11.8044, F -13.0902, G 0.0064)] [G loss: 13.7668]\n",
      "6615 (5, 1) [D loss: (-1.1599)(R 14.5375, F -15.7757, G 0.0078)] [G loss: 15.8148]\n",
      "6616 (5, 1) [D loss: (-1.3920)(R 15.8772, F -17.3654, G 0.0096)] [G loss: 17.3730]\n",
      "6617 (5, 1) [D loss: (-1.5668)(R 17.5774, F -19.2578, G 0.0114)] [G loss: 18.9892]\n",
      "6618 (5, 1) [D loss: (-1.9508)(R 17.4535, F -19.5253, G 0.0121)] [G loss: 19.8873]\n",
      "6619 (5, 1) [D loss: (-1.3561)(R 19.2385, F -20.7198, G 0.0125)] [G loss: 20.0109]\n",
      "6620 (5, 1) [D loss: (-2.0463)(R 18.4992, F -20.6796, G 0.0134)] [G loss: 20.5073]\n",
      "6621 (5, 1) [D loss: (-1.8586)(R 18.8265, F -20.8331, G 0.0148)] [G loss: 20.4856]\n",
      "6622 (5, 1) [D loss: (-1.1509)(R 18.3761, F -19.6455, G 0.0119)] [G loss: 19.1415]\n",
      "6623 (5, 1) [D loss: (-1.9489)(R 18.2215, F -20.3218, G 0.0151)] [G loss: 19.4354]\n",
      "6624 (5, 1) [D loss: (-2.1228)(R 17.8893, F -20.1672, G 0.0155)] [G loss: 18.4814]\n",
      "6625 (5, 1) [D loss: (-2.1992)(R 17.7150, F -20.0698, G 0.0156)] [G loss: 18.9776]\n",
      "6626 (5, 1) [D loss: (-2.3060)(R 18.4892, F -21.0094, G 0.0214)] [G loss: 19.1710]\n",
      "6627 (5, 1) [D loss: (-1.9801)(R 18.4145, F -20.5653, G 0.0171)] [G loss: 19.0998]\n",
      "6628 (5, 1) [D loss: (-1.5518)(R 18.6337, F -20.3908, G 0.0205)] [G loss: 18.4273]\n",
      "6629 (5, 1) [D loss: (-1.2066)(R 19.1144, F -20.4876, G 0.0167)] [G loss: 18.2529]\n",
      "6630 (5, 1) [D loss: (-1.3613)(R 17.5888, F -19.0680, G 0.0118)] [G loss: 17.0865]\n",
      "6631 (5, 1) [D loss: (-0.7080)(R 17.1972, F -17.9934, G 0.0088)] [G loss: 16.5414]\n",
      "6632 (5, 1) [D loss: (-1.2773)(R 14.7528, F -16.0674, G 0.0037)] [G loss: 14.3701]\n",
      "6633 (5, 1) [D loss: (-0.5480)(R 14.0924, F -14.6674, G 0.0027)] [G loss: 13.5142]\n",
      "6634 (5, 1) [D loss: (-0.8364)(R 11.7155, F -12.5868, G 0.0035)] [G loss: 11.2892]\n",
      "6635 (5, 1) [D loss: (-0.0307)(R 10.6432, F -10.7081, G 0.0034)] [G loss: 10.1880]\n",
      "6636 (5, 1) [D loss: (-0.8027)(R 8.5956, F -9.4342, G 0.0036)] [G loss: 8.2892]\n",
      "6637 (5, 1) [D loss: (-1.0310)(R 7.2960, F -8.3561, G 0.0029)] [G loss: 7.5622]\n",
      "6638 (5, 1) [D loss: (-0.6945)(R 6.0983, F -6.8119, G 0.0019)] [G loss: 6.2815]\n",
      "6639 (5, 1) [D loss: (-0.8738)(R 4.0814, F -4.9752, G 0.0020)] [G loss: 4.5934]\n",
      "6640 (5, 1) [D loss: (-1.3246)(R 2.4389, F -3.7854, G 0.0022)] [G loss: 3.0197]\n",
      "6641 (5, 1) [D loss: (-1.1084)(R 1.1914, F -2.3285, G 0.0029)] [G loss: 2.3741]\n",
      "6642 (5, 1) [D loss: (-1.3877)(R 0.2975, F -1.7314, G 0.0046)] [G loss: 1.1790]\n",
      "6643 (5, 1) [D loss: (-1.2836)(R -1.2032, F -0.1264, G 0.0046)] [G loss: -0.3080]\n",
      "6644 (5, 1) [D loss: (-1.5752)(R -1.7504, F 0.1189, G 0.0056)] [G loss: -0.9780]\n",
      "6645 (5, 1) [D loss: (-1.1352)(R -2.8687, F 1.6735, G 0.0060)] [G loss: -1.2056]\n",
      "6646 (5, 1) [D loss: (-0.7791)(R -2.9713, F 2.1408, G 0.0051)] [G loss: -1.6240]\n",
      "6647 (5, 1) [D loss: (-1.2298)(R -3.7660, F 2.4816, G 0.0055)] [G loss: -2.3017]\n",
      "6648 (5, 1) [D loss: (-1.2661)(R -4.1559, F 2.8437, G 0.0046)] [G loss: -2.7048]\n",
      "6649 (5, 1) [D loss: (-0.9976)(R -4.2408, F 3.1875, G 0.0056)] [G loss: -2.8662]\n",
      "6650 (5, 1) [D loss: (-1.9053)(R -4.8467, F 2.8884, G 0.0053)] [G loss: -2.8352]\n",
      "6651 (5, 1) [D loss: (-1.1316)(R -4.6501, F 3.4510, G 0.0068)] [G loss: -3.3235]\n",
      "6652 (5, 1) [D loss: (-1.2815)(R -4.7657, F 3.4318, G 0.0052)] [G loss: -3.2277]\n",
      "6653 (5, 1) [D loss: (-2.0529)(R -5.1984, F 3.0966, G 0.0049)] [G loss: -3.3838]\n",
      "6654 (5, 1) [D loss: (-1.2434)(R -5.1583, F 3.8513, G 0.0064)] [G loss: -3.8741]\n",
      "6655 (5, 1) [D loss: (-0.9502)(R -5.5154, F 4.5036, G 0.0062)] [G loss: -4.5820]\n",
      "6656 (5, 1) [D loss: (-1.3867)(R -5.8689, F 4.4158, G 0.0066)] [G loss: -4.8006]\n",
      "6657 (5, 1) [D loss: (-1.4406)(R -6.1132, F 4.6150, G 0.0058)] [G loss: -5.4168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6658 (5, 1) [D loss: (-1.7400)(R -6.5628, F 4.7515, G 0.0071)] [G loss: -5.4801]\n",
      "6659 (5, 1) [D loss: (-1.2472)(R -6.2062, F 4.9051, G 0.0054)] [G loss: -5.3581]\n",
      "6660 (5, 1) [D loss: (-1.4647)(R -5.9596, F 4.4492, G 0.0046)] [G loss: -5.3487]\n",
      "6661 (5, 1) [D loss: (-0.8764)(R -5.4864, F 4.5669, G 0.0043)] [G loss: -4.6362]\n",
      "6662 (5, 1) [D loss: (-0.8474)(R -4.4438, F 3.5638, G 0.0033)] [G loss: -3.6271]\n",
      "6663 (5, 1) [D loss: (-1.0441)(R -4.6220, F 3.5375, G 0.0040)] [G loss: -3.7728]\n",
      "6664 (5, 1) [D loss: (-1.1939)(R -4.3468, F 3.1157, G 0.0037)] [G loss: -3.4903]\n",
      "6665 (5, 1) [D loss: (-0.9309)(R -3.9391, F 2.9710, G 0.0037)] [G loss: -2.9790]\n",
      "6666 (5, 1) [D loss: (-1.1959)(R -3.5051, F 2.2716, G 0.0038)] [G loss: -2.9303]\n",
      "6667 (5, 1) [D loss: (-1.0741)(R -3.1668, F 2.0494, G 0.0043)] [G loss: -3.0835]\n",
      "6668 (5, 1) [D loss: (-1.3348)(R -4.0091, F 2.6230, G 0.0051)] [G loss: -3.3204]\n",
      "6669 (5, 1) [D loss: (-1.2740)(R -3.8209, F 2.4962, G 0.0051)] [G loss: -3.4195]\n",
      "6670 (5, 1) [D loss: (-1.1735)(R -3.8591, F 2.6319, G 0.0054)] [G loss: -3.2466]\n",
      "6671 (5, 1) [D loss: (-0.9413)(R -3.1138, F 2.1348, G 0.0038)] [G loss: -2.8736]\n",
      "6672 (5, 1) [D loss: (-0.8493)(R -3.0922, F 2.2026, G 0.0040)] [G loss: -2.1772]\n",
      "6673 (5, 1) [D loss: (-0.1175)(R -2.2282, F 2.0723, G 0.0039)] [G loss: -1.6613]\n",
      "6674 (5, 1) [D loss: (-1.3250)(R -1.9371, F 0.5883, G 0.0024)] [G loss: -0.8343]\n",
      "6675 (5, 1) [D loss: (-0.8105)(R -0.8873, F 0.0401, G 0.0037)] [G loss: -0.0264]\n",
      "6676 (5, 1) [D loss: (-0.4856)(R 0.6504, F -1.1583, G 0.0022)] [G loss: 1.0779]\n",
      "6677 (5, 1) [D loss: (-1.3209)(R 1.8765, F -3.2223, G 0.0025)] [G loss: 3.6736]\n",
      "6678 (5, 1) [D loss: (-1.0653)(R 3.7835, F -4.8834, G 0.0034)] [G loss: 5.0261]\n",
      "6679 (5, 1) [D loss: (-1.5207)(R 5.9463, F -7.5031, G 0.0036)] [G loss: 8.0468]\n",
      "6680 (5, 1) [D loss: (-1.0297)(R 8.7051, F -9.7932, G 0.0058)] [G loss: 10.7696]\n",
      "6681 (5, 1) [D loss: (-1.4186)(R 11.0257, F -12.5229, G 0.0079)] [G loss: 13.2047]\n",
      "6682 (5, 1) [D loss: (-1.0921)(R 13.2765, F -14.4803, G 0.0112)] [G loss: 15.1500]\n",
      "6683 (5, 1) [D loss: (-1.8003)(R 14.8063, F -16.7282, G 0.0122)] [G loss: 17.0742]\n",
      "6684 (5, 1) [D loss: (-1.3963)(R 16.2837, F -17.7989, G 0.0119)] [G loss: 17.5714]\n",
      "6685 (5, 1) [D loss: (-1.8074)(R 15.5834, F -17.4800, G 0.0089)] [G loss: 16.9681]\n",
      "6686 (5, 1) [D loss: (-1.4492)(R 15.3356, F -16.8500, G 0.0065)] [G loss: 16.6622]\n",
      "6687 (5, 1) [D loss: (-1.5570)(R 14.6375, F -16.2441, G 0.0050)] [G loss: 16.6454]\n",
      "6688 (5, 1) [D loss: (-1.6561)(R 14.0014, F -15.7015, G 0.0044)] [G loss: 15.1529]\n",
      "6689 (5, 1) [D loss: (-1.4762)(R 12.8661, F -14.3729, G 0.0031)] [G loss: 14.2041]\n",
      "6690 (5, 1) [D loss: (-0.8214)(R 13.2396, F -14.1045, G 0.0043)] [G loss: 14.3326]\n",
      "6691 (5, 1) [D loss: (-1.6618)(R 13.9513, F -15.6851, G 0.0072)] [G loss: 15.5758]\n",
      "6692 (5, 1) [D loss: (-0.9083)(R 16.0187, F -17.0561, G 0.0129)] [G loss: 15.9088]\n",
      "6693 (5, 1) [D loss: (-1.2519)(R 18.0742, F -19.5390, G 0.0213)] [G loss: 18.3127]\n",
      "6694 (5, 1) [D loss: (-2.0053)(R 19.2143, F -21.5054, G 0.0286)] [G loss: 20.3756]\n",
      "6695 (5, 1) [D loss: (-2.2539)(R 20.7343, F -23.3257, G 0.0338)] [G loss: 20.7600]\n",
      "6696 (5, 1) [D loss: (-1.7850)(R 19.3250, F -21.3572, G 0.0247)] [G loss: 19.1737]\n",
      "6697 (5, 1) [D loss: (-1.6631)(R 17.9300, F -19.7400, G 0.0147)] [G loss: 18.0475]\n",
      "6698 (5, 1) [D loss: (-1.7561)(R 16.0164, F -17.8364, G 0.0064)] [G loss: 16.3328]\n",
      "6699 (5, 1) [D loss: (-0.4218)(R 14.8243, F -15.2802, G 0.0034)] [G loss: 14.0194]\n",
      "6700 (5, 1) [D loss: (-0.7654)(R 11.9917, F -12.7849, G 0.0028)] [G loss: 11.9265]\n",
      "6701 (5, 1) [D loss: (-0.8800)(R 9.4322, F -10.3657, G 0.0054)] [G loss: 9.5124]\n",
      "6702 (5, 1) [D loss: (-0.5184)(R 7.6246, F -8.1930, G 0.0050)] [G loss: 7.7208]\n",
      "6703 (5, 1) [D loss: (-0.8138)(R 5.2921, F -6.1483, G 0.0042)] [G loss: 5.4960]\n",
      "6704 (5, 1) [D loss: (-1.3738)(R 2.6244, F -4.0167, G 0.0019)] [G loss: 3.1048]\n",
      "6705 (5, 1) [D loss: (-1.3009)(R 0.7492, F -2.0668, G 0.0017)] [G loss: 1.4761]\n",
      "6706 (5, 1) [D loss: (-0.8111)(R -0.1729, F -0.6867, G 0.0049)] [G loss: 0.6602]\n",
      "6707 (5, 1) [D loss: (-1.0342)(R -0.7584, F -0.3222, G 0.0046)] [G loss: 0.7212]\n",
      "6708 (5, 1) [D loss: (-0.9445)(R -0.2800, F -0.7192, G 0.0055)] [G loss: 0.8547]\n",
      "6709 (5, 1) [D loss: (-0.7249)(R 0.4134, F -1.1799, G 0.0042)] [G loss: 1.3240]\n",
      "6710 (5, 1) [D loss: (-0.4360)(R 1.2274, F -1.6973, G 0.0034)] [G loss: 2.4767]\n",
      "6711 (5, 1) [D loss: (-0.7015)(R 2.0641, F -2.8031, G 0.0037)] [G loss: 3.6529]\n",
      "6712 (5, 1) [D loss: (-1.3174)(R 3.1366, F -4.5000, G 0.0046)] [G loss: 4.9339]\n",
      "6713 (5, 1) [D loss: (-1.7720)(R 3.9981, F -5.8487, G 0.0079)] [G loss: 5.6483]\n",
      "6714 (5, 1) [D loss: (-1.5119)(R 4.4151, F -6.0098, G 0.0083)] [G loss: 6.0584]\n",
      "6715 (5, 1) [D loss: (-0.7632)(R 4.0874, F -4.9370, G 0.0086)] [G loss: 5.0204]\n",
      "6716 (5, 1) [D loss: (-0.7448)(R 2.8879, F -3.6847, G 0.0052)] [G loss: 3.7165]\n",
      "6717 (5, 1) [D loss: (-0.7056)(R 1.2262, F -1.9645, G 0.0033)] [G loss: 2.2707]\n",
      "6718 (5, 1) [D loss: (-0.8132)(R -0.1135, F -0.7383, G 0.0039)] [G loss: 0.6144]\n",
      "6719 (5, 1) [D loss: (-1.5318)(R -2.1008, F 0.5123, G 0.0057)] [G loss: -0.8287]\n",
      "6720 (5, 1) [D loss: (-1.8029)(R -2.9583, F 1.0760, G 0.0079)] [G loss: -1.8059]\n",
      "6721 (5, 1) [D loss: (-1.6145)(R -3.1806, F 1.4682, G 0.0098)] [G loss: -1.6131]\n",
      "6722 (5, 1) [D loss: (-1.4807)(R -3.2431, F 1.6848, G 0.0078)] [G loss: -1.5572]\n",
      "6723 (5, 1) [D loss: (-0.6541)(R -2.2842, F 1.5649, G 0.0065)] [G loss: -0.9331]\n",
      "6724 (5, 1) [D loss: (-0.9344)(R -1.5693, F 0.6020, G 0.0033)] [G loss: -0.7071]\n",
      "6725 (5, 1) [D loss: (-0.5612)(R -0.8975, F 0.3095, G 0.0027)] [G loss: -0.1469]\n",
      "6726 (5, 1) [D loss: (-0.5632)(R 0.0383, F -0.6189, G 0.0017)] [G loss: 1.2967]\n",
      "6727 (5, 1) [D loss: (-1.0539)(R 1.0328, F -2.1128, G 0.0026)] [G loss: 2.2259]\n",
      "6728 (5, 1) [D loss: (-1.1692)(R 1.8600, F -3.0576, G 0.0028)] [G loss: 3.2384]\n",
      "6729 (5, 1) [D loss: (-1.1245)(R 2.5831, F -3.7273, G 0.0020)] [G loss: 3.5624]\n",
      "6730 (5, 1) [D loss: (-1.2056)(R 2.8610, F -4.1014, G 0.0035)] [G loss: 4.1881]\n",
      "6731 (5, 1) [D loss: (-0.7569)(R 3.0529, F -3.8509, G 0.0041)] [G loss: 4.0209]\n",
      "6732 (5, 1) [D loss: (-0.8027)(R 2.4799, F -3.3287, G 0.0046)] [G loss: 2.7687]\n",
      "6733 (5, 1) [D loss: (-0.7749)(R 1.3216, F -2.1613, G 0.0065)] [G loss: 1.5435]\n",
      "6734 (5, 1) [D loss: (-0.8791)(R -0.1231, F -0.8094, G 0.0053)] [G loss: 0.5680]\n",
      "6735 (5, 1) [D loss: (-1.0138)(R -1.3498, F 0.2568, G 0.0079)] [G loss: -1.1004]\n",
      "6736 (5, 1) [D loss: (-1.3295)(R -2.8581, F 1.4413, G 0.0087)] [G loss: -2.1015]\n",
      "6737 (5, 1) [D loss: (-1.3113)(R -3.1732, F 1.7453, G 0.0117)] [G loss: -2.9250]\n",
      "6738 (5, 1) [D loss: (-1.0625)(R -2.6971, F 1.5658, G 0.0069)] [G loss: -1.9099]\n",
      "6739 (5, 1) [D loss: (-0.8367)(R -1.3635, F 0.4869, G 0.0040)] [G loss: -0.7637]\n",
      "6740 (5, 1) [D loss: (-0.8021)(R -0.1216, F -0.7054, G 0.0025)] [G loss: 0.5845]\n",
      "6741 (5, 1) [D loss: (-0.6216)(R 1.5902, F -2.2335, G 0.0022)] [G loss: 2.0933]\n",
      "6742 (5, 1) [D loss: (-0.2167)(R 4.0156, F -4.2547, G 0.0022)] [G loss: 5.1634]\n",
      "6743 (5, 1) [D loss: (-1.0831)(R 6.1173, F -7.2262, G 0.0026)] [G loss: 7.7657]\n",
      "6744 (5, 1) [D loss: (-0.7180)(R 8.7868, F -9.5295, G 0.0025)] [G loss: 10.3382]\n",
      "6745 (5, 1) [D loss: (-1.4378)(R 10.6747, F -12.1569, G 0.0044)] [G loss: 12.6997]\n",
      "6746 (5, 1) [D loss: (-0.7380)(R 12.7292, F -13.5428, G 0.0076)] [G loss: 13.5958]\n",
      "6747 (5, 1) [D loss: (-0.9683)(R 13.8057, F -14.8580, G 0.0084)] [G loss: 15.7113]\n",
      "6748 (5, 1) [D loss: (-1.2945)(R 14.5681, F -15.9305, G 0.0068)] [G loss: 15.8939]\n",
      "6749 (5, 1) [D loss: (-0.8946)(R 13.7305, F -14.6855, G 0.0060)] [G loss: 15.0611]\n",
      "6750 (5, 1) [D loss: (-0.7877)(R 12.3728, F -13.1973, G 0.0037)] [G loss: 12.9895]\n",
      "6751 (5, 1) [D loss: (-0.7439)(R 10.6469, F -11.4225, G 0.0032)] [G loss: 11.6437]\n",
      "6752 (5, 1) [D loss: (-0.7193)(R 8.8995, F -9.6497, G 0.0031)] [G loss: 9.4924]\n",
      "6753 (5, 1) [D loss: (-1.2902)(R 7.3117, F -8.6418, G 0.0040)] [G loss: 7.8697]\n",
      "6754 (5, 1) [D loss: (-1.7845)(R 6.7409, F -8.5640, G 0.0039)] [G loss: 8.7103]\n",
      "6755 (5, 1) [D loss: (-0.9431)(R 8.0449, F -9.0356, G 0.0048)] [G loss: 8.9404]\n",
      "6756 (5, 1) [D loss: (-1.1245)(R 9.7515, F -10.9275, G 0.0051)] [G loss: 11.7428]\n",
      "6757 (5, 1) [D loss: (-1.2264)(R 12.7294, F -14.0117, G 0.0056)] [G loss: 13.8374]\n",
      "6758 (5, 1) [D loss: (-1.2120)(R 16.0245, F -17.3224, G 0.0086)] [G loss: 17.6103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6759 (5, 1) [D loss: (-1.4348)(R 19.1905, F -20.7815, G 0.0156)] [G loss: 21.3292]\n",
      "6760 (5, 1) [D loss: (-1.7091)(R 24.1695, F -26.1635, G 0.0285)] [G loss: 25.8947]\n",
      "6761 (5, 1) [D loss: (-1.8851)(R 25.8604, F -28.0699, G 0.0324)] [G loss: 27.0560]\n",
      "6762 (5, 1) [D loss: (-2.4720)(R 26.0691, F -28.8151, G 0.0274)] [G loss: 27.0255]\n",
      "6763 (5, 1) [D loss: (-1.6027)(R 24.9431, F -26.7044, G 0.0159)] [G loss: 25.1706]\n",
      "6764 (5, 1) [D loss: (-1.6831)(R 23.3785, F -25.1512, G 0.0090)] [G loss: 23.5235]\n",
      "6765 (5, 1) [D loss: (-0.3052)(R 21.0951, F -21.4312, G 0.0031)] [G loss: 20.8070]\n",
      "6766 (5, 1) [D loss: (-1.0727)(R 17.3283, F -18.4174, G 0.0016)] [G loss: 17.5885]\n",
      "6767 (5, 1) [D loss: (-0.4622)(R 14.8716, F -15.3588, G 0.0025)] [G loss: 14.8590]\n",
      "6768 (5, 1) [D loss: (-0.9852)(R 11.7715, F -12.7776, G 0.0021)] [G loss: 11.9546]\n",
      "6769 (5, 1) [D loss: (-1.0294)(R 9.7326, F -10.7822, G 0.0020)] [G loss: 10.1987]\n",
      "6770 (5, 1) [D loss: (-0.8900)(R 8.2756, F -9.1845, G 0.0019)] [G loss: 8.9660]\n",
      "6771 (5, 1) [D loss: (-0.6094)(R 8.3722, F -9.0039, G 0.0022)] [G loss: 9.0036]\n",
      "6772 (5, 1) [D loss: (-1.1622)(R 8.7851, F -9.9772, G 0.0030)] [G loss: 9.8155]\n",
      "6773 (5, 1) [D loss: (-0.9552)(R 11.4723, F -12.4893, G 0.0062)] [G loss: 11.9465]\n",
      "6774 (5, 1) [D loss: (-1.4573)(R 12.3639, F -13.9287, G 0.0107)] [G loss: 12.9918]\n",
      "6775 (5, 1) [D loss: (-0.8974)(R 13.5901, F -14.5909, G 0.0103)] [G loss: 13.9084]\n",
      "6776 (5, 1) [D loss: (-0.8399)(R 13.2445, F -14.1676, G 0.0083)] [G loss: 13.4761]\n",
      "6777 (5, 1) [D loss: (-1.1877)(R 11.9990, F -13.2485, G 0.0062)] [G loss: 12.4902]\n",
      "6778 (5, 1) [D loss: (-0.6838)(R 10.1572, F -10.8712, G 0.0030)] [G loss: 10.0689]\n",
      "6779 (5, 1) [D loss: (-1.0693)(R 7.1049, F -8.1949, G 0.0021)] [G loss: 7.7233]\n",
      "6780 (5, 1) [D loss: (-0.9736)(R 5.0935, F -6.0895, G 0.0022)] [G loss: 5.5774]\n",
      "6781 (5, 1) [D loss: (-1.0982)(R 2.4653, F -3.5818, G 0.0018)] [G loss: 3.5835]\n",
      "6782 (5, 1) [D loss: (-1.9804)(R 0.0226, F -2.0277, G 0.0025)] [G loss: 1.0792]\n",
      "6783 (5, 1) [D loss: (-1.9039)(R -2.3866, F 0.4203, G 0.0062)] [G loss: -1.2624]\n",
      "6784 (5, 1) [D loss: (-2.0264)(R -4.0815, F 1.9405, G 0.0115)] [G loss: -2.4334]\n",
      "6785 (5, 1) [D loss: (-2.2197)(R -5.1768, F 2.7861, G 0.0171)] [G loss: -3.4600]\n",
      "6786 (5, 1) [D loss: (-1.7326)(R -4.8639, F 2.9860, G 0.0145)] [G loss: -3.0118]\n",
      "6787 (5, 1) [D loss: (-2.2564)(R -4.5543, F 2.1384, G 0.0159)] [G loss: -3.1328]\n",
      "6788 (5, 1) [D loss: (-1.5415)(R -4.1167, F 2.4334, G 0.0142)] [G loss: -2.8399]\n",
      "6789 (5, 1) [D loss: (-1.3196)(R -3.6491, F 2.2346, G 0.0095)] [G loss: -2.3328]\n",
      "6790 (5, 1) [D loss: (-1.4302)(R -3.6418, F 2.1292, G 0.0082)] [G loss: -2.0715]\n",
      "6791 (5, 1) [D loss: (-0.8857)(R -2.4018, F 1.4619, G 0.0054)] [G loss: -1.1653]\n",
      "6792 (5, 1) [D loss: (-0.8844)(R -1.5913, F 0.6763, G 0.0031)] [G loss: -0.4602]\n",
      "6793 (5, 1) [D loss: (-1.0950)(R -1.4012, F 0.2630, G 0.0043)] [G loss: -0.0157]\n",
      "6794 (5, 1) [D loss: (-0.9809)(R -1.1264, F 0.1028, G 0.0043)] [G loss: 0.1730]\n",
      "6795 (5, 1) [D loss: (-0.5516)(R -0.1468, F -0.4321, G 0.0027)] [G loss: 0.7017]\n",
      "6796 (5, 1) [D loss: (-0.7698)(R -0.3009, F -0.5053, G 0.0036)] [G loss: 0.4969]\n",
      "6797 (5, 1) [D loss: (-1.2741)(R -0.6541, F -0.6491, G 0.0029)] [G loss: 0.1929]\n",
      "6798 (5, 1) [D loss: (-1.5676)(R -1.5393, F -0.0759, G 0.0048)] [G loss: -0.4690]\n",
      "6799 (5, 1) [D loss: (-1.1640)(R -1.7496, F 0.5385, G 0.0047)] [G loss: -0.7764]\n",
      "6800 (5, 1) [D loss: (-1.0951)(R -1.9003, F 0.7418, G 0.0063)] [G loss: -1.6718]\n",
      "6801 (5, 1) [D loss: (-0.9990)(R -2.6042, F 1.5242, G 0.0081)] [G loss: -2.1462]\n",
      "6802 (5, 1) [D loss: (-1.1960)(R -1.9930, F 0.7258, G 0.0071)] [G loss: -1.5831]\n",
      "6803 (5, 1) [D loss: (-1.4107)(R -1.9996, F 0.5381, G 0.0051)] [G loss: -1.1778]\n",
      "6804 (5, 1) [D loss: (-1.2736)(R -2.1410, F 0.8063, G 0.0061)] [G loss: -1.4298]\n",
      "6805 (5, 1) [D loss: (-1.0292)(R -1.8665, F 0.7924, G 0.0045)] [G loss: -1.3988]\n",
      "6806 (5, 1) [D loss: (-0.7135)(R -1.0192, F 0.2666, G 0.0039)] [G loss: -1.3089]\n",
      "6807 (5, 1) [D loss: (-0.9817)(R -0.2731, F -0.7277, G 0.0019)] [G loss: 0.0578]\n",
      "6808 (5, 1) [D loss: (-1.3569)(R -0.0432, F -1.3415, G 0.0028)] [G loss: 0.5189]\n",
      "6809 (5, 1) [D loss: (-0.9497)(R 0.6699, F -1.6437, G 0.0024)] [G loss: 1.1633]\n",
      "6810 (5, 1) [D loss: (-0.7469)(R 0.8395, F -1.6203, G 0.0034)] [G loss: 1.0566]\n",
      "6811 (5, 1) [D loss: (-0.8562)(R 2.0563, F -2.9376, G 0.0025)] [G loss: 2.7543]\n",
      "6812 (5, 1) [D loss: (-0.6846)(R 2.9035, F -3.6192, G 0.0031)] [G loss: 3.2926]\n",
      "6813 (5, 1) [D loss: (-0.8514)(R 3.4119, F -4.2966, G 0.0033)] [G loss: 4.1766]\n",
      "6814 (5, 1) [D loss: (-0.8817)(R 4.4157, F -5.3326, G 0.0035)] [G loss: 5.0890]\n",
      "6815 (5, 1) [D loss: (-1.4354)(R 4.7416, F -6.2094, G 0.0032)] [G loss: 6.4942]\n",
      "6816 (5, 1) [D loss: (-1.0256)(R 5.6974, F -6.7656, G 0.0043)] [G loss: 7.2752]\n",
      "6817 (5, 1) [D loss: (-0.6866)(R 7.2220, F -7.9507, G 0.0042)] [G loss: 8.6706]\n",
      "6818 (5, 1) [D loss: (-0.9105)(R 8.6319, F -9.5877, G 0.0045)] [G loss: 9.8158]\n",
      "6819 (5, 1) [D loss: (-0.9607)(R 8.9793, F -9.9948, G 0.0055)] [G loss: 10.4384]\n",
      "6820 (5, 1) [D loss: (-1.3925)(R 10.0231, F -11.4709, G 0.0055)] [G loss: 11.8406]\n",
      "6821 (5, 1) [D loss: (-1.4327)(R 11.9109, F -13.4077, G 0.0064)] [G loss: 13.3117]\n",
      "6822 (5, 1) [D loss: (-1.3953)(R 13.5018, F -14.9684, G 0.0071)] [G loss: 15.8877]\n",
      "6823 (5, 1) [D loss: (-1.9004)(R 16.3338, F -18.3487, G 0.0115)] [G loss: 18.9381]\n",
      "6824 (5, 1) [D loss: (-1.6732)(R 19.4505, F -21.2848, G 0.0161)] [G loss: 21.3892]\n",
      "6825 (5, 1) [D loss: (-2.5126)(R 21.2399, F -23.9104, G 0.0158)] [G loss: 22.9400]\n",
      "6826 (5, 1) [D loss: (-2.9741)(R 23.6393, F -26.8480, G 0.0235)] [G loss: 26.5899]\n",
      "6827 (5, 1) [D loss: (-2.7196)(R 25.6752, F -28.6557, G 0.0261)] [G loss: 27.6548]\n",
      "6828 (5, 1) [D loss: (-1.8752)(R 25.0311, F -27.1110, G 0.0205)] [G loss: 26.4046]\n",
      "6829 (5, 1) [D loss: (-1.0837)(R 25.4207, F -26.6504, G 0.0146)] [G loss: 25.8466]\n",
      "6830 (5, 1) [D loss: (-0.5249)(R 24.2834, F -24.8916, G 0.0083)] [G loss: 24.1304]\n",
      "6831 (5, 1) [D loss: (-2.3152)(R 22.2234, F -24.5973, G 0.0059)] [G loss: 23.6813]\n",
      "6832 (5, 1) [D loss: (-1.6023)(R 23.6028, F -25.2883, G 0.0083)] [G loss: 24.4809]\n",
      "6833 (5, 1) [D loss: (-0.5604)(R 24.5696, F -25.2112, G 0.0081)] [G loss: 23.9852]\n",
      "6834 (5, 1) [D loss: (-1.5380)(R 24.2805, F -25.9012, G 0.0083)] [G loss: 24.5089]\n",
      "6835 (5, 1) [D loss: (-0.4349)(R 22.9260, F -23.4143, G 0.0053)] [G loss: 22.1680]\n",
      "6836 (5, 1) [D loss: (-1.4096)(R 21.8254, F -23.2796, G 0.0045)] [G loss: 22.0072]\n",
      "6837 (5, 1) [D loss: (-1.5725)(R 21.5744, F -23.1989, G 0.0052)] [G loss: 21.8823]\n",
      "6838 (5, 1) [D loss: (-2.4670)(R 21.3143, F -23.8337, G 0.0052)] [G loss: 21.9728]\n",
      "6839 (5, 1) [D loss: (-1.7042)(R 21.4281, F -23.2007, G 0.0068)] [G loss: 21.3145]\n",
      "6840 (5, 1) [D loss: (-0.5602)(R 21.8377, F -22.4675, G 0.0070)] [G loss: 20.7176]\n",
      "6841 (5, 1) [D loss: (-1.3181)(R 21.9782, F -23.3852, G 0.0089)] [G loss: 21.6268]\n",
      "6842 (5, 1) [D loss: (-1.3208)(R 21.1901, F -22.5775, G 0.0067)] [G loss: 21.0700]\n",
      "6843 (5, 1) [D loss: (-0.5621)(R 20.6060, F -21.2380, G 0.0070)] [G loss: 19.7265]\n",
      "6844 (5, 1) [D loss: (-1.2333)(R 19.1087, F -20.3882, G 0.0046)] [G loss: 18.8552]\n",
      "6845 (5, 1) [D loss: (-0.1723)(R 17.8366, F -18.0436, G 0.0035)] [G loss: 16.7533]\n",
      "6846 (5, 1) [D loss: (-0.8241)(R 15.4549, F -16.3004, G 0.0021)] [G loss: 15.0285]\n",
      "6847 (5, 1) [D loss: (-0.7822)(R 13.4890, F -14.3023, G 0.0031)] [G loss: 12.8973]\n",
      "6848 (5, 1) [D loss: (-0.5157)(R 11.5705, F -12.1111, G 0.0025)] [G loss: 11.0574]\n",
      "6849 (5, 1) [D loss: (-0.5017)(R 9.4820, F -10.0141, G 0.0030)] [G loss: 9.5443]\n",
      "6850 (5, 1) [D loss: (-0.9992)(R 6.9865, F -8.0074, G 0.0022)] [G loss: 7.4480]\n",
      "6851 (5, 1) [D loss: (-0.9636)(R 5.7478, F -6.7272, G 0.0016)] [G loss: 6.7272]\n",
      "6852 (5, 1) [D loss: (-0.9410)(R 3.9166, F -4.8835, G 0.0026)] [G loss: 4.5287]\n",
      "6853 (5, 1) [D loss: (-1.4175)(R 2.4354, F -3.8794, G 0.0026)] [G loss: 3.7415]\n",
      "6854 (5, 1) [D loss: (-0.6938)(R 2.2762, F -3.0063, G 0.0036)] [G loss: 3.3116]\n",
      "6855 (5, 1) [D loss: (-0.8755)(R 1.4174, F -2.3381, G 0.0045)] [G loss: 3.1107]\n",
      "6856 (5, 1) [D loss: (-1.2544)(R 0.4786, F -1.7840, G 0.0051)] [G loss: 1.8579]\n",
      "6857 (5, 1) [D loss: (-1.6146)(R -0.6493, F -1.0247, G 0.0059)] [G loss: 1.3462]\n",
      "6858 (5, 1) [D loss: (-1.6065)(R -0.7913, F -0.8947, G 0.0079)] [G loss: 0.3330]\n",
      "6859 (5, 1) [D loss: (-1.5885)(R -1.7439, F 0.0221, G 0.0133)] [G loss: -0.0905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6860 (5, 1) [D loss: (-2.3586)(R -2.8742, F 0.3274, G 0.0188)] [G loss: -0.7872]\n",
      "6861 (5, 1) [D loss: (-3.2363)(R -3.5203, F 0.1079, G 0.0176)] [G loss: -1.2853]\n",
      "6862 (5, 1) [D loss: (-2.0389)(R -2.9288, F 0.7074, G 0.0183)] [G loss: -1.2570]\n",
      "6863 (5, 1) [D loss: (-1.9911)(R -3.2463, F 1.0553, G 0.0200)] [G loss: -1.9102]\n",
      "6864 (5, 1) [D loss: (-1.8577)(R -3.0619, F 1.0145, G 0.0190)] [G loss: -1.2497]\n",
      "6865 (5, 1) [D loss: (-2.1350)(R -2.8758, F 0.5943, G 0.0147)] [G loss: -1.4098]\n",
      "6866 (5, 1) [D loss: (-1.3691)(R -2.6621, F 1.1327, G 0.0160)] [G loss: -1.9733]\n",
      "6867 (5, 1) [D loss: (-1.6087)(R -2.6465, F 0.9340, G 0.0104)] [G loss: -1.5060]\n",
      "6868 (5, 1) [D loss: (-1.9977)(R -2.7704, F 0.6849, G 0.0088)] [G loss: -1.9356]\n",
      "6869 (5, 1) [D loss: (-1.4511)(R -2.8728, F 1.3324, G 0.0089)] [G loss: -2.3916]\n",
      "6870 (5, 1) [D loss: (-1.1932)(R -2.2547, F 0.9731, G 0.0088)] [G loss: -2.3797]\n",
      "6871 (5, 1) [D loss: (-1.4721)(R -1.7966, F 0.2791, G 0.0045)] [G loss: -1.3050]\n",
      "6872 (5, 1) [D loss: (-1.8272)(R -1.9802, F 0.1072, G 0.0046)] [G loss: -1.6486]\n",
      "6873 (5, 1) [D loss: (-1.6346)(R -2.1120, F 0.4352, G 0.0042)] [G loss: -1.8140]\n",
      "6874 (5, 1) [D loss: (-1.3438)(R -1.2293, F -0.1433, G 0.0029)] [G loss: -1.3547]\n",
      "6875 (5, 1) [D loss: (-0.8594)(R -0.1437, F -0.7373, G 0.0022)] [G loss: -0.4731]\n",
      "6876 (5, 1) [D loss: (-1.2301)(R 0.4539, F -1.7001, G 0.0016)] [G loss: 0.7854]\n",
      "6877 (5, 1) [D loss: (-0.6089)(R 1.2578, F -1.8847, G 0.0018)] [G loss: 1.4659]\n",
      "6878 (5, 1) [D loss: (-0.7993)(R 1.7708, F -2.5893, G 0.0019)] [G loss: 1.6318]\n",
      "6879 (5, 1) [D loss: (-0.5443)(R 2.4736, F -3.0461, G 0.0028)] [G loss: 2.9563]\n",
      "6880 (5, 1) [D loss: (-0.4106)(R 3.5725, F -4.0113, G 0.0028)] [G loss: 3.7585]\n",
      "6881 (5, 1) [D loss: (-0.2030)(R 4.6987, F -4.9348, G 0.0033)] [G loss: 5.3430]\n",
      "6882 (5, 1) [D loss: (-0.4557)(R 5.4224, F -5.9105, G 0.0032)] [G loss: 6.5232]\n",
      "6883 (5, 1) [D loss: (-0.4114)(R 6.9352, F -7.3778, G 0.0031)] [G loss: 7.6456]\n",
      "6884 (5, 1) [D loss: (-0.7112)(R 8.3841, F -9.1351, G 0.0040)] [G loss: 9.0384]\n",
      "6885 (5, 1) [D loss: (-1.0268)(R 9.8006, F -10.8640, G 0.0037)] [G loss: 11.0228]\n",
      "6886 (5, 1) [D loss: (-1.2078)(R 11.3488, F -12.6062, G 0.0050)] [G loss: 12.7976]\n",
      "6887 (5, 1) [D loss: (-1.2888)(R 13.3599, F -14.6945, G 0.0046)] [G loss: 14.8905]\n",
      "6888 (5, 1) [D loss: (-1.4901)(R 14.5848, F -16.1345, G 0.0060)] [G loss: 16.2535]\n",
      "6889 (5, 1) [D loss: (-0.8856)(R 15.6626, F -16.6074, G 0.0059)] [G loss: 17.4285]\n",
      "6890 (5, 1) [D loss: (-1.4711)(R 15.8085, F -17.3354, G 0.0056)] [G loss: 17.3639]\n",
      "6891 (5, 1) [D loss: (-1.6114)(R 16.4229, F -18.0929, G 0.0059)] [G loss: 18.0259]\n",
      "6892 (5, 1) [D loss: (-1.6694)(R 16.5768, F -18.3045, G 0.0058)] [G loss: 18.9428]\n",
      "6893 (5, 1) [D loss: (-1.8952)(R 17.6674, F -19.6164, G 0.0054)] [G loss: 19.7030]\n",
      "6894 (5, 1) [D loss: (-1.6087)(R 18.2192, F -19.9033, G 0.0075)] [G loss: 20.1806]\n",
      "6895 (5, 1) [D loss: (-1.4271)(R 18.4597, F -19.9372, G 0.0050)] [G loss: 19.8674]\n",
      "6896 (5, 1) [D loss: (-0.8678)(R 19.4160, F -20.3526, G 0.0069)] [G loss: 20.0000]\n",
      "6897 (5, 1) [D loss: (-1.9988)(R 19.5793, F -21.6365, G 0.0058)] [G loss: 21.4613]\n",
      "6898 (5, 1) [D loss: (-0.9935)(R 21.8121, F -22.9029, G 0.0097)] [G loss: 23.2924]\n",
      "6899 (5, 1) [D loss: (-1.9636)(R 23.4746, F -25.5491, G 0.0111)] [G loss: 25.2579]\n",
      "6900 (5, 1) [D loss: (-1.8654)(R 26.4741, F -28.4910, G 0.0152)] [G loss: 27.9339]\n",
      "6901 (5, 1) [D loss: (-1.9970)(R 28.8977, F -31.0595, G 0.0165)] [G loss: 30.1015]\n",
      "6902 (5, 1) [D loss: (-2.2446)(R 29.7169, F -32.1605, G 0.0199)] [G loss: 31.6814]\n",
      "6903 (5, 1) [D loss: (-1.3277)(R 30.7709, F -32.2904, G 0.0192)] [G loss: 31.9791]\n",
      "6904 (5, 1) [D loss: (-2.2663)(R 29.9031, F -32.2918, G 0.0122)] [G loss: 31.5006]\n",
      "6905 (5, 1) [D loss: (-1.5176)(R 29.5858, F -31.2031, G 0.0100)] [G loss: 29.8997]\n",
      "6906 (5, 1) [D loss: (-0.7687)(R 27.6867, F -28.5162, G 0.0061)] [G loss: 27.7558]\n",
      "6907 (5, 1) [D loss: (-1.5144)(R 26.2123, F -27.7568, G 0.0030)] [G loss: 26.2169]\n",
      "6908 (5, 1) [D loss: (-1.7244)(R 25.6737, F -27.4270, G 0.0029)] [G loss: 26.0426]\n",
      "6909 (5, 1) [D loss: (-1.3608)(R 26.0475, F -27.4419, G 0.0034)] [G loss: 26.2532]\n",
      "6910 (5, 1) [D loss: (-1.3841)(R 25.9593, F -27.3747, G 0.0031)] [G loss: 26.2412]\n",
      "6911 (5, 1) [D loss: (-1.1316)(R 27.4911, F -28.6808, G 0.0058)] [G loss: 27.4700]\n",
      "6912 (5, 1) [D loss: (-1.2535)(R 28.3796, F -29.7022, G 0.0069)] [G loss: 28.2770]\n",
      "6913 (5, 1) [D loss: (-1.2945)(R 28.7784, F -30.1586, G 0.0086)] [G loss: 28.1763]\n",
      "6914 (5, 1) [D loss: (-1.4488)(R 29.6960, F -31.2388, G 0.0094)] [G loss: 28.7625]\n",
      "6915 (5, 1) [D loss: (-1.5176)(R 29.0306, F -30.6566, G 0.0108)] [G loss: 28.6840]\n",
      "6916 (5, 1) [D loss: (-1.0659)(R 28.1949, F -29.3366, G 0.0076)] [G loss: 26.6749]\n",
      "6917 (5, 1) [D loss: (-0.1919)(R 26.8353, F -27.0963, G 0.0069)] [G loss: 25.8864]\n",
      "6918 (5, 1) [D loss: (-0.7195)(R 24.4444, F -25.2072, G 0.0043)] [G loss: 23.5868]\n",
      "6919 (5, 1) [D loss: (-0.3125)(R 20.9874, F -21.3222, G 0.0022)] [G loss: 20.6998]\n",
      "6920 (5, 1) [D loss: (-0.3855)(R 17.4167, F -17.8368, G 0.0035)] [G loss: 17.0057]\n",
      "6921 (5, 1) [D loss: (-0.6578)(R 13.8431, F -14.5364, G 0.0035)] [G loss: 13.6990]\n",
      "6922 (5, 1) [D loss: (-0.5920)(R 10.9422, F -11.5511, G 0.0017)] [G loss: 11.1172]\n",
      "6923 (5, 1) [D loss: (-1.4497)(R 8.2219, F -9.6875, G 0.0016)] [G loss: 8.4194]\n",
      "6924 (5, 1) [D loss: (-1.7784)(R 4.8976, F -6.6940, G 0.0018)] [G loss: 6.2461]\n",
      "6925 (5, 1) [D loss: (-1.3982)(R 1.9732, F -3.4104, G 0.0039)] [G loss: 2.8055]\n",
      "6926 (5, 1) [D loss: (-1.8556)(R -0.1196, F -1.7928, G 0.0057)] [G loss: 1.6326]\n",
      "6927 (5, 1) [D loss: (-1.4781)(R -1.8942, F 0.3352, G 0.0081)] [G loss: 0.1967]\n",
      "6928 (5, 1) [D loss: (-1.6572)(R -2.1544, F 0.4381, G 0.0059)] [G loss: -0.4931]\n",
      "6929 (5, 1) [D loss: (-1.7763)(R -3.1941, F 1.3398, G 0.0078)] [G loss: -1.5508]\n",
      "6930 (5, 1) [D loss: (-2.2156)(R -4.4708, F 2.1738, G 0.0081)] [G loss: -2.7002]\n",
      "6931 (5, 1) [D loss: (-1.7117)(R -5.4082, F 3.5770, G 0.0120)] [G loss: -3.7542]\n",
      "6932 (5, 1) [D loss: (-2.7041)(R -6.8465, F 3.9904, G 0.0152)] [G loss: -4.3722]\n",
      "6933 (5, 1) [D loss: (-2.6646)(R -7.0636, F 4.1860, G 0.0213)] [G loss: -4.6839]\n",
      "6934 (5, 1) [D loss: (-3.3894)(R -7.0926, F 3.4445, G 0.0259)] [G loss: -4.6903]\n",
      "6935 (5, 1) [D loss: (-2.7846)(R -6.9318, F 3.9002, G 0.0247)] [G loss: -4.7204]\n",
      "6936 (5, 1) [D loss: (-2.4349)(R -5.9421, F 3.3062, G 0.0201)] [G loss: -4.5606]\n",
      "6937 (5, 1) [D loss: (-1.8209)(R -6.0550, F 4.0653, G 0.0169)] [G loss: -4.6782]\n",
      "6938 (5, 1) [D loss: (-1.6061)(R -5.5795, F 3.8614, G 0.0112)] [G loss: -4.4522]\n",
      "6939 (5, 1) [D loss: (-1.6023)(R -5.2976, F 3.5754, G 0.0120)] [G loss: -5.2698]\n",
      "6940 (5, 1) [D loss: (-1.1576)(R -5.1662, F 3.9189, G 0.0090)] [G loss: -4.9189]\n",
      "6941 (5, 1) [D loss: (-0.7255)(R -4.6567, F 3.8738, G 0.0057)] [G loss: -4.4757]\n",
      "6942 (5, 1) [D loss: (-1.0601)(R -4.5494, F 3.4444, G 0.0045)] [G loss: -3.9860]\n",
      "6943 (5, 1) [D loss: (-1.6159)(R -4.7307, F 3.0802, G 0.0035)] [G loss: -4.4647]\n",
      "6944 (5, 1) [D loss: (-0.7283)(R -3.9626, F 3.2073, G 0.0027)] [G loss: -4.0106]\n",
      "6945 (5, 1) [D loss: (-1.1873)(R -3.8601, F 2.6513, G 0.0022)] [G loss: -4.2026]\n",
      "6946 (5, 1) [D loss: (-1.3642)(R -3.7003, F 2.3212, G 0.0015)] [G loss: -3.3927]\n",
      "6947 (5, 1) [D loss: (-0.4701)(R -2.7979, F 2.3136, G 0.0014)] [G loss: -2.9792]\n",
      "6948 (5, 1) [D loss: (-0.6244)(R -2.2078, F 1.5653, G 0.0018)] [G loss: -2.5004]\n",
      "6949 (5, 1) [D loss: (-0.9365)(R -2.2532, F 1.2973, G 0.0019)] [G loss: -1.6717]\n",
      "6950 (5, 1) [D loss: (-0.2553)(R -1.3700, F 1.0955, G 0.0019)] [G loss: -1.1840]\n",
      "6951 (5, 1) [D loss: (-0.6156)(R -0.9559, F 0.3170, G 0.0023)] [G loss: -0.5786]\n",
      "6952 (5, 1) [D loss: (-1.1206)(R -0.4427, F -0.7028, G 0.0025)] [G loss: -0.1605]\n",
      "6953 (5, 1) [D loss: (-1.4830)(R 0.0863, F -1.6017, G 0.0032)] [G loss: 1.1842]\n",
      "6954 (5, 1) [D loss: (-0.8791)(R 0.7380, F -1.6560, G 0.0039)] [G loss: 1.5138]\n",
      "6955 (5, 1) [D loss: (-1.2176)(R 1.6398, F -2.8922, G 0.0035)] [G loss: 3.1617]\n",
      "6956 (5, 1) [D loss: (-0.7254)(R 2.9438, F -3.7191, G 0.0050)] [G loss: 3.9732]\n",
      "6957 (5, 1) [D loss: (-1.5295)(R 3.3436, F -4.9186, G 0.0046)] [G loss: 5.1608]\n",
      "6958 (5, 1) [D loss: (-1.0911)(R 4.3389, F -5.4822, G 0.0052)] [G loss: 6.0146]\n",
      "6959 (5, 1) [D loss: (-1.7199)(R 5.1374, F -6.9194, G 0.0062)] [G loss: 7.1935]\n",
      "6960 (5, 1) [D loss: (-0.6203)(R 6.5893, F -7.2876, G 0.0078)] [G loss: 8.2134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6961 (5, 1) [D loss: (-0.6285)(R 7.4102, F -8.0921, G 0.0053)] [G loss: 8.5680]\n",
      "6962 (5, 1) [D loss: (-0.9995)(R 7.4448, F -8.5080, G 0.0064)] [G loss: 9.4378]\n",
      "6963 (5, 1) [D loss: (-1.0340)(R 8.7514, F -9.8392, G 0.0054)] [G loss: 10.0045]\n",
      "6964 (5, 1) [D loss: (-0.9733)(R 9.3344, F -10.3626, G 0.0055)] [G loss: 10.9922]\n",
      "6965 (5, 1) [D loss: (-1.2531)(R 10.6323, F -11.9656, G 0.0080)] [G loss: 12.4721]\n",
      "6966 (5, 1) [D loss: (-1.2560)(R 11.7918, F -13.1341, G 0.0086)] [G loss: 13.3815]\n",
      "6967 (5, 1) [D loss: (-1.4000)(R 12.1799, F -13.6511, G 0.0071)] [G loss: 13.8112]\n",
      "6968 (5, 1) [D loss: (-1.5038)(R 12.2848, F -13.8613, G 0.0073)] [G loss: 14.1877]\n",
      "6969 (5, 1) [D loss: (-1.7703)(R 13.0380, F -14.8949, G 0.0087)] [G loss: 15.0716]\n",
      "6970 (5, 1) [D loss: (-1.7422)(R 13.1776, F -15.0015, G 0.0082)] [G loss: 15.0183]\n",
      "6971 (5, 1) [D loss: (-1.5274)(R 13.8846, F -15.4853, G 0.0073)] [G loss: 15.0285]\n",
      "6972 (5, 1) [D loss: (-1.4611)(R 13.7053, F -15.2375, G 0.0071)] [G loss: 15.3789]\n",
      "6973 (5, 1) [D loss: (-1.4834)(R 14.2467, F -15.7960, G 0.0066)] [G loss: 15.2581]\n",
      "6974 (5, 1) [D loss: (-1.1773)(R 14.3722, F -15.5851, G 0.0036)] [G loss: 15.2237]\n",
      "6975 (5, 1) [D loss: (-0.9133)(R 13.7532, F -14.6947, G 0.0028)] [G loss: 14.4790]\n",
      "6976 (5, 1) [D loss: (-1.2399)(R 13.2836, F -14.5566, G 0.0033)] [G loss: 14.1679]\n",
      "6977 (5, 1) [D loss: (-1.0587)(R 13.3489, F -14.4397, G 0.0032)] [G loss: 13.9092]\n",
      "6978 (5, 1) [D loss: (-1.0511)(R 12.5114, F -13.6062, G 0.0044)] [G loss: 13.0489]\n",
      "6979 (5, 1) [D loss: (-0.6023)(R 12.4655, F -13.1089, G 0.0041)] [G loss: 12.9108]\n",
      "6980 (5, 1) [D loss: (-1.3470)(R 12.7378, F -14.1401, G 0.0055)] [G loss: 13.0351]\n",
      "6981 (5, 1) [D loss: (-1.0734)(R 12.9976, F -14.1387, G 0.0068)] [G loss: 14.2713]\n",
      "6982 (5, 1) [D loss: (-1.0589)(R 12.7895, F -13.9098, G 0.0061)] [G loss: 13.2803]\n",
      "6983 (5, 1) [D loss: (-0.5759)(R 13.4657, F -14.1093, G 0.0068)] [G loss: 13.7707]\n",
      "6984 (5, 1) [D loss: (-2.2122)(R 12.5138, F -14.8172, G 0.0091)] [G loss: 13.6791]\n",
      "6985 (5, 1) [D loss: (-1.0618)(R 14.5298, F -15.7350, G 0.0143)] [G loss: 15.6650]\n",
      "6986 (5, 1) [D loss: (-2.4171)(R 13.9822, F -16.5325, G 0.0133)] [G loss: 15.0147]\n",
      "6987 (5, 1) [D loss: (-1.4825)(R 14.7795, F -16.4165, G 0.0155)] [G loss: 14.9624]\n",
      "6988 (5, 1) [D loss: (-0.7727)(R 13.7156, F -14.5731, G 0.0085)] [G loss: 13.3370]\n",
      "6989 (5, 1) [D loss: (-1.5557)(R 11.4911, F -13.0940, G 0.0047)] [G loss: 12.3344]\n",
      "6990 (5, 1) [D loss: (-1.4190)(R 10.6878, F -12.1488, G 0.0042)] [G loss: 11.5834]\n",
      "6991 (5, 1) [D loss: (-0.7258)(R 9.6127, F -10.3606, G 0.0022)] [G loss: 10.1201]\n",
      "6992 (5, 1) [D loss: (-0.4898)(R 8.7369, F -9.2448, G 0.0018)] [G loss: 8.9518]\n",
      "6993 (5, 1) [D loss: (-1.1162)(R 7.5033, F -8.6350, G 0.0015)] [G loss: 8.5025]\n",
      "6994 (5, 1) [D loss: (-1.0687)(R 6.9746, F -8.0669, G 0.0024)] [G loss: 8.4588]\n",
      "6995 (5, 1) [D loss: (-0.6463)(R 7.8121, F -8.4925, G 0.0034)] [G loss: 8.1863]\n",
      "6996 (5, 1) [D loss: (-1.0547)(R 7.6276, F -8.7240, G 0.0042)] [G loss: 8.7657]\n",
      "6997 (5, 1) [D loss: (-1.2817)(R 7.5770, F -8.9135, G 0.0055)] [G loss: 8.3915]\n",
      "6998 (5, 1) [D loss: (-1.2563)(R 6.6984, F -8.0002, G 0.0046)] [G loss: 7.5341]\n",
      "6999 (5, 1) [D loss: (-1.0897)(R 5.4428, F -6.5664, G 0.0034)] [G loss: 6.2955]\n",
      "7000 (5, 1) [D loss: (-0.6439)(R 4.4053, F -5.0757, G 0.0027)] [G loss: 4.8156]\n",
      "7001 (5, 1) [D loss: (-1.0487)(R 2.5783, F -3.6506, G 0.0024)] [G loss: 2.5769]\n",
      "7002 (5, 1) [D loss: (-1.0995)(R 0.2886, F -1.4236, G 0.0035)] [G loss: 0.7131]\n",
      "7003 (5, 1) [D loss: (-1.7472)(R -3.0413, F 1.2003, G 0.0094)] [G loss: -2.0175]\n",
      "7004 (5, 1) [D loss: (-1.8320)(R -5.2411, F 3.2200, G 0.0189)] [G loss: -4.1050]\n",
      "7005 (5, 1) [D loss: (-2.2808)(R -6.4125, F 3.8866, G 0.0245)] [G loss: -4.8179]\n",
      "7006 (5, 1) [D loss: (-1.7258)(R -5.6420, F 3.6557, G 0.0260)] [G loss: -4.6919]\n",
      "7007 (5, 1) [D loss: (-2.4508)(R -6.7008, F 3.9438, G 0.0306)] [G loss: -5.5323]\n",
      "7008 (5, 1) [D loss: (-2.7743)(R -6.6178, F 3.6045, G 0.0239)] [G loss: -5.2646]\n",
      "7009 (5, 1) [D loss: (-1.9115)(R -5.2985, F 3.2265, G 0.0161)] [G loss: -4.3796]\n",
      "7010 (5, 1) [D loss: (-1.1362)(R -4.0716, F 2.8321, G 0.0103)] [G loss: -3.5162]\n",
      "7011 (5, 1) [D loss: (-1.3271)(R -3.5608, F 2.1613, G 0.0072)] [G loss: -3.3354]\n",
      "7012 (5, 1) [D loss: (-1.4659)(R -3.0919, F 1.5962, G 0.0030)] [G loss: -2.8244]\n",
      "7013 (5, 1) [D loss: (-1.3387)(R -1.9369, F 0.5826, G 0.0016)] [G loss: -1.4084]\n",
      "7014 (5, 1) [D loss: (-0.5080)(R -1.1946, F 0.6671, G 0.0020)] [G loss: -0.8019]\n",
      "7015 (5, 1) [D loss: (-0.3766)(R 0.0137, F -0.4158, G 0.0025)] [G loss: 0.8399]\n",
      "7016 (5, 1) [D loss: (-0.7732)(R 0.6742, F -1.4768, G 0.0029)] [G loss: 1.8104]\n",
      "7017 (5, 1) [D loss: (-0.8614)(R 1.2790, F -2.1660, G 0.0026)] [G loss: 2.2357]\n",
      "7018 (5, 1) [D loss: (-0.9580)(R 2.1607, F -3.1430, G 0.0024)] [G loss: 3.0109]\n",
      "7019 (5, 1) [D loss: (-0.8926)(R 2.6064, F -3.5237, G 0.0025)] [G loss: 3.5882]\n",
      "7020 (5, 1) [D loss: (-1.2257)(R 3.0934, F -4.3563, G 0.0037)] [G loss: 3.8944]\n",
      "7021 (5, 1) [D loss: (-0.9625)(R 3.5032, F -4.5027, G 0.0037)] [G loss: 4.7570]\n",
      "7022 (5, 1) [D loss: (-1.1845)(R 3.6892, F -4.9265, G 0.0053)] [G loss: 4.9660]\n",
      "7023 (5, 1) [D loss: (-0.9657)(R 4.5715, F -5.5850, G 0.0048)] [G loss: 5.7934]\n",
      "7024 (5, 1) [D loss: (-1.2772)(R 4.9132, F -6.2515, G 0.0061)] [G loss: 6.5738]\n",
      "7025 (5, 1) [D loss: (-1.1642)(R 5.3478, F -6.5656, G 0.0054)] [G loss: 6.5739]\n",
      "7026 (5, 1) [D loss: (-1.9929)(R 4.9677, F -7.0245, G 0.0064)] [G loss: 6.9793]\n",
      "7027 (5, 1) [D loss: (-1.6202)(R 5.9090, F -7.6013, G 0.0072)] [G loss: 7.1889]\n",
      "7028 (5, 1) [D loss: (-0.9565)(R 6.4370, F -7.4609, G 0.0067)] [G loss: 7.7373]\n",
      "7029 (5, 1) [D loss: (-1.0672)(R 6.9081, F -8.0280, G 0.0053)] [G loss: 8.2116]\n",
      "7030 (5, 1) [D loss: (-0.5254)(R 8.4731, F -9.0645, G 0.0066)] [G loss: 9.0292]\n",
      "7031 (5, 1) [D loss: (-1.2790)(R 8.9111, F -10.2386, G 0.0048)] [G loss: 10.5063]\n",
      "7032 (5, 1) [D loss: (-1.2613)(R 9.8651, F -11.1986, G 0.0072)] [G loss: 11.3646]\n",
      "7033 (5, 1) [D loss: (-1.7715)(R 10.7306, F -12.5806, G 0.0078)] [G loss: 12.2626]\n",
      "7034 (5, 1) [D loss: (-0.7939)(R 12.1946, F -13.0883, G 0.0100)] [G loss: 13.1153]\n",
      "7035 (5, 1) [D loss: (-1.3095)(R 12.6636, F -14.0853, G 0.0112)] [G loss: 14.5742]\n",
      "7036 (5, 1) [D loss: (-1.1975)(R 13.9339, F -15.2530, G 0.0122)] [G loss: 15.1579]\n",
      "7037 (5, 1) [D loss: (-1.0088)(R 13.1433, F -14.2238, G 0.0072)] [G loss: 14.0959]\n",
      "7038 (5, 1) [D loss: (-1.1522)(R 11.9335, F -13.1430, G 0.0057)] [G loss: 13.0772]\n",
      "7039 (5, 1) [D loss: (-1.7370)(R 10.1929, F -11.9653, G 0.0035)] [G loss: 12.0219]\n",
      "7040 (5, 1) [D loss: (0.1101)(R 9.4254, F -9.3364, G 0.0021)] [G loss: 8.8711]\n",
      "7041 (5, 1) [D loss: (-0.7989)(R 6.5738, F -7.3921, G 0.0019)] [G loss: 7.0261]\n",
      "7042 (5, 1) [D loss: (-1.3979)(R 3.7431, F -5.1589, G 0.0018)] [G loss: 4.3866]\n",
      "7043 (5, 1) [D loss: (-0.5986)(R 3.5033, F -4.1261, G 0.0024)] [G loss: 3.9345]\n",
      "7044 (5, 1) [D loss: (-1.2467)(R 2.9687, F -4.2483, G 0.0033)] [G loss: 4.0632]\n",
      "7045 (5, 1) [D loss: (-1.4193)(R 3.8481, F -5.3232, G 0.0056)] [G loss: 4.4798]\n",
      "7046 (5, 1) [D loss: (-1.0813)(R 5.3637, F -6.5169, G 0.0072)] [G loss: 5.9448]\n",
      "7047 (5, 1) [D loss: (-1.9710)(R 7.6468, F -9.7352, G 0.0117)] [G loss: 9.5729]\n",
      "7048 (5, 1) [D loss: (-1.0579)(R 9.6220, F -10.8048, G 0.0125)] [G loss: 10.7306]\n",
      "7049 (5, 1) [D loss: (-1.4247)(R 10.6614, F -12.2744, G 0.0188)] [G loss: 12.0381]\n",
      "7050 (5, 1) [D loss: (-0.8209)(R 11.9165, F -12.9226, G 0.0185)] [G loss: 12.2999]\n",
      "7051 (5, 1) [D loss: (0.3135)(R 11.4275, F -11.2162, G 0.0102)] [G loss: 11.1172]\n",
      "7052 (5, 1) [D loss: (-0.3072)(R 8.9288, F -9.2627, G 0.0027)] [G loss: 8.6311]\n",
      "7053 (5, 1) [D loss: (-0.3665)(R 6.1721, F -6.5581, G 0.0019)] [G loss: 5.9495]\n",
      "7054 (5, 1) [D loss: (-0.6529)(R 2.8516, F -3.5252, G 0.0021)] [G loss: 2.6692]\n",
      "7055 (5, 1) [D loss: (-0.7671)(R -0.4882, F -0.2939, G 0.0015)] [G loss: -0.5336]\n",
      "7056 (5, 1) [D loss: (-1.0455)(R -4.4979, F 3.4028, G 0.0050)] [G loss: -3.5899]\n",
      "7057 (5, 1) [D loss: (-1.9697)(R -6.7801, F 4.7169, G 0.0094)] [G loss: -5.0488]\n",
      "7058 (5, 1) [D loss: (-1.2933)(R -7.8942, F 6.4512, G 0.0150)] [G loss: -5.9541]\n",
      "7059 (5, 1) [D loss: (-1.2463)(R -7.0473, F 5.7022, G 0.0099)] [G loss: -5.5249]\n",
      "7060 (5, 1) [D loss: (0.0633)(R -5.6129, F 5.6433, G 0.0033)] [G loss: -5.0200]\n",
      "7061 (5, 1) [D loss: (-0.6715)(R -4.4785, F 3.7916, G 0.0015)] [G loss: -3.5212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7062 (5, 1) [D loss: (-1.2933)(R -3.4857, F 2.1738, G 0.0019)] [G loss: -2.0587]\n",
      "7063 (5, 1) [D loss: (-1.6526)(R -3.6849, F 1.9874, G 0.0045)] [G loss: -2.4056]\n",
      "7064 (5, 1) [D loss: (-1.2236)(R -3.8282, F 2.5443, G 0.0060)] [G loss: -2.2147]\n",
      "7065 (5, 1) [D loss: (-1.5656)(R -5.6692, F 4.0206, G 0.0083)] [G loss: -4.4065]\n",
      "7066 (5, 1) [D loss: (-1.7608)(R -7.4920, F 5.6288, G 0.0102)] [G loss: -6.7102]\n",
      "7067 (5, 1) [D loss: (-1.1464)(R -9.2194, F 7.9018, G 0.0171)] [G loss: -8.3210]\n",
      "7068 (5, 1) [D loss: (-1.4127)(R -9.0640, F 7.4957, G 0.0156)] [G loss: -9.1798]\n",
      "7069 (5, 1) [D loss: (-1.6962)(R -9.8618, F 7.9566, G 0.0209)] [G loss: -9.8006]\n",
      "7070 (5, 1) [D loss: (-1.3773)(R -9.0543, F 7.5384, G 0.0139)] [G loss: -8.6870]\n",
      "7071 (5, 1) [D loss: (-1.1761)(R -7.2466, F 6.0094, G 0.0061)] [G loss: -7.1686]\n",
      "7072 (5, 1) [D loss: (-1.5093)(R -6.9400, F 5.3865, G 0.0044)] [G loss: -6.8148]\n",
      "7073 (5, 1) [D loss: (-0.9381)(R -5.9261, F 4.9741, G 0.0014)] [G loss: -5.0233]\n",
      "7074 (5, 1) [D loss: (-0.5715)(R -3.5877, F 2.9932, G 0.0023)] [G loss: -2.8874]\n",
      "7075 (5, 1) [D loss: (-0.6834)(R -2.1603, F 1.4358, G 0.0041)] [G loss: -1.8438]\n",
      "7076 (5, 1) [D loss: (-1.1610)(R -1.5724, F 0.3719, G 0.0039)] [G loss: -0.3768]\n",
      "7077 (5, 1) [D loss: (-0.9209)(R -0.0058, F -0.9558, G 0.0041)] [G loss: 0.9841]\n",
      "7078 (5, 1) [D loss: (-0.3674)(R 1.3866, F -1.7825, G 0.0028)] [G loss: 2.4055]\n",
      "7079 (5, 1) [D loss: (-1.0522)(R 2.5765, F -3.6562, G 0.0028)] [G loss: 3.8538]\n",
      "7080 (5, 1) [D loss: (-0.7932)(R 3.6903, F -4.5194, G 0.0036)] [G loss: 5.1899]\n",
      "7081 (5, 1) [D loss: (-0.7931)(R 4.4463, F -5.2895, G 0.0050)] [G loss: 5.1313]\n",
      "7082 (5, 1) [D loss: (-0.9831)(R 4.3540, F -5.3897, G 0.0053)] [G loss: 5.7852]\n",
      "7083 (5, 1) [D loss: (-0.9008)(R 4.7323, F -5.6803, G 0.0047)] [G loss: 5.8511]\n",
      "7084 (5, 1) [D loss: (-0.8311)(R 4.9710, F -5.8417, G 0.0040)] [G loss: 5.7988]\n",
      "7085 (5, 1) [D loss: (-0.9913)(R 4.5270, F -5.5444, G 0.0026)] [G loss: 5.8166]\n",
      "7086 (5, 1) [D loss: (-0.9229)(R 4.5877, F -5.5442, G 0.0034)] [G loss: 5.6760]\n",
      "7087 (5, 1) [D loss: (-1.2318)(R 4.2985, F -5.5694, G 0.0039)] [G loss: 5.7277]\n",
      "7088 (5, 1) [D loss: (-0.6143)(R 4.8475, F -5.4963, G 0.0034)] [G loss: 5.5377]\n",
      "7089 (5, 1) [D loss: (-1.2725)(R 4.7088, F -6.0287, G 0.0047)] [G loss: 6.0940]\n",
      "7090 (5, 1) [D loss: (-1.1470)(R 5.0975, F -6.2926, G 0.0048)] [G loss: 6.4956]\n",
      "7091 (5, 1) [D loss: (-1.0550)(R 6.1769, F -7.2894, G 0.0057)] [G loss: 7.6353]\n",
      "7092 (5, 1) [D loss: (-1.5495)(R 7.7404, F -9.3380, G 0.0048)] [G loss: 9.3287]\n",
      "7093 (5, 1) [D loss: (-1.5513)(R 9.9444, F -11.5835, G 0.0088)] [G loss: 11.3532]\n",
      "7094 (5, 1) [D loss: (-1.6215)(R 12.1902, F -13.9708, G 0.0159)] [G loss: 13.6907]\n",
      "7095 (5, 1) [D loss: (-1.6604)(R 14.5771, F -16.4534, G 0.0216)] [G loss: 16.6339]\n",
      "7096 (5, 1) [D loss: (-1.9155)(R 16.1940, F -18.3830, G 0.0273)] [G loss: 18.4195]\n",
      "7097 (5, 1) [D loss: (-2.3971)(R 17.2699, F -19.9637, G 0.0297)] [G loss: 19.3789]\n",
      "7098 (5, 1) [D loss: (-1.5015)(R 17.2572, F -18.9761, G 0.0217)] [G loss: 18.9301]\n",
      "7099 (5, 1) [D loss: (-0.9166)(R 17.5620, F -18.6473, G 0.0169)] [G loss: 18.1890]\n",
      "7100 (5, 1) [D loss: (-1.3899)(R 15.5771, F -17.0509, G 0.0084)] [G loss: 16.5401]\n",
      "7101 (5, 1) [D loss: (-0.9004)(R 15.5990, F -16.5580, G 0.0059)] [G loss: 15.8279]\n",
      "7102 (5, 1) [D loss: (-0.8219)(R 13.2889, F -14.1361, G 0.0025)] [G loss: 13.8575]\n",
      "7103 (5, 1) [D loss: (-2.0573)(R 11.4417, F -13.5209, G 0.0022)] [G loss: 12.6521]\n",
      "7104 (5, 1) [D loss: (-1.5075)(R 10.8088, F -12.3318, G 0.0015)] [G loss: 11.7312]\n",
      "7105 (5, 1) [D loss: (-0.2760)(R 11.6187, F -11.9191, G 0.0024)] [G loss: 11.4531]\n",
      "7106 (5, 1) [D loss: (-0.5632)(R 10.9684, F -11.5676, G 0.0036)] [G loss: 11.3161]\n",
      "7107 (5, 1) [D loss: (-1.1245)(R 10.7060, F -11.8683, G 0.0038)] [G loss: 11.4643]\n",
      "7108 (5, 1) [D loss: (-0.9173)(R 11.3443, F -12.3191, G 0.0057)] [G loss: 11.7658]\n",
      "7109 (5, 1) [D loss: (-0.5348)(R 12.7938, F -13.4215, G 0.0093)] [G loss: 12.6284]\n",
      "7110 (5, 1) [D loss: (-1.7919)(R 12.2698, F -14.1781, G 0.0116)] [G loss: 12.5290]\n",
      "7111 (5, 1) [D loss: (-2.0068)(R 13.5103, F -15.6867, G 0.0170)] [G loss: 14.1615]\n",
      "7112 (5, 1) [D loss: (-1.2112)(R 14.0856, F -15.4615, G 0.0165)] [G loss: 13.7627]\n",
      "7113 (5, 1) [D loss: (-1.7931)(R 12.9939, F -14.8827, G 0.0096)] [G loss: 13.1709]\n",
      "7114 (5, 1) [D loss: (-0.8495)(R 11.8903, F -12.7921, G 0.0052)] [G loss: 11.9571]\n",
      "7115 (5, 1) [D loss: (-0.5343)(R 10.8003, F -11.3599, G 0.0025)] [G loss: 10.5208]\n",
      "7116 (5, 1) [D loss: (-0.3767)(R 9.2736, F -9.6703, G 0.0020)] [G loss: 9.0222]\n",
      "7117 (5, 1) [D loss: (-0.6039)(R 6.8475, F -7.4810, G 0.0030)] [G loss: 6.8654]\n",
      "7118 (5, 1) [D loss: (-0.9427)(R 4.2351, F -5.2013, G 0.0024)] [G loss: 4.6822]\n",
      "7119 (5, 1) [D loss: (-1.3776)(R 2.1330, F -3.5295, G 0.0019)] [G loss: 2.8625]\n",
      "7120 (5, 1) [D loss: (-1.2620)(R 0.1191, F -1.4022, G 0.0021)] [G loss: 1.2446]\n",
      "7121 (5, 1) [D loss: (-1.2019)(R -2.0890, F 0.8463, G 0.0041)] [G loss: -0.8490]\n",
      "7122 (5, 1) [D loss: (-1.1537)(R -3.5702, F 2.3545, G 0.0062)] [G loss: -2.5196]\n",
      "7123 (5, 1) [D loss: (-1.2479)(R -4.5566, F 3.2259, G 0.0083)] [G loss: -3.4060]\n",
      "7124 (5, 1) [D loss: (-1.2054)(R -4.5419, F 3.2720, G 0.0065)] [G loss: -3.2196]\n",
      "7125 (5, 1) [D loss: (-1.2930)(R -4.8213, F 3.4785, G 0.0050)] [G loss: -3.3773]\n",
      "7126 (5, 1) [D loss: (-1.4904)(R -5.1626, F 3.6201, G 0.0052)] [G loss: -3.7043]\n",
      "7127 (5, 1) [D loss: (-1.8059)(R -5.1918, F 3.3342, G 0.0052)] [G loss: -3.0508]\n",
      "7128 (5, 1) [D loss: (-1.7216)(R -5.8095, F 4.0128, G 0.0075)] [G loss: -3.9894]\n",
      "7129 (5, 1) [D loss: (-1.7463)(R -6.6401, F 4.7907, G 0.0103)] [G loss: -4.7684]\n",
      "7130 (5, 1) [D loss: (-1.4771)(R -6.7326, F 5.1506, G 0.0105)] [G loss: -5.2364]\n",
      "7131 (5, 1) [D loss: (-1.7812)(R -7.7968, F 5.8847, G 0.0131)] [G loss: -6.8823]\n",
      "7132 (5, 1) [D loss: (-1.3446)(R -8.0174, F 6.5407, G 0.0132)] [G loss: -6.7891]\n",
      "7133 (5, 1) [D loss: (-1.2426)(R -7.9917, F 6.6466, G 0.0103)] [G loss: -6.9581]\n",
      "7134 (5, 1) [D loss: (-1.9749)(R -8.3093, F 6.2460, G 0.0088)] [G loss: -7.2515]\n",
      "7135 (5, 1) [D loss: (-0.5523)(R -6.9826, F 6.3290, G 0.0101)] [G loss: -6.9253]\n",
      "7136 (5, 1) [D loss: (-1.2219)(R -7.1321, F 5.8421, G 0.0068)] [G loss: -6.2926]\n",
      "7137 (5, 1) [D loss: (-0.6058)(R -6.7322, F 6.0672, G 0.0059)] [G loss: -6.0012]\n",
      "7138 (5, 1) [D loss: (-0.4966)(R -5.7304, F 5.2033, G 0.0031)] [G loss: -5.7603]\n",
      "7139 (5, 1) [D loss: (-0.9577)(R -5.7463, F 4.7593, G 0.0029)] [G loss: -5.3208]\n",
      "7140 (5, 1) [D loss: (-0.4926)(R -4.6172, F 4.1046, G 0.0020)] [G loss: -4.0315]\n",
      "7141 (5, 1) [D loss: (-1.0545)(R -3.4899, F 2.4167, G 0.0019)] [G loss: -2.5448]\n",
      "7142 (5, 1) [D loss: (-0.3618)(R -2.0314, F 1.6472, G 0.0022)] [G loss: -1.5636]\n",
      "7143 (5, 1) [D loss: (-0.6772)(R -1.2918, F 0.5877, G 0.0027)] [G loss: -0.2670]\n",
      "7144 (5, 1) [D loss: (-0.8918)(R -1.0122, F 0.0951, G 0.0025)] [G loss: 0.1869]\n",
      "7145 (5, 1) [D loss: (-1.0085)(R 0.2733, F -1.3073, G 0.0025)] [G loss: 1.3978]\n",
      "7146 (5, 1) [D loss: (-0.8852)(R 0.9883, F -1.9056, G 0.0032)] [G loss: 2.0274]\n",
      "7147 (5, 1) [D loss: (-1.0899)(R 1.1603, F -2.2879, G 0.0038)] [G loss: 2.1333]\n",
      "7148 (5, 1) [D loss: (-1.3780)(R 1.3970, F -2.8242, G 0.0049)] [G loss: 2.6186]\n",
      "7149 (5, 1) [D loss: (-0.7519)(R 1.1749, F -1.9761, G 0.0049)] [G loss: 2.7084]\n",
      "7150 (5, 1) [D loss: (-0.4704)(R 1.5295, F -2.0491, G 0.0049)] [G loss: 2.1897]\n",
      "7151 (5, 1) [D loss: (-1.0803)(R 1.0510, F -2.1646, G 0.0033)] [G loss: 2.3111]\n",
      "7152 (5, 1) [D loss: (-0.5562)(R 1.8663, F -2.4603, G 0.0038)] [G loss: 2.2599]\n",
      "7153 (5, 1) [D loss: (-0.3822)(R 1.6358, F -2.0534, G 0.0035)] [G loss: 2.1223]\n",
      "7154 (5, 1) [D loss: (-0.5058)(R 1.1820, F -1.7289, G 0.0041)] [G loss: 1.9077]\n",
      "7155 (5, 1) [D loss: (-1.0307)(R 1.0972, F -2.1651, G 0.0037)] [G loss: 1.4438]\n",
      "7156 (5, 1) [D loss: (-0.8321)(R 1.5005, F -2.3691, G 0.0037)] [G loss: 2.1229]\n",
      "7157 (5, 1) [D loss: (-0.9618)(R 1.8078, F -2.8112, G 0.0042)] [G loss: 3.1179]\n",
      "7158 (5, 1) [D loss: (-1.0090)(R 2.3285, F -3.3807, G 0.0043)] [G loss: 3.5915]\n",
      "7159 (5, 1) [D loss: (-0.8107)(R 3.2366, F -4.0903, G 0.0043)] [G loss: 4.3218]\n",
      "7160 (5, 1) [D loss: (-1.0973)(R 3.5897, F -4.7228, G 0.0036)] [G loss: 4.7519]\n",
      "7161 (5, 1) [D loss: (-0.9105)(R 4.3541, F -5.3057, G 0.0041)] [G loss: 5.4249]\n",
      "7162 (5, 1) [D loss: (-0.8822)(R 5.2864, F -6.2136, G 0.0045)] [G loss: 6.1514]\n",
      "7163 (5, 1) [D loss: (-1.1544)(R 5.7269, F -6.9399, G 0.0059)] [G loss: 7.1494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7164 (5, 1) [D loss: (-1.3117)(R 6.4686, F -7.8413, G 0.0061)] [G loss: 7.8073]\n",
      "7165 (5, 1) [D loss: (-1.3400)(R 7.7706, F -9.1855, G 0.0075)] [G loss: 9.3342]\n",
      "7166 (5, 1) [D loss: (-0.9260)(R 8.9478, F -9.9794, G 0.0106)] [G loss: 10.1390]\n",
      "7167 (5, 1) [D loss: (-0.8173)(R 8.9579, F -9.8700, G 0.0095)] [G loss: 9.9163]\n",
      "7168 (5, 1) [D loss: (-0.6028)(R 8.6517, F -9.3013, G 0.0047)] [G loss: 9.6115]\n",
      "7169 (5, 1) [D loss: (-0.4212)(R 8.0527, F -8.5050, G 0.0031)] [G loss: 8.8279]\n",
      "7170 (5, 1) [D loss: (-0.2512)(R 8.2180, F -8.5049, G 0.0036)] [G loss: 8.4326]\n",
      "7171 (5, 1) [D loss: (-0.8483)(R 7.1021, F -7.9713, G 0.0021)] [G loss: 8.1324]\n",
      "7172 (5, 1) [D loss: (-1.1601)(R 6.7093, F -7.8976, G 0.0028)] [G loss: 7.9280]\n",
      "7173 (5, 1) [D loss: (-0.9383)(R 6.7691, F -7.7312, G 0.0024)] [G loss: 7.7354]\n",
      "7174 (5, 1) [D loss: (-1.2523)(R 7.2032, F -8.4901, G 0.0035)] [G loss: 8.0277]\n",
      "7175 (5, 1) [D loss: (-0.8011)(R 6.6045, F -7.4486, G 0.0043)] [G loss: 7.3715]\n",
      "7176 (5, 1) [D loss: (-1.2386)(R 7.0095, F -8.3067, G 0.0059)] [G loss: 8.0007]\n",
      "7177 (5, 1) [D loss: (-1.9470)(R 7.5607, F -9.5949, G 0.0087)] [G loss: 9.0753]\n",
      "7178 (5, 1) [D loss: (-1.8631)(R 8.8156, F -10.8031, G 0.0124)] [G loss: 9.8755]\n",
      "7179 (5, 1) [D loss: (-1.8692)(R 9.2976, F -11.2811, G 0.0114)] [G loss: 10.6145]\n",
      "7180 (5, 1) [D loss: (-2.1449)(R 10.6339, F -12.9577, G 0.0179)] [G loss: 11.9502]\n",
      "7181 (5, 1) [D loss: (-0.7666)(R 12.3945, F -13.3772, G 0.0216)] [G loss: 12.5385]\n",
      "7182 (5, 1) [D loss: (-0.3801)(R 12.6372, F -13.1811, G 0.0164)] [G loss: 12.0543]\n",
      "7183 (5, 1) [D loss: (-1.1013)(R 10.7474, F -11.9119, G 0.0063)] [G loss: 10.9645]\n",
      "7184 (5, 1) [D loss: (-0.7290)(R 10.3598, F -11.1300, G 0.0041)] [G loss: 10.1128]\n",
      "7185 (5, 1) [D loss: (-0.3449)(R 9.4174, F -9.7857, G 0.0023)] [G loss: 8.4789]\n",
      "7186 (5, 1) [D loss: (0.1789)(R 8.0800, F -7.9235, G 0.0022)] [G loss: 7.4869]\n",
      "7187 (5, 1) [D loss: (-0.6809)(R 6.1385, F -6.8449, G 0.0025)] [G loss: 6.1183]\n",
      "7188 (5, 1) [D loss: (-0.7458)(R 4.8009, F -5.5633, G 0.0017)] [G loss: 5.1571]\n",
      "7189 (5, 1) [D loss: (-0.8209)(R 3.3427, F -4.1798, G 0.0016)] [G loss: 3.9961]\n",
      "7190 (5, 1) [D loss: (-1.0063)(R 2.3442, F -3.3659, G 0.0015)] [G loss: 3.1129]\n",
      "7191 (5, 1) [D loss: (-1.2339)(R 1.9936, F -3.2522, G 0.0025)] [G loss: 3.0853]\n",
      "7192 (5, 1) [D loss: (-0.6982)(R 2.3944, F -3.1186, G 0.0026)] [G loss: 3.6432]\n",
      "7193 (5, 1) [D loss: (-0.7860)(R 2.1009, F -2.9192, G 0.0032)] [G loss: 2.9392]\n",
      "7194 (5, 1) [D loss: (-0.7343)(R 1.6434, F -2.4105, G 0.0033)] [G loss: 2.6025]\n",
      "7195 (5, 1) [D loss: (-0.5647)(R 0.8724, F -1.4765, G 0.0039)] [G loss: 1.4643]\n",
      "7196 (5, 1) [D loss: (-1.2353)(R -0.3775, F -0.9004, G 0.0043)] [G loss: 0.9976]\n",
      "7197 (5, 1) [D loss: (-0.9685)(R -0.9833, F -0.0446, G 0.0059)] [G loss: 0.1720]\n",
      "7198 (5, 1) [D loss: (-1.3724)(R -1.7980, F 0.3716, G 0.0054)] [G loss: -0.8992]\n",
      "7199 (5, 1) [D loss: (-1.7050)(R -2.9540, F 1.1877, G 0.0061)] [G loss: -1.8671]\n",
      "7200 (5, 1) [D loss: (-1.4556)(R -4.3606, F 2.8119, G 0.0093)] [G loss: -3.5421]\n",
      "7201 (5, 1) [D loss: (-2.2042)(R -6.3935, F 4.0322, G 0.0157)] [G loss: -5.1958]\n",
      "7202 (5, 1) [D loss: (-1.7789)(R -8.2602, F 6.2736, G 0.0208)] [G loss: -6.8894]\n",
      "7203 (5, 1) [D loss: (-3.1558)(R -9.2203, F 5.7954, G 0.0269)] [G loss: -7.4435]\n",
      "7204 (5, 1) [D loss: (-2.0028)(R -8.9339, F 6.6450, G 0.0286)] [G loss: -7.9811]\n",
      "7205 (5, 1) [D loss: (-2.1614)(R -9.0430, F 6.6370, G 0.0245)] [G loss: -8.0373]\n",
      "7206 (5, 1) [D loss: (-1.4002)(R -7.6468, F 6.1151, G 0.0132)] [G loss: -6.7177]\n",
      "7207 (5, 1) [D loss: (-1.3212)(R -6.4754, F 5.0906, G 0.0064)] [G loss: -5.8374]\n",
      "7208 (5, 1) [D loss: (-0.8608)(R -5.7927, F 4.8998, G 0.0032)] [G loss: -5.0181]\n",
      "7209 (5, 1) [D loss: (-1.1854)(R -5.1806, F 3.9770, G 0.0018)] [G loss: -4.7117]\n",
      "7210 (5, 1) [D loss: (-0.9413)(R -4.7196, F 3.7636, G 0.0015)] [G loss: -3.9240]\n",
      "7211 (5, 1) [D loss: (-0.5738)(R -3.8755, F 3.2850, G 0.0017)] [G loss: -3.1292]\n",
      "7212 (5, 1) [D loss: (-0.7200)(R -2.9922, F 2.2510, G 0.0021)] [G loss: -2.8808]\n",
      "7213 (5, 1) [D loss: (-1.1500)(R -2.8260, F 1.6612, G 0.0015)] [G loss: -2.5464]\n",
      "7214 (5, 1) [D loss: (-0.9129)(R -2.2678, F 1.3327, G 0.0022)] [G loss: -1.5388]\n",
      "7215 (5, 1) [D loss: (-0.6808)(R -1.7363, F 1.0296, G 0.0026)] [G loss: -1.2335]\n",
      "7216 (5, 1) [D loss: (-0.7383)(R -1.1881, F 0.4267, G 0.0023)] [G loss: -0.4772]\n",
      "7217 (5, 1) [D loss: (-0.8667)(R -0.6789, F -0.2203, G 0.0033)] [G loss: 0.0142]\n",
      "7218 (5, 1) [D loss: (-0.7802)(R -0.8703, F 0.0612, G 0.0029)] [G loss: 0.0984]\n",
      "7219 (5, 1) [D loss: (-0.7120)(R -0.3457, F -0.4006, G 0.0034)] [G loss: 0.3830]\n",
      "7220 (5, 1) [D loss: (-0.8437)(R -0.1236, F -0.7502, G 0.0030)] [G loss: 1.0444]\n",
      "7221 (5, 1) [D loss: (-1.0297)(R 0.3285, F -1.4014, G 0.0043)] [G loss: 1.5925]\n",
      "7222 (5, 1) [D loss: (-1.1142)(R 0.9647, F -2.1132, G 0.0034)] [G loss: 2.4079]\n",
      "7223 (5, 1) [D loss: (-1.0029)(R 1.8703, F -2.9167, G 0.0044)] [G loss: 3.1021]\n",
      "7224 (5, 1) [D loss: (-0.7732)(R 2.7189, F -3.5329, G 0.0041)] [G loss: 3.9938]\n",
      "7225 (5, 1) [D loss: (-0.7708)(R 3.4574, F -4.2710, G 0.0043)] [G loss: 4.8564]\n",
      "7226 (5, 1) [D loss: (-1.2176)(R 4.1668, F -5.4330, G 0.0049)] [G loss: 5.6518]\n",
      "7227 (5, 1) [D loss: (-0.9069)(R 5.5892, F -6.5563, G 0.0060)] [G loss: 6.8169]\n",
      "7228 (5, 1) [D loss: (-1.1640)(R 5.8011, F -7.0223, G 0.0057)] [G loss: 7.0425]\n",
      "7229 (5, 1) [D loss: (-1.1677)(R 6.4796, F -7.7015, G 0.0054)] [G loss: 7.9040]\n",
      "7230 (5, 1) [D loss: (-1.4891)(R 7.0768, F -8.6288, G 0.0063)] [G loss: 8.2851]\n",
      "7231 (5, 1) [D loss: (-0.6317)(R 7.4521, F -8.1456, G 0.0062)] [G loss: 8.2496]\n",
      "7232 (5, 1) [D loss: (-1.2486)(R 7.0815, F -8.3739, G 0.0044)] [G loss: 7.7235]\n",
      "7233 (5, 1) [D loss: (-0.9096)(R 7.5998, F -8.5408, G 0.0031)] [G loss: 8.2641]\n",
      "7234 (5, 1) [D loss: (-1.0576)(R 6.9361, F -8.0235, G 0.0030)] [G loss: 7.5324]\n",
      "7235 (5, 1) [D loss: (-1.1005)(R 6.3789, F -7.5082, G 0.0029)] [G loss: 7.5466]\n",
      "7236 (5, 1) [D loss: (-0.6316)(R 5.8607, F -6.5115, G 0.0019)] [G loss: 6.9896]\n",
      "7237 (5, 1) [D loss: (-1.0035)(R 5.4138, F -6.4415, G 0.0024)] [G loss: 6.0619]\n",
      "7238 (5, 1) [D loss: (-1.4518)(R 4.8998, F -6.3767, G 0.0025)] [G loss: 5.8470]\n",
      "7239 (5, 1) [D loss: (-0.9255)(R 5.0632, F -6.0137, G 0.0025)] [G loss: 6.4063]\n",
      "7240 (5, 1) [D loss: (-0.5934)(R 5.5533, F -6.1821, G 0.0035)] [G loss: 6.3398]\n",
      "7241 (5, 1) [D loss: (-1.0250)(R 5.6034, F -6.6653, G 0.0037)] [G loss: 6.6451]\n",
      "7242 (5, 1) [D loss: (-1.5604)(R 6.3812, F -7.9865, G 0.0045)] [G loss: 7.6469]\n",
      "7243 (5, 1) [D loss: (-1.9170)(R 7.6002, F -9.5888, G 0.0072)] [G loss: 9.0732]\n",
      "7244 (5, 1) [D loss: (-1.0749)(R 10.1354, F -11.3372, G 0.0127)] [G loss: 10.8516]\n",
      "7245 (5, 1) [D loss: (-1.5055)(R 11.2577, F -12.9329, G 0.0170)] [G loss: 12.4928]\n",
      "7246 (5, 1) [D loss: (-1.9707)(R 12.2963, F -14.4798, G 0.0213)] [G loss: 13.4955]\n",
      "7247 (5, 1) [D loss: (-1.3622)(R 13.4188, F -14.9736, G 0.0193)] [G loss: 13.9892]\n",
      "7248 (5, 1) [D loss: (-1.0317)(R 14.1722, F -15.4036, G 0.0200)] [G loss: 14.1259]\n",
      "7249 (5, 1) [D loss: (-0.8482)(R 13.1753, F -14.1552, G 0.0132)] [G loss: 13.3204]\n",
      "7250 (5, 1) [D loss: (-1.3922)(R 11.1000, F -12.5292, G 0.0037)] [G loss: 11.4174]\n",
      "7251 (5, 1) [D loss: (-0.7572)(R 9.7455, F -10.5237, G 0.0021)] [G loss: 10.0564]\n",
      "7252 (5, 1) [D loss: (-0.4597)(R 8.8022, F -9.2835, G 0.0022)] [G loss: 8.7511]\n",
      "7253 (5, 1) [D loss: (-0.8988)(R 7.6044, F -8.5309, G 0.0028)] [G loss: 7.7991]\n",
      "7254 (5, 1) [D loss: (-0.9718)(R 6.0649, F -7.0631, G 0.0026)] [G loss: 7.1715]\n",
      "7255 (5, 1) [D loss: (-0.8638)(R 5.5796, F -6.4687, G 0.0025)] [G loss: 6.0952]\n",
      "7256 (5, 1) [D loss: (-1.3312)(R 4.7530, F -6.1074, G 0.0023)] [G loss: 5.4871]\n",
      "7257 (5, 1) [D loss: (-0.6779)(R 5.5161, F -6.2323, G 0.0038)] [G loss: 6.1688]\n",
      "7258 (5, 1) [D loss: (-0.8932)(R 5.2143, F -6.1425, G 0.0035)] [G loss: 5.7038]\n",
      "7259 (5, 1) [D loss: (-0.6434)(R 4.9204, F -5.5929, G 0.0029)] [G loss: 5.6304]\n",
      "7260 (5, 1) [D loss: (-1.0246)(R 4.4946, F -5.5496, G 0.0031)] [G loss: 5.1710]\n",
      "7261 (5, 1) [D loss: (-1.1739)(R 4.0979, F -5.3089, G 0.0037)] [G loss: 5.3198]\n",
      "7262 (5, 1) [D loss: (-1.0884)(R 3.2048, F -4.3205, G 0.0027)] [G loss: 3.8985]\n",
      "7263 (5, 1) [D loss: (-1.0225)(R 2.2212, F -3.2642, G 0.0021)] [G loss: 2.8082]\n",
      "7264 (5, 1) [D loss: (-1.3698)(R 0.5389, F -1.9303, G 0.0022)] [G loss: 1.6940]\n",
      "7265 (5, 1) [D loss: (-1.0852)(R -0.6053, F -0.5216, G 0.0042)] [G loss: 0.1727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7266 (5, 1) [D loss: (-1.5230)(R -2.4131, F 0.8225, G 0.0068)] [G loss: -1.3833]\n",
      "7267 (5, 1) [D loss: (-1.7766)(R -4.0559, F 2.1509, G 0.0128)] [G loss: -2.5783]\n",
      "7268 (5, 1) [D loss: (-1.9145)(R -4.8121, F 2.7198, G 0.0178)] [G loss: -3.5534]\n",
      "7269 (5, 1) [D loss: (-1.3915)(R -4.4360, F 2.9036, G 0.0141)] [G loss: -3.4165]\n",
      "7270 (5, 1) [D loss: (-1.4769)(R -4.7785, F 3.1563, G 0.0145)] [G loss: -3.3608]\n",
      "7271 (5, 1) [D loss: (-1.5655)(R -4.3149, F 2.6547, G 0.0095)] [G loss: -2.9288]\n",
      "7272 (5, 1) [D loss: (-1.7004)(R -4.7924, F 2.9982, G 0.0094)] [G loss: -3.8103]\n",
      "7273 (5, 1) [D loss: (-0.8887)(R -4.1175, F 3.1572, G 0.0072)] [G loss: -3.6566]\n",
      "7274 (5, 1) [D loss: (-1.7616)(R -4.2066, F 2.3821, G 0.0063)] [G loss: -3.6658]\n",
      "7275 (5, 1) [D loss: (-1.1625)(R -3.8143, F 2.6083, G 0.0043)] [G loss: -3.5577]\n",
      "7276 (5, 1) [D loss: (-0.7619)(R -3.6687, F 2.8665, G 0.0040)] [G loss: -3.3245]\n",
      "7277 (5, 1) [D loss: (-1.0527)(R -3.6464, F 2.5547, G 0.0039)] [G loss: -3.4672]\n",
      "7278 (5, 1) [D loss: (-0.8266)(R -3.7719, F 2.9193, G 0.0026)] [G loss: -2.9380]\n",
      "7279 (5, 1) [D loss: (-0.4222)(R -3.2985, F 2.8463, G 0.0030)] [G loss: -3.1001]\n",
      "7280 (5, 1) [D loss: (-1.2331)(R -3.4591, F 2.1982, G 0.0028)] [G loss: -3.2513]\n",
      "7281 (5, 1) [D loss: (-0.4655)(R -2.9345, F 2.4396, G 0.0029)] [G loss: -2.9076]\n",
      "7282 (5, 1) [D loss: (-0.7977)(R -2.4573, F 1.6353, G 0.0024)] [G loss: -2.1211]\n",
      "7283 (5, 1) [D loss: (-0.9360)(R -2.6433, F 1.6791, G 0.0028)] [G loss: -2.0007]\n",
      "7284 (5, 1) [D loss: (-1.1279)(R -2.2351, F 1.0756, G 0.0032)] [G loss: -2.0325]\n",
      "7285 (5, 1) [D loss: (-0.9001)(R -1.6288, F 0.7027, G 0.0026)] [G loss: -1.3026]\n",
      "7286 (5, 1) [D loss: (-1.0602)(R -1.3402, F 0.2585, G 0.0021)] [G loss: -0.4360]\n",
      "7287 (5, 1) [D loss: (-1.5880)(R -0.7949, F -0.8206, G 0.0027)] [G loss: -0.0666]\n",
      "7288 (5, 1) [D loss: (-0.1632)(R 0.5726, F -0.7621, G 0.0026)] [G loss: 0.6814]\n",
      "7289 (5, 1) [D loss: (-0.9028)(R 1.0411, F -1.9746, G 0.0031)] [G loss: 1.8413]\n",
      "7290 (5, 1) [D loss: (-0.6055)(R 1.2225, F -1.8716, G 0.0044)] [G loss: 1.9219]\n",
      "7291 (5, 1) [D loss: (-1.2109)(R 1.5395, F -2.7940, G 0.0044)] [G loss: 2.9512]\n",
      "7292 (5, 1) [D loss: (-0.9408)(R 2.1646, F -3.1469, G 0.0041)] [G loss: 3.3573]\n",
      "7293 (5, 1) [D loss: (-1.0332)(R 2.5815, F -3.6637, G 0.0049)] [G loss: 3.9442]\n",
      "7294 (5, 1) [D loss: (-0.8386)(R 3.2658, F -4.1482, G 0.0044)] [G loss: 4.5028]\n",
      "7295 (5, 1) [D loss: (-1.0753)(R 3.1580, F -4.2947, G 0.0061)] [G loss: 4.4899]\n",
      "7296 (5, 1) [D loss: (-1.1384)(R 3.5246, F -4.7103, G 0.0047)] [G loss: 5.1477]\n",
      "7297 (5, 1) [D loss: (-0.6977)(R 4.1800, F -4.9262, G 0.0048)] [G loss: 5.5319]\n",
      "7298 (5, 1) [D loss: (-0.6769)(R 4.4360, F -5.1600, G 0.0047)] [G loss: 5.0684]\n",
      "7299 (5, 1) [D loss: (-1.2067)(R 4.5761, F -5.8198, G 0.0037)] [G loss: 5.8815]\n",
      "7300 (5, 1) [D loss: (-1.5459)(R 4.7213, F -6.3140, G 0.0047)] [G loss: 6.3886]\n",
      "7301 (5, 1) [D loss: (-1.1514)(R 5.9102, F -7.1237, G 0.0062)] [G loss: 7.2496]\n",
      "7302 (5, 1) [D loss: (-0.8293)(R 7.1188, F -8.0029, G 0.0055)] [G loss: 8.3054]\n",
      "7303 (5, 1) [D loss: (-1.5223)(R 7.9674, F -9.5673, G 0.0078)] [G loss: 9.1628]\n",
      "7304 (5, 1) [D loss: (-1.7403)(R 8.4444, F -10.2974, G 0.0113)] [G loss: 10.4264]\n",
      "7305 (5, 1) [D loss: (-2.0988)(R 10.2838, F -12.4921, G 0.0109)] [G loss: 11.8262]\n",
      "7306 (5, 1) [D loss: (-1.4524)(R 12.3903, F -14.0168, G 0.0174)] [G loss: 12.7779]\n",
      "7307 (5, 1) [D loss: (-1.6185)(R 13.4567, F -15.2580, G 0.0183)] [G loss: 14.2949]\n",
      "7308 (5, 1) [D loss: (-1.8964)(R 13.9570, F -16.0638, G 0.0210)] [G loss: 15.3780]\n",
      "7309 (5, 1) [D loss: (-0.9587)(R 14.5312, F -15.6566, G 0.0167)] [G loss: 14.7333]\n",
      "7310 (5, 1) [D loss: (-1.0072)(R 13.6789, F -14.7815, G 0.0095)] [G loss: 14.1242]\n",
      "7311 (5, 1) [D loss: (-1.6479)(R 13.2957, F -15.0167, G 0.0073)] [G loss: 14.2085]\n",
      "7312 (5, 1) [D loss: (-1.0655)(R 13.0651, F -14.1945, G 0.0064)] [G loss: 13.2687]\n",
      "7313 (5, 1) [D loss: (-1.7842)(R 11.4268, F -13.2453, G 0.0034)] [G loss: 12.2588]\n",
      "7314 (5, 1) [D loss: (-1.4435)(R 11.5746, F -13.0520, G 0.0034)] [G loss: 12.0453]\n",
      "7315 (5, 1) [D loss: (-1.5813)(R 11.9819, F -13.6188, G 0.0056)] [G loss: 12.1562]\n",
      "7316 (5, 1) [D loss: (-1.5860)(R 11.9769, F -13.6327, G 0.0070)] [G loss: 12.4017]\n",
      "7317 (5, 1) [D loss: (-1.1628)(R 12.5708, F -13.8333, G 0.0100)] [G loss: 12.2539]\n",
      "7318 (5, 1) [D loss: (-1.4469)(R 12.5362, F -14.1060, G 0.0123)] [G loss: 12.3503]\n",
      "7319 (5, 1) [D loss: (-1.7140)(R 11.5965, F -13.4159, G 0.0105)] [G loss: 11.3720]\n",
      "7320 (5, 1) [D loss: (-1.2401)(R 11.1635, F -12.4843, G 0.0081)] [G loss: 11.5651]\n",
      "7321 (5, 1) [D loss: (-1.6758)(R 11.1982, F -12.9716, G 0.0098)] [G loss: 10.7230]\n",
      "7322 (5, 1) [D loss: (-1.2969)(R 10.3480, F -11.7197, G 0.0075)] [G loss: 9.8477]\n",
      "7323 (5, 1) [D loss: (-1.2744)(R 9.3781, F -10.7094, G 0.0057)] [G loss: 9.3323]\n",
      "7324 (5, 1) [D loss: (0.2118)(R 9.4542, F -9.2952, G 0.0053)] [G loss: 8.3363]\n",
      "7325 (5, 1) [D loss: (-1.1283)(R 7.2111, F -8.3764, G 0.0037)] [G loss: 7.1296]\n",
      "7326 (5, 1) [D loss: (-0.6819)(R 6.9407, F -7.6584, G 0.0036)] [G loss: 6.4066]\n",
      "7327 (5, 1) [D loss: (-0.7542)(R 4.8252, F -5.6111, G 0.0032)] [G loss: 4.8608]\n",
      "7328 (5, 1) [D loss: (-0.5083)(R 3.1087, F -3.6486, G 0.0032)] [G loss: 3.5045]\n",
      "7329 (5, 1) [D loss: (-0.8755)(R 0.7479, F -1.6394, G 0.0016)] [G loss: 1.4187]\n",
      "7330 (5, 1) [D loss: (-0.9001)(R -1.3655, F 0.4501, G 0.0015)] [G loss: -0.0099]\n",
      "7331 (5, 1) [D loss: (-2.2339)(R -3.3602, F 1.0904, G 0.0036)] [G loss: -1.6270]\n",
      "7332 (5, 1) [D loss: (-1.9783)(R -4.8170, F 2.7563, G 0.0082)] [G loss: -3.2668]\n",
      "7333 (5, 1) [D loss: (-1.8834)(R -5.9702, F 3.9740, G 0.0113)] [G loss: -3.9533]\n",
      "7334 (5, 1) [D loss: (-2.0112)(R -6.4130, F 4.2741, G 0.0128)] [G loss: -4.5932]\n",
      "7335 (5, 1) [D loss: (-1.5426)(R -6.4839, F 4.8135, G 0.0128)] [G loss: -4.5701]\n",
      "7336 (5, 1) [D loss: (-2.2708)(R -6.6621, F 4.2666, G 0.0125)] [G loss: -4.4716]\n",
      "7337 (5, 1) [D loss: (-1.3474)(R -5.2045, F 3.7678, G 0.0089)] [G loss: -4.1556]\n",
      "7338 (5, 1) [D loss: (-1.3854)(R -5.0901, F 3.6326, G 0.0072)] [G loss: -3.9071]\n",
      "7339 (5, 1) [D loss: (-1.7722)(R -6.0530, F 4.1836, G 0.0097)] [G loss: -4.6957]\n",
      "7340 (5, 1) [D loss: (-2.3412)(R -5.7639, F 3.3469, G 0.0076)] [G loss: -4.6144]\n",
      "7341 (5, 1) [D loss: (-1.0219)(R -5.4731, F 4.3695, G 0.0082)] [G loss: -4.8135]\n",
      "7342 (5, 1) [D loss: (-1.4188)(R -5.9068, F 4.3863, G 0.0102)] [G loss: -5.0210]\n",
      "7343 (5, 1) [D loss: (-1.2952)(R -5.8636, F 4.4764, G 0.0092)] [G loss: -4.7518]\n",
      "7344 (5, 1) [D loss: (-1.5926)(R -5.1287, F 3.4912, G 0.0045)] [G loss: -4.3232]\n",
      "7345 (5, 1) [D loss: (-0.8523)(R -4.2707, F 3.3879, G 0.0031)] [G loss: -3.9594]\n",
      "7346 (5, 1) [D loss: (-1.2902)(R -4.2403, F 2.9206, G 0.0029)] [G loss: -3.3998]\n",
      "7347 (5, 1) [D loss: (-0.9655)(R -3.7690, F 2.7887, G 0.0015)] [G loss: -3.4808]\n",
      "7348 (5, 1) [D loss: (-0.6828)(R -3.0412, F 2.3415, G 0.0017)] [G loss: -2.8556]\n",
      "7349 (5, 1) [D loss: (-0.9457)(R -2.5507, F 1.5874, G 0.0018)] [G loss: -2.0264]\n",
      "7350 (5, 1) [D loss: (-0.7659)(R -1.7845, F 0.9991, G 0.0020)] [G loss: -1.3325]\n",
      "7351 (5, 1) [D loss: (-0.7816)(R -1.2118, F 0.4032, G 0.0027)] [G loss: -0.8046]\n",
      "7352 (5, 1) [D loss: (-0.9293)(R -1.3692, F 0.4191, G 0.0021)] [G loss: -0.9818]\n",
      "7353 (5, 1) [D loss: (-0.8354)(R -0.9325, F 0.0718, G 0.0025)] [G loss: -0.4016]\n",
      "7354 (5, 1) [D loss: (-0.8120)(R -1.1470, F 0.2893, G 0.0046)] [G loss: -0.4927]\n",
      "7355 (5, 1) [D loss: (-0.7208)(R -0.8463, F 0.0943, G 0.0031)] [G loss: -0.3199]\n",
      "7356 (5, 1) [D loss: (-1.1516)(R -1.0235, F -0.1639, G 0.0036)] [G loss: -0.1864]\n",
      "7357 (5, 1) [D loss: (-1.3503)(R -1.0591, F -0.3315, G 0.0040)] [G loss: -0.2077]\n",
      "7358 (5, 1) [D loss: (-1.1784)(R -0.9894, F -0.2377, G 0.0049)] [G loss: -0.3588]\n",
      "7359 (5, 1) [D loss: (-0.9597)(R -0.8493, F -0.1601, G 0.0050)] [G loss: 0.3169]\n",
      "7360 (5, 1) [D loss: (-1.2507)(R -1.1033, F -0.1990, G 0.0052)] [G loss: -0.1662]\n",
      "7361 (5, 1) [D loss: (-0.6152)(R -0.5386, F -0.1217, G 0.0045)] [G loss: 0.3324]\n",
      "7362 (5, 1) [D loss: (-0.9341)(R -0.1092, F -0.8625, G 0.0038)] [G loss: 0.6160]\n",
      "7363 (5, 1) [D loss: (-0.9554)(R 0.0733, F -1.0666, G 0.0038)] [G loss: 1.4768]\n",
      "7364 (5, 1) [D loss: (-1.0476)(R 0.6311, F -1.7140, G 0.0035)] [G loss: 1.7403]\n",
      "7365 (5, 1) [D loss: (-0.9379)(R 1.0886, F -2.0891, G 0.0063)] [G loss: 2.0716]\n",
      "7366 (5, 1) [D loss: (-1.2425)(R 0.8854, F -2.1924, G 0.0064)] [G loss: 2.4220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7367 (5, 1) [D loss: (-1.6269)(R 0.9049, F -2.5917, G 0.0060)] [G loss: 2.8213]\n",
      "7368 (5, 1) [D loss: (-1.0572)(R 1.6376, F -2.7622, G 0.0067)] [G loss: 3.0699]\n",
      "7369 (5, 1) [D loss: (-0.7777)(R 2.1812, F -3.0299, G 0.0071)] [G loss: 3.3749]\n",
      "7370 (5, 1) [D loss: (-1.3189)(R 1.5925, F -2.9753, G 0.0064)] [G loss: 3.2781]\n",
      "7371 (5, 1) [D loss: (-1.2940)(R 1.7309, F -3.0705, G 0.0046)] [G loss: 2.6661]\n",
      "7372 (5, 1) [D loss: (-0.6674)(R 1.2783, F -1.9844, G 0.0039)] [G loss: 2.4112]\n",
      "7373 (5, 1) [D loss: (-1.0584)(R 1.1084, F -2.2078, G 0.0041)] [G loss: 2.0736]\n",
      "7374 (5, 1) [D loss: (-1.5066)(R 0.8859, F -2.4271, G 0.0035)] [G loss: 1.7945]\n",
      "7375 (5, 1) [D loss: (-0.6985)(R 1.6886, F -2.4279, G 0.0041)] [G loss: 2.8220]\n",
      "7376 (5, 1) [D loss: (-1.5418)(R 2.0628, F -3.6487, G 0.0044)] [G loss: 3.4661]\n",
      "7377 (5, 1) [D loss: (-0.9458)(R 3.4774, F -4.5055, G 0.0082)] [G loss: 4.7999]\n",
      "7378 (5, 1) [D loss: (-1.2298)(R 5.3233, F -6.6894, G 0.0136)] [G loss: 6.7765]\n",
      "7379 (5, 1) [D loss: (-1.9680)(R 7.2320, F -9.4480, G 0.0248)] [G loss: 8.7508]\n",
      "7380 (5, 1) [D loss: (-1.7449)(R 9.1632, F -11.2820, G 0.0374)] [G loss: 10.3333]\n",
      "7381 (5, 1) [D loss: (-1.5879)(R 9.6388, F -11.6136, G 0.0387)] [G loss: 10.1592]\n",
      "7382 (5, 1) [D loss: (-1.4692)(R 8.4668, F -10.1655, G 0.0229)] [G loss: 9.2743]\n",
      "7383 (5, 1) [D loss: (-1.7189)(R 8.4936, F -10.3911, G 0.0179)] [G loss: 8.7803]\n",
      "7384 (5, 1) [D loss: (-1.0176)(R 8.1302, F -9.2760, G 0.0128)] [G loss: 8.6024]\n",
      "7385 (5, 1) [D loss: (-0.5521)(R 8.0552, F -8.7170, G 0.0110)] [G loss: 7.5621]\n",
      "7386 (5, 1) [D loss: (-0.5780)(R 6.2980, F -6.9185, G 0.0042)] [G loss: 6.4215]\n",
      "7387 (5, 1) [D loss: (-1.6329)(R 5.0499, F -6.7173, G 0.0035)] [G loss: 5.6738]\n",
      "7388 (5, 1) [D loss: (-0.5851)(R 3.9562, F -4.5694, G 0.0028)] [G loss: 4.2299]\n",
      "7389 (5, 1) [D loss: (-0.9791)(R 2.7492, F -3.7596, G 0.0031)] [G loss: 3.1870]\n",
      "7390 (5, 1) [D loss: (-1.0886)(R 1.5737, F -2.6831, G 0.0021)] [G loss: 1.9920]\n",
      "7391 (5, 1) [D loss: (-0.9956)(R 0.3164, F -1.3291, G 0.0017)] [G loss: 1.0618]\n",
      "7392 (5, 1) [D loss: (-0.8932)(R 0.6504, F -1.5665, G 0.0023)] [G loss: 1.2200]\n",
      "7393 (5, 1) [D loss: (-0.9490)(R 0.9649, F -1.9378, G 0.0024)] [G loss: 2.0129]\n",
      "7394 (5, 1) [D loss: (-1.4627)(R 1.9430, F -3.4498, G 0.0044)] [G loss: 3.1749]\n",
      "7395 (5, 1) [D loss: (-1.2816)(R 3.0213, F -4.3751, G 0.0072)] [G loss: 4.1120]\n",
      "7396 (5, 1) [D loss: (-1.0827)(R 3.2427, F -4.3818, G 0.0056)] [G loss: 4.0606]\n",
      "7397 (5, 1) [D loss: (-1.0706)(R 2.4191, F -3.5352, G 0.0045)] [G loss: 3.4726]\n",
      "7398 (5, 1) [D loss: (-1.1340)(R 0.5002, F -1.6603, G 0.0026)] [G loss: 1.0506]\n",
      "7399 (5, 1) [D loss: (-0.7127)(R -2.4475, F 1.7219, G 0.0013)] [G loss: -2.2911]\n",
      "7400 (5, 1) [D loss: (-1.5376)(R -6.0706, F 4.5064, G 0.0027)] [G loss: -5.3691]\n",
      "7401 (5, 1) [D loss: (-2.2438)(R -9.1968, F 6.8594, G 0.0094)] [G loss: -8.5650]\n",
      "7402 (5, 1) [D loss: (-1.4668)(R -11.2343, F 9.5761, G 0.0191)] [G loss: -9.7872]\n",
      "7403 (5, 1) [D loss: (-1.5597)(R -11.6423, F 9.8536, G 0.0229)] [G loss: -10.1731]\n",
      "7404 (5, 1) [D loss: (-2.4134)(R -11.2527, F 8.6965, G 0.0143)] [G loss: -9.9225]\n",
      "7405 (5, 1) [D loss: (-1.0164)(R -10.5303, F 9.4196, G 0.0094)] [G loss: -8.6438]\n",
      "7406 (5, 1) [D loss: (-1.4639)(R -9.5328, F 8.0332, G 0.0036)] [G loss: -7.8446]\n",
      "7407 (5, 1) [D loss: (-0.8239)(R -7.9284, F 7.0838, G 0.0021)] [G loss: -7.2006]\n",
      "7408 (5, 1) [D loss: (-1.2323)(R -7.3354, F 6.0901, G 0.0013)] [G loss: -5.8988]\n",
      "7409 (5, 1) [D loss: (-0.8561)(R -6.3911, F 5.5213, G 0.0014)] [G loss: -5.3091]\n",
      "7410 (5, 1) [D loss: (-1.1404)(R -5.9619, F 4.8056, G 0.0016)] [G loss: -5.1657]\n",
      "7411 (5, 1) [D loss: (-0.9616)(R -5.9700, F 4.9885, G 0.0020)] [G loss: -5.2997]\n",
      "7412 (5, 1) [D loss: (-1.0432)(R -6.1059, F 5.0450, G 0.0018)] [G loss: -5.3600]\n",
      "7413 (5, 1) [D loss: (-1.2849)(R -6.3589, F 5.0494, G 0.0025)] [G loss: -5.5679]\n",
      "7414 (5, 1) [D loss: (-1.2133)(R -6.5499, F 5.3077, G 0.0029)] [G loss: -5.8069]\n",
      "7415 (5, 1) [D loss: (-1.2028)(R -7.3402, F 6.0872, G 0.0050)] [G loss: -6.3431]\n",
      "7416 (5, 1) [D loss: (-0.9476)(R -7.1290, F 6.1335, G 0.0048)] [G loss: -6.5946]\n",
      "7417 (5, 1) [D loss: (-1.4700)(R -6.9000, F 5.3873, G 0.0043)] [G loss: -5.9889]\n",
      "7418 (5, 1) [D loss: (-0.8628)(R -5.9882, F 5.0910, G 0.0034)] [G loss: -5.2938]\n",
      "7419 (5, 1) [D loss: (-0.9163)(R -4.7632, F 3.8234, G 0.0023)] [G loss: -3.8195]\n",
      "7420 (5, 1) [D loss: (-0.8898)(R -3.9527, F 3.0378, G 0.0025)] [G loss: -2.6181]\n",
      "7421 (5, 1) [D loss: (-1.1400)(R -2.8778, F 1.7143, G 0.0024)] [G loss: -1.5977]\n",
      "7422 (5, 1) [D loss: (-1.0535)(R -1.3812, F 0.2915, G 0.0036)] [G loss: -0.3630]\n",
      "7423 (5, 1) [D loss: (-0.5197)(R -0.6618, F 0.0980, G 0.0044)] [G loss: 0.2897]\n",
      "7424 (5, 1) [D loss: (-0.8627)(R -0.2071, F -0.7120, G 0.0056)] [G loss: 1.0600]\n",
      "7425 (5, 1) [D loss: (-1.1952)(R 0.4932, F -1.7590, G 0.0071)] [G loss: 1.7985]\n",
      "7426 (5, 1) [D loss: (-0.8947)(R 0.6110, F -1.5629, G 0.0057)] [G loss: 1.6886]\n",
      "7427 (5, 1) [D loss: (-0.6328)(R 0.4895, F -1.1675, G 0.0045)] [G loss: 1.6823]\n",
      "7428 (5, 1) [D loss: (-1.4957)(R -0.7909, F -0.7431, G 0.0038)] [G loss: 0.6981]\n",
      "7429 (5, 1) [D loss: (-0.6931)(R -0.5230, F -0.1970, G 0.0027)] [G loss: 0.2123]\n",
      "7430 (5, 1) [D loss: (-1.1235)(R -1.2412, F 0.0901, G 0.0028)] [G loss: -0.3874]\n",
      "7431 (5, 1) [D loss: (-1.3051)(R -1.7431, F 0.4085, G 0.0030)] [G loss: -0.8198]\n",
      "7432 (5, 1) [D loss: (-1.4877)(R -2.1051, F 0.5842, G 0.0033)] [G loss: -0.3701]\n",
      "7433 (5, 1) [D loss: (-1.2600)(R -1.9681, F 0.6642, G 0.0044)] [G loss: -0.7219]\n",
      "7434 (5, 1) [D loss: (-1.4127)(R -1.7141, F 0.2461, G 0.0055)] [G loss: -0.4957]\n",
      "7435 (5, 1) [D loss: (-1.0723)(R -0.7219, F -0.4017, G 0.0051)] [G loss: 0.4952]\n",
      "7436 (5, 1) [D loss: (-0.8749)(R 1.1224, F -2.0686, G 0.0071)] [G loss: 2.1443]\n",
      "7437 (5, 1) [D loss: (-1.1548)(R 3.5361, F -4.8494, G 0.0158)] [G loss: 4.7151]\n",
      "7438 (5, 1) [D loss: (-1.3150)(R 5.0911, F -6.6363, G 0.0230)] [G loss: 6.7764]\n",
      "7439 (5, 1) [D loss: (-1.0579)(R 5.9908, F -7.2503, G 0.0202)] [G loss: 7.2358]\n",
      "7440 (5, 1) [D loss: (-0.8186)(R 5.3389, F -6.2651, G 0.0108)] [G loss: 6.6879]\n",
      "7441 (5, 1) [D loss: (-1.2640)(R 4.3871, F -5.6950, G 0.0044)] [G loss: 5.6754]\n",
      "7442 (5, 1) [D loss: (-0.3158)(R 3.9368, F -4.2823, G 0.0030)] [G loss: 3.9930]\n",
      "7443 (5, 1) [D loss: (-0.1098)(R 2.9321, F -3.0614, G 0.0019)] [G loss: 3.0569]\n",
      "7444 (5, 1) [D loss: (-1.0501)(R 0.0993, F -1.1704, G 0.0021)] [G loss: 0.5089]\n",
      "7445 (5, 1) [D loss: (-1.2465)(R -1.9029, F 0.6415, G 0.0015)] [G loss: -1.2907]\n",
      "7446 (5, 1) [D loss: (-1.6399)(R -3.6930, F 2.0344, G 0.0019)] [G loss: -2.4631]\n",
      "7447 (5, 1) [D loss: (-1.1298)(R -4.6304, F 3.4641, G 0.0037)] [G loss: -3.7167]\n",
      "7448 (5, 1) [D loss: (-0.7426)(R -4.5910, F 3.8181, G 0.0030)] [G loss: -3.3861]\n",
      "7449 (5, 1) [D loss: (-0.2905)(R -3.2732, F 2.9655, G 0.0017)] [G loss: -2.1313]\n",
      "7450 (5, 1) [D loss: (-0.5894)(R -1.4552, F 0.8466, G 0.0019)] [G loss: -0.4226]\n",
      "7451 (5, 1) [D loss: (-1.4692)(R 0.4900, F -1.9941, G 0.0035)] [G loss: 2.1314]\n",
      "7452 (5, 1) [D loss: (-1.8247)(R 3.2434, F -5.1664, G 0.0098)] [G loss: 4.8632]\n",
      "7453 (5, 1) [D loss: (-1.6578)(R 4.9825, F -6.8576, G 0.0217)] [G loss: 6.0389]\n",
      "7454 (5, 1) [D loss: (-1.0669)(R 5.1409, F -6.3811, G 0.0173)] [G loss: 6.2243]\n",
      "7455 (5, 1) [D loss: (-1.0041)(R 4.8437, F -5.9639, G 0.0116)] [G loss: 5.9093]\n",
      "7456 (5, 1) [D loss: (-0.2680)(R 3.8616, F -4.1799, G 0.0050)] [G loss: 3.8328]\n",
      "7457 (5, 1) [D loss: (-0.7020)(R 1.6293, F -2.3510, G 0.0020)] [G loss: 2.0460]\n",
      "7458 (5, 1) [D loss: (-0.7292)(R -0.2906, F -0.4542, G 0.0016)] [G loss: 0.4162]\n",
      "7459 (5, 1) [D loss: (-0.8595)(R -2.6737, F 1.7982, G 0.0016)] [G loss: -2.0456]\n",
      "7460 (5, 1) [D loss: (-1.4021)(R -4.9474, F 3.5168, G 0.0028)] [G loss: -4.2275]\n",
      "7461 (5, 1) [D loss: (-1.7783)(R -6.9954, F 5.1393, G 0.0078)] [G loss: -6.0300]\n",
      "7462 (5, 1) [D loss: (-1.1023)(R -7.0890, F 5.9083, G 0.0078)] [G loss: -5.4099]\n",
      "7463 (5, 1) [D loss: (-0.7669)(R -6.3551, F 5.5289, G 0.0059)] [G loss: -5.3985]\n",
      "7464 (5, 1) [D loss: (-0.5523)(R -5.1358, F 4.5538, G 0.0030)] [G loss: -3.7739]\n",
      "7465 (5, 1) [D loss: (-0.6550)(R -3.3864, F 2.7147, G 0.0017)] [G loss: -2.3136]\n",
      "7466 (5, 1) [D loss: (-0.6123)(R -2.1577, F 1.5316, G 0.0014)] [G loss: -1.1249]\n",
      "7467 (5, 1) [D loss: (-0.8134)(R -1.0049, F 0.1738, G 0.0018)] [G loss: 0.2193]\n",
      "7468 (5, 1) [D loss: (-1.1317)(R -0.3888, F -0.7653, G 0.0022)] [G loss: 1.1237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7469 (5, 1) [D loss: (-1.0083)(R 0.7972, F -1.8346, G 0.0029)] [G loss: 1.9101]\n",
      "7470 (5, 1) [D loss: (-0.8744)(R 0.5709, F -1.4673, G 0.0022)] [G loss: 1.6340]\n",
      "7471 (5, 1) [D loss: (-1.1356)(R -0.2941, F -0.8740, G 0.0032)] [G loss: 0.5283]\n",
      "7472 (5, 1) [D loss: (-1.2667)(R -1.4999, F 0.1827, G 0.0050)] [G loss: -0.8996]\n",
      "7473 (5, 1) [D loss: (-1.4074)(R -3.2368, F 1.7654, G 0.0064)] [G loss: -1.9050]\n",
      "7474 (5, 1) [D loss: (-1.5303)(R -3.4275, F 1.8404, G 0.0057)] [G loss: -2.4340]\n",
      "7475 (5, 1) [D loss: (-1.1792)(R -4.2011, F 2.9613, G 0.0061)] [G loss: -3.3274]\n",
      "7476 (5, 1) [D loss: (-1.1898)(R -4.2877, F 3.0433, G 0.0055)] [G loss: -3.8568]\n",
      "7477 (5, 1) [D loss: (-0.8672)(R -3.9701, F 3.0482, G 0.0055)] [G loss: -3.2264]\n",
      "7478 (5, 1) [D loss: (-0.4357)(R -2.3533, F 1.8919, G 0.0026)] [G loss: -1.4346]\n",
      "7479 (5, 1) [D loss: (-0.4469)(R -0.7925, F 0.3272, G 0.0018)] [G loss: -0.0944]\n",
      "7480 (5, 1) [D loss: (-0.4248)(R 0.7760, F -1.2295, G 0.0029)] [G loss: 1.5562]\n",
      "7481 (5, 1) [D loss: (-0.9524)(R 1.5968, F -2.5919, G 0.0043)] [G loss: 2.9610]\n",
      "7482 (5, 1) [D loss: (-1.0489)(R 3.1433, F -4.2594, G 0.0067)] [G loss: 4.2296]\n",
      "7483 (5, 1) [D loss: (-1.2870)(R 4.0753, F -5.4744, G 0.0112)] [G loss: 5.6020]\n",
      "7484 (5, 1) [D loss: (-1.2163)(R 4.9706, F -6.2956, G 0.0109)] [G loss: 6.2023]\n",
      "7485 (5, 1) [D loss: (-0.9553)(R 4.6631, F -5.7001, G 0.0082)] [G loss: 5.8746]\n",
      "7486 (5, 1) [D loss: (-1.4665)(R 4.2114, F -5.7386, G 0.0061)] [G loss: 5.7462]\n",
      "7487 (5, 1) [D loss: (-0.9528)(R 3.0473, F -4.0343, G 0.0034)] [G loss: 4.4189]\n",
      "7488 (5, 1) [D loss: (-0.7128)(R 1.9167, F -2.6553, G 0.0026)] [G loss: 2.6573]\n",
      "7489 (5, 1) [D loss: (-0.6957)(R 0.3767, F -1.0919, G 0.0020)] [G loss: 0.7391]\n",
      "7490 (5, 1) [D loss: (-0.7622)(R -0.5334, F -0.2502, G 0.0021)] [G loss: -0.1918]\n",
      "7491 (5, 1) [D loss: (-1.1371)(R -1.8117, F 0.6474, G 0.0027)] [G loss: -0.7638]\n",
      "7492 (5, 1) [D loss: (-0.6792)(R -2.0315, F 1.3259, G 0.0026)] [G loss: -1.6157]\n",
      "7493 (5, 1) [D loss: (-0.6758)(R -1.6273, F 0.9235, G 0.0028)] [G loss: -0.6706]\n",
      "7494 (5, 1) [D loss: (-0.8357)(R -0.8569, F -0.0092, G 0.0030)] [G loss: -0.0899]\n",
      "7495 (5, 1) [D loss: (-0.7465)(R 0.3373, F -1.1061, G 0.0022)] [G loss: 1.4590]\n",
      "7496 (5, 1) [D loss: (-1.0265)(R 1.7419, F -2.8093, G 0.0041)] [G loss: 3.0735]\n",
      "7497 (5, 1) [D loss: (-1.2997)(R 3.4987, F -4.8446, G 0.0046)] [G loss: 5.3048]\n",
      "7498 (5, 1) [D loss: (-0.9895)(R 5.0907, F -6.1712, G 0.0091)] [G loss: 6.8583]\n",
      "7499 (5, 1) [D loss: (-1.4931)(R 6.4807, F -8.0997, G 0.0126)] [G loss: 8.2363]\n",
      "7500 (5, 1) [D loss: (-1.1405)(R 7.2679, F -8.5574, G 0.0149)] [G loss: 8.7777]\n",
      "7501 (5, 1) [D loss: (-0.9277)(R 7.3098, F -8.3541, G 0.0117)] [G loss: 8.5166]\n",
      "7502 (5, 1) [D loss: (-0.5458)(R 6.9312, F -7.5501, G 0.0073)] [G loss: 7.8893]\n",
      "7503 (5, 1) [D loss: (-0.3268)(R 5.7880, F -6.1479, G 0.0033)] [G loss: 6.0066]\n",
      "7504 (5, 1) [D loss: (-0.3498)(R 4.5695, F -4.9392, G 0.0020)] [G loss: 5.0625]\n",
      "7505 (5, 1) [D loss: (-0.7382)(R 2.9310, F -3.6886, G 0.0019)] [G loss: 3.4566]\n",
      "7506 (5, 1) [D loss: (-0.6313)(R 1.7264, F -2.3780, G 0.0020)] [G loss: 2.2358]\n",
      "7507 (5, 1) [D loss: (-1.4688)(R -0.4864, F -1.0005, G 0.0018)] [G loss: 0.3053]\n",
      "7508 (5, 1) [D loss: (-0.9159)(R -1.5579, F 0.6185, G 0.0023)] [G loss: -0.7463]\n",
      "7509 (5, 1) [D loss: (-1.1724)(R -2.7027, F 1.4801, G 0.0050)] [G loss: -1.7672]\n",
      "7510 (5, 1) [D loss: (-0.7518)(R -2.1675, F 1.3900, G 0.0026)] [G loss: -0.9878]\n",
      "7511 (5, 1) [D loss: (-0.9987)(R -1.0160, F -0.0118, G 0.0029)] [G loss: 0.2259]\n",
      "7512 (5, 1) [D loss: (-0.7778)(R 0.6433, F -1.4469, G 0.0026)] [G loss: 1.8788]\n",
      "7513 (5, 1) [D loss: (-0.8195)(R 3.4614, F -4.3256, G 0.0045)] [G loss: 4.1796]\n",
      "7514 (5, 1) [D loss: (-0.9116)(R 6.1044, F -7.1456, G 0.0130)] [G loss: 6.8764]\n",
      "7515 (5, 1) [D loss: (-1.8620)(R 7.4330, F -9.4809, G 0.0186)] [G loss: 8.8208]\n",
      "7516 (5, 1) [D loss: (-1.2276)(R 7.9718, F -9.4033, G 0.0204)] [G loss: 9.1057]\n",
      "7517 (5, 1) [D loss: (-1.3233)(R 6.9664, F -8.3843, G 0.0095)] [G loss: 7.5974]\n",
      "7518 (5, 1) [D loss: (-0.2683)(R 7.2474, F -7.5654, G 0.0050)] [G loss: 7.0255]\n",
      "7519 (5, 1) [D loss: (-0.2735)(R 5.4567, F -5.7522, G 0.0022)] [G loss: 5.2195]\n",
      "7520 (5, 1) [D loss: (-0.1516)(R 3.8042, F -3.9755, G 0.0020)] [G loss: 3.7596]\n",
      "7521 (5, 1) [D loss: (-1.1175)(R 1.1736, F -2.3112, G 0.0020)] [G loss: 2.1540]\n",
      "7522 (5, 1) [D loss: (-1.1321)(R -0.8635, F -0.2844, G 0.0016)] [G loss: 0.5984]\n",
      "7523 (5, 1) [D loss: (-1.1787)(R -1.8468, F 0.6417, G 0.0026)] [G loss: -0.9337]\n",
      "7524 (5, 1) [D loss: (-1.3814)(R -3.7313, F 2.3058, G 0.0044)] [G loss: -2.7456]\n",
      "7525 (5, 1) [D loss: (-1.2272)(R -4.0133, F 2.7259, G 0.0060)] [G loss: -2.8419]\n",
      "7526 (5, 1) [D loss: (-0.8488)(R -3.5573, F 2.6582, G 0.0050)] [G loss: -2.2847]\n",
      "7527 (5, 1) [D loss: (-0.9170)(R -1.9248, F 0.9778, G 0.0030)] [G loss: -1.4361]\n",
      "7528 (5, 1) [D loss: (-0.9586)(R -0.7779, F -0.2044, G 0.0024)] [G loss: 0.2087]\n",
      "7529 (5, 1) [D loss: (-0.8534)(R 0.3467, F -1.2188, G 0.0019)] [G loss: 1.5778]\n",
      "7530 (5, 1) [D loss: (-0.7046)(R 1.1415, F -1.8695, G 0.0023)] [G loss: 2.1647]\n",
      "7531 (5, 1) [D loss: (-1.3393)(R 1.3035, F -2.6685, G 0.0026)] [G loss: 2.7128]\n",
      "7532 (5, 1) [D loss: (-0.9908)(R 1.6040, F -2.6413, G 0.0046)] [G loss: 2.7206]\n",
      "7533 (5, 1) [D loss: (-1.3636)(R 1.7510, F -3.1630, G 0.0048)] [G loss: 3.7186]\n",
      "7534 (5, 1) [D loss: (-0.9324)(R 1.7353, F -2.7181, G 0.0050)] [G loss: 2.4990]\n",
      "7535 (5, 1) [D loss: (-1.0633)(R 0.6880, F -1.8015, G 0.0050)] [G loss: 1.6621]\n",
      "7536 (5, 1) [D loss: (-1.2325)(R -0.6578, F -0.6237, G 0.0049)] [G loss: 0.2611]\n",
      "7537 (5, 1) [D loss: (-0.5036)(R -1.4263, F 0.8671, G 0.0056)] [G loss: -1.1345]\n",
      "7538 (5, 1) [D loss: (-1.4145)(R -2.8095, F 1.3299, G 0.0065)] [G loss: -2.5444]\n",
      "7539 (5, 1) [D loss: (-1.1515)(R -4.6767, F 3.4147, G 0.0111)] [G loss: -3.7799]\n",
      "7540 (5, 1) [D loss: (-0.5181)(R -4.0190, F 3.4089, G 0.0092)] [G loss: -3.4489]\n",
      "7541 (5, 1) [D loss: (-0.6948)(R -3.2691, F 2.5200, G 0.0054)] [G loss: -2.6561]\n",
      "7542 (5, 1) [D loss: (-0.4908)(R -2.4328, F 1.9164, G 0.0026)] [G loss: -1.3046]\n",
      "7543 (5, 1) [D loss: (-0.5802)(R -1.4674, F 0.8620, G 0.0025)] [G loss: -0.3383]\n",
      "7544 (5, 1) [D loss: (-0.4436)(R -0.2915, F -0.1761, G 0.0024)] [G loss: 0.6174]\n",
      "7545 (5, 1) [D loss: (-0.4649)(R 0.6402, F -1.1396, G 0.0035)] [G loss: 1.3801]\n",
      "7546 (5, 1) [D loss: (-0.9279)(R 1.2543, F -2.2006, G 0.0018)] [G loss: 2.1631]\n",
      "7547 (5, 1) [D loss: (-1.0137)(R 1.7695, F -2.8189, G 0.0036)] [G loss: 2.7175]\n",
      "7548 (5, 1) [D loss: (-0.9034)(R 2.6943, F -3.6477, G 0.0050)] [G loss: 3.9682]\n",
      "7549 (5, 1) [D loss: (-0.8381)(R 3.8248, F -4.7339, G 0.0071)] [G loss: 4.8249]\n",
      "7550 (5, 1) [D loss: (-1.0138)(R 4.3943, F -5.4872, G 0.0079)] [G loss: 5.5902]\n",
      "7551 (5, 1) [D loss: (-0.8660)(R 4.7271, F -5.6671, G 0.0074)] [G loss: 5.8833]\n",
      "7552 (5, 1) [D loss: (-0.7338)(R 4.6363, F -5.4252, G 0.0055)] [G loss: 5.8916]\n",
      "7553 (5, 1) [D loss: (-0.7527)(R 4.5721, F -5.3718, G 0.0047)] [G loss: 5.4631]\n",
      "7554 (5, 1) [D loss: (-0.9264)(R 4.5571, F -5.5204, G 0.0037)] [G loss: 5.5600]\n",
      "7555 (5, 1) [D loss: (-0.7757)(R 4.0553, F -4.8646, G 0.0034)] [G loss: 4.5880]\n",
      "7556 (5, 1) [D loss: (-0.7272)(R 3.4789, F -4.2347, G 0.0029)] [G loss: 4.5462]\n",
      "7557 (5, 1) [D loss: (-0.8302)(R 3.2540, F -4.1109, G 0.0027)] [G loss: 4.2213]\n",
      "7558 (5, 1) [D loss: (-1.1052)(R 2.9884, F -4.1249, G 0.0031)] [G loss: 3.9332]\n",
      "7559 (5, 1) [D loss: (-0.9051)(R 3.1890, F -4.1300, G 0.0036)] [G loss: 4.4540]\n",
      "7560 (5, 1) [D loss: (-0.3615)(R 4.0328, F -4.4374, G 0.0043)] [G loss: 4.6792]\n",
      "7561 (5, 1) [D loss: (-1.2038)(R 4.3997, F -5.6506, G 0.0047)] [G loss: 5.4537]\n",
      "7562 (5, 1) [D loss: (-1.4222)(R 5.3741, F -6.8466, G 0.0050)] [G loss: 6.4196]\n",
      "7563 (5, 1) [D loss: (-0.8400)(R 6.3400, F -7.2414, G 0.0061)] [G loss: 7.4696]\n",
      "7564 (5, 1) [D loss: (-1.6413)(R 6.5928, F -8.2931, G 0.0059)] [G loss: 8.0620]\n",
      "7565 (5, 1) [D loss: (-1.0782)(R 7.6660, F -8.8151, G 0.0071)] [G loss: 8.6095]\n",
      "7566 (5, 1) [D loss: (-1.1241)(R 8.3789, F -9.5781, G 0.0075)] [G loss: 9.3406]\n",
      "7567 (5, 1) [D loss: (-1.0097)(R 8.8158, F -9.9012, G 0.0076)] [G loss: 9.5129]\n",
      "7568 (5, 1) [D loss: (-0.3627)(R 8.9673, F -9.4020, G 0.0072)] [G loss: 9.8551]\n",
      "7569 (5, 1) [D loss: (-0.4843)(R 9.0167, F -9.5566, G 0.0056)] [G loss: 9.3879]\n",
      "7570 (5, 1) [D loss: (-0.5548)(R 7.1856, F -7.7711, G 0.0031)] [G loss: 7.5021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7571 (5, 1) [D loss: (-0.4088)(R 5.9933, F -6.4234, G 0.0021)] [G loss: 5.9568]\n",
      "7572 (5, 1) [D loss: (-1.1955)(R 4.0577, F -5.2729, G 0.0020)] [G loss: 4.5134]\n",
      "7573 (5, 1) [D loss: (-0.5299)(R 2.9525, F -3.5023, G 0.0020)] [G loss: 3.5033]\n",
      "7574 (5, 1) [D loss: (-0.8537)(R 1.5845, F -2.4567, G 0.0018)] [G loss: 2.2042]\n",
      "7575 (5, 1) [D loss: (-0.6716)(R 0.8283, F -1.5177, G 0.0018)] [G loss: 1.6231]\n",
      "7576 (5, 1) [D loss: (-1.2638)(R 0.0121, F -1.3052, G 0.0029)] [G loss: 1.0028]\n",
      "7577 (5, 1) [D loss: (-0.9134)(R 0.7578, F -1.7011, G 0.0030)] [G loss: 1.6203]\n",
      "7578 (5, 1) [D loss: (-0.4274)(R 0.6779, F -1.1417, G 0.0036)] [G loss: 1.5718]\n",
      "7579 (5, 1) [D loss: (-1.1493)(R 1.1953, F -2.3812, G 0.0037)] [G loss: 2.3936]\n",
      "7580 (5, 1) [D loss: (-0.8056)(R 2.0433, F -2.8995, G 0.0051)] [G loss: 3.3413]\n",
      "7581 (5, 1) [D loss: (-1.2277)(R 2.8436, F -4.1279, G 0.0057)] [G loss: 3.9530]\n",
      "7582 (5, 1) [D loss: (-0.7209)(R 3.6917, F -4.4816, G 0.0069)] [G loss: 4.8616]\n",
      "7583 (5, 1) [D loss: (-0.8451)(R 3.6069, F -4.5156, G 0.0064)] [G loss: 4.8230]\n",
      "7584 (5, 1) [D loss: (-1.2223)(R 2.9750, F -4.2415, G 0.0044)] [G loss: 3.7752]\n",
      "7585 (5, 1) [D loss: (-0.8695)(R 1.7549, F -2.6550, G 0.0031)] [G loss: 2.1285]\n",
      "7586 (5, 1) [D loss: (-1.0556)(R 0.1459, F -1.2239, G 0.0022)] [G loss: 0.5608]\n",
      "7587 (5, 1) [D loss: (-1.0698)(R -1.8681, F 0.7660, G 0.0032)] [G loss: -0.7688]\n",
      "7588 (5, 1) [D loss: (-1.4942)(R -3.2710, F 1.7238, G 0.0053)] [G loss: -2.3676]\n",
      "7589 (5, 1) [D loss: (-2.2269)(R -4.7683, F 2.4729, G 0.0068)] [G loss: -3.6867]\n",
      "7590 (5, 1) [D loss: (-0.9495)(R -5.4183, F 4.3513, G 0.0118)] [G loss: -4.6081]\n",
      "7591 (5, 1) [D loss: (-1.0090)(R -5.4651, F 4.3583, G 0.0098)] [G loss: -4.3665]\n",
      "7592 (5, 1) [D loss: (-0.9575)(R -4.8132, F 3.7831, G 0.0073)] [G loss: -3.9326]\n",
      "7593 (5, 1) [D loss: (-1.1518)(R -3.7523, F 2.5608, G 0.0040)] [G loss: -2.5580]\n",
      "7594 (5, 1) [D loss: (-0.7618)(R -2.8031, F 2.0090, G 0.0032)] [G loss: -1.8183]\n",
      "7595 (5, 1) [D loss: (-0.9407)(R -2.2287, F 1.2622, G 0.0026)] [G loss: -1.7617]\n",
      "7596 (5, 1) [D loss: (-0.8862)(R -1.1162, F 0.2112, G 0.0019)] [G loss: -0.4934]\n",
      "7597 (5, 1) [D loss: (-0.6856)(R -0.1014, F -0.6036, G 0.0019)] [G loss: 0.4043]\n",
      "7598 (5, 1) [D loss: (-0.9162)(R 0.0332, F -0.9673, G 0.0018)] [G loss: 0.9115]\n",
      "7599 (5, 1) [D loss: (-0.8499)(R 0.1997, F -1.0738, G 0.0024)] [G loss: 0.8307]\n",
      "7600 (5, 1) [D loss: (-0.4008)(R 1.0078, F -1.4364, G 0.0028)] [G loss: 1.2680]\n",
      "7601 (5, 1) [D loss: (-1.0351)(R 0.7204, F -1.7821, G 0.0027)] [G loss: 1.2433]\n",
      "7602 (5, 1) [D loss: (-0.8565)(R -0.1316, F -0.7536, G 0.0029)] [G loss: 0.4599]\n",
      "7603 (5, 1) [D loss: (-0.3651)(R -0.1587, F -0.2398, G 0.0033)] [G loss: -0.1708]\n",
      "7604 (5, 1) [D loss: (-0.7897)(R -0.5105, F -0.3111, G 0.0032)] [G loss: 0.0305]\n",
      "7605 (5, 1) [D loss: (-0.6746)(R -0.6826, F -0.0233, G 0.0031)] [G loss: 0.4853]\n",
      "7606 (5, 1) [D loss: (-0.6159)(R -0.1936, F -0.4531, G 0.0031)] [G loss: 0.5804]\n",
      "7607 (5, 1) [D loss: (-0.9719)(R 0.1271, F -1.1288, G 0.0030)] [G loss: 1.3669]\n",
      "7608 (5, 1) [D loss: (-0.8804)(R 0.9049, F -1.8150, G 0.0030)] [G loss: 2.2676]\n",
      "7609 (5, 1) [D loss: (-0.8913)(R 1.8826, F -2.8084, G 0.0034)] [G loss: 3.3798]\n",
      "7610 (5, 1) [D loss: (-1.2080)(R 3.1231, F -4.3718, G 0.0041)] [G loss: 4.3698]\n",
      "7611 (5, 1) [D loss: (-1.0348)(R 4.5975, F -5.6895, G 0.0057)] [G loss: 5.7621]\n",
      "7612 (5, 1) [D loss: (-1.1837)(R 5.8688, F -7.1259, G 0.0073)] [G loss: 7.2626]\n",
      "7613 (5, 1) [D loss: (-2.1055)(R 7.3607, F -9.5879, G 0.0122)] [G loss: 9.6971]\n",
      "7614 (5, 1) [D loss: (-1.4798)(R 8.7917, F -10.3932, G 0.0122)] [G loss: 10.4347]\n",
      "7615 (5, 1) [D loss: (-1.3636)(R 10.0240, F -11.5231, G 0.0135)] [G loss: 11.1932]\n",
      "7616 (5, 1) [D loss: (-1.2166)(R 9.3972, F -10.6969, G 0.0083)] [G loss: 10.9360]\n",
      "7617 (5, 1) [D loss: (-0.7191)(R 9.7387, F -10.5220, G 0.0064)] [G loss: 10.5760]\n",
      "7618 (5, 1) [D loss: (-1.3094)(R 9.2423, F -10.6045, G 0.0053)] [G loss: 10.3770]\n",
      "7619 (5, 1) [D loss: (-1.1096)(R 8.5937, F -9.7352, G 0.0032)] [G loss: 9.3272]\n",
      "7620 (5, 1) [D loss: (-0.9792)(R 7.5215, F -8.5169, G 0.0016)] [G loss: 8.4896]\n",
      "7621 (5, 1) [D loss: (-1.3752)(R 6.9316, F -8.3281, G 0.0021)] [G loss: 8.0753]\n",
      "7622 (5, 1) [D loss: (-1.0722)(R 7.4175, F -8.5147, G 0.0025)] [G loss: 8.0196]\n",
      "7623 (5, 1) [D loss: (-1.2261)(R 7.2074, F -8.4631, G 0.0030)] [G loss: 7.9038]\n",
      "7624 (5, 1) [D loss: (-0.7686)(R 7.2320, F -8.0343, G 0.0034)] [G loss: 7.4147]\n",
      "7625 (5, 1) [D loss: (-0.6320)(R 6.9975, F -7.6658, G 0.0036)] [G loss: 7.2245]\n",
      "7626 (5, 1) [D loss: (-0.4055)(R 7.2910, F -7.7344, G 0.0038)] [G loss: 7.3460]\n",
      "7627 (5, 1) [D loss: (-1.4940)(R 7.1321, F -8.6772, G 0.0051)] [G loss: 8.1600]\n",
      "7628 (5, 1) [D loss: (-0.8564)(R 8.0061, F -8.9179, G 0.0055)] [G loss: 8.6889]\n",
      "7629 (5, 1) [D loss: (-0.3593)(R 8.3842, F -8.8005, G 0.0057)] [G loss: 8.5882]\n",
      "7630 (5, 1) [D loss: (-0.7772)(R 7.9457, F -8.7722, G 0.0049)] [G loss: 8.6482]\n",
      "7631 (5, 1) [D loss: (-0.6614)(R 7.3702, F -8.0709, G 0.0039)] [G loss: 7.7496]\n",
      "7632 (5, 1) [D loss: (-0.5520)(R 6.7604, F -7.3421, G 0.0030)] [G loss: 7.6168]\n",
      "7633 (5, 1) [D loss: (-0.7584)(R 5.8971, F -6.6799, G 0.0024)] [G loss: 6.1503]\n",
      "7634 (5, 1) [D loss: (-0.5411)(R 5.0422, F -5.5992, G 0.0016)] [G loss: 5.4391]\n",
      "7635 (5, 1) [D loss: (-0.9727)(R 3.5755, F -4.5698, G 0.0022)] [G loss: 4.3209]\n",
      "7636 (5, 1) [D loss: (-0.7109)(R 3.0697, F -3.8010, G 0.0020)] [G loss: 3.5643]\n",
      "7637 (5, 1) [D loss: (-0.6394)(R 1.3210, F -1.9829, G 0.0023)] [G loss: 1.6778]\n",
      "7638 (5, 1) [D loss: (-1.1764)(R -0.4304, F -0.7815, G 0.0036)] [G loss: 0.7359]\n",
      "7639 (5, 1) [D loss: (-0.8499)(R -0.7031, F -0.1794, G 0.0033)] [G loss: 0.2230]\n",
      "7640 (5, 1) [D loss: (-1.0915)(R -1.0039, F -0.1318, G 0.0044)] [G loss: -0.1012]\n",
      "7641 (5, 1) [D loss: (-0.8470)(R -1.2830, F 0.3955, G 0.0040)] [G loss: -0.0801]\n",
      "7642 (5, 1) [D loss: (-1.2727)(R -1.5418, F 0.2172, G 0.0052)] [G loss: -0.7398]\n",
      "7643 (5, 1) [D loss: (-0.9918)(R -1.5298, F 0.4915, G 0.0047)] [G loss: 0.1001]\n",
      "7644 (5, 1) [D loss: (-1.1782)(R -1.7934, F 0.5624, G 0.0053)] [G loss: -0.3487]\n",
      "7645 (5, 1) [D loss: (-1.4207)(R -1.9295, F 0.4554, G 0.0053)] [G loss: -0.5657]\n",
      "7646 (5, 1) [D loss: (-1.2885)(R -1.9925, F 0.6487, G 0.0055)] [G loss: -0.5693]\n",
      "7647 (5, 1) [D loss: (-0.7329)(R -2.2356, F 1.4397, G 0.0063)] [G loss: -1.1377]\n",
      "7648 (5, 1) [D loss: (-1.0109)(R -2.3226, F 1.2570, G 0.0055)] [G loss: -1.1984]\n",
      "7649 (5, 1) [D loss: (-1.0732)(R -2.3558, F 1.2328, G 0.0050)] [G loss: -1.3673]\n",
      "7650 (5, 1) [D loss: (-1.3856)(R -3.0776, F 1.6253, G 0.0067)] [G loss: -1.9324]\n",
      "7651 (5, 1) [D loss: (-1.5976)(R -3.5679, F 1.9249, G 0.0045)] [G loss: -2.5130]\n",
      "7652 (5, 1) [D loss: (-0.9883)(R -3.3178, F 2.2690, G 0.0060)] [G loss: -2.0947]\n",
      "7653 (5, 1) [D loss: (-1.3792)(R -3.4125, F 1.9734, G 0.0060)] [G loss: -2.9316]\n",
      "7654 (5, 1) [D loss: (-1.6648)(R -3.4748, F 1.7567, G 0.0053)] [G loss: -2.4209]\n",
      "7655 (5, 1) [D loss: (-1.0342)(R -2.8616, F 1.7941, G 0.0033)] [G loss: -2.2758]\n",
      "7656 (5, 1) [D loss: (-0.5561)(R -2.1414, F 1.5602, G 0.0025)] [G loss: -1.0995]\n",
      "7657 (5, 1) [D loss: (-0.5371)(R -1.0330, F 0.4752, G 0.0021)] [G loss: -0.3036]\n",
      "7658 (5, 1) [D loss: (-0.3236)(R -0.1948, F -0.1484, G 0.0020)] [G loss: 0.8041]\n",
      "7659 (5, 1) [D loss: (-0.7068)(R 0.3806, F -1.1115, G 0.0024)] [G loss: 1.2925]\n",
      "7660 (5, 1) [D loss: (-0.7591)(R 0.8113, F -1.6003, G 0.0030)] [G loss: 1.6405]\n",
      "7661 (5, 1) [D loss: (-0.5341)(R 1.5185, F -2.0773, G 0.0025)] [G loss: 2.3176]\n",
      "7662 (5, 1) [D loss: (-0.8068)(R 2.0531, F -2.8961, G 0.0036)] [G loss: 2.7626]\n",
      "7663 (5, 1) [D loss: (-0.7912)(R 2.1830, F -3.0127, G 0.0039)] [G loss: 3.1319]\n",
      "7664 (5, 1) [D loss: (-0.9213)(R 2.8871, F -3.8522, G 0.0044)] [G loss: 3.8164]\n",
      "7665 (5, 1) [D loss: (-0.4771)(R 2.4321, F -2.9483, G 0.0039)] [G loss: 2.8265]\n",
      "7666 (5, 1) [D loss: (-0.6807)(R 2.5323, F -3.2542, G 0.0041)] [G loss: 3.3695]\n",
      "7667 (5, 1) [D loss: (-0.8586)(R 1.8126, F -2.7103, G 0.0039)] [G loss: 2.4709]\n",
      "7668 (5, 1) [D loss: (-0.5107)(R 1.9834, F -2.5286, G 0.0035)] [G loss: 2.1725]\n",
      "7669 (5, 1) [D loss: (-1.0528)(R 0.9104, F -1.9947, G 0.0031)] [G loss: 1.8532]\n",
      "7670 (5, 1) [D loss: (-1.2061)(R 0.5205, F -1.7706, G 0.0044)] [G loss: 1.7803]\n",
      "7671 (5, 1) [D loss: (-0.9349)(R 0.7273, F -1.7074, G 0.0045)] [G loss: 1.7933]\n",
      "7672 (5, 1) [D loss: (-0.9649)(R 1.1518, F -2.1616, G 0.0045)] [G loss: 2.3519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673 (5, 1) [D loss: (-1.1271)(R 2.2986, F -3.4633, G 0.0038)] [G loss: 3.5257]\n",
      "7674 (5, 1) [D loss: (-1.0039)(R 3.3003, F -4.3504, G 0.0046)] [G loss: 4.8333]\n",
      "7675 (5, 1) [D loss: (-1.3774)(R 4.8314, F -6.2721, G 0.0063)] [G loss: 6.4179]\n",
      "7676 (5, 1) [D loss: (-1.3703)(R 7.3257, F -8.7993, G 0.0103)] [G loss: 8.7363]\n",
      "7677 (5, 1) [D loss: (-1.0923)(R 9.1540, F -10.4196, G 0.0173)] [G loss: 10.3600]\n",
      "7678 (5, 1) [D loss: (-1.6126)(R 10.0119, F -11.7907, G 0.0166)] [G loss: 11.7781]\n",
      "7679 (5, 1) [D loss: (-1.4843)(R 10.6629, F -12.2892, G 0.0142)] [G loss: 11.9967]\n",
      "7680 (5, 1) [D loss: (-1.4850)(R 10.7222, F -12.3327, G 0.0125)] [G loss: 11.3435]\n",
      "7681 (5, 1) [D loss: (-0.2128)(R 10.5676, F -10.8469, G 0.0066)] [G loss: 10.6664]\n",
      "7682 (5, 1) [D loss: (-0.9856)(R 9.3558, F -10.3741, G 0.0033)] [G loss: 9.8699]\n",
      "7683 (5, 1) [D loss: (-0.8202)(R 8.2824, F -9.1219, G 0.0019)] [G loss: 8.5097]\n",
      "7684 (5, 1) [D loss: (-0.8845)(R 7.1509, F -8.0499, G 0.0015)] [G loss: 7.6919]\n",
      "7685 (5, 1) [D loss: (-0.3828)(R 6.8078, F -7.2102, G 0.0020)] [G loss: 6.7846]\n",
      "7686 (5, 1) [D loss: (-0.6686)(R 5.7770, F -6.4617, G 0.0016)] [G loss: 6.2343]\n",
      "7687 (5, 1) [D loss: (-1.1028)(R 4.9631, F -6.0879, G 0.0022)] [G loss: 5.9620]\n",
      "7688 (5, 1) [D loss: (-0.9509)(R 6.1133, F -7.0927, G 0.0029)] [G loss: 6.9554]\n",
      "7689 (5, 1) [D loss: (-0.7931)(R 6.8911, F -7.7140, G 0.0030)] [G loss: 7.8414]\n",
      "7690 (5, 1) [D loss: (-1.3670)(R 7.4209, F -8.8417, G 0.0054)] [G loss: 8.7108]\n",
      "7691 (5, 1) [D loss: (-0.8728)(R 8.0709, F -8.9891, G 0.0045)] [G loss: 8.0559]\n",
      "7692 (5, 1) [D loss: (-1.0510)(R 8.2720, F -9.3778, G 0.0055)] [G loss: 8.8131]\n",
      "7693 (5, 1) [D loss: (-1.2040)(R 8.2866, F -9.5404, G 0.0050)] [G loss: 8.7439]\n",
      "7694 (5, 1) [D loss: (-1.1151)(R 7.6114, F -8.7744, G 0.0048)] [G loss: 8.2120]\n",
      "7695 (5, 1) [D loss: (-0.4119)(R 7.6819, F -8.1301, G 0.0036)] [G loss: 7.7804]\n",
      "7696 (5, 1) [D loss: (-0.7110)(R 6.0464, F -6.7873, G 0.0030)] [G loss: 6.7238]\n",
      "7697 (5, 1) [D loss: (-0.5123)(R 4.8800, F -5.4079, G 0.0016)] [G loss: 5.0215]\n",
      "7698 (5, 1) [D loss: (-1.0703)(R 3.7997, F -4.8856, G 0.0016)] [G loss: 4.3786]\n",
      "7699 (5, 1) [D loss: (-1.1063)(R 2.5220, F -3.6469, G 0.0019)] [G loss: 3.1771]\n",
      "7700 (5, 1) [D loss: (-1.2739)(R 0.3206, F -1.6200, G 0.0026)] [G loss: 1.3192]\n",
      "7701 (5, 1) [D loss: (-1.2093)(R -0.8634, F -0.3948, G 0.0049)] [G loss: 0.1004]\n",
      "7702 (5, 1) [D loss: (-1.1790)(R -2.0162, F 0.7659, G 0.0071)] [G loss: -0.8081]\n",
      "7703 (5, 1) [D loss: (-0.7433)(R -1.8716, F 1.0646, G 0.0064)] [G loss: -1.1173]\n",
      "7704 (5, 1) [D loss: (-0.4008)(R -2.1496, F 1.6655, G 0.0083)] [G loss: -1.5637]\n",
      "7705 (5, 1) [D loss: (-0.7709)(R -2.1957, F 1.3565, G 0.0068)] [G loss: -1.2895]\n",
      "7706 (5, 1) [D loss: (-1.1963)(R -2.2476, F 1.0072, G 0.0044)] [G loss: -1.1004]\n",
      "7707 (5, 1) [D loss: (-0.7907)(R -1.7754, F 0.9428, G 0.0042)] [G loss: -0.9105]\n",
      "7708 (5, 1) [D loss: (-1.0964)(R -1.8457, F 0.7015, G 0.0048)] [G loss: -0.8171]\n",
      "7709 (5, 1) [D loss: (-1.0462)(R -1.3979, F 0.3144, G 0.0037)] [G loss: -0.4629]\n",
      "7710 (5, 1) [D loss: (-0.6307)(R -0.7908, F 0.1308, G 0.0029)] [G loss: 0.0631]\n",
      "7711 (5, 1) [D loss: (-1.0918)(R -0.9278, F -0.1968, G 0.0033)] [G loss: 0.1317]\n",
      "7712 (5, 1) [D loss: (-0.9212)(R -0.3010, F -0.6495, G 0.0029)] [G loss: 0.4276]\n",
      "7713 (5, 1) [D loss: (-0.7476)(R -0.8631, F 0.0778, G 0.0038)] [G loss: -0.1633]\n",
      "7714 (5, 1) [D loss: (-1.3166)(R -1.3357, F -0.0160, G 0.0035)] [G loss: -0.3416]\n",
      "7715 (5, 1) [D loss: (-1.1098)(R -1.5750, F 0.4309, G 0.0034)] [G loss: -0.6607]\n",
      "7716 (5, 1) [D loss: (-0.9180)(R -1.2912, F 0.3407, G 0.0033)] [G loss: -0.2506]\n",
      "7717 (5, 1) [D loss: (-0.7037)(R -0.9172, F 0.1884, G 0.0025)] [G loss: 0.3075]\n",
      "7718 (5, 1) [D loss: (-0.5392)(R 0.0402, F -0.6087, G 0.0029)] [G loss: 0.9929]\n",
      "7719 (5, 1) [D loss: (-0.9931)(R 0.7509, F -1.7735, G 0.0029)] [G loss: 1.7175]\n",
      "7720 (5, 1) [D loss: (-0.7843)(R 1.6210, F -2.4418, G 0.0037)] [G loss: 2.5495]\n",
      "7721 (5, 1) [D loss: (-1.2508)(R 3.1102, F -4.4093, G 0.0048)] [G loss: 4.3610]\n",
      "7722 (5, 1) [D loss: (-1.3247)(R 3.9101, F -5.3162, G 0.0081)] [G loss: 5.0381]\n",
      "7723 (5, 1) [D loss: (-0.7225)(R 4.6456, F -5.4532, G 0.0085)] [G loss: 5.8323]\n",
      "7724 (5, 1) [D loss: (-1.0872)(R 4.2430, F -5.3819, G 0.0052)] [G loss: 5.2596]\n",
      "7725 (5, 1) [D loss: (-0.2217)(R 4.4276, F -4.6850, G 0.0036)] [G loss: 4.9726]\n",
      "7726 (5, 1) [D loss: (-0.6400)(R 2.9318, F -3.5927, G 0.0021)] [G loss: 3.3725]\n",
      "7727 (5, 1) [D loss: (-0.7492)(R 1.9082, F -2.6829, G 0.0026)] [G loss: 2.3524]\n",
      "7728 (5, 1) [D loss: (-0.7422)(R 1.5392, F -2.3073, G 0.0026)] [G loss: 1.9790]\n",
      "7729 (5, 1) [D loss: (-0.9925)(R 0.3146, F -1.3427, G 0.0036)] [G loss: 1.0725]\n",
      "7730 (5, 1) [D loss: (-1.3211)(R -0.0207, F -1.3407, G 0.0040)] [G loss: 1.1769]\n",
      "7731 (5, 1) [D loss: (-1.1667)(R 0.1215, F -1.3216, G 0.0033)] [G loss: 1.0968]\n",
      "7732 (5, 1) [D loss: (-0.8141)(R 0.5801, F -1.4217, G 0.0028)] [G loss: 1.8127]\n",
      "7733 (5, 1) [D loss: (-1.0219)(R 1.6333, F -2.6853, G 0.0030)] [G loss: 3.0428]\n",
      "7734 (5, 1) [D loss: (-0.8372)(R 2.8342, F -3.7083, G 0.0037)] [G loss: 3.7087]\n",
      "7735 (5, 1) [D loss: (-0.9064)(R 3.9059, F -4.8713, G 0.0059)] [G loss: 5.3195]\n",
      "7736 (5, 1) [D loss: (-1.1540)(R 5.1349, F -6.3765, G 0.0088)] [G loss: 6.6629]\n",
      "7737 (5, 1) [D loss: (-1.1008)(R 5.6575, F -6.8537, G 0.0095)] [G loss: 6.8480]\n",
      "7738 (5, 1) [D loss: (-0.7603)(R 6.7589, F -7.6118, G 0.0093)] [G loss: 7.7179]\n",
      "7739 (5, 1) [D loss: (-1.1655)(R 6.4638, F -7.7212, G 0.0092)] [G loss: 8.2752]\n",
      "7740 (5, 1) [D loss: (-0.4247)(R 7.4700, F -7.9677, G 0.0073)] [G loss: 8.0736]\n",
      "7741 (5, 1) [D loss: (-0.7586)(R 6.7490, F -7.5711, G 0.0063)] [G loss: 7.2892]\n",
      "7742 (5, 1) [D loss: (-0.5231)(R 5.8241, F -6.3784, G 0.0031)] [G loss: 6.5215]\n",
      "7743 (5, 1) [D loss: (-0.9789)(R 4.4730, F -5.4794, G 0.0027)] [G loss: 5.5289]\n",
      "7744 (5, 1) [D loss: (-0.6277)(R 3.8724, F -4.5206, G 0.0020)] [G loss: 4.5588]\n",
      "7745 (5, 1) [D loss: (-0.8170)(R 2.9073, F -3.7467, G 0.0022)] [G loss: 3.7095]\n",
      "7746 (5, 1) [D loss: (-0.6591)(R 2.0962, F -2.7820, G 0.0027)] [G loss: 2.7147]\n",
      "7747 (5, 1) [D loss: (-0.5520)(R 1.3287, F -1.9126, G 0.0032)] [G loss: 2.2125]\n",
      "7748 (5, 1) [D loss: (-0.5746)(R 1.2621, F -1.8748, G 0.0038)] [G loss: 2.5329]\n",
      "7749 (5, 1) [D loss: (-1.0419)(R 2.5046, F -3.5800, G 0.0033)] [G loss: 3.5268]\n",
      "7750 (5, 1) [D loss: (-0.9535)(R 3.2456, F -4.2355, G 0.0036)] [G loss: 3.5783]\n",
      "7751 (5, 1) [D loss: (-0.9123)(R 3.8218, F -4.7723, G 0.0038)] [G loss: 4.5941]\n",
      "7752 (5, 1) [D loss: (-0.7629)(R 4.4055, F -5.2206, G 0.0052)] [G loss: 5.3549]\n",
      "7753 (5, 1) [D loss: (-0.8115)(R 5.2266, F -6.0915, G 0.0053)] [G loss: 5.8825]\n",
      "7754 (5, 1) [D loss: (-0.9721)(R 5.7992, F -6.8377, G 0.0066)] [G loss: 7.0225]\n",
      "7755 (5, 1) [D loss: (-0.7608)(R 7.2269, F -8.0742, G 0.0086)] [G loss: 7.6001]\n",
      "7756 (5, 1) [D loss: (-0.7999)(R 6.3207, F -7.1965, G 0.0076)] [G loss: 7.0491]\n",
      "7757 (5, 1) [D loss: (-0.4632)(R 5.1494, F -5.6496, G 0.0037)] [G loss: 5.6560]\n",
      "7758 (5, 1) [D loss: (-0.9715)(R 3.9558, F -4.9499, G 0.0023)] [G loss: 4.7698]\n",
      "7759 (5, 1) [D loss: (-0.7946)(R 2.4933, F -3.3109, G 0.0023)] [G loss: 3.1033]\n",
      "7760 (5, 1) [D loss: (-0.7850)(R 0.6712, F -1.4784, G 0.0022)] [G loss: 1.1028]\n",
      "7761 (5, 1) [D loss: (-1.1235)(R -0.7587, F -0.3970, G 0.0032)] [G loss: -0.0019]\n",
      "7762 (5, 1) [D loss: (-0.9336)(R -1.4627, F 0.4908, G 0.0038)] [G loss: -0.2793]\n",
      "7763 (5, 1) [D loss: (-0.9368)(R -1.5003, F 0.5158, G 0.0048)] [G loss: -0.7571]\n",
      "7764 (5, 1) [D loss: (-0.9164)(R -1.6775, F 0.7269, G 0.0034)] [G loss: -0.6589]\n",
      "7765 (5, 1) [D loss: (-0.7685)(R -0.9826, F 0.1820, G 0.0032)] [G loss: -0.2600]\n",
      "7766 (5, 1) [D loss: (-1.2334)(R -0.5779, F -0.6828, G 0.0027)] [G loss: 0.4384]\n",
      "7767 (5, 1) [D loss: (-0.9102)(R 0.1779, F -1.1146, G 0.0026)] [G loss: 0.9071]\n",
      "7768 (5, 1) [D loss: (-0.8348)(R 0.0729, F -0.9450, G 0.0037)] [G loss: 1.0640]\n",
      "7769 (5, 1) [D loss: (-0.8907)(R -0.5465, F -0.3824, G 0.0038)] [G loss: 0.6967]\n",
      "7770 (5, 1) [D loss: (-0.7309)(R -0.7934, F 0.0261, G 0.0036)] [G loss: 0.1066]\n",
      "7771 (5, 1) [D loss: (-1.0786)(R -2.0453, F 0.9276, G 0.0039)] [G loss: -1.0420]\n",
      "7772 (5, 1) [D loss: (-1.8062)(R -3.8253, F 1.9515, G 0.0068)] [G loss: -3.1183]\n",
      "7773 (5, 1) [D loss: (-1.7594)(R -5.5632, F 3.7027, G 0.0101)] [G loss: -4.2421]\n",
      "7774 (5, 1) [D loss: (-1.2614)(R -5.3494, F 3.9637, G 0.0124)] [G loss: -4.2281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7775 (5, 1) [D loss: (-1.3981)(R -5.3262, F 3.8213, G 0.0107)] [G loss: -4.2011]\n",
      "7776 (5, 1) [D loss: (-0.8141)(R -4.2567, F 3.3922, G 0.0050)] [G loss: -3.4794]\n",
      "7777 (5, 1) [D loss: (-1.1090)(R -3.5290, F 2.3967, G 0.0023)] [G loss: -2.6777]\n",
      "7778 (5, 1) [D loss: (-0.7239)(R -2.3704, F 1.6278, G 0.0019)] [G loss: -1.6775]\n",
      "7779 (5, 1) [D loss: (-0.9376)(R -1.8871, F 0.9289, G 0.0021)] [G loss: -1.1522]\n",
      "7780 (5, 1) [D loss: (-0.7192)(R -0.2454, F -0.5017, G 0.0028)] [G loss: 0.3756]\n",
      "7781 (5, 1) [D loss: (-0.3608)(R 0.7111, F -1.0945, G 0.0023)] [G loss: 1.4224]\n",
      "7782 (5, 1) [D loss: (-1.2982)(R 0.8538, F -2.1721, G 0.0020)] [G loss: 2.1944]\n",
      "7783 (5, 1) [D loss: (-1.0050)(R 1.6491, F -2.6864, G 0.0032)] [G loss: 2.6854]\n",
      "7784 (5, 1) [D loss: (-1.2406)(R 1.8887, F -3.1715, G 0.0042)] [G loss: 3.0213]\n",
      "7785 (5, 1) [D loss: (-0.7662)(R 2.2245, F -3.0356, G 0.0045)] [G loss: 3.4048]\n",
      "7786 (5, 1) [D loss: (-0.9882)(R 1.8320, F -2.8792, G 0.0059)] [G loss: 2.9683]\n",
      "7787 (5, 1) [D loss: (-1.0946)(R 1.8415, F -2.9738, G 0.0038)] [G loss: 2.9051]\n",
      "7788 (5, 1) [D loss: (-0.4260)(R 2.3352, F -2.8053, G 0.0044)] [G loss: 2.6180]\n",
      "7789 (5, 1) [D loss: (-0.7811)(R 1.2941, F -2.1011, G 0.0026)] [G loss: 2.1049]\n",
      "7790 (5, 1) [D loss: (-0.5405)(R 0.3730, F -0.9430, G 0.0029)] [G loss: 1.2850]\n",
      "7791 (5, 1) [D loss: (-1.1162)(R -0.4163, F -0.7397, G 0.0040)] [G loss: 0.5185]\n",
      "7792 (5, 1) [D loss: (-0.5687)(R -0.3776, F -0.2339, G 0.0043)] [G loss: 0.5122]\n",
      "7793 (5, 1) [D loss: (-1.2606)(R -0.2598, F -1.0452, G 0.0044)] [G loss: 0.2976]\n",
      "7794 (5, 1) [D loss: (-0.8810)(R 1.2781, F -2.1987, G 0.0040)] [G loss: 2.3100]\n",
      "7795 (5, 1) [D loss: (-0.9525)(R 3.0237, F -4.0120, G 0.0036)] [G loss: 4.4740]\n",
      "7796 (5, 1) [D loss: (-0.9748)(R 4.8733, F -5.9255, G 0.0077)] [G loss: 6.0360]\n",
      "7797 (5, 1) [D loss: (-1.6587)(R 5.9835, F -7.7630, G 0.0121)] [G loss: 7.7879]\n",
      "7798 (5, 1) [D loss: (-1.5242)(R 7.5984, F -9.2507, G 0.0128)] [G loss: 9.1925]\n",
      "7799 (5, 1) [D loss: (-1.3609)(R 8.7529, F -10.2680, G 0.0154)] [G loss: 10.1040]\n",
      "7800 (5, 1) [D loss: (-2.0491)(R 8.4767, F -10.6651, G 0.0139)] [G loss: 9.7646]\n",
      "7801 (5, 1) [D loss: (-1.0054)(R 9.3607, F -10.4861, G 0.0120)] [G loss: 10.2383]\n",
      "7802 (5, 1) [D loss: (-0.7511)(R 8.2326, F -9.0409, G 0.0057)] [G loss: 8.4114]\n",
      "7803 (5, 1) [D loss: (-0.9695)(R 6.6658, F -7.6523, G 0.0017)] [G loss: 7.5819]\n",
      "7804 (5, 1) [D loss: (-0.7697)(R 5.4760, F -6.2606, G 0.0015)] [G loss: 6.4873]\n",
      "7805 (5, 1) [D loss: (-1.0819)(R 4.4165, F -5.5171, G 0.0019)] [G loss: 5.2324]\n",
      "7806 (5, 1) [D loss: (-0.3963)(R 4.2324, F -4.6470, G 0.0018)] [G loss: 4.3207]\n",
      "7807 (5, 1) [D loss: (-0.7910)(R 3.2904, F -4.0963, G 0.0015)] [G loss: 3.7619]\n",
      "7808 (5, 1) [D loss: (-0.8001)(R 2.9107, F -3.7280, G 0.0017)] [G loss: 3.5338]\n",
      "7809 (5, 1) [D loss: (-0.7159)(R 2.7008, F -3.4393, G 0.0023)] [G loss: 3.4805]\n",
      "7810 (5, 1) [D loss: (-0.7485)(R 3.4091, F -4.1893, G 0.0032)] [G loss: 4.0942]\n",
      "7811 (5, 1) [D loss: (-0.7952)(R 3.8213, F -4.6521, G 0.0036)] [G loss: 4.5566]\n",
      "7812 (5, 1) [D loss: (-0.6942)(R 4.6972, F -5.4323, G 0.0041)] [G loss: 5.4481]\n",
      "7813 (5, 1) [D loss: (-0.9674)(R 4.6988, F -5.7055, G 0.0039)] [G loss: 5.6629]\n",
      "7814 (5, 1) [D loss: (-0.9781)(R 4.8327, F -5.8642, G 0.0053)] [G loss: 6.1237]\n",
      "7815 (5, 1) [D loss: (-0.8019)(R 4.9821, F -5.8315, G 0.0047)] [G loss: 5.3096]\n",
      "7816 (5, 1) [D loss: (-0.6590)(R 4.2613, F -4.9604, G 0.0040)] [G loss: 4.9522]\n",
      "7817 (5, 1) [D loss: (-0.6335)(R 3.1299, F -3.7879, G 0.0025)] [G loss: 3.4969]\n",
      "7818 (5, 1) [D loss: (-0.9375)(R 1.9827, F -2.9476, G 0.0027)] [G loss: 2.2796]\n",
      "7819 (5, 1) [D loss: (-0.9398)(R 0.3487, F -1.3201, G 0.0032)] [G loss: 0.8289]\n",
      "7820 (5, 1) [D loss: (-1.2484)(R -0.8652, F -0.4144, G 0.0031)] [G loss: -0.3684]\n",
      "7821 (5, 1) [D loss: (-0.8056)(R -2.0465, F 1.1926, G 0.0048)] [G loss: -0.9255]\n",
      "7822 (5, 1) [D loss: (-1.7191)(R -3.6936, F 1.9134, G 0.0061)] [G loss: -2.0810]\n",
      "7823 (5, 1) [D loss: (-1.2829)(R -4.2100, F 2.8505, G 0.0077)] [G loss: -2.5189]\n",
      "7824 (5, 1) [D loss: (-1.0587)(R -4.5135, F 3.3807, G 0.0074)] [G loss: -3.4748]\n",
      "7825 (5, 1) [D loss: (-1.5104)(R -4.4072, F 2.8397, G 0.0057)] [G loss: -3.0594]\n",
      "7826 (5, 1) [D loss: (-0.4171)(R -2.6993, F 2.2476, G 0.0035)] [G loss: -1.6305]\n",
      "7827 (5, 1) [D loss: (-1.1487)(R -2.7912, F 1.6103, G 0.0032)] [G loss: -1.6065]\n",
      "7828 (5, 1) [D loss: (-0.9203)(R -1.7271, F 0.7788, G 0.0028)] [G loss: -0.4621]\n",
      "7829 (5, 1) [D loss: (-1.0121)(R -1.2147, F 0.1786, G 0.0024)] [G loss: 0.0960]\n",
      "7830 (5, 1) [D loss: (-0.5094)(R -0.4353, F -0.0997, G 0.0025)] [G loss: 0.2520]\n",
      "7831 (5, 1) [D loss: (-0.9458)(R -0.8261, F -0.1484, G 0.0029)] [G loss: 0.1038]\n",
      "7832 (5, 1) [D loss: (-0.5608)(R -0.9505, F 0.3566, G 0.0033)] [G loss: -0.5148]\n",
      "7833 (5, 1) [D loss: (-1.0193)(R -1.5212, F 0.4723, G 0.0030)] [G loss: -0.9682]\n",
      "7834 (5, 1) [D loss: (-1.0773)(R -2.2199, F 1.0932, G 0.0049)] [G loss: -1.4969]\n",
      "7835 (5, 1) [D loss: (-0.9238)(R -2.5401, F 1.5631, G 0.0053)] [G loss: -1.9088]\n",
      "7836 (5, 1) [D loss: (-1.2472)(R -2.4437, F 1.1566, G 0.0040)] [G loss: -1.2482]\n",
      "7837 (5, 1) [D loss: (-0.8760)(R -2.1947, F 1.2767, G 0.0042)] [G loss: -1.4768]\n",
      "7838 (5, 1) [D loss: (-0.1347)(R -1.2054, F 1.0416, G 0.0029)] [G loss: -0.8472]\n",
      "7839 (5, 1) [D loss: (-0.2709)(R -0.8149, F 0.5165, G 0.0028)] [G loss: -0.3766]\n",
      "7840 (5, 1) [D loss: (-0.4016)(R 0.3635, F -0.7852, G 0.0020)] [G loss: 0.8882]\n",
      "7841 (5, 1) [D loss: (-0.7142)(R 1.6393, F -2.3825, G 0.0029)] [G loss: 2.4846]\n",
      "7842 (5, 1) [D loss: (-0.8923)(R 2.2944, F -3.2333, G 0.0047)] [G loss: 3.5583]\n",
      "7843 (5, 1) [D loss: (-1.2571)(R 2.9838, F -4.3156, G 0.0075)] [G loss: 4.4671]\n",
      "7844 (5, 1) [D loss: (-1.5861)(R 3.6152, F -5.3063, G 0.0105)] [G loss: 5.2823]\n",
      "7845 (5, 1) [D loss: (-0.7003)(R 3.9381, F -4.7213, G 0.0083)] [G loss: 5.1138]\n",
      "7846 (5, 1) [D loss: (-0.9211)(R 3.5753, F -4.5571, G 0.0061)] [G loss: 4.4800]\n",
      "7847 (5, 1) [D loss: (-0.7943)(R 2.8970, F -3.7339, G 0.0043)] [G loss: 3.6783]\n",
      "7848 (5, 1) [D loss: (-0.7578)(R 2.0363, F -2.8250, G 0.0031)] [G loss: 2.6921]\n",
      "7849 (5, 1) [D loss: (-0.5499)(R 1.6147, F -2.1961, G 0.0031)] [G loss: 2.3112]\n",
      "7850 (5, 1) [D loss: (-1.1030)(R 0.2584, F -1.3900, G 0.0029)] [G loss: 1.2945]\n",
      "7851 (5, 1) [D loss: (-1.2610)(R -0.3449, F -0.9490, G 0.0033)] [G loss: 0.5640]\n",
      "7852 (5, 1) [D loss: (-0.9692)(R -0.4427, F -0.5608, G 0.0034)] [G loss: 0.5898]\n",
      "7853 (5, 1) [D loss: (-1.1842)(R -0.2589, F -0.9614, G 0.0036)] [G loss: 0.5482]\n",
      "7854 (5, 1) [D loss: (-0.6871)(R 0.6664, F -1.3867, G 0.0033)] [G loss: 1.8780]\n",
      "7855 (5, 1) [D loss: (-0.9758)(R 1.9620, F -2.9699, G 0.0032)] [G loss: 2.9960]\n",
      "7856 (5, 1) [D loss: (-0.9812)(R 2.8380, F -3.8576, G 0.0038)] [G loss: 3.7951]\n",
      "7857 (5, 1) [D loss: (-1.4261)(R 4.0587, F -5.5436, G 0.0059)] [G loss: 5.2097]\n",
      "7858 (5, 1) [D loss: (-1.5063)(R 5.5697, F -7.1700, G 0.0094)] [G loss: 7.1280]\n",
      "7859 (5, 1) [D loss: (-0.6255)(R 6.8360, F -7.5879, G 0.0126)] [G loss: 7.6480]\n",
      "7860 (5, 1) [D loss: (-1.0655)(R 6.9506, F -8.1580, G 0.0142)] [G loss: 7.7870]\n",
      "7861 (5, 1) [D loss: (-1.2106)(R 6.6309, F -7.9385, G 0.0097)] [G loss: 7.7075]\n",
      "7862 (5, 1) [D loss: (-1.0639)(R 5.4164, F -6.5203, G 0.0040)] [G loss: 6.4178]\n",
      "7863 (5, 1) [D loss: (-0.3264)(R 4.5664, F -4.9155, G 0.0023)] [G loss: 4.5916]\n",
      "7864 (5, 1) [D loss: (-0.6562)(R 2.7135, F -3.3887, G 0.0019)] [G loss: 2.8648]\n",
      "7865 (5, 1) [D loss: (-1.4134)(R 0.6035, F -2.0323, G 0.0015)] [G loss: 1.2714]\n",
      "7866 (5, 1) [D loss: (-0.7216)(R -1.0198, F 0.2819, G 0.0016)] [G loss: -0.4731]\n",
      "7867 (5, 1) [D loss: (-0.8102)(R -2.5325, F 1.6886, G 0.0034)] [G loss: -1.9733]\n",
      "7868 (5, 1) [D loss: (-0.8491)(R -3.3646, F 2.4610, G 0.0055)] [G loss: -2.4008]\n",
      "7869 (5, 1) [D loss: (-0.7776)(R -2.8807, F 2.0660, G 0.0037)] [G loss: -2.5607]\n",
      "7870 (5, 1) [D loss: (-0.8976)(R -2.1019, F 1.1758, G 0.0029)] [G loss: -1.0327]\n",
      "7871 (5, 1) [D loss: (-1.0065)(R -0.5278, F -0.5043, G 0.0025)] [G loss: 0.8158]\n",
      "7872 (5, 1) [D loss: (-1.1267)(R 1.0491, F -2.2019, G 0.0026)] [G loss: 2.3364]\n",
      "7873 (5, 1) [D loss: (-1.0463)(R 2.5966, F -3.6940, G 0.0051)] [G loss: 3.8536]\n",
      "7874 (5, 1) [D loss: (-1.2241)(R 3.5979, F -4.8825, G 0.0061)] [G loss: 4.6722]\n",
      "7875 (5, 1) [D loss: (-1.3618)(R 4.1632, F -5.5961, G 0.0071)] [G loss: 5.6862]\n",
      "7876 (5, 1) [D loss: (-0.8169)(R 4.7293, F -5.6209, G 0.0075)] [G loss: 5.4708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7877 (5, 1) [D loss: (-0.2013)(R 3.8210, F -4.0781, G 0.0056)] [G loss: 4.0100]\n",
      "7878 (5, 1) [D loss: (-0.5982)(R 1.7773, F -2.4089, G 0.0033)] [G loss: 2.0001]\n",
      "7879 (5, 1) [D loss: (-0.9734)(R -0.5924, F -0.4016, G 0.0021)] [G loss: -0.0821]\n",
      "7880 (5, 1) [D loss: (-0.8066)(R -2.0114, F 1.1695, G 0.0035)] [G loss: -1.4717]\n",
      "7881 (5, 1) [D loss: (-0.7843)(R -2.6046, F 1.7743, G 0.0046)] [G loss: -2.3307]\n",
      "7882 (5, 1) [D loss: (-1.4961)(R -3.9091, F 2.3374, G 0.0076)] [G loss: -2.8075]\n",
      "7883 (5, 1) [D loss: (-0.8090)(R -3.1410, F 2.2897, G 0.0042)] [G loss: -2.5153]\n",
      "7884 (5, 1) [D loss: (-0.4534)(R -2.1603, F 1.6710, G 0.0036)] [G loss: -1.2191]\n",
      "7885 (5, 1) [D loss: (-0.4740)(R -0.3461, F -0.1412, G 0.0013)] [G loss: 0.3966]\n",
      "7886 (5, 1) [D loss: (-0.6120)(R 0.7608, F -1.3900, G 0.0017)] [G loss: 1.6942]\n",
      "7887 (5, 1) [D loss: (-1.0671)(R 1.5988, F -2.6865, G 0.0021)] [G loss: 2.8304]\n",
      "7888 (5, 1) [D loss: (-1.6367)(R 2.3127, F -3.9833, G 0.0034)] [G loss: 4.4427]\n",
      "7889 (5, 1) [D loss: (-1.2901)(R 3.7222, F -5.0623, G 0.0050)] [G loss: 4.9708]\n",
      "7890 (5, 1) [D loss: (-0.8453)(R 4.2273, F -5.1393, G 0.0067)] [G loss: 4.9370]\n",
      "7891 (5, 1) [D loss: (-0.9876)(R 4.2096, F -5.2525, G 0.0055)] [G loss: 4.9676]\n",
      "7892 (5, 1) [D loss: (-0.7260)(R 3.4413, F -4.2142, G 0.0047)] [G loss: 4.2856]\n",
      "7893 (5, 1) [D loss: (-1.0419)(R 2.4822, F -3.5590, G 0.0035)] [G loss: 3.1714]\n",
      "7894 (5, 1) [D loss: (-0.8946)(R 1.1683, F -2.0968, G 0.0034)] [G loss: 2.0366]\n",
      "7895 (5, 1) [D loss: (-1.1292)(R 0.1483, F -1.3163, G 0.0039)] [G loss: 1.1497]\n",
      "7896 (5, 1) [D loss: (-1.0662)(R -0.2724, F -0.8331, G 0.0039)] [G loss: 0.5377]\n",
      "7897 (5, 1) [D loss: (-0.8938)(R 0.0910, F -1.0266, G 0.0042)] [G loss: 1.1704]\n",
      "7898 (5, 1) [D loss: (-0.8493)(R 0.8961, F -1.7829, G 0.0037)] [G loss: 1.6467]\n",
      "7899 (5, 1) [D loss: (-1.0268)(R 1.2095, F -2.2626, G 0.0026)] [G loss: 2.5550]\n",
      "7900 (5, 1) [D loss: (-0.6789)(R 2.5302, F -3.2425, G 0.0033)] [G loss: 3.5426]\n",
      "7901 (5, 1) [D loss: (-0.9692)(R 2.9363, F -3.9470, G 0.0042)] [G loss: 4.3545]\n",
      "7902 (5, 1) [D loss: (-0.8017)(R 3.7276, F -4.5764, G 0.0047)] [G loss: 4.3935]\n",
      "7903 (5, 1) [D loss: (-0.8004)(R 3.4940, F -4.3415, G 0.0047)] [G loss: 4.5726]\n",
      "7904 (5, 1) [D loss: (-1.4165)(R 3.3271, F -4.7941, G 0.0051)] [G loss: 4.4914]\n",
      "7905 (5, 1) [D loss: (-0.5094)(R 3.3909, F -3.9464, G 0.0046)] [G loss: 3.9999]\n",
      "7906 (5, 1) [D loss: (-1.1974)(R 2.4299, F -3.6541, G 0.0027)] [G loss: 3.6493]\n",
      "7907 (5, 1) [D loss: (-0.6650)(R 2.2213, F -2.9254, G 0.0039)] [G loss: 2.9462]\n",
      "7908 (5, 1) [D loss: (-0.8334)(R 1.5562, F -2.4270, G 0.0038)] [G loss: 2.4623]\n",
      "7909 (5, 1) [D loss: (-0.9164)(R 1.3800, F -2.3329, G 0.0036)] [G loss: 2.2836]\n",
      "7910 (5, 1) [D loss: (-0.8133)(R 0.5699, F -1.4160, G 0.0033)] [G loss: 1.2616]\n",
      "7911 (5, 1) [D loss: (-0.6010)(R 0.8757, F -1.5145, G 0.0038)] [G loss: 1.1706]\n",
      "7912 (5, 1) [D loss: (-1.1848)(R 0.6837, F -1.9102, G 0.0042)] [G loss: 1.4709]\n",
      "7913 (5, 1) [D loss: (-1.0161)(R 0.8598, F -1.9155, G 0.0040)] [G loss: 1.8881]\n",
      "7914 (5, 1) [D loss: (-0.9383)(R 1.7243, F -2.7031, G 0.0041)] [G loss: 2.7116]\n",
      "7915 (5, 1) [D loss: (-0.4911)(R 2.5842, F -3.1137, G 0.0038)] [G loss: 3.2175]\n",
      "7916 (5, 1) [D loss: (-1.0662)(R 2.6534, F -3.7593, G 0.0040)] [G loss: 3.9834]\n",
      "7917 (5, 1) [D loss: (-0.7439)(R 3.9092, F -4.7009, G 0.0048)] [G loss: 4.9084]\n",
      "7918 (5, 1) [D loss: (-1.3233)(R 4.0903, F -5.4598, G 0.0046)] [G loss: 5.6110]\n",
      "7919 (5, 1) [D loss: (-1.2543)(R 4.3108, F -5.6150, G 0.0050)] [G loss: 5.8422]\n",
      "7920 (5, 1) [D loss: (-0.5672)(R 4.7581, F -5.3812, G 0.0056)] [G loss: 5.0056]\n",
      "7921 (5, 1) [D loss: (-0.3713)(R 3.5531, F -3.9657, G 0.0041)] [G loss: 4.1616]\n",
      "7922 (5, 1) [D loss: (-1.3183)(R 2.2834, F -3.6316, G 0.0030)] [G loss: 3.3400]\n",
      "7923 (5, 1) [D loss: (-0.8063)(R 1.4026, F -2.2369, G 0.0028)] [G loss: 2.6884]\n",
      "7924 (5, 1) [D loss: (-1.0806)(R 0.7901, F -1.9010, G 0.0030)] [G loss: 1.7460]\n",
      "7925 (5, 1) [D loss: (-1.3686)(R -0.3137, F -1.0864, G 0.0032)] [G loss: 0.3588]\n",
      "7926 (5, 1) [D loss: (-0.8760)(R -1.6258, F 0.7072, G 0.0043)] [G loss: -0.8861]\n",
      "7927 (5, 1) [D loss: (-0.8505)(R -2.0306, F 1.1304, G 0.0050)] [G loss: -0.7518]\n",
      "7928 (5, 1) [D loss: (-1.1484)(R -1.8958, F 0.7011, G 0.0046)] [G loss: -0.4732]\n",
      "7929 (5, 1) [D loss: (-0.7655)(R -0.6103, F -0.1817, G 0.0026)] [G loss: 0.5749]\n",
      "7930 (5, 1) [D loss: (-0.5918)(R 0.7893, F -1.4068, G 0.0026)] [G loss: 2.0030]\n",
      "7931 (5, 1) [D loss: (-0.4758)(R 2.2595, F -2.7592, G 0.0024)] [G loss: 3.0738]\n",
      "7932 (5, 1) [D loss: (-1.2323)(R 3.1161, F -4.3851, G 0.0037)] [G loss: 4.8021]\n",
      "7933 (5, 1) [D loss: (-0.7296)(R 4.9662, F -5.7471, G 0.0051)] [G loss: 5.9244]\n",
      "7934 (5, 1) [D loss: (-1.7238)(R 5.5884, F -7.3998, G 0.0088)] [G loss: 7.1349]\n",
      "7935 (5, 1) [D loss: (-1.1607)(R 6.5474, F -7.8035, G 0.0095)] [G loss: 7.8540]\n",
      "7936 (5, 1) [D loss: (-1.1775)(R 6.4627, F -7.7132, G 0.0073)] [G loss: 7.2154]\n",
      "7937 (5, 1) [D loss: (-0.8155)(R 5.9106, F -6.7774, G 0.0051)] [G loss: 6.6797]\n",
      "7938 (5, 1) [D loss: (-1.0378)(R 4.9166, F -5.9841, G 0.0030)] [G loss: 5.3180]\n",
      "7939 (5, 1) [D loss: (-0.6331)(R 3.7064, F -4.3602, G 0.0021)] [G loss: 4.0200]\n",
      "7940 (5, 1) [D loss: (-0.9492)(R 1.6063, F -2.5703, G 0.0015)] [G loss: 2.3993]\n",
      "7941 (5, 1) [D loss: (-1.1425)(R 0.3878, F -1.5540, G 0.0024)] [G loss: 0.8625]\n",
      "7942 (5, 1) [D loss: (-1.0956)(R -1.1984, F 0.0721, G 0.0031)] [G loss: -0.1957]\n",
      "7943 (5, 1) [D loss: (-1.0374)(R -1.2681, F 0.1914, G 0.0039)] [G loss: -0.0915]\n",
      "7944 (5, 1) [D loss: (-0.9738)(R -1.1054, F 0.0910, G 0.0041)] [G loss: -0.0117]\n",
      "7945 (5, 1) [D loss: (-0.8012)(R -0.3719, F -0.4608, G 0.0031)] [G loss: 0.8091]\n",
      "7946 (5, 1) [D loss: (-0.8205)(R 0.9059, F -1.7482, G 0.0022)] [G loss: 1.8935]\n",
      "7947 (5, 1) [D loss: (-0.8148)(R 2.0637, F -2.9033, G 0.0025)] [G loss: 2.9135]\n",
      "7948 (5, 1) [D loss: (-0.4732)(R 3.1333, F -3.6414, G 0.0035)] [G loss: 4.0181]\n",
      "7949 (5, 1) [D loss: (-0.9329)(R 4.2041, F -5.1768, G 0.0040)] [G loss: 5.3870]\n",
      "7950 (5, 1) [D loss: (-1.3251)(R 4.9441, F -6.3317, G 0.0063)] [G loss: 6.5114]\n",
      "7951 (5, 1) [D loss: (-1.0589)(R 6.2704, F -7.4203, G 0.0091)] [G loss: 7.6038]\n",
      "7952 (5, 1) [D loss: (-0.7758)(R 6.0805, F -6.9360, G 0.0080)] [G loss: 7.4303]\n",
      "7953 (5, 1) [D loss: (-0.9776)(R 5.6336, F -6.6662, G 0.0055)] [G loss: 6.5706]\n",
      "7954 (5, 1) [D loss: (-0.8252)(R 4.5342, F -5.3969, G 0.0038)] [G loss: 5.0139]\n",
      "7955 (5, 1) [D loss: (-0.9695)(R 2.8146, F -3.8123, G 0.0028)] [G loss: 3.2369]\n",
      "7956 (5, 1) [D loss: (-0.7658)(R 1.4677, F -2.2602, G 0.0027)] [G loss: 2.1401]\n",
      "7957 (5, 1) [D loss: (-1.2933)(R 0.6044, F -1.9240, G 0.0026)] [G loss: 1.9150]\n",
      "7958 (5, 1) [D loss: (-0.7529)(R 0.2284, F -1.0101, G 0.0029)] [G loss: 1.2715]\n",
      "7959 (5, 1) [D loss: (-0.9713)(R 0.0505, F -1.0484, G 0.0027)] [G loss: 0.8435]\n",
      "7960 (5, 1) [D loss: (-0.6815)(R 0.8711, F -1.5814, G 0.0029)] [G loss: 1.4828]\n",
      "7961 (5, 1) [D loss: (-1.0776)(R 1.0605, F -2.1697, G 0.0032)] [G loss: 2.2727]\n",
      "7962 (5, 1) [D loss: (-0.8767)(R 1.8970, F -2.8086, G 0.0035)] [G loss: 2.7114]\n",
      "7963 (5, 1) [D loss: (-0.9913)(R 2.2806, F -3.3054, G 0.0034)] [G loss: 3.5521]\n",
      "7964 (5, 1) [D loss: (-1.0808)(R 2.4209, F -3.5406, G 0.0039)] [G loss: 3.8738]\n",
      "7965 (5, 1) [D loss: (-0.9934)(R 2.8366, F -3.8699, G 0.0040)] [G loss: 3.8714]\n",
      "7966 (5, 1) [D loss: (-0.8853)(R 3.1230, F -4.0530, G 0.0045)] [G loss: 4.1620]\n",
      "7967 (5, 1) [D loss: (-0.6759)(R 2.7443, F -3.4600, G 0.0040)] [G loss: 4.1939]\n",
      "7968 (5, 1) [D loss: (-0.5471)(R 2.7781, F -3.3617, G 0.0037)] [G loss: 3.6086]\n",
      "7969 (5, 1) [D loss: (-0.6738)(R 2.5787, F -3.2888, G 0.0036)] [G loss: 3.3032]\n",
      "7970 (5, 1) [D loss: (-0.4163)(R 1.7806, F -2.2316, G 0.0035)] [G loss: 2.2324]\n",
      "7971 (5, 1) [D loss: (-0.5995)(R 1.1081, F -1.7480, G 0.0040)] [G loss: 1.3913]\n",
      "7972 (5, 1) [D loss: (-1.0732)(R -0.1494, F -0.9595, G 0.0036)] [G loss: 0.8235]\n",
      "7973 (5, 1) [D loss: (-1.1560)(R -0.4289, F -0.7696, G 0.0043)] [G loss: 0.4293]\n",
      "7974 (5, 1) [D loss: (-0.8331)(R -0.1413, F -0.7364, G 0.0045)] [G loss: 0.8737]\n",
      "7975 (5, 1) [D loss: (-0.4933)(R 0.4192, F -0.9465, G 0.0034)] [G loss: 1.8051]\n",
      "7976 (5, 1) [D loss: (-0.9721)(R 1.6148, F -2.6127, G 0.0026)] [G loss: 2.6986]\n",
      "7977 (5, 1) [D loss: (-1.0503)(R 2.7475, F -3.8360, G 0.0038)] [G loss: 3.6639]\n",
      "7978 (5, 1) [D loss: (-1.0412)(R 3.6679, F -4.7486, G 0.0040)] [G loss: 4.7345]\n",
      "7979 (5, 1) [D loss: (-0.9727)(R 4.0507, F -5.0770, G 0.0054)] [G loss: 5.1536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7980 (5, 1) [D loss: (-0.7177)(R 4.6650, F -5.4394, G 0.0057)] [G loss: 5.1576]\n",
      "7981 (5, 1) [D loss: (-0.8125)(R 3.6772, F -4.5414, G 0.0052)] [G loss: 4.6441]\n",
      "7982 (5, 1) [D loss: (-0.6721)(R 2.6538, F -3.3555, G 0.0030)] [G loss: 3.2487]\n",
      "7983 (5, 1) [D loss: (-0.8798)(R 0.7652, F -1.6751, G 0.0030)] [G loss: 1.7853]\n",
      "7984 (5, 1) [D loss: (-1.0857)(R -0.4554, F -0.6676, G 0.0037)] [G loss: 0.2580]\n",
      "7985 (5, 1) [D loss: (-1.3557)(R -1.9252, F 0.5100, G 0.0059)] [G loss: -0.8686]\n",
      "7986 (5, 1) [D loss: (-1.2749)(R -2.7187, F 1.3744, G 0.0069)] [G loss: -1.6077]\n",
      "7987 (5, 1) [D loss: (-0.7456)(R -2.0905, F 1.2843, G 0.0061)] [G loss: -1.4340]\n",
      "7988 (5, 1) [D loss: (-0.8545)(R -1.2152, F 0.3312, G 0.0030)] [G loss: -0.2886]\n",
      "7989 (5, 1) [D loss: (-0.7592)(R -0.0217, F -0.7619, G 0.0024)] [G loss: 1.0411]\n",
      "7990 (5, 1) [D loss: (-1.0473)(R 0.6347, F -1.7073, G 0.0025)] [G loss: 1.7022]\n",
      "7991 (5, 1) [D loss: (-0.8114)(R 2.1800, F -3.0191, G 0.0028)] [G loss: 3.4055]\n",
      "7992 (5, 1) [D loss: (-1.5972)(R 3.6566, F -5.2993, G 0.0045)] [G loss: 5.5023]\n",
      "7993 (5, 1) [D loss: (-1.4006)(R 5.4659, F -6.9517, G 0.0085)] [G loss: 7.1283]\n",
      "7994 (5, 1) [D loss: (-1.2734)(R 7.0799, F -8.4978, G 0.0145)] [G loss: 8.3771]\n",
      "7995 (5, 1) [D loss: (-1.0773)(R 6.8183, F -8.0411, G 0.0145)] [G loss: 8.0519]\n",
      "7996 (5, 1) [D loss: (-0.5211)(R 6.6647, F -7.2517, G 0.0066)] [G loss: 7.3181]\n",
      "7997 (5, 1) [D loss: (0.0925)(R 5.7253, F -5.6629, G 0.0030)] [G loss: 5.9743]\n",
      "7998 (5, 1) [D loss: (-0.1916)(R 3.9169, F -4.1282, G 0.0020)] [G loss: 3.9847]\n",
      "7999 (5, 1) [D loss: (-1.2172)(R 1.6268, F -2.8619, G 0.0018)] [G loss: 2.4179]\n",
      "8000 (5, 1) [D loss: (-1.3893)(R 0.0830, F -1.4873, G 0.0015)] [G loss: 1.0262]\n",
      "8001 (5, 1) [D loss: (-1.4309)(R -1.6534, F 0.1727, G 0.0050)] [G loss: -0.5325]\n",
      "8002 (5, 1) [D loss: (-1.0757)(R -2.2948, F 1.1505, G 0.0069)] [G loss: -0.8110]\n",
      "8003 (5, 1) [D loss: (-0.7817)(R -1.8979, F 1.0626, G 0.0054)] [G loss: -0.7120]\n",
      "8004 (5, 1) [D loss: (-0.2544)(R -0.5837, F 0.3056, G 0.0024)] [G loss: 0.2697]\n",
      "8005 (5, 1) [D loss: (-0.7492)(R 0.9822, F -1.7466, G 0.0015)] [G loss: 2.4561]\n",
      "8006 (5, 1) [D loss: (-0.6970)(R 2.8328, F -3.5453, G 0.0015)] [G loss: 3.6445]\n",
      "8007 (5, 1) [D loss: (-0.6302)(R 4.5424, F -5.1958, G 0.0023)] [G loss: 5.4933]\n",
      "8008 (5, 1) [D loss: (-1.1879)(R 5.4192, F -6.6548, G 0.0048)] [G loss: 7.2363]\n",
      "8009 (5, 1) [D loss: (-1.3529)(R 6.5393, F -7.9835, G 0.0091)] [G loss: 8.2511]\n",
      "8010 (5, 1) [D loss: (-0.9850)(R 7.7408, F -8.8369, G 0.0111)] [G loss: 9.2300]\n",
      "8011 (5, 1) [D loss: (-0.6779)(R 7.0600, F -7.8196, G 0.0082)] [G loss: 7.7330]\n",
      "8012 (5, 1) [D loss: (-1.0088)(R 5.5647, F -6.6252, G 0.0052)] [G loss: 6.9247]\n",
      "8013 (5, 1) [D loss: (-0.5946)(R 4.8533, F -5.4785, G 0.0031)] [G loss: 5.3007]\n",
      "8014 (5, 1) [D loss: (-0.6993)(R 3.2403, F -3.9683, G 0.0029)] [G loss: 4.2579]\n",
      "8015 (5, 1) [D loss: (-0.9420)(R 2.1413, F -3.1069, G 0.0024)] [G loss: 2.5082]\n",
      "8016 (5, 1) [D loss: (-1.0595)(R 1.1756, F -2.2689, G 0.0034)] [G loss: 1.8467]\n",
      "8017 (5, 1) [D loss: (-0.9484)(R 0.3856, F -1.3741, G 0.0040)] [G loss: 0.8777]\n",
      "8018 (5, 1) [D loss: (-0.5378)(R 0.3167, F -0.8902, G 0.0036)] [G loss: 1.1923]\n",
      "8019 (5, 1) [D loss: (-0.7350)(R 1.0369, F -1.7981, G 0.0026)] [G loss: 2.2526]\n",
      "8020 (5, 1) [D loss: (-0.8279)(R 1.7232, F -2.5756, G 0.0025)] [G loss: 2.9821]\n",
      "8021 (5, 1) [D loss: (-0.7515)(R 3.0350, F -3.8154, G 0.0029)] [G loss: 4.1634]\n",
      "8022 (5, 1) [D loss: (-0.9721)(R 4.0162, F -5.0261, G 0.0038)] [G loss: 4.8719]\n",
      "8023 (5, 1) [D loss: (-1.3295)(R 4.5879, F -5.9718, G 0.0054)] [G loss: 5.6150]\n",
      "8024 (5, 1) [D loss: (-1.3062)(R 5.0037, F -6.3697, G 0.0060)] [G loss: 6.3267]\n",
      "8025 (5, 1) [D loss: (-0.9698)(R 5.9027, F -6.9308, G 0.0058)] [G loss: 6.9070]\n",
      "8026 (5, 1) [D loss: (-0.9248)(R 5.8832, F -6.8811, G 0.0073)] [G loss: 6.4893]\n",
      "8027 (5, 1) [D loss: (-1.2226)(R 5.0319, F -6.2998, G 0.0045)] [G loss: 5.9846]\n",
      "8028 (5, 1) [D loss: (-0.2920)(R 4.7270, F -5.0589, G 0.0040)] [G loss: 5.0304]\n",
      "8029 (5, 1) [D loss: (-0.7554)(R 2.9542, F -3.7342, G 0.0025)] [G loss: 3.4253]\n",
      "8030 (5, 1) [D loss: (-1.1299)(R 0.8904, F -2.0448, G 0.0024)] [G loss: 1.3571]\n",
      "8031 (5, 1) [D loss: (-1.3063)(R -1.2169, F -0.1314, G 0.0042)] [G loss: -0.5159]\n",
      "8032 (5, 1) [D loss: (-1.5198)(R -1.9410, F 0.3753, G 0.0046)] [G loss: -1.2483]\n",
      "8033 (5, 1) [D loss: (-0.9648)(R -2.5059, F 1.4786, G 0.0063)] [G loss: -1.0931]\n",
      "8034 (5, 1) [D loss: (-0.9911)(R -2.0067, F 0.9710, G 0.0045)] [G loss: -0.9028]\n",
      "8035 (5, 1) [D loss: (-0.9410)(R -0.8422, F -0.1281, G 0.0029)] [G loss: 0.6644]\n",
      "8036 (5, 1) [D loss: (-0.8959)(R 0.1338, F -1.0565, G 0.0027)] [G loss: 1.3667]\n",
      "8037 (5, 1) [D loss: (-1.0656)(R 1.0628, F -2.1554, G 0.0027)] [G loss: 2.6061]\n",
      "8038 (5, 1) [D loss: (-0.9796)(R 2.4794, F -3.4915, G 0.0033)] [G loss: 3.4155]\n",
      "8039 (5, 1) [D loss: (-0.9906)(R 3.8017, F -4.8467, G 0.0054)] [G loss: 5.1151]\n",
      "8040 (5, 1) [D loss: (-1.1912)(R 4.1682, F -5.4219, G 0.0062)] [G loss: 5.4295]\n",
      "8041 (5, 1) [D loss: (-1.2051)(R 3.7495, F -5.0123, G 0.0058)] [G loss: 4.9050]\n",
      "8042 (5, 1) [D loss: (-0.8884)(R 3.4070, F -4.3340, G 0.0039)] [G loss: 4.0547]\n",
      "8043 (5, 1) [D loss: (-0.6229)(R 2.2432, F -2.8937, G 0.0028)] [G loss: 2.9105]\n",
      "8044 (5, 1) [D loss: (-1.0233)(R 1.3930, F -2.4395, G 0.0023)] [G loss: 1.7143]\n",
      "8045 (5, 1) [D loss: (-1.1506)(R -0.3435, F -0.8319, G 0.0025)] [G loss: 0.4147]\n",
      "8046 (5, 1) [D loss: (-1.1525)(R -1.1032, F -0.0805, G 0.0031)] [G loss: -0.4885]\n",
      "8047 (5, 1) [D loss: (-1.2208)(R -1.7001, F 0.4239, G 0.0055)] [G loss: -0.4326]\n",
      "8048 (5, 1) [D loss: (-0.9902)(R -1.7920, F 0.7556, G 0.0046)] [G loss: -0.5332]\n",
      "8049 (5, 1) [D loss: (-1.0871)(R -1.1235, F -0.0002, G 0.0037)] [G loss: -0.0767]\n",
      "8050 (5, 1) [D loss: (-0.6784)(R 0.0522, F -0.7661, G 0.0036)] [G loss: 1.3043]\n",
      "8051 (5, 1) [D loss: (-0.7292)(R 1.8085, F -2.5596, G 0.0022)] [G loss: 2.6057]\n",
      "8052 (5, 1) [D loss: (-0.9948)(R 2.7413, F -3.7687, G 0.0033)] [G loss: 4.1045]\n",
      "8053 (5, 1) [D loss: (-1.1693)(R 4.0933, F -5.3077, G 0.0045)] [G loss: 5.3273]\n",
      "8054 (5, 1) [D loss: (-0.9879)(R 4.9824, F -6.0358, G 0.0065)] [G loss: 6.3679]\n",
      "8055 (5, 1) [D loss: (-0.9817)(R 5.8335, F -6.8999, G 0.0085)] [G loss: 6.7717]\n",
      "8056 (5, 1) [D loss: (-0.7495)(R 5.4435, F -6.2632, G 0.0070)] [G loss: 6.2549]\n",
      "8057 (5, 1) [D loss: (-0.7967)(R 4.7072, F -5.5528, G 0.0049)] [G loss: 5.8428]\n",
      "8058 (5, 1) [D loss: (-0.7249)(R 3.8758, F -4.6339, G 0.0033)] [G loss: 4.2972]\n",
      "8059 (5, 1) [D loss: (-0.7740)(R 2.4604, F -3.2567, G 0.0022)] [G loss: 2.9215]\n",
      "8060 (5, 1) [D loss: (-0.9754)(R 0.6413, F -1.6459, G 0.0029)] [G loss: 1.0162]\n",
      "8061 (5, 1) [D loss: (-1.5356)(R -0.9871, F -0.5826, G 0.0034)] [G loss: -0.2690]\n",
      "8062 (5, 1) [D loss: (-0.8788)(R -1.4534, F 0.5276, G 0.0047)] [G loss: -0.4576]\n",
      "8063 (5, 1) [D loss: (-1.3609)(R -1.0071, F -0.3978, G 0.0044)] [G loss: 0.4786]\n",
      "8064 (5, 1) [D loss: (-0.6769)(R -0.0675, F -0.6403, G 0.0031)] [G loss: 1.1399]\n",
      "8065 (5, 1) [D loss: (-0.4744)(R 1.4554, F -1.9623, G 0.0033)] [G loss: 2.2993]\n",
      "8066 (5, 1) [D loss: (-1.0636)(R 2.3189, F -3.4152, G 0.0033)] [G loss: 3.4806]\n",
      "8067 (5, 1) [D loss: (-1.4682)(R 3.5589, F -5.0517, G 0.0025)] [G loss: 4.9952]\n",
      "8068 (5, 1) [D loss: (-1.2311)(R 4.8698, F -6.1558, G 0.0055)] [G loss: 5.9522]\n",
      "8069 (5, 1) [D loss: (-1.0369)(R 5.5182, F -6.6235, G 0.0068)] [G loss: 6.4671]\n",
      "8070 (5, 1) [D loss: (-0.3194)(R 6.1874, F -6.5641, G 0.0057)] [G loss: 7.0330]\n",
      "8071 (5, 1) [D loss: (-0.7815)(R 5.8201, F -6.6503, G 0.0049)] [G loss: 6.3934]\n",
      "8072 (5, 1) [D loss: (-0.8549)(R 5.0915, F -5.9873, G 0.0041)] [G loss: 5.8057]\n",
      "8073 (5, 1) [D loss: (-0.9472)(R 4.6288, F -5.6131, G 0.0037)] [G loss: 5.5254]\n",
      "8074 (5, 1) [D loss: (-1.0432)(R 3.6794, F -4.7532, G 0.0031)] [G loss: 4.3769]\n",
      "8075 (5, 1) [D loss: (-1.0558)(R 2.5144, F -3.6024, G 0.0032)] [G loss: 3.2069]\n",
      "8076 (5, 1) [D loss: (-1.5424)(R 0.7371, F -2.3135, G 0.0034)] [G loss: 1.8318]\n",
      "8077 (5, 1) [D loss: (-1.1884)(R 0.0617, F -1.2916, G 0.0042)] [G loss: 0.5753]\n",
      "8078 (5, 1) [D loss: (-1.1065)(R -0.8100, F -0.3364, G 0.0040)] [G loss: 0.1313]\n",
      "8079 (5, 1) [D loss: (-0.8129)(R -0.9136, F 0.0626, G 0.0038)] [G loss: -0.0318]\n",
      "8080 (5, 1) [D loss: (-0.6653)(R -0.3787, F -0.3155, G 0.0029)] [G loss: 0.5268]\n",
      "8081 (5, 1) [D loss: (-0.9581)(R 0.3646, F -1.3494, G 0.0027)] [G loss: 1.3717]\n",
      "8082 (5, 1) [D loss: (-0.8889)(R 1.3771, F -2.2923, G 0.0026)] [G loss: 1.7745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083 (5, 1) [D loss: (-1.2902)(R 1.9738, F -3.2961, G 0.0032)] [G loss: 3.4993]\n",
      "8084 (5, 1) [D loss: (-1.4561)(R 2.6503, F -4.1467, G 0.0040)] [G loss: 4.3074]\n",
      "8085 (5, 1) [D loss: (-0.8349)(R 3.7166, F -4.5980, G 0.0047)] [G loss: 4.9127]\n",
      "8086 (5, 1) [D loss: (-1.2527)(R 3.4687, F -4.7746, G 0.0053)] [G loss: 4.9029]\n",
      "8087 (5, 1) [D loss: (-1.1695)(R 2.9167, F -4.1411, G 0.0055)] [G loss: 3.9353]\n",
      "8088 (5, 1) [D loss: (-0.8943)(R 2.1159, F -3.0596, G 0.0049)] [G loss: 3.0645]\n",
      "8089 (5, 1) [D loss: (-1.4087)(R 0.4279, F -1.8835, G 0.0047)] [G loss: 1.4930]\n",
      "8090 (5, 1) [D loss: (-1.1341)(R -1.2851, F 0.0849, G 0.0066)] [G loss: -0.0882]\n",
      "8091 (5, 1) [D loss: (-1.1107)(R -1.7337, F 0.5676, G 0.0055)] [G loss: -0.8599]\n",
      "8092 (5, 1) [D loss: (-0.9648)(R -1.1743, F 0.1754, G 0.0034)] [G loss: -0.3439]\n",
      "8093 (5, 1) [D loss: (-0.4503)(R -0.1616, F -0.3157, G 0.0027)] [G loss: 1.0498]\n",
      "8094 (5, 1) [D loss: (-0.8798)(R 0.6105, F -1.5152, G 0.0025)] [G loss: 1.5673]\n",
      "8095 (5, 1) [D loss: (-0.6275)(R 1.5757, F -2.2221, G 0.0019)] [G loss: 2.5869]\n",
      "8096 (5, 1) [D loss: (-0.8222)(R 2.7075, F -3.5552, G 0.0025)] [G loss: 3.7582]\n",
      "8097 (5, 1) [D loss: (-0.6753)(R 3.7346, F -4.4507, G 0.0041)] [G loss: 4.7969]\n",
      "8098 (5, 1) [D loss: (-1.0783)(R 4.9703, F -6.0937, G 0.0045)] [G loss: 6.2391]\n",
      "8099 (5, 1) [D loss: (-1.4285)(R 5.7150, F -7.2152, G 0.0072)] [G loss: 7.1805]\n",
      "8100 (5, 1) [D loss: (-1.5065)(R 6.4126, F -8.0059, G 0.0087)] [G loss: 7.8095]\n",
      "8101 (5, 1) [D loss: (-1.2759)(R 6.7920, F -8.1289, G 0.0061)] [G loss: 7.5189]\n",
      "8102 (5, 1) [D loss: (-1.4350)(R 5.4497, F -6.9254, G 0.0041)] [G loss: 6.8382]\n",
      "8103 (5, 1) [D loss: (-1.1498)(R 4.6360, F -5.8185, G 0.0033)] [G loss: 5.4760]\n",
      "8104 (5, 1) [D loss: (-0.5671)(R 3.6493, F -4.2444, G 0.0028)] [G loss: 4.2389]\n",
      "8105 (5, 1) [D loss: (-0.5164)(R 2.6735, F -3.2135, G 0.0024)] [G loss: 3.2877]\n",
      "8106 (5, 1) [D loss: (-0.9275)(R 1.4009, F -2.3554, G 0.0027)] [G loss: 2.3114]\n",
      "8107 (5, 1) [D loss: (-0.8811)(R 1.4199, F -2.3308, G 0.0030)] [G loss: 2.1484]\n",
      "8108 (5, 1) [D loss: (-1.3113)(R 1.2253, F -2.5663, G 0.0030)] [G loss: 2.3336]\n",
      "8109 (5, 1) [D loss: (-0.9416)(R 2.0084, F -2.9944, G 0.0044)] [G loss: 3.2534]\n",
      "8110 (5, 1) [D loss: (-1.3002)(R 2.4625, F -3.7966, G 0.0034)] [G loss: 3.7491]\n",
      "8111 (5, 1) [D loss: (-0.3799)(R 3.1688, F -3.5811, G 0.0032)] [G loss: 4.0214]\n",
      "8112 (5, 1) [D loss: (-1.2198)(R 3.4862, F -4.7447, G 0.0039)] [G loss: 4.5887]\n",
      "8113 (5, 1) [D loss: (-1.3107)(R 4.1483, F -5.4959, G 0.0037)] [G loss: 5.3084]\n",
      "8114 (5, 1) [D loss: (-1.4244)(R 4.4366, F -5.9201, G 0.0059)] [G loss: 5.8377]\n",
      "8115 (5, 1) [D loss: (-0.5810)(R 4.9535, F -5.5828, G 0.0048)] [G loss: 6.0400]\n",
      "8116 (5, 1) [D loss: (-0.6999)(R 4.6931, F -5.4439, G 0.0051)] [G loss: 5.2643]\n",
      "8117 (5, 1) [D loss: (-0.1689)(R 5.0397, F -5.2527, G 0.0044)] [G loss: 5.4524]\n",
      "8118 (5, 1) [D loss: (-0.6485)(R 3.7676, F -4.4595, G 0.0043)] [G loss: 4.1397]\n",
      "8119 (5, 1) [D loss: (-0.7952)(R 2.9609, F -3.7872, G 0.0031)] [G loss: 3.6726]\n",
      "8120 (5, 1) [D loss: (-1.2412)(R 2.3435, F -3.6208, G 0.0036)] [G loss: 3.6026]\n",
      "8121 (5, 1) [D loss: (-0.8053)(R 1.8867, F -2.7180, G 0.0026)] [G loss: 2.3732]\n",
      "8122 (5, 1) [D loss: (-0.7091)(R 1.3302, F -2.0824, G 0.0043)] [G loss: 1.8880]\n",
      "8123 (5, 1) [D loss: (-0.8729)(R 1.5506, F -2.4655, G 0.0042)] [G loss: 2.1261]\n",
      "8124 (5, 1) [D loss: (-0.8053)(R 1.5620, F -2.4021, G 0.0035)] [G loss: 2.2927]\n",
      "8125 (5, 1) [D loss: (-0.8793)(R 1.7139, F -2.6334, G 0.0040)] [G loss: 3.0811]\n",
      "8126 (5, 1) [D loss: (-0.7077)(R 2.8939, F -3.6377, G 0.0036)] [G loss: 3.8380]\n",
      "8127 (5, 1) [D loss: (-0.5771)(R 3.9785, F -4.5982, G 0.0043)] [G loss: 4.6277]\n",
      "8128 (5, 1) [D loss: (-1.6702)(R 4.5534, F -6.2738, G 0.0050)] [G loss: 6.0094]\n",
      "8129 (5, 1) [D loss: (-0.9478)(R 6.3044, F -7.3349, G 0.0083)] [G loss: 7.3303]\n",
      "8130 (5, 1) [D loss: (-1.5909)(R 6.4480, F -8.1345, G 0.0096)] [G loss: 7.9321]\n",
      "8131 (5, 1) [D loss: (-0.6859)(R 7.3101, F -8.0793, G 0.0083)] [G loss: 8.0980]\n",
      "8132 (5, 1) [D loss: (-1.0594)(R 7.0210, F -8.1338, G 0.0053)] [G loss: 7.7581]\n",
      "8133 (5, 1) [D loss: (-0.4825)(R 6.0553, F -6.5744, G 0.0037)] [G loss: 6.5317]\n",
      "8134 (5, 1) [D loss: (-0.6436)(R 4.6319, F -5.2976, G 0.0022)] [G loss: 5.2148]\n",
      "8135 (5, 1) [D loss: (-0.8966)(R 2.7531, F -3.6646, G 0.0015)] [G loss: 3.0265]\n",
      "8136 (5, 1) [D loss: (-1.2163)(R 0.3052, F -1.5376, G 0.0016)] [G loss: 1.3264]\n",
      "8137 (5, 1) [D loss: (-1.3178)(R -1.1774, F -0.1806, G 0.0040)] [G loss: -0.2809]\n",
      "8138 (5, 1) [D loss: (-1.1930)(R -2.0113, F 0.7414, G 0.0077)] [G loss: -1.4085]\n",
      "8139 (5, 1) [D loss: (-1.5315)(R -3.2870, F 1.6595, G 0.0096)] [G loss: -1.7021]\n",
      "8140 (5, 1) [D loss: (-1.2331)(R -2.6819, F 1.3780, G 0.0071)] [G loss: -1.5209]\n",
      "8141 (5, 1) [D loss: (-1.4032)(R -2.0193, F 0.5717, G 0.0044)] [G loss: -0.6474]\n",
      "8142 (5, 1) [D loss: (-1.2743)(R -1.0129, F -0.2965, G 0.0035)] [G loss: 0.3598]\n",
      "8143 (5, 1) [D loss: (-0.6110)(R 0.2599, F -0.8901, G 0.0019)] [G loss: 1.7371]\n",
      "8144 (5, 1) [D loss: (-0.5188)(R 1.3734, F -1.9119, G 0.0020)] [G loss: 2.1890]\n",
      "8145 (5, 1) [D loss: (-0.7881)(R 1.5623, F -2.3731, G 0.0023)] [G loss: 3.0234]\n",
      "8146 (5, 1) [D loss: (-1.0762)(R 1.7994, F -2.9042, G 0.0029)] [G loss: 3.2641]\n",
      "8147 (5, 1) [D loss: (-0.7116)(R 2.0212, F -2.7617, G 0.0029)] [G loss: 3.1861]\n",
      "8148 (5, 1) [D loss: (-1.2642)(R 1.6740, F -2.9713, G 0.0033)] [G loss: 2.6891]\n",
      "8149 (5, 1) [D loss: (-1.0639)(R 1.6167, F -2.7111, G 0.0030)] [G loss: 2.3766]\n",
      "8150 (5, 1) [D loss: (-1.0374)(R 0.9903, F -2.0704, G 0.0043)] [G loss: 2.3731]\n",
      "8151 (5, 1) [D loss: (-1.2058)(R 0.5645, F -1.8367, G 0.0066)] [G loss: 1.5627]\n",
      "8152 (5, 1) [D loss: (-1.4632)(R -0.2891, F -1.2308, G 0.0057)] [G loss: 1.2955]\n",
      "8153 (5, 1) [D loss: (-0.7160)(R 0.3570, F -1.1174, G 0.0044)] [G loss: 0.9989]\n",
      "8154 (5, 1) [D loss: (-0.7448)(R 0.9718, F -1.7455, G 0.0029)] [G loss: 2.4504]\n",
      "8155 (5, 1) [D loss: (-1.2571)(R 1.5913, F -2.8795, G 0.0031)] [G loss: 3.1440]\n",
      "8156 (5, 1) [D loss: (-0.8733)(R 2.6573, F -3.5611, G 0.0030)] [G loss: 3.5622]\n",
      "8157 (5, 1) [D loss: (-1.0425)(R 3.6569, F -4.7377, G 0.0038)] [G loss: 5.0544]\n",
      "8158 (5, 1) [D loss: (-0.7646)(R 4.5829, F -5.3864, G 0.0039)] [G loss: 5.7466]\n",
      "8159 (5, 1) [D loss: (-1.1709)(R 4.6071, F -5.8188, G 0.0041)] [G loss: 5.7097]\n",
      "8160 (5, 1) [D loss: (-0.8255)(R 4.6216, F -5.4905, G 0.0043)] [G loss: 5.3445]\n",
      "8161 (5, 1) [D loss: (-1.0599)(R 4.1005, F -5.1950, G 0.0035)] [G loss: 4.7627]\n",
      "8162 (5, 1) [D loss: (-0.9306)(R 3.0599, F -4.0210, G 0.0030)] [G loss: 3.4855]\n",
      "8163 (5, 1) [D loss: (-0.7898)(R 2.0870, F -2.9031, G 0.0026)] [G loss: 2.5369]\n",
      "8164 (5, 1) [D loss: (-0.9365)(R 0.7037, F -1.6734, G 0.0033)] [G loss: 1.5752]\n",
      "8165 (5, 1) [D loss: (-0.9420)(R -0.0583, F -0.9240, G 0.0040)] [G loss: 0.7337]\n",
      "8166 (5, 1) [D loss: (-0.9712)(R 0.0597, F -1.0705, G 0.0040)] [G loss: 0.8484]\n",
      "8167 (5, 1) [D loss: (-1.3280)(R 0.1386, F -1.5048, G 0.0038)] [G loss: 1.4124]\n",
      "8168 (5, 1) [D loss: (-1.2606)(R 0.9778, F -2.2786, G 0.0040)] [G loss: 2.3985]\n",
      "8169 (5, 1) [D loss: (-1.1381)(R 2.4661, F -3.6381, G 0.0034)] [G loss: 4.0412]\n",
      "8170 (5, 1) [D loss: (-1.3347)(R 3.9938, F -5.3932, G 0.0065)] [G loss: 5.0834]\n",
      "8171 (5, 1) [D loss: (-1.0220)(R 5.3795, F -6.4788, G 0.0077)] [G loss: 6.4380]\n",
      "8172 (5, 1) [D loss: (-0.7636)(R 6.4943, F -7.3293, G 0.0071)] [G loss: 7.4804]\n",
      "8173 (5, 1) [D loss: (-0.6629)(R 7.3897, F -8.1321, G 0.0080)] [G loss: 8.2819]\n",
      "8174 (5, 1) [D loss: (-0.7771)(R 7.5016, F -8.3313, G 0.0053)] [G loss: 8.1218]\n",
      "8175 (5, 1) [D loss: (-1.1578)(R 6.9652, F -8.1749, G 0.0052)] [G loss: 8.0396]\n",
      "8176 (5, 1) [D loss: (-1.1676)(R 6.1452, F -7.3476, G 0.0035)] [G loss: 6.8380]\n",
      "8177 (5, 1) [D loss: (-1.0788)(R 5.3207, F -6.4265, G 0.0027)] [G loss: 6.2123]\n",
      "8178 (5, 1) [D loss: (-1.2698)(R 3.5025, F -4.7929, G 0.0021)] [G loss: 4.3843]\n",
      "8179 (5, 1) [D loss: (-1.6121)(R 1.3639, F -2.9985, G 0.0023)] [G loss: 2.7411]\n",
      "8180 (5, 1) [D loss: (-1.7870)(R 0.2364, F -2.0580, G 0.0035)] [G loss: 1.3420]\n",
      "8181 (5, 1) [D loss: (-1.2317)(R -1.0281, F -0.2492, G 0.0046)] [G loss: -0.0170]\n",
      "8182 (5, 1) [D loss: (-0.9761)(R -1.3646, F 0.3478, G 0.0041)] [G loss: -0.1943]\n",
      "8183 (5, 1) [D loss: (-0.8228)(R -0.2563, F -0.5963, G 0.0030)] [G loss: 0.2504]\n",
      "8184 (5, 1) [D loss: (-0.7420)(R 0.3322, F -1.0945, G 0.0020)] [G loss: 1.1302]\n",
      "8185 (5, 1) [D loss: (-1.1553)(R 1.2645, F -2.4386, G 0.0019)] [G loss: 2.0306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8186 (5, 1) [D loss: (-0.8426)(R 2.1597, F -3.0231, G 0.0021)] [G loss: 3.3082]\n",
      "8187 (5, 1) [D loss: (-1.4017)(R 3.3391, F -4.7694, G 0.0029)] [G loss: 5.0263]\n",
      "8188 (5, 1) [D loss: (-1.5765)(R 4.3016, F -5.9284, G 0.0050)] [G loss: 5.7579]\n",
      "8189 (5, 1) [D loss: (-1.6067)(R 4.8560, F -6.5270, G 0.0064)] [G loss: 6.3043]\n",
      "8190 (5, 1) [D loss: (-1.5516)(R 5.4065, F -7.0515, G 0.0093)] [G loss: 6.7770]\n",
      "8191 (5, 1) [D loss: (-1.4112)(R 5.1836, F -6.6839, G 0.0089)] [G loss: 6.7418]\n",
      "8192 (5, 1) [D loss: (-1.2703)(R 4.1678, F -5.5132, G 0.0075)] [G loss: 5.7951]\n",
      "8193 (5, 1) [D loss: (-1.2396)(R 3.8782, F -5.1759, G 0.0058)] [G loss: 5.2421]\n",
      "8194 (5, 1) [D loss: (-0.5632)(R 2.9766, F -3.5856, G 0.0046)] [G loss: 3.6567]\n",
      "8195 (5, 1) [D loss: (-0.5835)(R 2.5710, F -3.1888, G 0.0034)] [G loss: 2.6934]\n",
      "8196 (5, 1) [D loss: (-0.6221)(R 1.4957, F -2.1440, G 0.0026)] [G loss: 1.9485]\n",
      "8197 (5, 1) [D loss: (-0.6424)(R 1.1035, F -1.7642, G 0.0018)] [G loss: 1.7443]\n",
      "8198 (5, 1) [D loss: (-1.0557)(R 0.7684, F -1.8481, G 0.0024)] [G loss: 1.5280]\n",
      "8199 (5, 1) [D loss: (-0.9998)(R 0.9309, F -1.9587, G 0.0028)] [G loss: 2.0059]\n",
      "8200 (5, 1) [D loss: (-0.6881)(R 1.0021, F -1.7142, G 0.0024)] [G loss: 1.8983]\n",
      "8201 (5, 1) [D loss: (-0.9384)(R 1.4365, F -2.4072, G 0.0032)] [G loss: 2.7723]\n",
      "8202 (5, 1) [D loss: (-1.2618)(R 1.8473, F -3.1439, G 0.0035)] [G loss: 3.2847]\n",
      "8203 (5, 1) [D loss: (-0.8135)(R 2.3949, F -3.2520, G 0.0044)] [G loss: 3.4182]\n",
      "8204 (5, 1) [D loss: (-0.7020)(R 2.7002, F -3.4554, G 0.0053)] [G loss: 3.8280]\n",
      "8205 (5, 1) [D loss: (-1.0415)(R 2.6837, F -3.7795, G 0.0054)] [G loss: 3.3896]\n",
      "8206 (5, 1) [D loss: (-1.1074)(R 2.0423, F -3.2023, G 0.0053)] [G loss: 3.0618]\n",
      "8207 (5, 1) [D loss: (-1.1701)(R 2.0553, F -3.2738, G 0.0048)] [G loss: 3.2008]\n",
      "8208 (5, 1) [D loss: (-1.0691)(R 2.7329, F -3.8376, G 0.0036)] [G loss: 3.9386]\n",
      "8209 (5, 1) [D loss: (-0.7245)(R 2.8318, F -3.5953, G 0.0039)] [G loss: 3.8344]\n",
      "8210 (5, 1) [D loss: (-0.5223)(R 3.4291, F -3.9895, G 0.0038)] [G loss: 3.7979]\n",
      "8211 (5, 1) [D loss: (-0.7301)(R 3.3336, F -4.1036, G 0.0040)] [G loss: 4.1138]\n",
      "8212 (5, 1) [D loss: (-0.5371)(R 3.0895, F -3.6668, G 0.0040)] [G loss: 4.0803]\n",
      "8213 (5, 1) [D loss: (-1.3335)(R 3.6092, F -4.9837, G 0.0041)] [G loss: 4.7820]\n",
      "8214 (5, 1) [D loss: (-0.8398)(R 3.4984, F -4.3829, G 0.0045)] [G loss: 4.2937]\n",
      "8215 (5, 1) [D loss: (-0.8142)(R 3.1869, F -4.0371, G 0.0036)] [G loss: 3.9677]\n",
      "8216 (5, 1) [D loss: (-0.8237)(R 2.7757, F -3.6285, G 0.0029)] [G loss: 3.8626]\n",
      "8217 (5, 1) [D loss: (-1.0291)(R 2.7534, F -3.8244, G 0.0042)] [G loss: 3.7809]\n",
      "8218 (5, 1) [D loss: (-1.1265)(R 2.5652, F -3.7361, G 0.0044)] [G loss: 3.6952]\n",
      "8219 (5, 1) [D loss: (-1.1088)(R 2.4645, F -3.6259, G 0.0053)] [G loss: 3.8605]\n",
      "8220 (5, 1) [D loss: (-0.8445)(R 2.3392, F -3.2260, G 0.0042)] [G loss: 3.7603]\n",
      "8221 (5, 1) [D loss: (-1.1619)(R 2.6580, F -3.8695, G 0.0050)] [G loss: 3.9139]\n",
      "8222 (5, 1) [D loss: (-1.0504)(R 2.6585, F -3.7553, G 0.0046)] [G loss: 4.0462]\n",
      "8223 (5, 1) [D loss: (-0.5533)(R 3.8542, F -4.4434, G 0.0036)] [G loss: 4.1578]\n",
      "8224 (5, 1) [D loss: (-0.3218)(R 2.6671, F -3.0208, G 0.0032)] [G loss: 2.7615]\n",
      "8225 (5, 1) [D loss: (-0.3425)(R 2.0213, F -2.3963, G 0.0033)] [G loss: 1.9633]\n",
      "8226 (5, 1) [D loss: (-0.6962)(R 0.8978, F -1.6182, G 0.0024)] [G loss: 1.5540]\n",
      "8227 (5, 1) [D loss: (-0.6201)(R 0.1921, F -0.8409, G 0.0029)] [G loss: 1.2829]\n",
      "8228 (5, 1) [D loss: (-0.7863)(R -0.1281, F -0.6870, G 0.0029)] [G loss: 0.9710]\n",
      "8229 (5, 1) [D loss: (-0.7925)(R -0.4764, F -0.3578, G 0.0042)] [G loss: 0.9407]\n",
      "8230 (5, 1) [D loss: (-0.7035)(R 0.2925, F -1.0298, G 0.0034)] [G loss: 0.9676]\n",
      "8231 (5, 1) [D loss: (-1.1355)(R -0.0776, F -1.1031, G 0.0045)] [G loss: 1.0579]\n",
      "8232 (5, 1) [D loss: (-1.2516)(R 0.1649, F -1.4592, G 0.0043)] [G loss: 1.4805]\n",
      "8233 (5, 1) [D loss: (-1.2124)(R 0.4835, F -1.7486, G 0.0053)] [G loss: 1.6577]\n",
      "8234 (5, 1) [D loss: (-1.1246)(R 0.9491, F -2.1234, G 0.0050)] [G loss: 2.0185]\n",
      "8235 (5, 1) [D loss: (-0.8696)(R 1.2940, F -2.2078, G 0.0044)] [G loss: 2.3828]\n",
      "8236 (5, 1) [D loss: (-0.9689)(R 1.7631, F -2.7752, G 0.0043)] [G loss: 2.4273]\n",
      "8237 (5, 1) [D loss: (-0.7297)(R 2.0156, F -2.7902, G 0.0045)] [G loss: 2.7503]\n",
      "8238 (5, 1) [D loss: (-0.9362)(R 1.3590, F -2.3359, G 0.0041)] [G loss: 2.4259]\n",
      "8239 (5, 1) [D loss: (-0.8635)(R 0.9292, F -1.8276, G 0.0035)] [G loss: 1.4500]\n",
      "8240 (5, 1) [D loss: (-1.1937)(R -0.1816, F -1.0504, G 0.0038)] [G loss: 0.8807]\n",
      "8241 (5, 1) [D loss: (-0.9774)(R -1.1645, F 0.1518, G 0.0035)] [G loss: -0.2696]\n",
      "8242 (5, 1) [D loss: (-0.7281)(R -1.8795, F 1.1082, G 0.0043)] [G loss: -1.0975]\n",
      "8243 (5, 1) [D loss: (-1.0457)(R -2.5876, F 1.4973, G 0.0045)] [G loss: -1.8133]\n",
      "8244 (5, 1) [D loss: (-1.1158)(R -3.2620, F 2.0928, G 0.0053)] [G loss: -2.1274]\n",
      "8245 (5, 1) [D loss: (-0.8849)(R -3.1704, F 2.2365, G 0.0049)] [G loss: -2.2752]\n",
      "8246 (5, 1) [D loss: (-0.5885)(R -2.7868, F 2.1521, G 0.0046)] [G loss: -2.0026]\n",
      "8247 (5, 1) [D loss: (-0.7551)(R -2.2416, F 1.4454, G 0.0041)] [G loss: -1.0238]\n",
      "8248 (5, 1) [D loss: (-0.8561)(R -1.0776, F 0.1982, G 0.0023)] [G loss: 0.0368]\n",
      "8249 (5, 1) [D loss: (-1.1363)(R 0.0566, F -1.2134, G 0.0020)] [G loss: 1.5728]\n",
      "8250 (5, 1) [D loss: (-0.5260)(R 2.0827, F -2.6353, G 0.0027)] [G loss: 2.9291]\n",
      "8251 (5, 1) [D loss: (-0.4049)(R 3.4389, F -3.8802, G 0.0036)] [G loss: 4.1776]\n",
      "8252 (5, 1) [D loss: (-1.2060)(R 3.8875, F -5.1324, G 0.0039)] [G loss: 4.9411]\n",
      "8253 (5, 1) [D loss: (-0.8201)(R 4.6719, F -5.5438, G 0.0052)] [G loss: 5.6552]\n",
      "8254 (5, 1) [D loss: (-0.6513)(R 4.5316, F -5.2261, G 0.0043)] [G loss: 5.4497]\n",
      "8255 (5, 1) [D loss: (-0.5510)(R 4.2623, F -4.8407, G 0.0027)] [G loss: 4.8433]\n",
      "8256 (5, 1) [D loss: (-0.9175)(R 2.9505, F -3.9012, G 0.0033)] [G loss: 3.6338]\n",
      "8257 (5, 1) [D loss: (-0.4277)(R 2.5288, F -2.9861, G 0.0030)] [G loss: 3.2332]\n",
      "8258 (5, 1) [D loss: (-1.1808)(R 1.4150, F -2.6264, G 0.0031)] [G loss: 2.5299]\n",
      "8259 (5, 1) [D loss: (-1.0735)(R 0.7491, F -1.8575, G 0.0035)] [G loss: 2.0093]\n",
      "8260 (5, 1) [D loss: (-1.2000)(R 0.3055, F -1.5475, G 0.0042)] [G loss: 1.4846]\n",
      "8261 (5, 1) [D loss: (-1.1027)(R 0.4482, F -1.5942, G 0.0043)] [G loss: 1.2503]\n",
      "8262 (5, 1) [D loss: (-1.0799)(R 0.6047, F -1.7300, G 0.0045)] [G loss: 1.7262]\n",
      "8263 (5, 1) [D loss: (-0.8713)(R 1.4739, F -2.3892, G 0.0044)] [G loss: 2.2070]\n",
      "8264 (5, 1) [D loss: (-1.0714)(R 2.2147, F -3.3214, G 0.0035)] [G loss: 3.5683]\n",
      "8265 (5, 1) [D loss: (-0.5777)(R 3.1865, F -3.8051, G 0.0041)] [G loss: 4.2478]\n",
      "8266 (5, 1) [D loss: (-0.8488)(R 4.1330, F -5.0316, G 0.0050)] [G loss: 4.8565]\n",
      "8267 (5, 1) [D loss: (-0.4844)(R 4.7714, F -5.3061, G 0.0050)] [G loss: 5.3940]\n",
      "8268 (5, 1) [D loss: (-0.6015)(R 4.5049, F -5.1511, G 0.0045)] [G loss: 5.3838]\n",
      "8269 (5, 1) [D loss: (-0.4654)(R 4.7610, F -5.2763, G 0.0050)] [G loss: 5.0654]\n",
      "8270 (5, 1) [D loss: (-0.3575)(R 4.1248, F -4.5186, G 0.0036)] [G loss: 4.8335]\n",
      "8271 (5, 1) [D loss: (-0.8853)(R 2.8047, F -3.7229, G 0.0033)] [G loss: 3.4720]\n",
      "8272 (5, 1) [D loss: (-0.9960)(R 2.1011, F -3.1320, G 0.0035)] [G loss: 2.8766]\n",
      "8273 (5, 1) [D loss: (-1.5878)(R -0.1205, F -1.5073, G 0.0040)] [G loss: 0.9975]\n",
      "8274 (5, 1) [D loss: (-1.1663)(R -0.7081, F -0.5126, G 0.0054)] [G loss: 0.3740]\n",
      "8275 (5, 1) [D loss: (-1.1157)(R -1.4041, F 0.2344, G 0.0054)] [G loss: -0.0019]\n",
      "8276 (5, 1) [D loss: (-1.4280)(R -1.7246, F 0.2414, G 0.0055)] [G loss: -0.3949]\n",
      "8277 (5, 1) [D loss: (-0.9497)(R -1.8716, F 0.8691, G 0.0053)] [G loss: -0.6257]\n",
      "8278 (5, 1) [D loss: (-0.5694)(R -1.3008, F 0.7045, G 0.0027)] [G loss: -0.3586]\n",
      "8279 (5, 1) [D loss: (-0.6353)(R -1.0703, F 0.4102, G 0.0025)] [G loss: -0.0050]\n",
      "8280 (5, 1) [D loss: (-0.4763)(R 0.0277, F -0.5217, G 0.0018)] [G loss: 0.4528]\n",
      "8281 (5, 1) [D loss: (-0.7652)(R -0.2418, F -0.5445, G 0.0021)] [G loss: 0.3837]\n",
      "8282 (5, 1) [D loss: (-0.5988)(R 0.0616, F -0.6830, G 0.0023)] [G loss: 0.5343]\n",
      "8283 (5, 1) [D loss: (-0.7016)(R 0.0774, F -0.8001, G 0.0021)] [G loss: 1.0070]\n",
      "8284 (5, 1) [D loss: (-0.9559)(R 0.3261, F -1.3113, G 0.0029)] [G loss: 1.4515]\n",
      "8285 (5, 1) [D loss: (-0.8680)(R 0.4102, F -1.3157, G 0.0037)] [G loss: 1.3154]\n",
      "8286 (5, 1) [D loss: (-0.8874)(R 0.4430, F -1.3685, G 0.0038)] [G loss: 1.4313]\n",
      "8287 (5, 1) [D loss: (-0.8626)(R 0.3254, F -1.2317, G 0.0044)] [G loss: 1.1834]\n",
      "8288 (5, 1) [D loss: (-0.8973)(R 0.2472, F -1.1935, G 0.0049)] [G loss: 1.3824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8289 (5, 1) [D loss: (-1.1253)(R 0.0938, F -1.2700, G 0.0051)] [G loss: 1.3304]\n",
      "8290 (5, 1) [D loss: (-0.8514)(R 0.2701, F -1.1800, G 0.0058)] [G loss: 1.2935]\n",
      "8291 (5, 1) [D loss: (-1.0147)(R 0.5147, F -1.5769, G 0.0048)] [G loss: 1.4298]\n",
      "8292 (5, 1) [D loss: (-0.6885)(R 1.0511, F -1.7917, G 0.0052)] [G loss: 1.9127]\n",
      "8293 (5, 1) [D loss: (-1.2635)(R 0.8720, F -2.1769, G 0.0041)] [G loss: 1.9349]\n",
      "8294 (5, 1) [D loss: (-1.1744)(R 1.4588, F -2.6737, G 0.0041)] [G loss: 2.6659]\n",
      "8295 (5, 1) [D loss: (-0.9615)(R 2.0001, F -3.0031, G 0.0041)] [G loss: 2.8555]\n",
      "8296 (5, 1) [D loss: (-0.5344)(R 2.2695, F -2.8388, G 0.0035)] [G loss: 2.8200]\n",
      "8297 (5, 1) [D loss: (-0.9925)(R 1.8707, F -2.8909, G 0.0028)] [G loss: 2.8061]\n",
      "8298 (5, 1) [D loss: (-0.8991)(R 1.5674, F -2.5043, G 0.0038)] [G loss: 2.7427]\n",
      "8299 (5, 1) [D loss: (-0.8796)(R 1.1649, F -2.0763, G 0.0032)] [G loss: 2.2029]\n",
      "8300 (5, 1) [D loss: (-1.2163)(R 0.6738, F -1.9248, G 0.0035)] [G loss: 1.7157]\n",
      "8301 (5, 1) [D loss: (-1.3633)(R 0.1619, F -1.5607, G 0.0036)] [G loss: 1.3427]\n",
      "8302 (5, 1) [D loss: (-1.2744)(R -0.2588, F -1.0533, G 0.0038)] [G loss: 0.7660]\n",
      "8303 (5, 1) [D loss: (-1.1058)(R -0.3980, F -0.7508, G 0.0043)] [G loss: 0.4973]\n",
      "8304 (5, 1) [D loss: (-0.9532)(R -0.2009, F -0.7910, G 0.0039)] [G loss: 0.9531]\n",
      "8305 (5, 1) [D loss: (-1.3041)(R -0.4546, F -0.8911, G 0.0042)] [G loss: 0.8582]\n",
      "8306 (5, 1) [D loss: (-0.6334)(R 0.3736, F -1.0381, G 0.0031)] [G loss: 0.9898]\n",
      "8307 (5, 1) [D loss: (-0.9484)(R 0.3362, F -1.3154, G 0.0031)] [G loss: 1.5747]\n",
      "8308 (5, 1) [D loss: (-0.8226)(R 0.9426, F -1.7978, G 0.0033)] [G loss: 1.7232]\n",
      "8309 (5, 1) [D loss: (-0.7644)(R 1.2684, F -2.0644, G 0.0032)] [G loss: 2.1723]\n",
      "8310 (5, 1) [D loss: (-0.8221)(R 1.2946, F -2.1534, G 0.0037)] [G loss: 2.5837]\n",
      "8311 (5, 1) [D loss: (-0.4478)(R 1.9956, F -2.4820, G 0.0039)] [G loss: 2.7200]\n",
      "8312 (5, 1) [D loss: (-0.8543)(R 1.5509, F -2.4381, G 0.0033)] [G loss: 2.3891]\n",
      "8313 (5, 1) [D loss: (-0.7814)(R 1.1707, F -1.9954, G 0.0043)] [G loss: 1.9571]\n",
      "8314 (5, 1) [D loss: (-1.2279)(R 0.4169, F -1.6768, G 0.0032)] [G loss: 1.6491]\n",
      "8315 (5, 1) [D loss: (-0.8855)(R -0.2387, F -0.6825, G 0.0036)] [G loss: 0.5963]\n",
      "8316 (5, 1) [D loss: (-0.9368)(R -0.7559, F -0.2174, G 0.0036)] [G loss: 0.1322]\n",
      "8317 (5, 1) [D loss: (-0.8891)(R -1.6299, F 0.6945, G 0.0046)] [G loss: -1.2504]\n",
      "8318 (5, 1) [D loss: (-1.4549)(R -2.9793, F 1.4666, G 0.0058)] [G loss: -1.9759]\n",
      "8319 (5, 1) [D loss: (-1.0728)(R -2.5573, F 1.4436, G 0.0041)] [G loss: -1.8065]\n",
      "8320 (5, 1) [D loss: (-1.4015)(R -2.3708, F 0.9365, G 0.0033)] [G loss: -1.4722]\n",
      "8321 (5, 1) [D loss: (-1.0563)(R -2.2892, F 1.1977, G 0.0035)] [G loss: -1.7987]\n",
      "8322 (5, 1) [D loss: (-1.3005)(R -2.3296, F 1.0003, G 0.0029)] [G loss: -1.7256]\n",
      "8323 (5, 1) [D loss: (-0.8046)(R -2.2173, F 1.3759, G 0.0037)] [G loss: -1.4640]\n",
      "8324 (5, 1) [D loss: (-0.6348)(R -1.8599, F 1.1936, G 0.0031)] [G loss: -1.0144]\n",
      "8325 (5, 1) [D loss: (-1.1436)(R -1.8320, F 0.6501, G 0.0038)] [G loss: -1.1921]\n",
      "8326 (5, 1) [D loss: (-0.8697)(R -1.4204, F 0.5172, G 0.0033)] [G loss: -0.7576]\n",
      "8327 (5, 1) [D loss: (-0.8011)(R -1.1401, F 0.3046, G 0.0034)] [G loss: -0.3174]\n",
      "8328 (5, 1) [D loss: (-1.2077)(R -1.2072, F -0.0381, G 0.0038)] [G loss: -0.2713]\n",
      "8329 (5, 1) [D loss: (-0.7416)(R -0.5498, F -0.2383, G 0.0046)] [G loss: 0.2962]\n",
      "8330 (5, 1) [D loss: (-0.7198)(R -0.3525, F -0.4021, G 0.0035)] [G loss: 0.6629]\n",
      "8331 (5, 1) [D loss: (-0.9349)(R 0.1294, F -1.1025, G 0.0038)] [G loss: 1.3871]\n",
      "8332 (5, 1) [D loss: (-1.2585)(R 0.5057, F -1.8087, G 0.0045)] [G loss: 1.7703]\n",
      "8333 (5, 1) [D loss: (-1.2419)(R 0.9301, F -2.2228, G 0.0051)] [G loss: 2.2787]\n",
      "8334 (5, 1) [D loss: (-1.4849)(R 1.4922, F -3.0298, G 0.0053)] [G loss: 3.0636]\n",
      "8335 (5, 1) [D loss: (-0.2718)(R 3.3962, F -3.7405, G 0.0073)] [G loss: 3.8253]\n",
      "8336 (5, 1) [D loss: (-1.2211)(R 3.4816, F -4.7677, G 0.0065)] [G loss: 4.9414]\n",
      "8337 (5, 1) [D loss: (-0.7833)(R 4.2828, F -5.1326, G 0.0067)] [G loss: 4.8507]\n",
      "8338 (5, 1) [D loss: (-1.0085)(R 4.2155, F -5.2758, G 0.0052)] [G loss: 4.8476]\n",
      "8339 (5, 1) [D loss: (-0.8371)(R 4.3845, F -5.2712, G 0.0050)] [G loss: 5.1484]\n",
      "8340 (5, 1) [D loss: (-1.0298)(R 4.0244, F -5.0970, G 0.0043)] [G loss: 4.9958]\n",
      "8341 (5, 1) [D loss: (-0.8330)(R 3.8319, F -4.6991, G 0.0034)] [G loss: 4.5713]\n",
      "8342 (5, 1) [D loss: (-1.1183)(R 3.5342, F -4.6823, G 0.0030)] [G loss: 4.2295]\n",
      "8343 (5, 1) [D loss: (-0.8124)(R 2.6551, F -3.4951, G 0.0028)] [G loss: 3.7763]\n",
      "8344 (5, 1) [D loss: (-0.7047)(R 2.0368, F -2.7685, G 0.0027)] [G loss: 2.9205]\n",
      "8345 (5, 1) [D loss: (-0.9066)(R 1.6332, F -2.5739, G 0.0034)] [G loss: 2.7951]\n",
      "8346 (5, 1) [D loss: (-1.0301)(R 1.7916, F -2.8591, G 0.0037)] [G loss: 2.6841]\n",
      "8347 (5, 1) [D loss: (-1.0596)(R 1.8601, F -2.9562, G 0.0036)] [G loss: 3.1301]\n",
      "8348 (5, 1) [D loss: (-0.7419)(R 2.6233, F -3.3946, G 0.0029)] [G loss: 3.1968]\n",
      "8349 (5, 1) [D loss: (-0.7538)(R 3.3117, F -4.1088, G 0.0043)] [G loss: 4.4915]\n",
      "8350 (5, 1) [D loss: (-1.0611)(R 3.8176, F -4.9271, G 0.0048)] [G loss: 4.9775]\n",
      "8351 (5, 1) [D loss: (-0.7438)(R 5.2220, F -6.0266, G 0.0061)] [G loss: 5.5970]\n",
      "8352 (5, 1) [D loss: (-1.1156)(R 4.7032, F -5.8641, G 0.0045)] [G loss: 5.3705]\n",
      "8353 (5, 1) [D loss: (-1.2209)(R 4.4015, F -5.6611, G 0.0039)] [G loss: 5.2969]\n",
      "8354 (5, 1) [D loss: (-0.9735)(R 3.9644, F -4.9740, G 0.0036)] [G loss: 4.7049]\n",
      "8355 (5, 1) [D loss: (-0.5109)(R 4.1590, F -4.6995, G 0.0030)] [G loss: 4.6566]\n",
      "8356 (5, 1) [D loss: (-0.8064)(R 2.9091, F -3.7365, G 0.0021)] [G loss: 3.4988]\n",
      "8357 (5, 1) [D loss: (-0.8185)(R 1.8804, F -2.7205, G 0.0022)] [G loss: 2.4768]\n",
      "8358 (5, 1) [D loss: (-0.5501)(R 0.6004, F -1.1786, G 0.0028)] [G loss: 1.2799]\n",
      "8359 (5, 1) [D loss: (-0.8622)(R -0.3900, F -0.4978, G 0.0026)] [G loss: 0.4449]\n",
      "8360 (5, 1) [D loss: (-0.7354)(R -0.9749, F 0.2060, G 0.0033)] [G loss: -0.0972]\n",
      "8361 (5, 1) [D loss: (-1.2209)(R -1.6154, F 0.3536, G 0.0041)] [G loss: -0.2728]\n",
      "8362 (5, 1) [D loss: (-1.4221)(R -2.0239, F 0.5674, G 0.0034)] [G loss: -0.6474]\n",
      "8363 (5, 1) [D loss: (-1.1068)(R -1.7520, F 0.6116, G 0.0034)] [G loss: -0.5494]\n",
      "8364 (5, 1) [D loss: (-0.9479)(R -1.5653, F 0.5787, G 0.0039)] [G loss: -0.5489]\n",
      "8365 (5, 1) [D loss: (-1.0739)(R -2.1604, F 1.0528, G 0.0034)] [G loss: -0.9359]\n",
      "8366 (5, 1) [D loss: (-0.8917)(R -1.7200, F 0.7913, G 0.0037)] [G loss: -0.9185]\n",
      "8367 (5, 1) [D loss: (-1.3009)(R -2.0558, F 0.7215, G 0.0033)] [G loss: -0.8196]\n",
      "8368 (5, 1) [D loss: (-0.8594)(R -2.3585, F 1.4620, G 0.0037)] [G loss: -1.6201]\n",
      "8369 (5, 1) [D loss: (-0.8075)(R -2.3500, F 1.5124, G 0.0030)] [G loss: -1.4252]\n",
      "8370 (5, 1) [D loss: (-0.6551)(R -2.2217, F 1.5325, G 0.0034)] [G loss: -1.5549]\n",
      "8371 (5, 1) [D loss: (-0.7428)(R -2.6565, F 1.8733, G 0.0040)] [G loss: -1.8741]\n",
      "8372 (5, 1) [D loss: (-0.9454)(R -2.8612, F 1.8812, G 0.0035)] [G loss: -1.6414]\n",
      "8373 (5, 1) [D loss: (-0.8049)(R -2.7665, F 1.9141, G 0.0048)] [G loss: -1.7773]\n",
      "8374 (5, 1) [D loss: (-1.2075)(R -2.5990, F 1.3553, G 0.0036)] [G loss: -1.4350]\n",
      "8375 (5, 1) [D loss: (-0.8529)(R -2.3405, F 1.4410, G 0.0047)] [G loss: -1.1724]\n",
      "8376 (5, 1) [D loss: (-1.1686)(R -2.1632, F 0.9513, G 0.0043)] [G loss: -0.9544]\n",
      "8377 (5, 1) [D loss: (-0.6068)(R -1.4445, F 0.7999, G 0.0038)] [G loss: -0.6189]\n",
      "8378 (5, 1) [D loss: (-0.5672)(R -1.4392, F 0.8304, G 0.0042)] [G loss: -0.5261]\n",
      "8379 (5, 1) [D loss: (-0.9489)(R -1.6679, F 0.6837, G 0.0035)] [G loss: -0.8375]\n",
      "8380 (5, 1) [D loss: (-0.5385)(R -1.8663, F 1.2974, G 0.0030)] [G loss: -1.6444]\n",
      "8381 (5, 1) [D loss: (-0.5014)(R -2.4026, F 1.8652, G 0.0036)] [G loss: -2.1113]\n",
      "8382 (5, 1) [D loss: (-0.6548)(R -3.1555, F 2.4542, G 0.0047)] [G loss: -2.2342]\n",
      "8383 (5, 1) [D loss: (-0.9229)(R -3.2226, F 2.2722, G 0.0027)] [G loss: -2.2688]\n",
      "8384 (5, 1) [D loss: (-0.7920)(R -3.1206, F 2.2861, G 0.0043)] [G loss: -2.3979]\n",
      "8385 (5, 1) [D loss: (-1.1157)(R -3.4408, F 2.2799, G 0.0045)] [G loss: -2.5581]\n",
      "8386 (5, 1) [D loss: (-0.9059)(R -3.1033, F 2.1712, G 0.0026)] [G loss: -2.2031]\n",
      "8387 (5, 1) [D loss: (-0.8877)(R -2.8102, F 1.8847, G 0.0038)] [G loss: -1.5032]\n",
      "8388 (5, 1) [D loss: (-1.1861)(R -2.3841, F 1.1573, G 0.0041)] [G loss: -1.0971]\n",
      "8389 (5, 1) [D loss: (-0.5008)(R -1.8959, F 1.3593, G 0.0036)] [G loss: -0.9030]\n",
      "8390 (5, 1) [D loss: (-1.0106)(R -1.4013, F 0.3513, G 0.0039)] [G loss: -0.8413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8391 (5, 1) [D loss: (-1.2019)(R -1.5942, F 0.3485, G 0.0044)] [G loss: -0.3412]\n",
      "8392 (5, 1) [D loss: (-0.9797)(R -0.9415, F -0.0771, G 0.0039)] [G loss: -0.0439]\n",
      "8393 (5, 1) [D loss: (-0.7863)(R -0.0402, F -0.7811, G 0.0035)] [G loss: 0.8127]\n",
      "8394 (5, 1) [D loss: (-0.7839)(R 0.2600, F -1.0879, G 0.0044)] [G loss: 0.7595]\n",
      "8395 (5, 1) [D loss: (-0.6063)(R 0.3892, F -1.0309, G 0.0035)] [G loss: 1.0159]\n",
      "8396 (5, 1) [D loss: (-1.0272)(R 0.2894, F -1.3549, G 0.0038)] [G loss: 1.3719]\n",
      "8397 (5, 1) [D loss: (-0.4211)(R 1.1556, F -1.6092, G 0.0033)] [G loss: 1.8275]\n",
      "8398 (5, 1) [D loss: (-0.7321)(R 0.9071, F -1.6752, G 0.0036)] [G loss: 1.9830]\n",
      "8399 (5, 1) [D loss: (-0.7978)(R 0.6119, F -1.4487, G 0.0039)] [G loss: 1.6542]\n",
      "8400 (5, 1) [D loss: (-0.8783)(R 0.2672, F -1.1806, G 0.0035)] [G loss: 1.5627]\n",
      "8401 (5, 1) [D loss: (-1.1819)(R 0.3325, F -1.5502, G 0.0036)] [G loss: 1.7305]\n",
      "8402 (5, 1) [D loss: (-1.5600)(R -0.0386, F -1.5604, G 0.0039)] [G loss: 1.5226]\n",
      "8403 (5, 1) [D loss: (-1.2582)(R 0.1241, F -1.4352, G 0.0053)] [G loss: 1.4518]\n",
      "8404 (5, 1) [D loss: (-0.5847)(R 0.9677, F -1.5975, G 0.0045)] [G loss: 1.8499]\n",
      "8405 (5, 1) [D loss: (-1.0734)(R 0.3297, F -1.4466, G 0.0043)] [G loss: 1.3416]\n",
      "8406 (5, 1) [D loss: (-1.2305)(R 0.1079, F -1.3761, G 0.0038)] [G loss: 1.6588]\n",
      "8407 (5, 1) [D loss: (-0.8298)(R 0.0236, F -0.8892, G 0.0036)] [G loss: 0.8301]\n",
      "8408 (5, 1) [D loss: (-0.5006)(R -0.0356, F -0.4976, G 0.0033)] [G loss: 0.7326]\n",
      "8409 (5, 1) [D loss: (-0.7690)(R -0.4320, F -0.3615, G 0.0024)] [G loss: 0.0550]\n",
      "8410 (5, 1) [D loss: (-0.8492)(R -0.8998, F 0.0206, G 0.0030)] [G loss: -0.1072]\n",
      "8411 (5, 1) [D loss: (-0.9391)(R -0.3435, F -0.6212, G 0.0026)] [G loss: 0.4777]\n",
      "8412 (5, 1) [D loss: (-0.7729)(R -0.4560, F -0.3475, G 0.0031)] [G loss: 0.6189]\n",
      "8413 (5, 1) [D loss: (-1.0887)(R -0.1790, F -0.9399, G 0.0030)] [G loss: 1.3142]\n",
      "8414 (5, 1) [D loss: (-0.8141)(R -0.0670, F -0.7880, G 0.0041)] [G loss: 0.8904]\n",
      "8415 (5, 1) [D loss: (-1.0984)(R 0.3488, F -1.4939, G 0.0047)] [G loss: 1.5576]\n",
      "8416 (5, 1) [D loss: (-1.3323)(R 0.5665, F -1.9457, G 0.0047)] [G loss: 1.6710]\n",
      "8417 (5, 1) [D loss: (-1.2051)(R 1.1307, F -2.3921, G 0.0056)] [G loss: 2.5284]\n",
      "8418 (5, 1) [D loss: (-1.4301)(R 1.3553, F -2.8385, G 0.0053)] [G loss: 2.6573]\n",
      "8419 (5, 1) [D loss: (-1.0351)(R 2.0297, F -3.1241, G 0.0059)] [G loss: 3.0391]\n",
      "8420 (5, 1) [D loss: (-0.6550)(R 2.6344, F -3.3406, G 0.0051)] [G loss: 3.2981]\n",
      "8421 (5, 1) [D loss: (-0.7291)(R 2.6890, F -3.4699, G 0.0052)] [G loss: 3.3490]\n",
      "8422 (5, 1) [D loss: (-0.9396)(R 2.3819, F -3.3550, G 0.0034)] [G loss: 3.0056]\n",
      "8423 (5, 1) [D loss: (-0.0531)(R 2.8275, F -2.9075, G 0.0027)] [G loss: 2.4418]\n",
      "8424 (5, 1) [D loss: (-0.7759)(R 1.3277, F -2.1283, G 0.0025)] [G loss: 2.2337]\n",
      "8425 (5, 1) [D loss: (-0.8619)(R 0.6691, F -1.5533, G 0.0022)] [G loss: 1.2634]\n",
      "8426 (5, 1) [D loss: (-1.0455)(R -0.6712, F -0.3954, G 0.0021)] [G loss: -0.0872]\n",
      "8427 (5, 1) [D loss: (-0.7740)(R -1.1940, F 0.3926, G 0.0027)] [G loss: -0.4876]\n",
      "8428 (5, 1) [D loss: (-0.8421)(R -1.5256, F 0.6480, G 0.0036)] [G loss: -0.6189]\n",
      "8429 (5, 1) [D loss: (-0.9433)(R -1.1978, F 0.2157, G 0.0039)] [G loss: -0.2905]\n",
      "8430 (5, 1) [D loss: (-0.9190)(R -0.7400, F -0.2249, G 0.0046)] [G loss: 0.3866]\n",
      "8431 (5, 1) [D loss: (-0.9750)(R -0.5174, F -0.4962, G 0.0039)] [G loss: 0.7305]\n",
      "8432 (5, 1) [D loss: (-1.0118)(R -0.3146, F -0.7360, G 0.0039)] [G loss: 0.6452]\n",
      "8433 (5, 1) [D loss: (-1.2872)(R -0.8847, F -0.4448, G 0.0042)] [G loss: 0.5936]\n",
      "8434 (5, 1) [D loss: (-1.0665)(R -1.0068, F -0.1085, G 0.0049)] [G loss: 0.0945]\n",
      "8435 (5, 1) [D loss: (-1.0679)(R -1.4012, F 0.2941, G 0.0039)] [G loss: -0.5250]\n",
      "8436 (5, 1) [D loss: (-0.6194)(R -1.8089, F 1.1503, G 0.0039)] [G loss: -1.3563]\n",
      "8437 (5, 1) [D loss: (-1.0188)(R -2.4619, F 1.4104, G 0.0033)] [G loss: -2.2535]\n",
      "8438 (5, 1) [D loss: (-0.8791)(R -3.5143, F 2.5909, G 0.0044)] [G loss: -2.4969]\n",
      "8439 (5, 1) [D loss: (-0.9384)(R -3.8291, F 2.8482, G 0.0042)] [G loss: -2.8205]\n",
      "8440 (5, 1) [D loss: (-1.0972)(R -3.6310, F 2.5028, G 0.0031)] [G loss: -2.7989]\n",
      "8441 (5, 1) [D loss: (-0.7753)(R -3.3439, F 2.5382, G 0.0030)] [G loss: -2.3495]\n",
      "8442 (5, 1) [D loss: (-0.5496)(R -3.2420, F 2.6604, G 0.0032)] [G loss: -2.1733]\n",
      "8443 (5, 1) [D loss: (-0.5020)(R -2.2272, F 1.7006, G 0.0025)] [G loss: -0.7534]\n",
      "8444 (5, 1) [D loss: (-0.8760)(R -0.6153, F -0.2865, G 0.0026)] [G loss: 0.5212]\n",
      "8445 (5, 1) [D loss: (-1.0620)(R 0.3551, F -1.4590, G 0.0042)] [G loss: 1.5709]\n",
      "8446 (5, 1) [D loss: (-1.1269)(R 2.2505, F -3.4439, G 0.0067)] [G loss: 3.5472]\n",
      "8447 (5, 1) [D loss: (-1.1798)(R 3.6995, F -4.9825, G 0.0103)] [G loss: 4.7660]\n",
      "8448 (5, 1) [D loss: (-0.9515)(R 4.4941, F -5.5460, G 0.0100)] [G loss: 5.4733]\n",
      "8449 (5, 1) [D loss: (-0.9998)(R 4.0902, F -5.1580, G 0.0068)] [G loss: 4.8621]\n",
      "8450 (5, 1) [D loss: (-0.7663)(R 3.5657, F -4.3753, G 0.0043)] [G loss: 3.9407]\n",
      "8451 (5, 1) [D loss: (-0.5906)(R 2.5511, F -3.1626, G 0.0021)] [G loss: 3.1271]\n",
      "8452 (5, 1) [D loss: (-0.9877)(R 0.0067, F -1.0114, G 0.0017)] [G loss: 0.7082]\n",
      "8453 (5, 1) [D loss: (-1.3867)(R -1.6796, F 0.2709, G 0.0022)] [G loss: -0.8014]\n",
      "8454 (5, 1) [D loss: (-1.2121)(R -3.0224, F 1.7802, G 0.0030)] [G loss: -2.2916]\n",
      "8455 (5, 1) [D loss: (-1.1268)(R -4.2081, F 3.0411, G 0.0040)] [G loss: -3.5362]\n",
      "8456 (5, 1) [D loss: (-0.8390)(R -4.7612, F 3.8864, G 0.0036)] [G loss: -3.8822]\n",
      "8457 (5, 1) [D loss: (-0.5870)(R -3.9995, F 3.3894, G 0.0023)] [G loss: -3.2170]\n",
      "8458 (5, 1) [D loss: (-1.0027)(R -3.4976, F 2.4730, G 0.0022)] [G loss: -2.3808]\n",
      "8459 (5, 1) [D loss: (-1.1279)(R -2.4118, F 1.2601, G 0.0024)] [G loss: -1.4318]\n",
      "8460 (5, 1) [D loss: (-1.0583)(R -2.0490, F 0.9527, G 0.0038)] [G loss: -0.8088]\n",
      "8461 (5, 1) [D loss: (-1.2801)(R -0.4966, F -0.8209, G 0.0037)] [G loss: 0.7552]\n",
      "8462 (5, 1) [D loss: (-0.8833)(R 0.4770, F -1.4235, G 0.0063)] [G loss: 1.7295]\n",
      "8463 (5, 1) [D loss: (-1.2057)(R 0.9341, F -2.2242, G 0.0084)] [G loss: 2.0530]\n",
      "8464 (5, 1) [D loss: (-0.9164)(R 0.7694, F -1.7548, G 0.0069)] [G loss: 1.8716]\n",
      "8465 (5, 1) [D loss: (-0.9521)(R 0.1965, F -1.1993, G 0.0051)] [G loss: 1.3583]\n",
      "8466 (5, 1) [D loss: (-0.7316)(R -0.3625, F -0.4105, G 0.0041)] [G loss: 0.4697]\n",
      "8467 (5, 1) [D loss: (-0.5756)(R -1.1326, F 0.5278, G 0.0029)] [G loss: -1.0561]\n",
      "8468 (5, 1) [D loss: (-0.7002)(R -2.2261, F 1.4865, G 0.0039)] [G loss: -1.4722]\n",
      "8469 (5, 1) [D loss: (-0.7207)(R -2.5345, F 1.7819, G 0.0032)] [G loss: -1.6457]\n",
      "8470 (5, 1) [D loss: (-0.9596)(R -2.4586, F 1.4648, G 0.0034)] [G loss: -1.4325]\n",
      "8471 (5, 1) [D loss: (-1.1217)(R -2.1159, F 0.9545, G 0.0040)] [G loss: -0.9367]\n",
      "8472 (5, 1) [D loss: (-0.9319)(R -1.4943, F 0.5280, G 0.0034)] [G loss: -0.2366]\n",
      "8473 (5, 1) [D loss: (-0.8861)(R -0.4597, F -0.4649, G 0.0038)] [G loss: 0.6548]\n",
      "8474 (5, 1) [D loss: (-1.3382)(R 0.2445, F -1.6245, G 0.0042)] [G loss: 1.7323]\n",
      "8475 (5, 1) [D loss: (-0.8511)(R 1.5340, F -2.4418, G 0.0057)] [G loss: 2.5432]\n",
      "8476 (5, 1) [D loss: (-1.7418)(R 1.8878, F -3.7183, G 0.0089)] [G loss: 3.2892]\n",
      "8477 (5, 1) [D loss: (-1.2693)(R 2.7505, F -4.1026, G 0.0083)] [G loss: 3.8945]\n",
      "8478 (5, 1) [D loss: (-1.2659)(R 2.3778, F -3.7030, G 0.0059)] [G loss: 3.4318]\n",
      "8479 (5, 1) [D loss: (-1.0031)(R 1.9039, F -2.9486, G 0.0042)] [G loss: 2.9906]\n",
      "8480 (5, 1) [D loss: (-1.1294)(R 0.1786, F -1.3322, G 0.0024)] [G loss: 0.8061]\n",
      "8481 (5, 1) [D loss: (-0.6714)(R -0.9450, F 0.2575, G 0.0016)] [G loss: -0.4091]\n",
      "8482 (5, 1) [D loss: (-0.3222)(R -2.4548, F 2.1172, G 0.0015)] [G loss: -2.0995]\n",
      "8483 (5, 1) [D loss: (-1.0338)(R -3.8682, F 2.8137, G 0.0021)] [G loss: -3.0325]\n",
      "8484 (5, 1) [D loss: (-1.1933)(R -4.8453, F 3.6183, G 0.0034)] [G loss: -3.9726]\n",
      "8485 (5, 1) [D loss: (-1.2360)(R -5.1061, F 3.8353, G 0.0035)] [G loss: -4.3430]\n",
      "8486 (5, 1) [D loss: (-1.6655)(R -4.8895, F 3.1835, G 0.0041)] [G loss: -3.7464]\n",
      "8487 (5, 1) [D loss: (-1.4205)(R -3.9412, F 2.4841, G 0.0037)] [G loss: -2.5214]\n",
      "8488 (5, 1) [D loss: (-0.7112)(R -2.1077, F 1.3619, G 0.0035)] [G loss: -1.1910]\n",
      "8489 (5, 1) [D loss: (-1.1963)(R -0.8235, F -0.4185, G 0.0046)] [G loss: 0.8181]\n",
      "8490 (5, 1) [D loss: (-1.3826)(R 0.2922, F -1.7499, G 0.0075)] [G loss: 1.8216]\n",
      "8491 (5, 1) [D loss: (-1.2438)(R 0.9428, F -2.2569, G 0.0070)] [G loss: 2.3933]\n",
      "8492 (5, 1) [D loss: (-1.0051)(R 1.3545, F -2.4300, G 0.0070)] [G loss: 2.0621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8493 (5, 1) [D loss: (-0.8931)(R -0.4508, F -0.4846, G 0.0042)] [G loss: -0.0306]\n",
      "8494 (5, 1) [D loss: (-0.7121)(R -1.9154, F 1.1719, G 0.0031)] [G loss: -1.3529]\n",
      "8495 (5, 1) [D loss: (-0.5560)(R -3.4863, F 2.8961, G 0.0034)] [G loss: -3.2472]\n",
      "8496 (5, 1) [D loss: (-1.1137)(R -5.6172, F 4.4508, G 0.0053)] [G loss: -5.2777]\n",
      "8497 (5, 1) [D loss: (-0.7711)(R -7.1652, F 6.3012, G 0.0093)] [G loss: -6.6066]\n",
      "8498 (5, 1) [D loss: (-1.8129)(R -7.6782, F 5.7867, G 0.0079)] [G loss: -6.2262]\n",
      "8499 (5, 1) [D loss: (-1.1108)(R -6.8604, F 5.6970, G 0.0053)] [G loss: -5.5547]\n",
      "8500 (5, 1) [D loss: (-0.7309)(R -5.5459, F 4.7882, G 0.0027)] [G loss: -4.6860]\n",
      "8501 (5, 1) [D loss: (-0.6851)(R -4.6572, F 3.9533, G 0.0019)] [G loss: -3.8700]\n",
      "8502 (5, 1) [D loss: (-0.2829)(R -2.7864, F 2.4842, G 0.0019)] [G loss: -1.9338]\n",
      "8503 (5, 1) [D loss: (-0.7363)(R -1.4544, F 0.7023, G 0.0016)] [G loss: -0.2129]\n",
      "8504 (5, 1) [D loss: (-0.7967)(R 0.0070, F -0.8287, G 0.0025)] [G loss: 1.4286]\n",
      "8505 (5, 1) [D loss: (-1.4027)(R 1.6113, F -3.0781, G 0.0064)] [G loss: 3.3083]\n",
      "8506 (5, 1) [D loss: (-0.7483)(R 3.4876, F -4.3348, G 0.0099)] [G loss: 4.3749]\n",
      "8507 (5, 1) [D loss: (-1.1553)(R 3.7260, F -4.9690, G 0.0088)] [G loss: 5.1713]\n",
      "8508 (5, 1) [D loss: (-0.8804)(R 3.8312, F -4.7759, G 0.0064)] [G loss: 4.8473]\n",
      "8509 (5, 1) [D loss: (-1.2014)(R 3.3445, F -4.6000, G 0.0054)] [G loss: 4.1974]\n",
      "8510 (5, 1) [D loss: (-0.5301)(R 2.8908, F -3.4633, G 0.0042)] [G loss: 3.4978]\n",
      "8511 (5, 1) [D loss: (-0.7764)(R 1.7025, F -2.5013, G 0.0022)] [G loss: 2.4209]\n",
      "8512 (5, 1) [D loss: (-1.0412)(R 0.5339, F -1.5969, G 0.0022)] [G loss: 1.1946]\n",
      "8513 (5, 1) [D loss: (-0.6814)(R -0.3266, F -0.3783, G 0.0023)] [G loss: 0.5369]\n",
      "8514 (5, 1) [D loss: (-0.9030)(R -1.5500, F 0.6206, G 0.0026)] [G loss: -0.5426]\n",
      "8515 (5, 1) [D loss: (-0.7628)(R -1.8524, F 1.0623, G 0.0027)] [G loss: -1.0879]\n",
      "8516 (5, 1) [D loss: (-0.5546)(R -2.3939, F 1.8068, G 0.0033)] [G loss: -1.8680]\n",
      "8517 (5, 1) [D loss: (-0.6767)(R -2.5984, F 1.8903, G 0.0031)] [G loss: -1.8397]\n",
      "8518 (5, 1) [D loss: (-0.2362)(R -1.3961, F 1.1313, G 0.0029)] [G loss: -0.8411]\n",
      "8519 (5, 1) [D loss: (-0.5076)(R -1.0841, F 0.5427, G 0.0034)] [G loss: -0.4743]\n",
      "8520 (5, 1) [D loss: (-0.8656)(R -1.0153, F 0.1219, G 0.0028)] [G loss: -0.0719]\n",
      "8521 (5, 1) [D loss: (-0.7482)(R -0.6821, F -0.1016, G 0.0035)] [G loss: 0.1781]\n",
      "8522 (5, 1) [D loss: (-1.0749)(R -0.6621, F -0.4485, G 0.0036)] [G loss: 0.1656]\n",
      "8523 (5, 1) [D loss: (-1.0606)(R -0.4962, F -0.5988, G 0.0034)] [G loss: 0.3349]\n",
      "8524 (5, 1) [D loss: (-0.5033)(R -0.7326, F 0.1925, G 0.0037)] [G loss: 0.0215]\n",
      "8525 (5, 1) [D loss: (-0.5896)(R -1.6180, F 0.9942, G 0.0034)] [G loss: -1.1775]\n",
      "8526 (5, 1) [D loss: (-0.9481)(R -2.4323, F 1.4491, G 0.0035)] [G loss: -1.6358]\n",
      "8527 (5, 1) [D loss: (-0.9562)(R -3.1336, F 2.1332, G 0.0044)] [G loss: -2.3407]\n",
      "8528 (5, 1) [D loss: (-0.7626)(R -3.1855, F 2.3758, G 0.0047)] [G loss: -2.3323]\n",
      "8529 (5, 1) [D loss: (-0.7857)(R -2.9479, F 2.1225, G 0.0040)] [G loss: -1.9577]\n",
      "8530 (5, 1) [D loss: (-0.9363)(R -2.7134, F 1.7271, G 0.0050)] [G loss: -1.8633]\n",
      "8531 (5, 1) [D loss: (-0.9085)(R -1.9731, F 1.0292, G 0.0035)] [G loss: -0.9831]\n",
      "8532 (5, 1) [D loss: (-0.6631)(R -1.2978, F 0.6044, G 0.0030)] [G loss: -0.6403]\n",
      "8533 (5, 1) [D loss: (-0.5217)(R -0.2102, F -0.3549, G 0.0043)] [G loss: 0.5227]\n",
      "8534 (5, 1) [D loss: (-1.3063)(R 0.5267, F -1.8739, G 0.0041)] [G loss: 1.8119]\n",
      "8535 (5, 1) [D loss: (-0.8603)(R 1.6847, F -2.6087, G 0.0064)] [G loss: 2.5397]\n",
      "8536 (5, 1) [D loss: (-1.2406)(R 1.3800, F -2.6836, G 0.0063)] [G loss: 2.5939]\n",
      "8537 (5, 1) [D loss: (-0.9113)(R 2.1148, F -3.0863, G 0.0060)] [G loss: 2.7110]\n",
      "8538 (5, 1) [D loss: (-0.6844)(R 1.2152, F -1.9578, G 0.0058)] [G loss: 1.9120]\n",
      "8539 (5, 1) [D loss: (-0.7368)(R 0.4623, F -1.2325, G 0.0033)] [G loss: 1.2690]\n",
      "8540 (5, 1) [D loss: (-0.8650)(R -0.7263, F -0.1623, G 0.0024)] [G loss: 0.1720]\n",
      "8541 (5, 1) [D loss: (-1.2590)(R -2.5710, F 1.2875, G 0.0024)] [G loss: -1.7402]\n",
      "8542 (5, 1) [D loss: (-1.2220)(R -3.8376, F 2.5794, G 0.0036)] [G loss: -3.0298]\n",
      "8543 (5, 1) [D loss: (-1.3630)(R -5.0301, F 3.6257, G 0.0041)] [G loss: -3.7789]\n",
      "8544 (5, 1) [D loss: (-1.0611)(R -5.4742, F 4.3545, G 0.0059)] [G loss: -4.8028]\n",
      "8545 (5, 1) [D loss: (-0.5708)(R -6.2027, F 5.5682, G 0.0064)] [G loss: -5.5149]\n",
      "8546 (5, 1) [D loss: (-0.8526)(R -5.4497, F 4.5558, G 0.0041)] [G loss: -4.5546]\n",
      "8547 (5, 1) [D loss: (-0.8082)(R -4.6065, F 3.7718, G 0.0026)] [G loss: -3.3888]\n",
      "8548 (5, 1) [D loss: (-0.5632)(R -3.0974, F 2.5146, G 0.0020)] [G loss: -2.5021]\n",
      "8549 (5, 1) [D loss: (-0.5152)(R -1.9506, F 1.4053, G 0.0030)] [G loss: -1.1787]\n",
      "8550 (5, 1) [D loss: (-1.5107)(R -1.1276, F -0.4117, G 0.0029)] [G loss: -0.0887]\n",
      "8551 (5, 1) [D loss: (-1.1743)(R -0.7441, F -0.4818, G 0.0052)] [G loss: 0.8696]\n",
      "8552 (5, 1) [D loss: (-1.0839)(R 0.1833, F -1.3161, G 0.0049)] [G loss: 1.2920]\n",
      "8553 (5, 1) [D loss: (-0.9286)(R -0.0534, F -0.9254, G 0.0050)] [G loss: 1.0194]\n",
      "8554 (5, 1) [D loss: (-0.7720)(R -0.6275, F -0.1833, G 0.0039)] [G loss: 0.3353]\n",
      "8555 (5, 1) [D loss: (-0.8308)(R -0.9504, F 0.0887, G 0.0031)] [G loss: -0.1636]\n",
      "8556 (5, 1) [D loss: (-0.7313)(R -2.0644, F 1.3057, G 0.0027)] [G loss: -1.3777]\n",
      "8557 (5, 1) [D loss: (-1.0082)(R -2.6614, F 1.6246, G 0.0029)] [G loss: -2.0405]\n",
      "8558 (5, 1) [D loss: (-0.7095)(R -3.3469, F 2.6037, G 0.0034)] [G loss: -2.2735]\n",
      "8559 (5, 1) [D loss: (-0.8795)(R -2.6321, F 1.7231, G 0.0030)] [G loss: -1.3667]\n",
      "8560 (5, 1) [D loss: (-0.7440)(R -1.5887, F 0.8169, G 0.0028)] [G loss: -1.0355]\n",
      "8561 (5, 1) [D loss: (-0.8277)(R -1.2593, F 0.3967, G 0.0035)] [G loss: -0.6821]\n",
      "8562 (5, 1) [D loss: (-0.6156)(R -0.1357, F -0.5084, G 0.0029)] [G loss: 0.4478]\n",
      "8563 (5, 1) [D loss: (-1.0159)(R 0.8480, F -1.8949, G 0.0031)] [G loss: 1.9874]\n",
      "8564 (5, 1) [D loss: (-1.3524)(R 1.7086, F -3.1287, G 0.0068)] [G loss: 3.2363]\n",
      "8565 (5, 1) [D loss: (-1.2662)(R 3.0049, F -4.3246, G 0.0053)] [G loss: 4.0553]\n",
      "8566 (5, 1) [D loss: (-0.9455)(R 3.4925, F -4.5026, G 0.0065)] [G loss: 4.3410]\n",
      "8567 (5, 1) [D loss: (-1.0754)(R 3.5543, F -4.6869, G 0.0057)] [G loss: 5.0457]\n",
      "8568 (5, 1) [D loss: (-1.0198)(R 3.3796, F -4.4492, G 0.0050)] [G loss: 3.9505]\n",
      "8569 (5, 1) [D loss: (-0.9743)(R 2.8842, F -3.8916, G 0.0033)] [G loss: 3.6062]\n",
      "8570 (5, 1) [D loss: (-0.4867)(R 2.3859, F -2.9080, G 0.0035)] [G loss: 2.5763]\n",
      "8571 (5, 1) [D loss: (-0.5470)(R 1.9372, F -2.5173, G 0.0033)] [G loss: 2.6332]\n",
      "8572 (5, 1) [D loss: (-1.2421)(R 0.9246, F -2.1951, G 0.0028)] [G loss: 2.0215]\n",
      "8573 (5, 1) [D loss: (-0.5629)(R 0.8240, F -1.4199, G 0.0033)] [G loss: 1.4823]\n",
      "8574 (5, 1) [D loss: (-0.4889)(R 0.3926, F -0.9068, G 0.0025)] [G loss: 0.7902]\n",
      "8575 (5, 1) [D loss: (-0.7312)(R 0.4328, F -1.1903, G 0.0026)] [G loss: 0.7854]\n",
      "8576 (5, 1) [D loss: (-0.4186)(R 1.0313, F -1.4783, G 0.0028)] [G loss: 1.4651]\n",
      "8577 (5, 1) [D loss: (-1.0601)(R 1.4619, F -2.5555, G 0.0033)] [G loss: 2.4014]\n",
      "8578 (5, 1) [D loss: (-0.6171)(R 2.1897, F -2.8475, G 0.0041)] [G loss: 3.0651]\n",
      "8579 (5, 1) [D loss: (-0.5570)(R 2.9472, F -3.5462, G 0.0042)] [G loss: 3.7045]\n",
      "8580 (5, 1) [D loss: (-1.3896)(R 2.7187, F -4.1631, G 0.0055)] [G loss: 3.7858]\n",
      "8581 (5, 1) [D loss: (-1.0589)(R 3.3931, F -4.5068, G 0.0055)] [G loss: 4.0702]\n",
      "8582 (5, 1) [D loss: (-1.0450)(R 3.4500, F -4.5498, G 0.0055)] [G loss: 4.4551]\n",
      "8583 (5, 1) [D loss: (-0.7056)(R 3.7094, F -4.4638, G 0.0049)] [G loss: 4.0746]\n",
      "8584 (5, 1) [D loss: (-0.6777)(R 2.7084, F -3.4345, G 0.0048)] [G loss: 3.2522]\n",
      "8585 (5, 1) [D loss: (-0.6261)(R 1.8938, F -2.5492, G 0.0029)] [G loss: 2.5788]\n",
      "8586 (5, 1) [D loss: (-0.5467)(R 1.0981, F -1.6750, G 0.0030)] [G loss: 1.6860]\n",
      "8587 (5, 1) [D loss: (-0.8044)(R -0.3544, F -0.4796, G 0.0030)] [G loss: 0.4683]\n",
      "8588 (5, 1) [D loss: (-1.0561)(R -0.9565, F -0.1245, G 0.0025)] [G loss: -0.2727]\n",
      "8589 (5, 1) [D loss: (-1.2109)(R -2.3418, F 1.0987, G 0.0032)] [G loss: -1.5359]\n",
      "8590 (5, 1) [D loss: (-1.3269)(R -2.8331, F 1.4683, G 0.0038)] [G loss: -1.7268]\n",
      "8591 (5, 1) [D loss: (-0.6458)(R -2.9375, F 2.2606, G 0.0031)] [G loss: -1.6667]\n",
      "8592 (5, 1) [D loss: (-1.3176)(R -2.9063, F 1.5619, G 0.0027)] [G loss: -1.8700]\n",
      "8593 (5, 1) [D loss: (-0.7635)(R -3.1173, F 2.3231, G 0.0031)] [G loss: -2.1549]\n",
      "8594 (5, 1) [D loss: (-0.7468)(R -2.8788, F 2.0955, G 0.0036)] [G loss: -1.9748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8595 (5, 1) [D loss: (-0.7802)(R -3.1617, F 2.3516, G 0.0030)] [G loss: -2.1664]\n",
      "8596 (5, 1) [D loss: (-0.8294)(R -3.4742, F 2.5975, G 0.0047)] [G loss: -2.3526]\n",
      "8597 (5, 1) [D loss: (-0.9718)(R -3.4917, F 2.4768, G 0.0043)] [G loss: -2.5743]\n",
      "8598 (5, 1) [D loss: (-0.8500)(R -3.7523, F 2.8660, G 0.0036)] [G loss: -3.0501]\n",
      "8599 (5, 1) [D loss: (-0.7995)(R -4.1642, F 3.3192, G 0.0045)] [G loss: -2.8829]\n",
      "8600 (5, 1) [D loss: (-1.2797)(R -4.7422, F 3.4117, G 0.0051)] [G loss: -3.7196]\n",
      "8601 (5, 1) [D loss: (-1.0437)(R -5.0475, F 3.9532, G 0.0051)] [G loss: -4.6002]\n",
      "8602 (5, 1) [D loss: (-1.1462)(R -5.6375, F 4.4398, G 0.0051)] [G loss: -4.6236]\n",
      "8603 (5, 1) [D loss: (-0.9178)(R -5.7471, F 4.7794, G 0.0050)] [G loss: -5.3052]\n",
      "8604 (5, 1) [D loss: (-0.7981)(R -6.4515, F 5.5944, G 0.0059)] [G loss: -6.0967]\n",
      "8605 (5, 1) [D loss: (-0.9818)(R -6.7835, F 5.7543, G 0.0047)] [G loss: -5.9299]\n",
      "8606 (5, 1) [D loss: (-1.1848)(R -6.1721, F 4.9583, G 0.0029)] [G loss: -5.0726]\n",
      "8607 (5, 1) [D loss: (-0.7274)(R -5.6523, F 4.9002, G 0.0025)] [G loss: -4.6864]\n",
      "8608 (5, 1) [D loss: (-0.8221)(R -4.4752, F 3.6286, G 0.0025)] [G loss: -3.6951]\n",
      "8609 (5, 1) [D loss: (-0.8658)(R -3.6296, F 2.7425, G 0.0021)] [G loss: -2.1783]\n",
      "8610 (5, 1) [D loss: (-0.8925)(R -2.4677, F 1.5487, G 0.0027)] [G loss: -1.0963]\n",
      "8611 (5, 1) [D loss: (-0.9814)(R -1.7592, F 0.7466, G 0.0031)] [G loss: -0.5176]\n",
      "8612 (5, 1) [D loss: (-1.0799)(R -0.8719, F -0.2506, G 0.0043)] [G loss: 0.4630]\n",
      "8613 (5, 1) [D loss: (-1.0355)(R -0.0412, F -1.0593, G 0.0065)] [G loss: 1.4727]\n",
      "8614 (5, 1) [D loss: (-1.3078)(R 0.7145, F -2.0925, G 0.0070)] [G loss: 2.1016]\n",
      "8615 (5, 1) [D loss: (-0.8089)(R 1.3789, F -2.2610, G 0.0073)] [G loss: 1.8647]\n",
      "8616 (5, 1) [D loss: (-0.6549)(R 1.1849, F -1.8862, G 0.0046)] [G loss: 2.1490]\n",
      "8617 (5, 1) [D loss: (-1.0735)(R 0.5151, F -1.6361, G 0.0048)] [G loss: 1.2781]\n",
      "8618 (5, 1) [D loss: (-1.0620)(R -0.3408, F -0.7520, G 0.0031)] [G loss: 0.7510]\n",
      "8619 (5, 1) [D loss: (-0.7959)(R -0.4386, F -0.3964, G 0.0039)] [G loss: 0.1027]\n",
      "8620 (5, 1) [D loss: (-0.8065)(R -1.3843, F 0.5530, G 0.0025)] [G loss: -0.8535]\n",
      "8621 (5, 1) [D loss: (-0.6024)(R -1.6424, F 1.0103, G 0.0030)] [G loss: -0.9172]\n",
      "8622 (5, 1) [D loss: (-0.7426)(R -1.5786, F 0.8020, G 0.0034)] [G loss: -0.8338]\n",
      "8623 (5, 1) [D loss: (-0.7637)(R -1.6193, F 0.8207, G 0.0035)] [G loss: -0.6129]\n",
      "8624 (5, 1) [D loss: (-0.6103)(R -1.0296, F 0.3940, G 0.0025)] [G loss: -0.5870]\n",
      "8625 (5, 1) [D loss: (-0.7274)(R -0.5722, F -0.1804, G 0.0025)] [G loss: 0.2333]\n",
      "8626 (5, 1) [D loss: (-1.0529)(R -0.6260, F -0.4616, G 0.0035)] [G loss: 0.4234]\n",
      "8627 (5, 1) [D loss: (-1.0645)(R 0.3636, F -1.4670, G 0.0039)] [G loss: 1.2806]\n",
      "8628 (5, 1) [D loss: (-1.0676)(R 0.7154, F -1.8351, G 0.0052)] [G loss: 1.8291]\n",
      "8629 (5, 1) [D loss: (-0.9624)(R 1.3274, F -2.3473, G 0.0058)] [G loss: 2.4236]\n",
      "8630 (5, 1) [D loss: (-1.0538)(R 1.8493, F -2.9657, G 0.0063)] [G loss: 2.7222]\n",
      "8631 (5, 1) [D loss: (-0.6476)(R 1.1249, F -1.8170, G 0.0045)] [G loss: 1.7949]\n",
      "8632 (5, 1) [D loss: (-0.7171)(R 0.1632, F -0.9179, G 0.0038)] [G loss: 0.7376]\n",
      "8633 (5, 1) [D loss: (-0.9965)(R -1.0931, F 0.0669, G 0.0030)] [G loss: -0.5153]\n",
      "8634 (5, 1) [D loss: (-1.0773)(R -2.6701, F 1.5632, G 0.0030)] [G loss: -1.5729]\n",
      "8635 (5, 1) [D loss: (-0.6946)(R -3.9167, F 3.1833, G 0.0039)] [G loss: -3.0046]\n",
      "8636 (5, 1) [D loss: (-0.8929)(R -5.0726, F 4.1335, G 0.0046)] [G loss: -4.0837]\n",
      "8637 (5, 1) [D loss: (-0.7387)(R -5.8139, F 5.0206, G 0.0055)] [G loss: -5.1053]\n",
      "8638 (5, 1) [D loss: (-0.6158)(R -5.1901, F 4.5436, G 0.0031)] [G loss: -4.0975]\n",
      "8639 (5, 1) [D loss: (-1.0388)(R -4.3812, F 3.3160, G 0.0026)] [G loss: -2.7133]\n",
      "8640 (5, 1) [D loss: (-0.8724)(R -3.0228, F 2.1267, G 0.0024)] [G loss: -1.7277]\n",
      "8641 (5, 1) [D loss: (-0.8585)(R -1.5379, F 0.6544, G 0.0025)] [G loss: -0.6257]\n",
      "8642 (5, 1) [D loss: (-1.2547)(R -0.8048, F -0.4869, G 0.0037)] [G loss: 0.3296]\n",
      "8643 (5, 1) [D loss: (-1.0773)(R 0.4465, F -1.5667, G 0.0043)] [G loss: 1.1900]\n",
      "8644 (5, 1) [D loss: (-0.4670)(R 0.8626, F -1.3875, G 0.0058)] [G loss: 1.6353]\n",
      "8645 (5, 1) [D loss: (-0.9534)(R 0.7767, F -1.7752, G 0.0045)] [G loss: 1.4248]\n",
      "8646 (5, 1) [D loss: (-0.5046)(R 0.7811, F -1.3223, G 0.0037)] [G loss: 1.4770]\n",
      "8647 (5, 1) [D loss: (-1.0936)(R -0.3005, F -0.8309, G 0.0038)] [G loss: 0.7180]\n",
      "8648 (5, 1) [D loss: (-0.7600)(R -0.5545, F -0.2397, G 0.0034)] [G loss: 0.0813]\n",
      "8649 (5, 1) [D loss: (-0.9853)(R -1.1578, F 0.1392, G 0.0033)] [G loss: -0.1871]\n",
      "8650 (5, 1) [D loss: (-0.8296)(R -1.4264, F 0.5703, G 0.0026)] [G loss: -0.7357]\n",
      "8651 (5, 1) [D loss: (-0.9150)(R -2.2855, F 1.3360, G 0.0034)] [G loss: -1.4655]\n",
      "8652 (5, 1) [D loss: (-0.8948)(R -2.9018, F 1.9720, G 0.0035)] [G loss: -1.6462]\n",
      "8653 (5, 1) [D loss: (-1.0132)(R -2.0578, F 1.0083, G 0.0036)] [G loss: -1.0520]\n",
      "8654 (5, 1) [D loss: (-1.0269)(R -1.9137, F 0.8583, G 0.0028)] [G loss: -0.6362]\n",
      "8655 (5, 1) [D loss: (-0.6718)(R -0.9927, F 0.2878, G 0.0033)] [G loss: -0.1722]\n",
      "8656 (5, 1) [D loss: (-0.8120)(R -0.1128, F -0.7265, G 0.0027)] [G loss: 0.5279]\n",
      "8657 (5, 1) [D loss: (-1.0208)(R 0.0132, F -1.0631, G 0.0029)] [G loss: 0.6475]\n",
      "8658 (5, 1) [D loss: (-0.9081)(R 0.0163, F -0.9681, G 0.0044)] [G loss: 0.6225]\n",
      "8659 (5, 1) [D loss: (-0.7680)(R -0.3443, F -0.4616, G 0.0038)] [G loss: 0.0135]\n",
      "8660 (5, 1) [D loss: (-0.9267)(R -1.0642, F 0.1064, G 0.0031)] [G loss: 0.0169]\n",
      "8661 (5, 1) [D loss: (-0.7827)(R -1.5721, F 0.7537, G 0.0036)] [G loss: -0.9366]\n",
      "8662 (5, 1) [D loss: (-0.8369)(R -3.1144, F 2.2428, G 0.0035)] [G loss: -2.6910]\n",
      "8663 (5, 1) [D loss: (-0.7184)(R -3.6035, F 2.8559, G 0.0029)] [G loss: -2.9062]\n",
      "8664 (5, 1) [D loss: (-1.3781)(R -4.3162, F 2.8938, G 0.0044)] [G loss: -3.4740]\n",
      "8665 (5, 1) [D loss: (-0.7767)(R -4.8195, F 4.0030, G 0.0040)] [G loss: -3.8713]\n",
      "8666 (5, 1) [D loss: (-0.9096)(R -4.5009, F 3.5591, G 0.0032)] [G loss: -3.3839]\n",
      "8667 (5, 1) [D loss: (-0.6274)(R -3.8826, F 3.2226, G 0.0033)] [G loss: -3.2656]\n",
      "8668 (5, 1) [D loss: (-0.5791)(R -3.0874, F 2.4794, G 0.0029)] [G loss: -2.0909]\n",
      "8669 (5, 1) [D loss: (-0.5679)(R -1.8311, F 1.2350, G 0.0028)] [G loss: -1.0941]\n",
      "8670 (5, 1) [D loss: (-0.8023)(R -1.1509, F 0.3134, G 0.0035)] [G loss: -0.2736]\n",
      "8671 (5, 1) [D loss: (-0.7443)(R -0.7833, F -0.0110, G 0.0050)] [G loss: 0.0610]\n",
      "8672 (5, 1) [D loss: (-0.7400)(R -0.0518, F -0.7368, G 0.0049)] [G loss: 0.7081]\n",
      "8673 (5, 1) [D loss: (-0.8977)(R -0.3202, F -0.6173, G 0.0040)] [G loss: 0.4932]\n",
      "8674 (5, 1) [D loss: (-0.9753)(R -0.4118, F -0.6024, G 0.0039)] [G loss: 0.4198]\n",
      "8675 (5, 1) [D loss: (-1.0108)(R -0.8107, F -0.2379, G 0.0038)] [G loss: 0.0319]\n",
      "8676 (5, 1) [D loss: (-0.5962)(R -1.3786, F 0.7444, G 0.0038)] [G loss: -0.7460]\n",
      "8677 (5, 1) [D loss: (-1.0052)(R -2.5027, F 1.4630, G 0.0035)] [G loss: -1.7866]\n",
      "8678 (5, 1) [D loss: (-1.3163)(R -3.8136, F 2.4665, G 0.0031)] [G loss: -2.8701]\n",
      "8679 (5, 1) [D loss: (-0.7803)(R -4.4381, F 3.6092, G 0.0049)] [G loss: -3.9945]\n",
      "8680 (5, 1) [D loss: (-1.3553)(R -5.2187, F 3.8236, G 0.0040)] [G loss: -4.0834]\n",
      "8681 (5, 1) [D loss: (-0.6696)(R -4.9086, F 4.2015, G 0.0037)] [G loss: -3.9414]\n",
      "8682 (5, 1) [D loss: (-0.2188)(R -4.5706, F 4.3138, G 0.0038)] [G loss: -4.0747]\n",
      "8683 (5, 1) [D loss: (-0.7041)(R -4.7808, F 4.0432, G 0.0033)] [G loss: -3.7427]\n",
      "8684 (5, 1) [D loss: (-0.7021)(R -3.5039, F 2.7771, G 0.0025)] [G loss: -2.3362]\n",
      "8685 (5, 1) [D loss: (-1.0923)(R -2.9110, F 1.7922, G 0.0026)] [G loss: -1.6502]\n",
      "8686 (5, 1) [D loss: (-1.0196)(R -2.1617, F 1.1147, G 0.0027)] [G loss: -1.1452]\n",
      "8687 (5, 1) [D loss: (-0.8350)(R -1.7563, F 0.8743, G 0.0047)] [G loss: -0.4782]\n",
      "8688 (5, 1) [D loss: (-1.1822)(R -2.1279, F 0.8955, G 0.0050)] [G loss: -0.9492]\n",
      "8689 (5, 1) [D loss: (-0.9358)(R -2.0878, F 1.1019, G 0.0050)] [G loss: -0.8783]\n",
      "8690 (5, 1) [D loss: (-1.3432)(R -2.3421, F 0.9514, G 0.0048)] [G loss: -1.3886]\n",
      "8691 (5, 1) [D loss: (-0.5903)(R -2.4326, F 1.7867, G 0.0056)] [G loss: -1.1877]\n",
      "8692 (5, 1) [D loss: (-0.9123)(R -2.6931, F 1.7463, G 0.0035)] [G loss: -2.2100]\n",
      "8693 (5, 1) [D loss: (-1.1123)(R -3.7155, F 2.5706, G 0.0033)] [G loss: -3.1657]\n",
      "8694 (5, 1) [D loss: (-0.8252)(R -3.7658, F 2.9099, G 0.0031)] [G loss: -2.7551]\n",
      "8695 (5, 1) [D loss: (-0.4258)(R -2.7782, F 2.3153, G 0.0037)] [G loss: -2.2034]\n",
      "8696 (5, 1) [D loss: (-0.8017)(R -2.4370, F 1.6021, G 0.0033)] [G loss: -1.5671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8697 (5, 1) [D loss: (-0.6378)(R -1.1348, F 0.4716, G 0.0025)] [G loss: -0.1700]\n",
      "8698 (5, 1) [D loss: (-1.1907)(R -0.6889, F -0.5322, G 0.0030)] [G loss: 0.7703]\n",
      "8699 (5, 1) [D loss: (-0.8143)(R 0.1811, F -1.0432, G 0.0048)] [G loss: 1.1869]\n",
      "8700 (5, 1) [D loss: (-1.1974)(R 0.7448, F -1.9967, G 0.0054)] [G loss: 1.9159]\n",
      "8701 (5, 1) [D loss: (-0.7077)(R 1.4933, F -2.2546, G 0.0054)] [G loss: 2.4687]\n",
      "8702 (5, 1) [D loss: (-0.7589)(R 1.8714, F -2.6689, G 0.0039)] [G loss: 2.8990]\n",
      "8703 (5, 1) [D loss: (-1.0937)(R 1.6352, F -2.7662, G 0.0037)] [G loss: 2.9546]\n",
      "8704 (5, 1) [D loss: (-0.8239)(R 1.7553, F -2.6265, G 0.0047)] [G loss: 2.6132]\n",
      "8705 (5, 1) [D loss: (-0.5507)(R 1.5636, F -2.1481, G 0.0034)] [G loss: 2.0056]\n",
      "8706 (5, 1) [D loss: (-0.6907)(R 1.0189, F -1.7388, G 0.0029)] [G loss: 1.7302]\n",
      "8707 (5, 1) [D loss: (-1.0426)(R 0.1757, F -1.2474, G 0.0029)] [G loss: 0.6703]\n",
      "8708 (5, 1) [D loss: (-0.8077)(R -0.0368, F -0.8000, G 0.0029)] [G loss: 0.8270]\n",
      "8709 (5, 1) [D loss: (-0.5518)(R 0.0993, F -0.6784, G 0.0027)] [G loss: 0.9393]\n",
      "8710 (5, 1) [D loss: (-0.9829)(R -0.0316, F -0.9875, G 0.0036)] [G loss: 0.6757]\n",
      "8711 (5, 1) [D loss: (-0.5436)(R -0.3156, F -0.2595, G 0.0031)] [G loss: 0.5554]\n",
      "8712 (5, 1) [D loss: (-1.0829)(R -0.2844, F -0.8289, G 0.0030)] [G loss: 0.5442]\n",
      "8713 (5, 1) [D loss: (-0.8239)(R -0.1368, F -0.7235, G 0.0036)] [G loss: 0.4563]\n",
      "8714 (5, 1) [D loss: (-0.7959)(R -0.1420, F -0.6919, G 0.0038)] [G loss: 0.5870]\n",
      "8715 (5, 1) [D loss: (-1.0000)(R -0.2434, F -0.7929, G 0.0036)] [G loss: 0.4544]\n",
      "8716 (5, 1) [D loss: (-1.0291)(R -0.4788, F -0.5823, G 0.0032)] [G loss: 0.7502]\n",
      "8717 (5, 1) [D loss: (-1.2295)(R -0.7541, F -0.5190, G 0.0044)] [G loss: 0.3852]\n",
      "8718 (5, 1) [D loss: (-0.8053)(R -1.0277, F 0.1865, G 0.0036)] [G loss: -0.2688]\n",
      "8719 (5, 1) [D loss: (-0.5565)(R -1.3925, F 0.8014, G 0.0034)] [G loss: -0.6315]\n",
      "8720 (5, 1) [D loss: (-0.7194)(R -1.9200, F 1.1678, G 0.0033)] [G loss: -1.4545]\n",
      "8721 (5, 1) [D loss: (-1.2181)(R -3.3049, F 2.0602, G 0.0027)] [G loss: -2.0618]\n",
      "8722 (5, 1) [D loss: (-1.0297)(R -4.5730, F 3.5003, G 0.0043)] [G loss: -3.8837]\n",
      "8723 (5, 1) [D loss: (-1.0446)(R -5.3697, F 4.2888, G 0.0036)] [G loss: -4.1044]\n",
      "8724 (5, 1) [D loss: (-1.0418)(R -5.5750, F 4.4917, G 0.0041)] [G loss: -4.6105]\n",
      "8725 (5, 1) [D loss: (-1.2222)(R -5.7369, F 4.4847, G 0.0030)] [G loss: -4.5311]\n",
      "8726 (5, 1) [D loss: (-0.7238)(R -4.9880, F 4.2321, G 0.0032)] [G loss: -4.4415]\n",
      "8727 (5, 1) [D loss: (-0.6752)(R -4.9818, F 4.2701, G 0.0036)] [G loss: -4.0678]\n",
      "8728 (5, 1) [D loss: (-1.0440)(R -4.4282, F 3.3499, G 0.0034)] [G loss: -3.3454]\n",
      "8729 (5, 1) [D loss: (-0.5765)(R -3.3702, F 2.7642, G 0.0030)] [G loss: -2.1154]\n",
      "8730 (5, 1) [D loss: (-0.8172)(R -2.4817, F 1.6313, G 0.0033)] [G loss: -1.0730]\n",
      "8731 (5, 1) [D loss: (-1.4203)(R -2.3438, F 0.8651, G 0.0058)] [G loss: -1.1508]\n",
      "8732 (5, 1) [D loss: (-1.0629)(R -1.4599, F 0.3535, G 0.0043)] [G loss: -0.4320]\n",
      "8733 (5, 1) [D loss: (-1.0763)(R -1.0793, F -0.0497, G 0.0053)] [G loss: -0.3414]\n",
      "8734 (5, 1) [D loss: (-0.7123)(R -1.4018, F 0.6479, G 0.0042)] [G loss: -0.4089]\n",
      "8735 (5, 1) [D loss: (-0.5485)(R -2.1383, F 1.5479, G 0.0042)] [G loss: -1.6119]\n",
      "8736 (5, 1) [D loss: (-0.9496)(R -3.4597, F 2.4751, G 0.0035)] [G loss: -2.8708]\n",
      "8737 (5, 1) [D loss: (-0.9173)(R -4.0811, F 3.1346, G 0.0029)] [G loss: -3.4155]\n",
      "8738 (5, 1) [D loss: (-1.2323)(R -4.9633, F 3.6945, G 0.0037)] [G loss: -3.8842]\n",
      "8739 (5, 1) [D loss: (-1.0148)(R -4.9312, F 3.8764, G 0.0040)] [G loss: -3.8505]\n",
      "8740 (5, 1) [D loss: (-1.1241)(R -4.5965, F 3.4388, G 0.0034)] [G loss: -3.5318]\n",
      "8741 (5, 1) [D loss: (-1.2338)(R -4.1277, F 2.8620, G 0.0032)] [G loss: -2.9538]\n",
      "8742 (5, 1) [D loss: (-0.7251)(R -2.9664, F 2.2075, G 0.0034)] [G loss: -2.1171]\n",
      "8743 (5, 1) [D loss: (-1.2389)(R -2.4571, F 1.1911, G 0.0027)] [G loss: -1.4508]\n",
      "8744 (5, 1) [D loss: (-0.7615)(R -2.0642, F 1.2668, G 0.0036)] [G loss: -0.8663]\n",
      "8745 (5, 1) [D loss: (-1.0291)(R -1.2600, F 0.1964, G 0.0035)] [G loss: -0.3451]\n",
      "8746 (5, 1) [D loss: (-0.9457)(R -0.8452, F -0.1358, G 0.0035)] [G loss: 0.2729]\n",
      "8747 (5, 1) [D loss: (-0.5343)(R -0.9816, F 0.4087, G 0.0039)] [G loss: -0.0701]\n",
      "8748 (5, 1) [D loss: (-0.8999)(R -1.5188, F 0.5900, G 0.0029)] [G loss: -0.8438]\n",
      "8749 (5, 1) [D loss: (-0.5251)(R -2.4178, F 1.8634, G 0.0029)] [G loss: -2.0400]\n",
      "8750 (5, 1) [D loss: (-1.0709)(R -3.8775, F 2.7759, G 0.0031)] [G loss: -3.0009]\n",
      "8751 (5, 1) [D loss: (-0.8337)(R -4.1436, F 3.2736, G 0.0036)] [G loss: -3.3686]\n",
      "8752 (5, 1) [D loss: (-1.4092)(R -5.7308, F 4.2730, G 0.0049)] [G loss: -4.6592]\n",
      "8753 (5, 1) [D loss: (-0.7591)(R -5.6303, F 4.8378, G 0.0033)] [G loss: -4.6307]\n",
      "8754 (5, 1) [D loss: (-0.6953)(R -4.7523, F 4.0287, G 0.0028)] [G loss: -3.9762]\n",
      "8755 (5, 1) [D loss: (-0.4985)(R -4.0356, F 3.5047, G 0.0032)] [G loss: -2.8743]\n",
      "8756 (5, 1) [D loss: (-0.4696)(R -3.0997, F 2.6007, G 0.0029)] [G loss: -2.2061]\n",
      "8757 (5, 1) [D loss: (-1.1134)(R -2.8804, F 1.7344, G 0.0033)] [G loss: -1.6041]\n",
      "8758 (5, 1) [D loss: (-0.7148)(R -1.8310, F 1.0769, G 0.0039)] [G loss: -0.7012]\n",
      "8759 (5, 1) [D loss: (-0.8954)(R -1.2551, F 0.3110, G 0.0049)] [G loss: -0.0182]\n",
      "8760 (5, 1) [D loss: (-0.8931)(R -0.8012, F -0.1495, G 0.0058)] [G loss: 0.1667]\n",
      "8761 (5, 1) [D loss: (-0.8059)(R -0.2153, F -0.6494, G 0.0059)] [G loss: 0.8057]\n",
      "8762 (5, 1) [D loss: (-0.8164)(R -0.2575, F -0.5995, G 0.0041)] [G loss: 0.8236]\n",
      "8763 (5, 1) [D loss: (-0.4128)(R -0.1200, F -0.3372, G 0.0044)] [G loss: 0.4457]\n",
      "8764 (5, 1) [D loss: (-1.1644)(R -1.5805, F 0.3778, G 0.0038)] [G loss: -0.3185]\n",
      "8765 (5, 1) [D loss: (-0.8684)(R -1.7872, F 0.8873, G 0.0032)] [G loss: -0.7854]\n",
      "8766 (5, 1) [D loss: (-1.1893)(R -2.4752, F 1.2503, G 0.0036)] [G loss: -1.7411]\n",
      "8767 (5, 1) [D loss: (-0.5553)(R -2.5777, F 1.9925, G 0.0030)] [G loss: -1.6429]\n",
      "8768 (5, 1) [D loss: (-1.0319)(R -2.2981, F 1.2367, G 0.0030)] [G loss: -1.5102]\n",
      "8769 (5, 1) [D loss: (-1.0178)(R -1.7903, F 0.7338, G 0.0039)] [G loss: -0.5375]\n",
      "8770 (5, 1) [D loss: (-0.8465)(R -1.3506, F 0.4704, G 0.0034)] [G loss: -0.2688]\n",
      "8771 (5, 1) [D loss: (-0.9108)(R -0.5620, F -0.3899, G 0.0041)] [G loss: 0.2960]\n",
      "8772 (5, 1) [D loss: (-0.9126)(R 0.0236, F -0.9723, G 0.0036)] [G loss: 0.9596]\n",
      "8773 (5, 1) [D loss: (-1.2466)(R -0.0191, F -1.2651, G 0.0038)] [G loss: 1.1382]\n",
      "8774 (5, 1) [D loss: (-0.6367)(R 0.8541, F -1.5450, G 0.0054)] [G loss: 1.8374]\n",
      "8775 (5, 1) [D loss: (-1.3112)(R 0.3009, F -1.6499, G 0.0038)] [G loss: 1.4799]\n",
      "8776 (5, 1) [D loss: (-0.9226)(R 0.1001, F -1.0556, G 0.0033)] [G loss: 1.0811]\n",
      "8777 (5, 1) [D loss: (-1.0312)(R -0.5881, F -0.4721, G 0.0029)] [G loss: 0.2969]\n",
      "8778 (5, 1) [D loss: (-0.8611)(R -1.6227, F 0.7326, G 0.0029)] [G loss: -0.8360]\n",
      "8779 (5, 1) [D loss: (-0.4162)(R -2.5314, F 2.0822, G 0.0033)] [G loss: -1.9008]\n",
      "8780 (5, 1) [D loss: (-0.8560)(R -3.6709, F 2.7773, G 0.0038)] [G loss: -2.9687]\n",
      "8781 (5, 1) [D loss: (-0.7170)(R -4.2954, F 3.5398, G 0.0039)] [G loss: -3.3129]\n",
      "8782 (5, 1) [D loss: (-0.7422)(R -4.0426, F 3.2638, G 0.0037)] [G loss: -3.3576]\n",
      "8783 (5, 1) [D loss: (-0.6806)(R -3.2565, F 2.5471, G 0.0029)] [G loss: -2.5479]\n",
      "8784 (5, 1) [D loss: (-0.9615)(R -2.7602, F 1.7722, G 0.0027)] [G loss: -1.9776]\n",
      "8785 (5, 1) [D loss: (-0.5812)(R -1.7662, F 1.1630, G 0.0022)] [G loss: -0.5216]\n",
      "8786 (5, 1) [D loss: (-0.6059)(R -0.8772, F 0.2371, G 0.0034)] [G loss: -0.0843]\n",
      "8787 (5, 1) [D loss: (-0.5271)(R -0.2668, F -0.2974, G 0.0037)] [G loss: 0.5260]\n",
      "8788 (5, 1) [D loss: (-0.9607)(R 0.4032, F -1.4130, G 0.0049)] [G loss: 1.5442]\n",
      "8789 (5, 1) [D loss: (-0.7820)(R 1.0278, F -1.8681, G 0.0058)] [G loss: 1.7669]\n",
      "8790 (5, 1) [D loss: (-0.8560)(R 1.5268, F -2.4310, G 0.0048)] [G loss: 2.3906]\n",
      "8791 (5, 1) [D loss: (-1.1589)(R 1.1223, F -2.3353, G 0.0054)] [G loss: 1.8964]\n",
      "8792 (5, 1) [D loss: (-0.9813)(R 0.7843, F -1.8061, G 0.0041)] [G loss: 1.2925]\n",
      "8793 (5, 1) [D loss: (-0.7094)(R 0.8369, F -1.5766, G 0.0030)] [G loss: 1.3147]\n",
      "8794 (5, 1) [D loss: (-0.7623)(R 0.2396, F -1.0284, G 0.0027)] [G loss: 1.0020]\n",
      "8795 (5, 1) [D loss: (-0.9236)(R 0.0673, F -1.0210, G 0.0030)] [G loss: 0.8223]\n",
      "8796 (5, 1) [D loss: (-0.9581)(R -0.4057, F -0.5803, G 0.0028)] [G loss: 0.4915]\n",
      "8797 (5, 1) [D loss: (-0.9707)(R -0.5331, F -0.4719, G 0.0034)] [G loss: 0.3164]\n",
      "8798 (5, 1) [D loss: (-1.2235)(R -1.0231, F -0.2280, G 0.0028)] [G loss: 0.1344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8799 (5, 1) [D loss: (-0.7039)(R -1.2565, F 0.5194, G 0.0033)] [G loss: -0.2092]\n",
      "8800 (5, 1) [D loss: (-0.5947)(R -0.4421, F -0.1832, G 0.0031)] [G loss: -0.0263]\n",
      "8801 (5, 1) [D loss: (-1.0225)(R -0.5797, F -0.4770, G 0.0034)] [G loss: 0.5262]\n",
      "8802 (5, 1) [D loss: (-0.9688)(R -0.0202, F -0.9831, G 0.0034)] [G loss: 0.7442]\n",
      "8803 (5, 1) [D loss: (-1.0012)(R -0.5396, F -0.4947, G 0.0033)] [G loss: 0.3670]\n",
      "8804 (5, 1) [D loss: (-0.8225)(R -0.7224, F -0.1323, G 0.0032)] [G loss: 0.3108]\n",
      "8805 (5, 1) [D loss: (-1.1821)(R -1.2111, F -0.0023, G 0.0031)] [G loss: -0.1005]\n",
      "8806 (5, 1) [D loss: (-0.5474)(R -1.3271, F 0.7465, G 0.0033)] [G loss: -0.8197]\n",
      "8807 (5, 1) [D loss: (-0.9580)(R -2.5327, F 1.5338, G 0.0041)] [G loss: -1.6900]\n",
      "8808 (5, 1) [D loss: (-0.6944)(R -2.9650, F 2.2359, G 0.0035)] [G loss: -2.4107]\n",
      "8809 (5, 1) [D loss: (-1.0868)(R -4.1041, F 2.9752, G 0.0042)] [G loss: -2.8464]\n",
      "8810 (5, 1) [D loss: (-0.9534)(R -4.5755, F 3.5761, G 0.0046)] [G loss: -3.4573]\n",
      "8811 (5, 1) [D loss: (-0.8005)(R -4.7593, F 3.9186, G 0.0040)] [G loss: -3.7941]\n",
      "8812 (5, 1) [D loss: (-1.1059)(R -4.4081, F 3.2684, G 0.0034)] [G loss: -3.1974]\n",
      "8813 (5, 1) [D loss: (-0.6501)(R -4.2787, F 3.5901, G 0.0038)] [G loss: -3.3367]\n",
      "8814 (5, 1) [D loss: (-0.5184)(R -3.4506, F 2.9065, G 0.0026)] [G loss: -2.5324]\n",
      "8815 (5, 1) [D loss: (-0.7769)(R -3.3084, F 2.5017, G 0.0030)] [G loss: -2.2502]\n",
      "8816 (5, 1) [D loss: (-0.9755)(R -2.8555, F 1.8487, G 0.0031)] [G loss: -1.5178]\n",
      "8817 (5, 1) [D loss: (-0.7135)(R -2.0083, F 1.2592, G 0.0036)] [G loss: -1.1376]\n",
      "8818 (5, 1) [D loss: (-0.9075)(R -1.5393, F 0.5924, G 0.0039)] [G loss: -0.3790]\n",
      "8819 (5, 1) [D loss: (-0.8755)(R -0.9436, F 0.0304, G 0.0038)] [G loss: -0.1928]\n",
      "8820 (5, 1) [D loss: (-0.7515)(R -1.3640, F 0.5816, G 0.0031)] [G loss: -0.4371]\n",
      "8821 (5, 1) [D loss: (-0.8324)(R -1.1717, F 0.3051, G 0.0034)] [G loss: -0.2908]\n",
      "8822 (5, 1) [D loss: (-0.8345)(R -1.6827, F 0.8093, G 0.0039)] [G loss: -0.9860]\n",
      "8823 (5, 1) [D loss: (-1.1137)(R -2.3369, F 1.1826, G 0.0041)] [G loss: -1.3878]\n",
      "8824 (5, 1) [D loss: (-0.9413)(R -2.9100, F 1.9330, G 0.0036)] [G loss: -2.0486]\n",
      "8825 (5, 1) [D loss: (-0.9502)(R -2.8241, F 1.8404, G 0.0033)] [G loss: -2.0079]\n",
      "8826 (5, 1) [D loss: (-0.6457)(R -3.2621, F 2.5859, G 0.0030)] [G loss: -2.2372]\n",
      "8827 (5, 1) [D loss: (-0.4783)(R -3.1882, F 2.6784, G 0.0031)] [G loss: -2.3972]\n",
      "8828 (5, 1) [D loss: (-0.8861)(R -2.9093, F 1.9915, G 0.0032)] [G loss: -2.2433]\n",
      "8829 (5, 1) [D loss: (-0.8697)(R -2.9645, F 2.0671, G 0.0028)] [G loss: -1.9355]\n",
      "8830 (5, 1) [D loss: (-0.9542)(R -2.2593, F 1.2682, G 0.0037)] [G loss: -1.2544]\n",
      "8831 (5, 1) [D loss: (-0.9872)(R -2.4728, F 1.4456, G 0.0040)] [G loss: -1.3295]\n",
      "8832 (5, 1) [D loss: (-0.5629)(R -2.1535, F 1.5513, G 0.0039)] [G loss: -1.4568]\n",
      "8833 (5, 1) [D loss: (-1.3406)(R -2.4929, F 1.1168, G 0.0036)] [G loss: -1.6130]\n",
      "8834 (5, 1) [D loss: (-1.1913)(R -3.4979, F 2.2685, G 0.0038)] [G loss: -2.8449]\n",
      "8835 (5, 1) [D loss: (-0.9951)(R -4.5410, F 3.5079, G 0.0038)] [G loss: -3.6671]\n",
      "8836 (5, 1) [D loss: (-0.9670)(R -5.3505, F 4.3431, G 0.0040)] [G loss: -4.1499]\n",
      "8837 (5, 1) [D loss: (-1.0639)(R -5.6686, F 4.5551, G 0.0050)] [G loss: -4.5649]\n",
      "8838 (5, 1) [D loss: (-1.0157)(R -5.2302, F 4.1759, G 0.0039)] [G loss: -4.6919]\n",
      "8839 (5, 1) [D loss: (-1.0375)(R -4.6304, F 3.5678, G 0.0025)] [G loss: -3.3127]\n",
      "8840 (5, 1) [D loss: (-0.4932)(R -3.6927, F 3.1743, G 0.0025)] [G loss: -2.3693]\n",
      "8841 (5, 1) [D loss: (-0.9018)(R -2.4602, F 1.5345, G 0.0024)] [G loss: -1.6489]\n",
      "8842 (5, 1) [D loss: (-0.7289)(R -0.9584, F 0.1991, G 0.0030)] [G loss: -0.0578]\n",
      "8843 (5, 1) [D loss: (-0.7493)(R 0.0927, F -0.8879, G 0.0046)] [G loss: 1.1737]\n",
      "8844 (5, 1) [D loss: (-1.1651)(R 0.9727, F -2.1938, G 0.0056)] [G loss: 2.2821]\n",
      "8845 (5, 1) [D loss: (-0.9222)(R 1.8917, F -2.8713, G 0.0057)] [G loss: 2.6524]\n",
      "8846 (5, 1) [D loss: (-1.1138)(R 1.5581, F -2.7276, G 0.0056)] [G loss: 2.8394]\n",
      "8847 (5, 1) [D loss: (-1.0570)(R 1.0390, F -2.1272, G 0.0031)] [G loss: 1.7487]\n",
      "8848 (5, 1) [D loss: (-1.0139)(R -0.1979, F -0.8485, G 0.0032)] [G loss: 0.8788]\n",
      "8849 (5, 1) [D loss: (-0.6752)(R -0.6879, F -0.0157, G 0.0028)] [G loss: -0.2005]\n",
      "8850 (5, 1) [D loss: (-0.6900)(R -1.4483, F 0.7359, G 0.0022)] [G loss: -0.7027]\n",
      "8851 (5, 1) [D loss: (-1.1308)(R -2.2676, F 1.1095, G 0.0027)] [G loss: -1.2202]\n",
      "8852 (5, 1) [D loss: (-0.8665)(R -2.8756, F 1.9739, G 0.0035)] [G loss: -1.9489]\n",
      "8853 (5, 1) [D loss: (-0.6564)(R -2.9561, F 2.2633, G 0.0036)] [G loss: -2.2723]\n",
      "8854 (5, 1) [D loss: (-0.6746)(R -2.7741, F 2.0732, G 0.0026)] [G loss: -2.4244]\n",
      "8855 (5, 1) [D loss: (-0.3325)(R -2.5016, F 2.1388, G 0.0030)] [G loss: -2.1771]\n",
      "8856 (5, 1) [D loss: (-0.6591)(R -2.9297, F 2.2483, G 0.0022)] [G loss: -2.5251]\n",
      "8857 (5, 1) [D loss: (-0.9124)(R -2.9051, F 1.9650, G 0.0028)] [G loss: -2.0257]\n",
      "8858 (5, 1) [D loss: (-0.9970)(R -2.6758, F 1.6471, G 0.0032)] [G loss: -1.7935]\n",
      "8859 (5, 1) [D loss: (-0.7058)(R -2.7942, F 2.0513, G 0.0037)] [G loss: -2.0363]\n",
      "8860 (5, 1) [D loss: (-0.8339)(R -2.5665, F 1.6958, G 0.0037)] [G loss: -1.5652]\n",
      "8861 (5, 1) [D loss: (-1.1256)(R -2.5694, F 1.3955, G 0.0048)] [G loss: -1.7349]\n",
      "8862 (5, 1) [D loss: (-0.9854)(R -2.3757, F 1.3507, G 0.0040)] [G loss: -1.1819]\n",
      "8863 (5, 1) [D loss: (-0.5722)(R -2.0732, F 1.4536, G 0.0047)] [G loss: -1.4922]\n",
      "8864 (5, 1) [D loss: (-0.7173)(R -2.3025, F 1.5344, G 0.0051)] [G loss: -1.7889]\n",
      "8865 (5, 1) [D loss: (-1.0479)(R -2.6633, F 1.5708, G 0.0044)] [G loss: -1.9604]\n",
      "8866 (5, 1) [D loss: (-0.6837)(R -2.9518, F 2.2302, G 0.0038)] [G loss: -2.0693]\n",
      "8867 (5, 1) [D loss: (-0.9867)(R -2.9145, F 1.8833, G 0.0045)] [G loss: -1.9315]\n",
      "8868 (5, 1) [D loss: (-0.8812)(R -2.5113, F 1.5944, G 0.0036)] [G loss: -1.6076]\n",
      "8869 (5, 1) [D loss: (-0.8395)(R -2.2647, F 1.3948, G 0.0030)] [G loss: -1.3022]\n",
      "8870 (5, 1) [D loss: (-0.7632)(R -1.6449, F 0.8539, G 0.0028)] [G loss: -1.0050]\n",
      "8871 (5, 1) [D loss: (-0.4092)(R -1.2954, F 0.8572, G 0.0029)] [G loss: -0.4099]\n",
      "8872 (5, 1) [D loss: (-1.1591)(R -1.1956, F 0.0059, G 0.0031)] [G loss: 0.0349]\n",
      "8873 (5, 1) [D loss: (-1.2636)(R -0.7529, F -0.5563, G 0.0046)] [G loss: 0.5999]\n",
      "8874 (5, 1) [D loss: (-1.1152)(R -0.3064, F -0.8506, G 0.0042)] [G loss: 0.5256]\n",
      "8875 (5, 1) [D loss: (-0.7944)(R -1.0066, F 0.1753, G 0.0037)] [G loss: 0.0474]\n",
      "8876 (5, 1) [D loss: (-0.7535)(R -1.4826, F 0.6913, G 0.0038)] [G loss: -0.8053]\n",
      "8877 (5, 1) [D loss: (-0.7739)(R -2.3601, F 1.5580, G 0.0028)] [G loss: -1.8064]\n",
      "8878 (5, 1) [D loss: (-0.6698)(R -3.0011, F 2.3067, G 0.0025)] [G loss: -2.2919]\n",
      "8879 (5, 1) [D loss: (-0.4919)(R -3.1455, F 2.6217, G 0.0032)] [G loss: -2.2437]\n",
      "8880 (5, 1) [D loss: (-0.9023)(R -3.5070, F 2.5742, G 0.0030)] [G loss: -2.1282]\n",
      "8881 (5, 1) [D loss: (-0.6384)(R -2.7176, F 2.0569, G 0.0022)] [G loss: -1.7030]\n",
      "8882 (5, 1) [D loss: (-0.8768)(R -1.9655, F 1.0586, G 0.0030)] [G loss: -0.9641]\n",
      "8883 (5, 1) [D loss: (-1.2311)(R -1.8106, F 0.5349, G 0.0045)] [G loss: -0.7756]\n",
      "8884 (5, 1) [D loss: (-1.2612)(R -1.2098, F -0.0980, G 0.0047)] [G loss: -0.1496]\n",
      "8885 (5, 1) [D loss: (-1.1078)(R -0.7386, F -0.4370, G 0.0068)] [G loss: 0.6320]\n",
      "8886 (5, 1) [D loss: (-0.8207)(R -0.5794, F -0.3092, G 0.0068)] [G loss: 0.4964]\n",
      "8887 (5, 1) [D loss: (-0.5885)(R -0.5818, F -0.0690, G 0.0062)] [G loss: -0.0984]\n",
      "8888 (5, 1) [D loss: (-0.6226)(R -1.4818, F 0.8228, G 0.0036)] [G loss: -0.8240]\n",
      "8889 (5, 1) [D loss: (-1.0682)(R -2.8537, F 1.7534, G 0.0032)] [G loss: -2.1715]\n",
      "8890 (5, 1) [D loss: (-0.6754)(R -3.8780, F 3.1634, G 0.0039)] [G loss: -3.0709]\n",
      "8891 (5, 1) [D loss: (-0.6656)(R -3.8097, F 3.1051, G 0.0039)] [G loss: -3.1539]\n",
      "8892 (5, 1) [D loss: (-1.0952)(R -4.5645, F 3.4241, G 0.0045)] [G loss: -3.1612]\n",
      "8893 (5, 1) [D loss: (-0.9515)(R -4.1173, F 3.1189, G 0.0047)] [G loss: -3.3028]\n",
      "8894 (5, 1) [D loss: (-1.1303)(R -4.0480, F 2.8805, G 0.0037)] [G loss: -3.0796]\n",
      "8895 (5, 1) [D loss: (-1.0427)(R -4.1532, F 3.0759, G 0.0035)] [G loss: -3.2245]\n",
      "8896 (5, 1) [D loss: (-0.9861)(R -3.8798, F 2.8702, G 0.0024)] [G loss: -3.0942]\n",
      "8897 (5, 1) [D loss: (-0.4649)(R -3.6402, F 3.1522, G 0.0023)] [G loss: -2.7524]\n",
      "8898 (5, 1) [D loss: (-0.6710)(R -3.1111, F 2.4203, G 0.0020)] [G loss: -2.2570]\n",
      "8899 (5, 1) [D loss: (-1.0716)(R -2.5528, F 1.4562, G 0.0025)] [G loss: -1.5331]\n",
      "8900 (5, 1) [D loss: (-0.9944)(R -1.9338, F 0.9019, G 0.0037)] [G loss: -0.8298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8901 (5, 1) [D loss: (-0.7436)(R -0.9711, F 0.1716, G 0.0056)] [G loss: 0.0741]\n",
      "8902 (5, 1) [D loss: (-0.8657)(R 0.2152, F -1.1565, G 0.0076)] [G loss: 1.4143]\n",
      "8903 (5, 1) [D loss: (-1.2130)(R 0.5190, F -1.8168, G 0.0085)] [G loss: 1.9327]\n",
      "8904 (5, 1) [D loss: (-0.6880)(R 0.8892, F -1.6446, G 0.0067)] [G loss: 1.8419]\n",
      "8905 (5, 1) [D loss: (-0.6312)(R 0.5201, F -1.2083, G 0.0057)] [G loss: 1.1189]\n",
      "8906 (5, 1) [D loss: (-0.3433)(R -0.1883, F -0.1903, G 0.0035)] [G loss: 0.1295]\n",
      "8907 (5, 1) [D loss: (-0.7128)(R -1.2660, F 0.5327, G 0.0021)] [G loss: -0.8317]\n",
      "8908 (5, 1) [D loss: (-0.5488)(R -1.8982, F 1.3287, G 0.0021)] [G loss: -1.5081]\n",
      "8909 (5, 1) [D loss: (-0.7255)(R -2.8635, F 2.1169, G 0.0021)] [G loss: -2.1105]\n",
      "8910 (5, 1) [D loss: (-0.5196)(R -3.0314, F 2.4826, G 0.0029)] [G loss: -2.3402]\n",
      "8911 (5, 1) [D loss: (-0.9967)(R -3.1809, F 2.1545, G 0.0030)] [G loss: -2.2012]\n",
      "8912 (5, 1) [D loss: (-1.0123)(R -2.8268, F 1.7791, G 0.0035)] [G loss: -1.6683]\n",
      "8913 (5, 1) [D loss: (-0.9593)(R -2.8199, F 1.8227, G 0.0038)] [G loss: -1.7232]\n",
      "8914 (5, 1) [D loss: (-0.5455)(R -1.9203, F 1.3454, G 0.0029)] [G loss: -0.7901]\n",
      "8915 (5, 1) [D loss: (-1.1087)(R -2.0821, F 0.9366, G 0.0037)] [G loss: -1.2828]\n",
      "8916 (5, 1) [D loss: (-0.6159)(R -1.7867, F 1.1401, G 0.0031)] [G loss: -0.7840]\n",
      "8917 (5, 1) [D loss: (-1.0307)(R -1.9407, F 0.8774, G 0.0033)] [G loss: -0.9671]\n",
      "8918 (5, 1) [D loss: (-0.5786)(R -2.0138, F 1.4087, G 0.0027)] [G loss: -0.9158]\n",
      "8919 (5, 1) [D loss: (-1.1023)(R -2.1522, F 1.0191, G 0.0031)] [G loss: -0.9945]\n",
      "8920 (5, 1) [D loss: (-0.8077)(R -2.2751, F 1.4308, G 0.0037)] [G loss: -1.3231]\n",
      "8921 (5, 1) [D loss: (-0.7680)(R -2.6134, F 1.8134, G 0.0032)] [G loss: -2.0113]\n",
      "8922 (5, 1) [D loss: (-0.8226)(R -3.5818, F 2.7208, G 0.0038)] [G loss: -3.0168]\n",
      "8923 (5, 1) [D loss: (-0.4991)(R -4.3843, F 3.8459, G 0.0039)] [G loss: -3.6482]\n",
      "8924 (5, 1) [D loss: (-1.0623)(R -4.8384, F 3.7400, G 0.0036)] [G loss: -4.0831]\n",
      "8925 (5, 1) [D loss: (-0.7300)(R -5.0279, F 4.2553, G 0.0043)] [G loss: -4.2493]\n",
      "8926 (5, 1) [D loss: (-0.9895)(R -5.1390, F 4.1173, G 0.0032)] [G loss: -3.9355]\n",
      "8927 (5, 1) [D loss: (-1.1669)(R -4.4547, F 3.2536, G 0.0034)] [G loss: -3.3478]\n",
      "8928 (5, 1) [D loss: (-0.6417)(R -4.1179, F 3.4321, G 0.0044)] [G loss: -3.0409]\n",
      "8929 (5, 1) [D loss: (-1.4675)(R -3.8118, F 2.3075, G 0.0037)] [G loss: -2.6858]\n",
      "8930 (5, 1) [D loss: (-1.2793)(R -3.4771, F 2.1694, G 0.0028)] [G loss: -2.4449]\n",
      "8931 (5, 1) [D loss: (-1.0320)(R -3.4742, F 2.3980, G 0.0044)] [G loss: -2.4923]\n",
      "8932 (5, 1) [D loss: (-1.0460)(R -3.7146, F 2.6274, G 0.0041)] [G loss: -3.0011]\n",
      "8933 (5, 1) [D loss: (-0.7884)(R -4.1328, F 3.3045, G 0.0040)] [G loss: -3.3053]\n",
      "8934 (5, 1) [D loss: (-1.0084)(R -4.6185, F 3.5683, G 0.0042)] [G loss: -3.9877]\n",
      "8935 (5, 1) [D loss: (-1.0682)(R -5.6653, F 4.5566, G 0.0040)] [G loss: -5.0911]\n",
      "8936 (5, 1) [D loss: (-1.0021)(R -5.3955, F 4.3582, G 0.0035)] [G loss: -4.8770]\n",
      "8937 (5, 1) [D loss: (-0.7176)(R -6.0589, F 5.3010, G 0.0040)] [G loss: -5.5196]\n",
      "8938 (5, 1) [D loss: (-0.6951)(R -5.0518, F 4.3345, G 0.0022)] [G loss: -4.7897]\n",
      "8939 (5, 1) [D loss: (-0.7394)(R -4.9344, F 4.1759, G 0.0019)] [G loss: -4.0400]\n",
      "8940 (5, 1) [D loss: (-0.6718)(R -4.1596, F 3.4606, G 0.0027)] [G loss: -3.3669]\n",
      "8941 (5, 1) [D loss: (-0.9163)(R -3.4869, F 2.5369, G 0.0034)] [G loss: -2.2407]\n",
      "8942 (5, 1) [D loss: (-0.7789)(R -2.5906, F 1.7595, G 0.0052)] [G loss: -1.1889]\n",
      "8943 (5, 1) [D loss: (-0.7411)(R -1.0687, F 0.2778, G 0.0050)] [G loss: -0.0989]\n",
      "8944 (5, 1) [D loss: (-1.2667)(R -0.4677, F -0.8643, G 0.0065)] [G loss: 1.1678]\n",
      "8945 (5, 1) [D loss: (-1.0071)(R 0.3550, F -1.4350, G 0.0073)] [G loss: 0.9725]\n",
      "8946 (5, 1) [D loss: (-0.9737)(R 0.2607, F -1.2904, G 0.0056)] [G loss: 1.3768]\n",
      "8947 (5, 1) [D loss: (-0.8611)(R -0.1298, F -0.7668, G 0.0035)] [G loss: 0.8451]\n",
      "8948 (5, 1) [D loss: (-1.0062)(R -0.7556, F -0.2854, G 0.0035)] [G loss: 0.3564]\n",
      "8949 (5, 1) [D loss: (-0.8450)(R -1.5357, F 0.6598, G 0.0031)] [G loss: -0.7088]\n",
      "8950 (5, 1) [D loss: (-1.1749)(R -1.9229, F 0.7152, G 0.0033)] [G loss: -0.6119]\n",
      "8951 (5, 1) [D loss: (-1.0656)(R -1.6785, F 0.5773, G 0.0036)] [G loss: -0.6543]\n",
      "8952 (5, 1) [D loss: (-1.0625)(R -1.4300, F 0.3321, G 0.0035)] [G loss: -0.4847]\n",
      "8953 (5, 1) [D loss: (-1.0340)(R -1.2116, F 0.1515, G 0.0026)] [G loss: -0.2123]\n",
      "8954 (5, 1) [D loss: (-1.3237)(R -0.9905, F -0.3609, G 0.0028)] [G loss: 0.2840]\n",
      "8955 (5, 1) [D loss: (-0.5928)(R -0.1776, F -0.4479, G 0.0033)] [G loss: 0.5863]\n",
      "8956 (5, 1) [D loss: (-1.0391)(R -0.2561, F -0.8160, G 0.0033)] [G loss: 0.8757]\n",
      "8957 (5, 1) [D loss: (-0.7322)(R 0.3361, F -1.1158, G 0.0047)] [G loss: 1.1322]\n",
      "8958 (5, 1) [D loss: (-0.7640)(R -0.5022, F -0.2930, G 0.0031)] [G loss: 0.4945]\n",
      "8959 (5, 1) [D loss: (-0.8025)(R -1.3164, F 0.4834, G 0.0031)] [G loss: -0.6020]\n",
      "8960 (5, 1) [D loss: (-0.9528)(R -2.7009, F 1.7217, G 0.0026)] [G loss: -1.9523]\n",
      "8961 (5, 1) [D loss: (-1.1626)(R -3.7610, F 2.5656, G 0.0033)] [G loss: -2.7755]\n",
      "8962 (5, 1) [D loss: (-1.3224)(R -5.2951, F 3.9361, G 0.0037)] [G loss: -4.6638]\n",
      "8963 (5, 1) [D loss: (-1.2745)(R -6.5041, F 5.1753, G 0.0054)] [G loss: -5.4180]\n",
      "8964 (5, 1) [D loss: (-0.8699)(R -6.1572, F 5.2425, G 0.0045)] [G loss: -5.4199]\n",
      "8965 (5, 1) [D loss: (-0.9650)(R -5.6818, F 4.6782, G 0.0039)] [G loss: -4.7167]\n",
      "8966 (5, 1) [D loss: (-1.2760)(R -5.1910, F 3.8825, G 0.0032)] [G loss: -4.2127]\n",
      "8967 (5, 1) [D loss: (-0.6240)(R -3.6550, F 3.0005, G 0.0031)] [G loss: -2.7784]\n",
      "8968 (5, 1) [D loss: (-0.7435)(R -2.8122, F 2.0346, G 0.0034)] [G loss: -1.6291]\n",
      "8969 (5, 1) [D loss: (-0.9391)(R -1.6658, F 0.6777, G 0.0049)] [G loss: -0.0730]\n",
      "8970 (5, 1) [D loss: (-0.8079)(R -0.4376, F -0.4259, G 0.0056)] [G loss: 0.9204]\n",
      "8971 (5, 1) [D loss: (-0.6949)(R 0.3080, F -1.0652, G 0.0062)] [G loss: 1.2897]\n",
      "8972 (5, 1) [D loss: (-1.1953)(R 0.6595, F -1.8996, G 0.0045)] [G loss: 1.9098]\n",
      "8973 (5, 1) [D loss: (-0.5472)(R 1.5442, F -2.1530, G 0.0062)] [G loss: 1.9793]\n",
      "8974 (5, 1) [D loss: (-1.3459)(R 0.5011, F -1.8792, G 0.0032)] [G loss: 1.7358]\n",
      "8975 (5, 1) [D loss: (-0.9988)(R 0.2144, F -1.2481, G 0.0035)] [G loss: 1.3132]\n",
      "8976 (5, 1) [D loss: (-1.0492)(R -0.7701, F -0.3148, G 0.0036)] [G loss: 0.1659]\n",
      "8977 (5, 1) [D loss: (-0.7569)(R -1.5009, F 0.7113, G 0.0033)] [G loss: -0.8539]\n",
      "8978 (5, 1) [D loss: (-1.2154)(R -2.6239, F 1.3866, G 0.0022)] [G loss: -1.7152]\n",
      "8979 (5, 1) [D loss: (-1.1231)(R -3.1066, F 1.9648, G 0.0019)] [G loss: -2.1744]\n",
      "8980 (5, 1) [D loss: (-0.8056)(R -3.1471, F 2.3193, G 0.0022)] [G loss: -1.9808]\n",
      "8981 (5, 1) [D loss: (-0.6527)(R -3.0503, F 2.3739, G 0.0024)] [G loss: -2.5186]\n",
      "8982 (5, 1) [D loss: (-0.6253)(R -3.6196, F 2.9701, G 0.0024)] [G loss: -2.8195]\n",
      "8983 (5, 1) [D loss: (-0.9986)(R -4.1731, F 3.1459, G 0.0029)] [G loss: -2.6947]\n",
      "8984 (5, 1) [D loss: (-0.4020)(R -3.2713, F 2.8472, G 0.0022)] [G loss: -2.4976]\n",
      "8985 (5, 1) [D loss: (-0.7951)(R -3.1739, F 2.3491, G 0.0030)] [G loss: -2.1832]\n",
      "8986 (5, 1) [D loss: (-0.6497)(R -2.7887, F 2.0909, G 0.0048)] [G loss: -1.8453]\n",
      "8987 (5, 1) [D loss: (-1.1031)(R -3.2399, F 2.0806, G 0.0056)] [G loss: -2.2236]\n",
      "8988 (5, 1) [D loss: (-1.2911)(R -3.1967, F 1.8532, G 0.0052)] [G loss: -2.0807]\n",
      "8989 (5, 1) [D loss: (-1.1270)(R -3.3073, F 2.1268, G 0.0054)] [G loss: -2.1279]\n",
      "8990 (5, 1) [D loss: (-0.7484)(R -3.2742, F 2.4756, G 0.0050)] [G loss: -2.5583]\n",
      "8991 (5, 1) [D loss: (-0.8520)(R -3.6352, F 2.7388, G 0.0044)] [G loss: -2.5967]\n",
      "8992 (5, 1) [D loss: (-1.1961)(R -3.5142, F 2.2758, G 0.0042)] [G loss: -2.5430]\n",
      "8993 (5, 1) [D loss: (-1.0334)(R -3.0711, F 1.9968, G 0.0041)] [G loss: -2.0820]\n",
      "8994 (5, 1) [D loss: (-1.1565)(R -2.5074, F 1.3139, G 0.0037)] [G loss: -1.4863]\n",
      "8995 (5, 1) [D loss: (-0.7987)(R -1.4552, F 0.6137, G 0.0043)] [G loss: -0.5590]\n",
      "8996 (5, 1) [D loss: (-1.1569)(R -1.0713, F -0.1242, G 0.0039)] [G loss: 0.3265]\n",
      "8997 (5, 1) [D loss: (-1.0956)(R 0.0068, F -1.1544, G 0.0052)] [G loss: 0.8286]\n",
      "8998 (5, 1) [D loss: (-1.2135)(R 0.3131, F -1.5764, G 0.0050)] [G loss: 1.7044]\n",
      "8999 (5, 1) [D loss: (-0.6299)(R 0.7931, F -1.4649, G 0.0042)] [G loss: 1.6752]\n",
      "9000 (5, 1) [D loss: (-0.8076)(R 0.5925, F -1.4414, G 0.0041)] [G loss: 1.5151]\n",
      "9001 (5, 1) [D loss: (-0.8917)(R -0.0202, F -0.8965, G 0.0025)] [G loss: 0.6709]\n",
      "9002 (5, 1) [D loss: (-0.7211)(R -1.3490, F 0.6104, G 0.0017)] [G loss: -0.7486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9003 (5, 1) [D loss: (-0.8302)(R -2.1709, F 1.3205, G 0.0020)] [G loss: -1.5307]\n",
      "9004 (5, 1) [D loss: (-1.0298)(R -3.2373, F 2.1833, G 0.0024)] [G loss: -2.0251]\n",
      "9005 (5, 1) [D loss: (-0.9196)(R -3.2297, F 2.2871, G 0.0023)] [G loss: -2.2019]\n",
      "9006 (5, 1) [D loss: (-0.9961)(R -3.1430, F 2.1211, G 0.0026)] [G loss: -1.9264]\n",
      "9007 (5, 1) [D loss: (-1.1123)(R -2.4582, F 1.3137, G 0.0032)] [G loss: -1.0001]\n",
      "9008 (5, 1) [D loss: (-0.8933)(R -0.9287, F 0.0112, G 0.0024)] [G loss: 0.1311]\n",
      "9009 (5, 1) [D loss: (-1.3541)(R 0.0894, F -1.4866, G 0.0043)] [G loss: 1.3749]\n",
      "9010 (5, 1) [D loss: (-1.2304)(R 1.2230, F -2.5559, G 0.0102)] [G loss: 2.3354]\n",
      "9011 (5, 1) [D loss: (-0.7430)(R 1.9337, F -2.7506, G 0.0074)] [G loss: 2.6267]\n",
      "9012 (5, 1) [D loss: (-1.1022)(R 1.8713, F -3.0418, G 0.0068)] [G loss: 2.8389]\n",
      "9013 (5, 1) [D loss: (-0.5966)(R 1.7371, F -2.3916, G 0.0058)] [G loss: 2.5403]\n",
      "9014 (5, 1) [D loss: (-0.6576)(R 0.1827, F -0.8658, G 0.0025)] [G loss: 0.6313]\n",
      "9015 (5, 1) [D loss: (-1.2733)(R -2.2859, F 0.9913, G 0.0021)] [G loss: -1.5091]\n",
      "9016 (5, 1) [D loss: (-1.0449)(R -3.9113, F 2.8168, G 0.0050)] [G loss: -3.1121]\n",
      "9017 (5, 1) [D loss: (-1.5350)(R -5.3259, F 3.7371, G 0.0054)] [G loss: -4.3279]\n",
      "9018 (5, 1) [D loss: (-1.4021)(R -5.5997, F 4.1468, G 0.0051)] [G loss: -4.4420]\n",
      "9019 (5, 1) [D loss: (-0.8693)(R -5.5812, F 4.6595, G 0.0052)] [G loss: -4.3362]\n",
      "9020 (5, 1) [D loss: (-0.8342)(R -4.0445, F 3.1789, G 0.0031)] [G loss: -3.0362]\n",
      "9021 (5, 1) [D loss: (-0.7289)(R -3.0349, F 2.2886, G 0.0017)] [G loss: -2.0623]\n",
      "9022 (5, 1) [D loss: (-0.6664)(R -1.7202, F 1.0290, G 0.0025)] [G loss: -0.7629]\n",
      "9023 (5, 1) [D loss: (-0.8912)(R -1.2223, F 0.3097, G 0.0021)] [G loss: -0.1668]\n",
      "9024 (5, 1) [D loss: (-0.4777)(R -0.3271, F -0.1836, G 0.0033)] [G loss: 0.1347]\n",
      "9025 (5, 1) [D loss: (-0.9083)(R -0.7483, F -0.1980, G 0.0038)] [G loss: 0.2061]\n",
      "9026 (5, 1) [D loss: (-0.9343)(R -1.3117, F 0.3432, G 0.0034)] [G loss: -0.0717]\n",
      "9027 (5, 1) [D loss: (-0.7079)(R -1.5318, F 0.7898, G 0.0034)] [G loss: -0.8916]\n",
      "9028 (5, 1) [D loss: (-1.1433)(R -2.6418, F 1.4690, G 0.0030)] [G loss: -1.6082]\n",
      "9029 (5, 1) [D loss: (-0.9558)(R -3.1880, F 2.1984, G 0.0034)] [G loss: -2.3710]\n",
      "9030 (5, 1) [D loss: (-0.8905)(R -3.7182, F 2.7996, G 0.0028)] [G loss: -2.8601]\n",
      "9031 (5, 1) [D loss: (-1.0777)(R -4.1435, F 3.0327, G 0.0033)] [G loss: -3.0977]\n",
      "9032 (5, 1) [D loss: (-0.8252)(R -4.1138, F 3.2649, G 0.0024)] [G loss: -3.1813]\n",
      "9033 (5, 1) [D loss: (-1.2215)(R -3.7750, F 2.5197, G 0.0034)] [G loss: -2.5451]\n",
      "9034 (5, 1) [D loss: (-0.6255)(R -3.3517, F 2.6870, G 0.0039)] [G loss: -2.5892]\n",
      "9035 (5, 1) [D loss: (-0.8533)(R -2.8620, F 1.9773, G 0.0031)] [G loss: -1.9592]\n",
      "9036 (5, 1) [D loss: (-0.3541)(R -2.3349, F 1.9496, G 0.0031)] [G loss: -1.9188]\n",
      "9037 (5, 1) [D loss: (-0.7979)(R -2.1193, F 1.2744, G 0.0047)] [G loss: -1.5960]\n",
      "9038 (5, 1) [D loss: (-0.6280)(R -2.0127, F 1.3456, G 0.0039)] [G loss: -1.0737]\n",
      "9039 (5, 1) [D loss: (-0.5909)(R -1.8605, F 1.2260, G 0.0044)] [G loss: -1.1754]\n",
      "9040 (5, 1) [D loss: (-0.5007)(R -2.0440, F 1.5126, G 0.0031)] [G loss: -1.2300]\n",
      "9041 (5, 1) [D loss: (-0.7592)(R -2.1270, F 1.3338, G 0.0034)] [G loss: -1.5933]\n",
      "9042 (5, 1) [D loss: (-0.9238)(R -2.6137, F 1.6432, G 0.0047)] [G loss: -1.7054]\n",
      "9043 (5, 1) [D loss: (-1.0754)(R -3.1068, F 1.9936, G 0.0038)] [G loss: -2.1995]\n",
      "9044 (5, 1) [D loss: (-1.2630)(R -3.3741, F 2.0759, G 0.0035)] [G loss: -2.5960]\n",
      "9045 (5, 1) [D loss: (-0.9789)(R -3.6744, F 2.6585, G 0.0037)] [G loss: -2.5210]\n",
      "9046 (5, 1) [D loss: (-0.8110)(R -2.9487, F 2.1061, G 0.0032)] [G loss: -1.8555]\n",
      "9047 (5, 1) [D loss: (-0.7110)(R -2.9500, F 2.2017, G 0.0037)] [G loss: -2.0144]\n",
      "9048 (5, 1) [D loss: (-1.0148)(R -2.6561, F 1.6117, G 0.0030)] [G loss: -1.4159]\n",
      "9049 (5, 1) [D loss: (-0.9044)(R -2.5017, F 1.5740, G 0.0023)] [G loss: -1.0509]\n",
      "9050 (5, 1) [D loss: (-1.0246)(R -1.7405, F 0.6882, G 0.0028)] [G loss: -0.8743]\n",
      "9051 (5, 1) [D loss: (-0.6473)(R -1.8569, F 1.1836, G 0.0026)] [G loss: -0.9888]\n",
      "9052 (5, 1) [D loss: (-0.7163)(R -2.5297, F 1.7796, G 0.0034)] [G loss: -1.8132]\n",
      "9053 (5, 1) [D loss: (-0.8458)(R -3.1620, F 2.2868, G 0.0029)] [G loss: -2.3994]\n",
      "9054 (5, 1) [D loss: (-0.7264)(R -3.9684, F 3.2044, G 0.0038)] [G loss: -2.8599]\n",
      "9055 (5, 1) [D loss: (-1.2870)(R -4.3254, F 3.0003, G 0.0038)] [G loss: -3.2287]\n",
      "9056 (5, 1) [D loss: (-0.6420)(R -4.0339, F 3.3510, G 0.0041)] [G loss: -3.1020]\n",
      "9057 (5, 1) [D loss: (-0.7018)(R -4.1165, F 3.3787, G 0.0036)] [G loss: -3.3505]\n",
      "9058 (5, 1) [D loss: (-0.8140)(R -4.0673, F 3.2093, G 0.0044)] [G loss: -3.4389]\n",
      "9059 (5, 1) [D loss: (-1.0408)(R -4.2745, F 3.1909, G 0.0043)] [G loss: -3.6043]\n",
      "9060 (5, 1) [D loss: (-1.0243)(R -3.8859, F 2.8244, G 0.0037)] [G loss: -2.6625]\n",
      "9061 (5, 1) [D loss: (-1.3868)(R -3.5733, F 2.1470, G 0.0040)] [G loss: -2.7207]\n",
      "9062 (5, 1) [D loss: (-1.0708)(R -2.6247, F 1.5171, G 0.0037)] [G loss: -1.3939]\n",
      "9063 (5, 1) [D loss: (-0.7098)(R -1.8487, F 1.1023, G 0.0037)] [G loss: -0.9792]\n",
      "9064 (5, 1) [D loss: (-1.2013)(R -1.2882, F 0.0403, G 0.0047)] [G loss: -0.0517]\n",
      "9065 (5, 1) [D loss: (-1.0347)(R -0.5668, F -0.5120, G 0.0044)] [G loss: 0.7238]\n",
      "9066 (5, 1) [D loss: (-0.9029)(R -0.0085, F -0.9475, G 0.0053)] [G loss: 0.9306]\n",
      "9067 (5, 1) [D loss: (-0.4973)(R 0.2029, F -0.7441, G 0.0044)] [G loss: 0.7779]\n",
      "9068 (5, 1) [D loss: (-0.7333)(R -0.0311, F -0.7418, G 0.0040)] [G loss: 0.6301]\n",
      "9069 (5, 1) [D loss: (-1.0462)(R -0.5215, F -0.5567, G 0.0032)] [G loss: 0.4341]\n",
      "9070 (5, 1) [D loss: (-0.8522)(R -1.3498, F 0.4620, G 0.0036)] [G loss: -0.6724]\n",
      "9071 (5, 1) [D loss: (-0.7299)(R -2.1286, F 1.3600, G 0.0039)] [G loss: -1.1061]\n",
      "9072 (5, 1) [D loss: (-1.1892)(R -2.7843, F 1.5689, G 0.0026)] [G loss: -1.6219]\n",
      "9073 (5, 1) [D loss: (-0.9909)(R -2.5468, F 1.5242, G 0.0032)] [G loss: -1.7308]\n",
      "9074 (5, 1) [D loss: (-0.6337)(R -2.1528, F 1.4963, G 0.0023)] [G loss: -1.5193]\n",
      "9075 (5, 1) [D loss: (-0.5661)(R -2.1047, F 1.5092, G 0.0029)] [G loss: -1.1683]\n",
      "9076 (5, 1) [D loss: (-1.0487)(R -1.8083, F 0.7387, G 0.0021)] [G loss: -0.8060]\n",
      "9077 (5, 1) [D loss: (-1.0399)(R -0.9767, F -0.0903, G 0.0027)] [G loss: 0.1595]\n",
      "9078 (5, 1) [D loss: (-0.6026)(R 0.1506, F -0.7880, G 0.0035)] [G loss: 0.7031]\n",
      "9079 (5, 1) [D loss: (-0.9720)(R -0.3491, F -0.6627, G 0.0040)] [G loss: 0.6003]\n",
      "9080 (5, 1) [D loss: (-0.7811)(R -0.4657, F -0.3548, G 0.0039)] [G loss: 0.2223]\n",
      "9081 (5, 1) [D loss: (-0.6535)(R -0.6237, F -0.0707, G 0.0041)] [G loss: 0.1868]\n",
      "9082 (5, 1) [D loss: (-1.0590)(R -1.0751, F -0.0229, G 0.0039)] [G loss: -0.3012]\n",
      "9083 (5, 1) [D loss: (-1.1686)(R -1.2918, F 0.0826, G 0.0041)] [G loss: -0.2481]\n",
      "9084 (5, 1) [D loss: (-0.8108)(R -1.5212, F 0.6683, G 0.0042)] [G loss: -0.8006]\n",
      "9085 (5, 1) [D loss: (-1.0435)(R -1.4047, F 0.3267, G 0.0034)] [G loss: -0.5957]\n",
      "9086 (5, 1) [D loss: (-0.4657)(R -1.4635, F 0.9612, G 0.0037)] [G loss: -0.8935]\n",
      "9087 (5, 1) [D loss: (-0.6838)(R -2.0548, F 1.3439, G 0.0027)] [G loss: -1.2720]\n",
      "9088 (5, 1) [D loss: (-0.8449)(R -2.2589, F 1.3841, G 0.0030)] [G loss: -1.1331]\n",
      "9089 (5, 1) [D loss: (-0.3273)(R -1.3961, F 1.0389, G 0.0030)] [G loss: -0.9188]\n",
      "9090 (5, 1) [D loss: (-0.8398)(R -1.2712, F 0.3954, G 0.0036)] [G loss: -0.3826]\n",
      "9091 (5, 1) [D loss: (-1.1642)(R -1.1703, F -0.0428, G 0.0049)] [G loss: -0.0865]\n",
      "9092 (5, 1) [D loss: (-1.1027)(R -1.1649, F 0.0132, G 0.0049)] [G loss: 0.0674]\n",
      "9093 (5, 1) [D loss: (-0.6929)(R -1.0009, F 0.2697, G 0.0038)] [G loss: -0.3229]\n",
      "9094 (5, 1) [D loss: (-1.1806)(R -1.6878, F 0.4648, G 0.0042)] [G loss: -0.9275]\n",
      "9095 (5, 1) [D loss: (-1.1943)(R -2.6368, F 1.3989, G 0.0044)] [G loss: -1.9471]\n",
      "9096 (5, 1) [D loss: (-0.9059)(R -2.7687, F 1.8239, G 0.0039)] [G loss: -2.2550]\n",
      "9097 (5, 1) [D loss: (-0.8003)(R -3.3216, F 2.4832, G 0.0038)] [G loss: -2.6311]\n",
      "9098 (5, 1) [D loss: (-1.1086)(R -3.8920, F 2.7476, G 0.0036)] [G loss: -2.8965]\n",
      "9099 (5, 1) [D loss: (-1.0109)(R -4.1955, F 3.1519, G 0.0033)] [G loss: -3.7335]\n",
      "9100 (5, 1) [D loss: (-0.4203)(R -3.9552, F 3.5029, G 0.0032)] [G loss: -3.0572]\n",
      "9101 (5, 1) [D loss: (-0.7807)(R -3.1888, F 2.3851, G 0.0023)] [G loss: -2.3264]\n",
      "9102 (5, 1) [D loss: (-0.8173)(R -2.4017, F 1.5539, G 0.0030)] [G loss: -1.5312]\n",
      "9103 (5, 1) [D loss: (-0.8597)(R -1.9442, F 1.0446, G 0.0040)] [G loss: -1.1897]\n",
      "9104 (5, 1) [D loss: (-0.6846)(R -1.5357, F 0.8152, G 0.0036)] [G loss: -0.7677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9105 (5, 1) [D loss: (-0.4323)(R -1.2644, F 0.7992, G 0.0033)] [G loss: -0.6125]\n",
      "9106 (5, 1) [D loss: (-0.6519)(R -1.3229, F 0.6318, G 0.0039)] [G loss: -0.8457]\n",
      "9107 (5, 1) [D loss: (-1.3898)(R -2.3100, F 0.8793, G 0.0041)] [G loss: -1.3692]\n",
      "9108 (5, 1) [D loss: (-1.1317)(R -2.9406, F 1.7617, G 0.0047)] [G loss: -1.8597]\n",
      "9109 (5, 1) [D loss: (-1.1771)(R -3.5323, F 2.3155, G 0.0040)] [G loss: -2.7301]\n",
      "9110 (5, 1) [D loss: (-1.1031)(R -4.4564, F 3.3061, G 0.0047)] [G loss: -3.4189]\n",
      "9111 (5, 1) [D loss: (-0.9042)(R -5.1831, F 4.2235, G 0.0055)] [G loss: -4.2847]\n",
      "9112 (5, 1) [D loss: (-0.8588)(R -5.7425, F 4.8262, G 0.0057)] [G loss: -4.8713]\n",
      "9113 (5, 1) [D loss: (-0.7838)(R -5.5931, F 4.7751, G 0.0034)] [G loss: -4.7461]\n",
      "9114 (5, 1) [D loss: (-0.8622)(R -4.9839, F 4.1018, G 0.0020)] [G loss: -4.3272]\n",
      "9115 (5, 1) [D loss: (-0.5475)(R -4.1043, F 3.5364, G 0.0020)] [G loss: -3.4003]\n",
      "9116 (5, 1) [D loss: (-0.9975)(R -3.5437, F 2.5235, G 0.0023)] [G loss: -2.6652]\n",
      "9117 (5, 1) [D loss: (-1.2243)(R -2.5385, F 1.2900, G 0.0024)] [G loss: -1.3031]\n",
      "9118 (5, 1) [D loss: (-0.8375)(R -1.4732, F 0.5920, G 0.0044)] [G loss: -0.1792]\n",
      "9119 (5, 1) [D loss: (-1.1663)(R -0.8261, F -0.3984, G 0.0058)] [G loss: 0.7509]\n",
      "9120 (5, 1) [D loss: (-0.9873)(R -0.2770, F -0.7776, G 0.0067)] [G loss: 0.5724]\n",
      "9121 (5, 1) [D loss: (-0.7428)(R -1.0088, F 0.2107, G 0.0055)] [G loss: -0.4381]\n",
      "9122 (5, 1) [D loss: (-1.0238)(R -2.2776, F 1.2212, G 0.0033)] [G loss: -1.5468]\n",
      "9123 (5, 1) [D loss: (-1.0549)(R -3.5364, F 2.4513, G 0.0030)] [G loss: -2.7349]\n",
      "9124 (5, 1) [D loss: (-0.6042)(R -3.7480, F 3.1134, G 0.0030)] [G loss: -2.7812]\n",
      "9125 (5, 1) [D loss: (-0.6781)(R -3.9717, F 3.2650, G 0.0029)] [G loss: -3.1876]\n",
      "9126 (5, 1) [D loss: (-1.0196)(R -4.2182, F 3.1657, G 0.0033)] [G loss: -2.9660]\n",
      "9127 (5, 1) [D loss: (-0.7641)(R -3.4829, F 2.6850, G 0.0034)] [G loss: -2.4499]\n",
      "9128 (5, 1) [D loss: (-0.8101)(R -2.6193, F 1.7845, G 0.0025)] [G loss: -1.6335]\n",
      "9129 (5, 1) [D loss: (-1.0553)(R -1.8771, F 0.7930, G 0.0029)] [G loss: -0.5250]\n",
      "9130 (5, 1) [D loss: (-0.9880)(R -0.6494, F -0.3675, G 0.0029)] [G loss: 0.6627]\n",
      "9131 (5, 1) [D loss: (-0.9549)(R 0.5043, F -1.5013, G 0.0042)] [G loss: 1.2317]\n",
      "9132 (5, 1) [D loss: (-0.7773)(R 0.4351, F -1.2667, G 0.0054)] [G loss: 1.6114]\n",
      "9133 (5, 1) [D loss: (-0.8691)(R 0.5675, F -1.4786, G 0.0042)] [G loss: 1.6384]\n",
      "9134 (5, 1) [D loss: (-1.1204)(R 0.2981, F -1.4562, G 0.0038)] [G loss: 0.9542]\n",
      "9135 (5, 1) [D loss: (-0.6203)(R -0.0863, F -0.5698, G 0.0036)] [G loss: 0.6009]\n",
      "9136 (5, 1) [D loss: (-0.5685)(R -1.3344, F 0.7420, G 0.0024)] [G loss: -0.9034]\n",
      "9137 (5, 1) [D loss: (-0.9644)(R -2.9462, F 1.9588, G 0.0023)] [G loss: -2.1850]\n",
      "9138 (5, 1) [D loss: (-0.9865)(R -3.5776, F 2.5629, G 0.0028)] [G loss: -2.9732]\n",
      "9139 (5, 1) [D loss: (-0.9285)(R -3.5030, F 2.5356, G 0.0039)] [G loss: -3.0055]\n",
      "9140 (5, 1) [D loss: (-0.8664)(R -3.7101, F 2.8121, G 0.0032)] [G loss: -2.3432]\n",
      "9141 (5, 1) [D loss: (-0.5860)(R -2.9103, F 2.2957, G 0.0029)] [G loss: -2.2021]\n",
      "9142 (5, 1) [D loss: (-0.8560)(R -2.5815, F 1.7011, G 0.0024)] [G loss: -1.5183]\n",
      "9143 (5, 1) [D loss: (-1.1130)(R -1.4322, F 0.2901, G 0.0029)] [G loss: -0.0673]\n",
      "9144 (5, 1) [D loss: (-1.3651)(R -0.1709, F -1.2541, G 0.0060)] [G loss: 1.1297]\n",
      "9145 (5, 1) [D loss: (-1.4127)(R 0.8718, F -2.3493, G 0.0065)] [G loss: 2.1165]\n",
      "9146 (5, 1) [D loss: (-0.8283)(R 1.4072, F -2.3041, G 0.0069)] [G loss: 2.5937]\n",
      "9147 (5, 1) [D loss: (-0.8817)(R 1.4884, F -2.4262, G 0.0056)] [G loss: 2.3681]\n",
      "9148 (5, 1) [D loss: (-0.8015)(R 0.7844, F -1.6164, G 0.0031)] [G loss: 1.2095]\n",
      "9149 (5, 1) [D loss: (-0.4064)(R -0.5353, F 0.1071, G 0.0022)] [G loss: -0.4659]\n",
      "9150 (5, 1) [D loss: (-0.8485)(R -2.3491, F 1.4817, G 0.0019)] [G loss: -1.8750]\n",
      "9151 (5, 1) [D loss: (-0.7479)(R -3.5967, F 2.8219, G 0.0027)] [G loss: -3.1689]\n",
      "9152 (5, 1) [D loss: (-1.2582)(R -5.1209, F 3.8194, G 0.0043)] [G loss: -4.3308]\n",
      "9153 (5, 1) [D loss: (-1.0887)(R -5.0955, F 3.9644, G 0.0042)] [G loss: -4.1029]\n",
      "9154 (5, 1) [D loss: (-0.8111)(R -4.0285, F 3.1925, G 0.0025)] [G loss: -2.6799]\n",
      "9155 (5, 1) [D loss: (-0.5361)(R -2.2427, F 1.6841, G 0.0023)] [G loss: -1.2925]\n",
      "9156 (5, 1) [D loss: (-0.4835)(R -1.4013, F 0.8976, G 0.0020)] [G loss: -0.4328]\n",
      "9157 (5, 1) [D loss: (-1.0708)(R -1.1258, F 0.0221, G 0.0033)] [G loss: -0.1455]\n",
      "9158 (5, 1) [D loss: (-0.8670)(R -1.3251, F 0.4163, G 0.0042)] [G loss: -0.9049]\n",
      "9159 (5, 1) [D loss: (-0.9675)(R -2.3019, F 1.2977, G 0.0037)] [G loss: -1.4209]\n",
      "9160 (5, 1) [D loss: (-1.0791)(R -4.0486, F 2.9316, G 0.0038)] [G loss: -3.7757]\n",
      "9161 (5, 1) [D loss: (-1.4536)(R -6.2660, F 4.7568, G 0.0056)] [G loss: -5.7727]\n",
      "9162 (5, 1) [D loss: (-1.7031)(R -7.7506, F 5.9781, G 0.0069)] [G loss: -7.0997]\n",
      "9163 (5, 1) [D loss: (-1.2298)(R -8.1449, F 6.8122, G 0.0103)] [G loss: -6.9066]\n",
      "9164 (5, 1) [D loss: (-1.0368)(R -7.3070, F 6.1941, G 0.0076)] [G loss: -6.0408]\n",
      "9165 (5, 1) [D loss: (-1.2582)(R -6.6782, F 5.3781, G 0.0042)] [G loss: -5.4362]\n",
      "9166 (5, 1) [D loss: (-0.8107)(R -5.2310, F 4.4014, G 0.0019)] [G loss: -4.2812]\n",
      "9167 (5, 1) [D loss: (-0.3875)(R -3.9320, F 3.5284, G 0.0016)] [G loss: -3.0459]\n",
      "9168 (5, 1) [D loss: (-0.6701)(R -3.1614, F 2.4727, G 0.0019)] [G loss: -2.0606]\n",
      "9169 (5, 1) [D loss: (-0.3338)(R -1.7323, F 1.3755, G 0.0023)] [G loss: -0.7978]\n",
      "9170 (5, 1) [D loss: (-1.1234)(R -0.6954, F -0.4732, G 0.0045)] [G loss: 0.6340]\n",
      "9171 (5, 1) [D loss: (-1.0259)(R 0.2832, F -1.3541, G 0.0045)] [G loss: 1.3851]\n",
      "9172 (5, 1) [D loss: (-1.1804)(R 0.2434, F -1.4846, G 0.0061)] [G loss: 1.4307]\n",
      "9173 (5, 1) [D loss: (-0.7294)(R -0.0660, F -0.7110, G 0.0048)] [G loss: 0.6325]\n",
      "9174 (5, 1) [D loss: (-0.6735)(R -0.6699, F -0.0340, G 0.0030)] [G loss: 0.3666]\n",
      "9175 (5, 1) [D loss: (-1.3985)(R -1.8132, F 0.3746, G 0.0040)] [G loss: -0.6964]\n",
      "9176 (5, 1) [D loss: (-1.2106)(R -2.1629, F 0.9080, G 0.0044)] [G loss: -1.1258]\n",
      "9177 (5, 1) [D loss: (-1.0635)(R -2.2945, F 1.1966, G 0.0034)] [G loss: -1.2588]\n",
      "9178 (5, 1) [D loss: (-0.8606)(R -2.2751, F 1.3828, G 0.0032)] [G loss: -1.3299]\n",
      "9179 (5, 1) [D loss: (-0.9672)(R -2.1163, F 1.1275, G 0.0022)] [G loss: -1.2748]\n",
      "9180 (5, 1) [D loss: (-0.6070)(R -1.4414, F 0.8118, G 0.0023)] [G loss: -0.8075]\n",
      "9181 (5, 1) [D loss: (-0.6821)(R -1.1607, F 0.4541, G 0.0025)] [G loss: -0.3546]\n",
      "9182 (5, 1) [D loss: (-0.7370)(R -0.6687, F -0.0941, G 0.0026)] [G loss: 0.5450]\n",
      "9183 (5, 1) [D loss: (-1.0418)(R -0.2269, F -0.8527, G 0.0038)] [G loss: 0.9087]\n",
      "9184 (5, 1) [D loss: (-1.0856)(R 0.3916, F -1.5117, G 0.0035)] [G loss: 1.4274]\n",
      "9185 (5, 1) [D loss: (-0.9090)(R 0.4953, F -1.4586, G 0.0054)] [G loss: 1.6863]\n",
      "9186 (5, 1) [D loss: (-0.8651)(R 0.3461, F -1.2701, G 0.0059)] [G loss: 1.3384]\n",
      "9187 (5, 1) [D loss: (-1.4595)(R -0.0272, F -1.4902, G 0.0058)] [G loss: 1.1789]\n",
      "9188 (5, 1) [D loss: (-0.9295)(R 0.1074, F -1.0960, G 0.0059)] [G loss: 1.0755]\n",
      "9189 (5, 1) [D loss: (-0.7406)(R 0.0595, F -0.8338, G 0.0034)] [G loss: 0.7366]\n",
      "9190 (5, 1) [D loss: (-0.6640)(R -0.7737, F 0.0750, G 0.0035)] [G loss: -0.1083]\n",
      "9191 (5, 1) [D loss: (-0.5663)(R -0.4536, F -0.1486, G 0.0036)] [G loss: 0.1840]\n",
      "9192 (5, 1) [D loss: (-0.8202)(R -0.1909, F -0.6724, G 0.0043)] [G loss: 0.2886]\n",
      "9193 (5, 1) [D loss: (-0.4827)(R 0.5404, F -1.0658, G 0.0043)] [G loss: 1.1247]\n",
      "9194 (5, 1) [D loss: (-0.9982)(R 0.2696, F -1.3131, G 0.0045)] [G loss: 1.2498]\n",
      "9195 (5, 1) [D loss: (-1.3946)(R 0.3306, F -1.7705, G 0.0045)] [G loss: 1.6365]\n",
      "9196 (5, 1) [D loss: (-1.2202)(R 0.7866, F -2.0603, G 0.0054)] [G loss: 2.2144]\n",
      "9197 (5, 1) [D loss: (-0.8726)(R 1.3293, F -2.2446, G 0.0043)] [G loss: 2.2101]\n",
      "9198 (5, 1) [D loss: (-1.0069)(R 0.0428, F -1.0882, G 0.0038)] [G loss: 0.9881]\n",
      "9199 (5, 1) [D loss: (-0.5968)(R 0.2229, F -0.8474, G 0.0028)] [G loss: 0.2990]\n",
      "9200 (5, 1) [D loss: (-0.8467)(R -0.9530, F 0.0825, G 0.0024)] [G loss: -0.4273]\n",
      "9201 (5, 1) [D loss: (-0.2540)(R -1.8137, F 1.5423, G 0.0017)] [G loss: -1.3918]\n",
      "9202 (5, 1) [D loss: (-0.9305)(R -3.1181, F 2.1695, G 0.0018)] [G loss: -2.2465]\n",
      "9203 (5, 1) [D loss: (-0.7688)(R -3.6220, F 2.8247, G 0.0028)] [G loss: -2.9080]\n",
      "9204 (5, 1) [D loss: (-1.1538)(R -4.6658, F 3.4783, G 0.0034)] [G loss: -3.8254]\n",
      "9205 (5, 1) [D loss: (-0.8412)(R -4.9754, F 4.0993, G 0.0035)] [G loss: -4.0153]\n",
      "9206 (5, 1) [D loss: (-0.6821)(R -4.3660, F 3.6603, G 0.0024)] [G loss: -3.3480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9207 (5, 1) [D loss: (-0.8478)(R -3.3921, F 2.5210, G 0.0023)] [G loss: -1.9937]\n",
      "9208 (5, 1) [D loss: (-0.6322)(R -1.9356, F 1.2709, G 0.0032)] [G loss: -0.7305]\n",
      "9209 (5, 1) [D loss: (-0.8713)(R -0.9050, F -0.0167, G 0.0050)] [G loss: 0.2846]\n",
      "9210 (5, 1) [D loss: (-1.1363)(R -0.2075, F -1.0052, G 0.0076)] [G loss: 1.0937]\n",
      "9211 (5, 1) [D loss: (-0.8828)(R -0.2391, F -0.6917, G 0.0048)] [G loss: 0.4779]\n",
      "9212 (5, 1) [D loss: (-0.7082)(R -1.3987, F 0.6430, G 0.0047)] [G loss: -0.3460]\n",
      "9213 (5, 1) [D loss: (-0.6222)(R -2.6358, F 1.9863, G 0.0027)] [G loss: -2.1815]\n",
      "9214 (5, 1) [D loss: (-1.3940)(R -5.7719, F 4.3426, G 0.0035)] [G loss: -5.3472]\n",
      "9215 (5, 1) [D loss: (-1.2191)(R -8.2753, F 6.9657, G 0.0090)] [G loss: -7.8181]\n",
      "9216 (5, 1) [D loss: (-1.0495)(R -9.0064, F 7.8374, G 0.0119)] [G loss: -8.1994]\n",
      "9217 (5, 1) [D loss: (-1.0902)(R -8.5538, F 7.3696, G 0.0094)] [G loss: -7.8398]\n",
      "9218 (5, 1) [D loss: (-1.3653)(R -7.8136, F 6.4006, G 0.0048)] [G loss: -6.8908]\n",
      "9219 (5, 1) [D loss: (-0.9475)(R -6.8344, F 5.8476, G 0.0039)] [G loss: -6.4654]\n",
      "9220 (5, 1) [D loss: (-0.5851)(R -5.6689, F 5.0619, G 0.0022)] [G loss: -5.1219]\n",
      "9221 (5, 1) [D loss: (-0.4093)(R -4.4462, F 4.0241, G 0.0013)] [G loss: -3.8245]\n",
      "9222 (5, 1) [D loss: (-0.6857)(R -2.9987, F 2.2972, G 0.0016)] [G loss: -1.9803]\n",
      "9223 (5, 1) [D loss: (-0.7078)(R -1.5635, F 0.8378, G 0.0018)] [G loss: -0.8653]\n",
      "9224 (5, 1) [D loss: (-1.1702)(R -1.0380, F -0.1534, G 0.0021)] [G loss: 0.3477]\n",
      "9225 (5, 1) [D loss: (-0.8462)(R -0.1733, F -0.7010, G 0.0028)] [G loss: 0.6389]\n",
      "9226 (5, 1) [D loss: (-0.4361)(R 0.9361, F -1.4148, G 0.0043)] [G loss: 1.7383]\n",
      "9227 (5, 1) [D loss: (-0.7940)(R 0.9508, F -1.7964, G 0.0052)] [G loss: 2.1306]\n",
      "9228 (5, 1) [D loss: (-1.0279)(R 1.0985, F -2.1734, G 0.0047)] [G loss: 2.2054]\n",
      "9229 (5, 1) [D loss: (-1.2209)(R 1.2452, F -2.5281, G 0.0062)] [G loss: 2.6168]\n",
      "9230 (5, 1) [D loss: (-1.0562)(R 1.3927, F -2.4968, G 0.0048)] [G loss: 2.4234]\n",
      "9231 (5, 1) [D loss: (-1.2755)(R 1.7371, F -3.0562, G 0.0044)] [G loss: 2.7313]\n",
      "9232 (5, 1) [D loss: (-0.8206)(R 2.8778, F -3.7556, G 0.0057)] [G loss: 3.8175]\n",
      "9233 (5, 1) [D loss: (-0.9087)(R 3.0455, F -4.0102, G 0.0056)] [G loss: 4.0014]\n",
      "9234 (5, 1) [D loss: (-0.9641)(R 2.6961, F -3.7032, G 0.0043)] [G loss: 4.0110]\n",
      "9235 (5, 1) [D loss: (-1.1341)(R 2.8123, F -3.9878, G 0.0041)] [G loss: 3.6079]\n",
      "9236 (5, 1) [D loss: (-1.1325)(R 2.4906, F -3.6679, G 0.0045)] [G loss: 3.2271]\n",
      "9237 (5, 1) [D loss: (-0.9601)(R 2.0908, F -3.0833, G 0.0032)] [G loss: 2.6526]\n",
      "9238 (5, 1) [D loss: (-0.7960)(R 1.5275, F -2.3607, G 0.0037)] [G loss: 2.2220]\n",
      "9239 (5, 1) [D loss: (-1.0719)(R 0.2006, F -1.3055, G 0.0033)] [G loss: 0.9901]\n",
      "9240 (5, 1) [D loss: (-0.5586)(R -0.0770, F -0.5058, G 0.0024)] [G loss: 0.7224]\n",
      "9241 (5, 1) [D loss: (-0.9481)(R -0.6143, F -0.3605, G 0.0027)] [G loss: 0.0430]\n",
      "9242 (5, 1) [D loss: (-0.8542)(R -0.8141, F -0.0641, G 0.0024)] [G loss: 0.0462]\n",
      "9243 (5, 1) [D loss: (-0.7598)(R -0.4211, F -0.3628, G 0.0024)] [G loss: 0.0976]\n",
      "9244 (5, 1) [D loss: (-0.8848)(R -0.9162, F 0.0094, G 0.0022)] [G loss: 0.0657]\n",
      "9245 (5, 1) [D loss: (-0.9364)(R -0.6815, F -0.2803, G 0.0025)] [G loss: 0.1878]\n",
      "9246 (5, 1) [D loss: (-1.0932)(R -0.7899, F -0.3338, G 0.0030)] [G loss: 0.3450]\n",
      "9247 (5, 1) [D loss: (-0.9460)(R -0.3099, F -0.6686, G 0.0033)] [G loss: 0.6530]\n",
      "9248 (5, 1) [D loss: (-1.0636)(R -0.2843, F -0.8210, G 0.0042)] [G loss: 0.8600]\n",
      "9249 (5, 1) [D loss: (-1.0602)(R 0.0082, F -1.1149, G 0.0046)] [G loss: 0.9761]\n",
      "9250 (5, 1) [D loss: (-0.8554)(R -0.1441, F -0.7556, G 0.0044)] [G loss: 0.9859]\n",
      "9251 (5, 1) [D loss: (-1.1710)(R 0.2484, F -1.4614, G 0.0042)] [G loss: 1.5785]\n",
      "9252 (5, 1) [D loss: (-0.8428)(R 0.8071, F -1.6959, G 0.0046)] [G loss: 1.5796]\n",
      "9253 (5, 1) [D loss: (-1.1329)(R 0.1478, F -1.3170, G 0.0036)] [G loss: 1.6395]\n",
      "9254 (5, 1) [D loss: (-1.0134)(R -0.2433, F -0.8115, G 0.0041)] [G loss: 0.5776]\n",
      "9255 (5, 1) [D loss: (-1.0831)(R -1.2576, F 0.1332, G 0.0041)] [G loss: -0.2523]\n",
      "9256 (5, 1) [D loss: (-0.8912)(R -1.8907, F 0.9449, G 0.0055)] [G loss: -1.0961]\n",
      "9257 (5, 1) [D loss: (-0.7307)(R -2.6718, F 1.8894, G 0.0052)] [G loss: -2.0403]\n",
      "9258 (5, 1) [D loss: (-0.6560)(R -2.5892, F 1.8912, G 0.0042)] [G loss: -1.6782]\n",
      "9259 (5, 1) [D loss: (-1.1442)(R -2.9619, F 1.7769, G 0.0041)] [G loss: -1.8552]\n",
      "9260 (5, 1) [D loss: (-1.1174)(R -3.2050, F 2.0533, G 0.0034)] [G loss: -2.4199]\n",
      "9261 (5, 1) [D loss: (-0.8480)(R -2.3932, F 1.5185, G 0.0027)] [G loss: -1.3439]\n",
      "9262 (5, 1) [D loss: (-0.7553)(R -1.9506, F 1.1655, G 0.0030)] [G loss: -1.0284]\n",
      "9263 (5, 1) [D loss: (-0.7596)(R -1.3709, F 0.5854, G 0.0026)] [G loss: -0.6067]\n",
      "9264 (5, 1) [D loss: (-1.1861)(R -1.1423, F -0.0670, G 0.0023)] [G loss: -0.1646]\n",
      "9265 (5, 1) [D loss: (-0.5999)(R -1.2858, F 0.6590, G 0.0027)] [G loss: -0.6518]\n",
      "9266 (5, 1) [D loss: (-0.6740)(R -1.5777, F 0.8726, G 0.0031)] [G loss: -0.3789]\n",
      "9267 (5, 1) [D loss: (-1.0045)(R -1.6595, F 0.6280, G 0.0027)] [G loss: -1.0137]\n",
      "9268 (5, 1) [D loss: (-1.1622)(R -2.2975, F 1.1019, G 0.0033)] [G loss: -1.5734]\n",
      "9269 (5, 1) [D loss: (-1.0431)(R -2.5007, F 1.4183, G 0.0039)] [G loss: -1.4655]\n",
      "9270 (5, 1) [D loss: (-1.2452)(R -2.5437, F 1.2639, G 0.0035)] [G loss: -1.4683]\n",
      "9271 (5, 1) [D loss: (-0.5582)(R -2.2516, F 1.6583, G 0.0035)] [G loss: -1.5675]\n",
      "9272 (5, 1) [D loss: (-0.4797)(R -2.0193, F 1.5101, G 0.0029)] [G loss: -1.3450]\n",
      "9273 (5, 1) [D loss: (-0.5194)(R -1.8263, F 1.2722, G 0.0035)] [G loss: -1.3100]\n",
      "9274 (5, 1) [D loss: (-0.4667)(R -1.6954, F 1.2021, G 0.0027)] [G loss: -0.9878]\n",
      "9275 (5, 1) [D loss: (-0.8610)(R -1.5711, F 0.6793, G 0.0031)] [G loss: -0.6021]\n",
      "9276 (5, 1) [D loss: (-0.7003)(R -1.6399, F 0.8962, G 0.0043)] [G loss: -0.7108]\n",
      "9277 (5, 1) [D loss: (-1.1131)(R -1.7042, F 0.5536, G 0.0038)] [G loss: -0.6984]\n",
      "9278 (5, 1) [D loss: (-0.7667)(R -1.8034, F 0.9948, G 0.0042)] [G loss: -1.0407]\n",
      "9279 (5, 1) [D loss: (-0.6442)(R -1.9513, F 1.2633, G 0.0044)] [G loss: -1.2510]\n",
      "9280 (5, 1) [D loss: (-1.1048)(R -2.1904, F 1.0471, G 0.0038)] [G loss: -1.1590]\n",
      "9281 (5, 1) [D loss: (-0.4690)(R -2.1233, F 1.6223, G 0.0032)] [G loss: -1.6711]\n",
      "9282 (5, 1) [D loss: (-0.6311)(R -2.5147, F 1.8575, G 0.0026)] [G loss: -1.8490]\n",
      "9283 (5, 1) [D loss: (-0.5296)(R -2.3759, F 1.8239, G 0.0022)] [G loss: -1.9291]\n",
      "9284 (5, 1) [D loss: (-0.9004)(R -2.3722, F 1.4499, G 0.0022)] [G loss: -1.5722]\n",
      "9285 (5, 1) [D loss: (-0.8119)(R -1.8847, F 1.0534, G 0.0019)] [G loss: -0.8341]\n",
      "9286 (5, 1) [D loss: (-1.1860)(R -1.2137, F 0.0030, G 0.0025)] [G loss: -0.1590]\n",
      "9287 (5, 1) [D loss: (-1.1846)(R -0.3706, F -0.8420, G 0.0028)] [G loss: 1.0776]\n",
      "9288 (5, 1) [D loss: (-1.1949)(R 0.7944, F -2.0344, G 0.0045)] [G loss: 1.9423]\n",
      "9289 (5, 1) [D loss: (-0.8870)(R 1.5773, F -2.5186, G 0.0054)] [G loss: 2.7580]\n",
      "9290 (5, 1) [D loss: (-0.8131)(R 2.6576, F -3.5129, G 0.0042)] [G loss: 3.6902]\n",
      "9291 (5, 1) [D loss: (-0.9409)(R 3.4120, F -4.4179, G 0.0065)] [G loss: 4.5462]\n",
      "9292 (5, 1) [D loss: (-0.9150)(R 3.6642, F -4.6367, G 0.0058)] [G loss: 4.6296]\n",
      "9293 (5, 1) [D loss: (-0.9479)(R 3.3817, F -4.3730, G 0.0043)] [G loss: 4.0486]\n",
      "9294 (5, 1) [D loss: (-1.0713)(R 3.2399, F -4.3494, G 0.0038)] [G loss: 4.1356]\n",
      "9295 (5, 1) [D loss: (-0.8211)(R 3.3467, F -4.2095, G 0.0042)] [G loss: 3.9708]\n",
      "9296 (5, 1) [D loss: (-0.8443)(R 2.8295, F -3.7188, G 0.0045)] [G loss: 3.6207]\n",
      "9297 (5, 1) [D loss: (-1.1470)(R 2.1596, F -3.3520, G 0.0045)] [G loss: 3.1220]\n",
      "9298 (5, 1) [D loss: (-0.8229)(R 1.8727, F -2.7423, G 0.0047)] [G loss: 2.5796]\n",
      "9299 (5, 1) [D loss: (-1.2617)(R 1.2533, F -2.5538, G 0.0039)] [G loss: 2.5348]\n",
      "9300 (5, 1) [D loss: (-0.8109)(R 1.8407, F -2.6851, G 0.0034)] [G loss: 2.6114]\n",
      "9301 (5, 1) [D loss: (-1.1340)(R 1.3384, F -2.5079, G 0.0035)] [G loss: 2.4984]\n",
      "9302 (5, 1) [D loss: (-0.9326)(R 1.1419, F -2.0959, G 0.0021)] [G loss: 2.2046]\n",
      "9303 (5, 1) [D loss: (-0.7301)(R 0.8876, F -1.6405, G 0.0023)] [G loss: 1.8696]\n",
      "9304 (5, 1) [D loss: (-0.9145)(R 0.4105, F -1.3441, G 0.0019)] [G loss: 1.4888]\n",
      "9305 (5, 1) [D loss: (-0.5158)(R 0.3592, F -0.8954, G 0.0020)] [G loss: 0.8095]\n",
      "9306 (5, 1) [D loss: (-0.6392)(R -0.1703, F -0.4881, G 0.0019)] [G loss: 0.4877]\n",
      "9307 (5, 1) [D loss: (-0.8044)(R 0.1661, F -0.9936, G 0.0023)] [G loss: 0.8331]\n",
      "9308 (5, 1) [D loss: (-1.1213)(R 0.5184, F -1.6667, G 0.0027)] [G loss: 1.7297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9309 (5, 1) [D loss: (-1.1987)(R 1.2031, F -2.4404, G 0.0039)] [G loss: 2.4225]\n",
      "9310 (5, 1) [D loss: (-1.0926)(R 2.3400, F -3.4810, G 0.0048)] [G loss: 3.4336]\n",
      "9311 (5, 1) [D loss: (-1.2010)(R 3.5007, F -4.7650, G 0.0063)] [G loss: 4.1953]\n",
      "9312 (5, 1) [D loss: (-0.7270)(R 3.3434, F -4.1437, G 0.0073)] [G loss: 4.5809]\n",
      "9313 (5, 1) [D loss: (-0.9609)(R 3.1898, F -4.1982, G 0.0047)] [G loss: 3.6826]\n",
      "9314 (5, 1) [D loss: (-0.5680)(R 2.6730, F -3.2755, G 0.0034)] [G loss: 2.9798]\n",
      "9315 (5, 1) [D loss: (-0.9001)(R 1.0024, F -1.9281, G 0.0026)] [G loss: 1.7649]\n",
      "9316 (5, 1) [D loss: (-0.7717)(R -0.7241, F -0.0722, G 0.0025)] [G loss: -0.5031]\n",
      "9317 (5, 1) [D loss: (-0.9300)(R -3.9497, F 2.9790, G 0.0041)] [G loss: -3.5168]\n",
      "9318 (5, 1) [D loss: (-0.7922)(R -5.2368, F 4.3837, G 0.0061)] [G loss: -4.5040]\n",
      "9319 (5, 1) [D loss: (-1.1352)(R -6.1535, F 4.9415, G 0.0077)] [G loss: -5.0709]\n",
      "9320 (5, 1) [D loss: (-0.8171)(R -6.8521, F 5.9560, G 0.0079)] [G loss: -5.6875]\n",
      "9321 (5, 1) [D loss: (-1.3998)(R -7.2310, F 5.7576, G 0.0074)] [G loss: -6.3724]\n",
      "9322 (5, 1) [D loss: (-0.4527)(R -6.7364, F 6.2196, G 0.0064)] [G loss: -5.9507]\n",
      "9323 (5, 1) [D loss: (-0.8210)(R -6.2249, F 5.3761, G 0.0028)] [G loss: -5.6608]\n",
      "9324 (5, 1) [D loss: (-0.7252)(R -5.8622, F 5.1145, G 0.0022)] [G loss: -4.8966]\n",
      "9325 (5, 1) [D loss: (-0.6610)(R -4.9897, F 4.3172, G 0.0011)] [G loss: -4.2068]\n",
      "9326 (5, 1) [D loss: (-0.9802)(R -4.8292, F 3.8326, G 0.0016)] [G loss: -4.1002]\n",
      "9327 (5, 1) [D loss: (-0.9612)(R -4.8424, F 3.8607, G 0.0021)] [G loss: -3.8869]\n",
      "9328 (5, 1) [D loss: (-1.0466)(R -4.2769, F 3.2017, G 0.0029)] [G loss: -2.8094]\n",
      "9329 (5, 1) [D loss: (-0.8173)(R -2.8544, F 2.0165, G 0.0021)] [G loss: -1.8343]\n",
      "9330 (5, 1) [D loss: (-0.9093)(R -1.7422, F 0.8043, G 0.0029)] [G loss: -0.7546]\n",
      "9331 (5, 1) [D loss: (-0.7562)(R -0.6418, F -0.1502, G 0.0036)] [G loss: 0.0622]\n",
      "9332 (5, 1) [D loss: (-0.7462)(R 0.2721, F -1.0550, G 0.0037)] [G loss: 1.2286]\n",
      "9333 (5, 1) [D loss: (-0.3919)(R 1.3196, F -1.7462, G 0.0035)] [G loss: 2.1763]\n",
      "9334 (5, 1) [D loss: (-0.6164)(R 1.6472, F -2.3058, G 0.0042)] [G loss: 2.5314]\n",
      "9335 (5, 1) [D loss: (-0.8071)(R 1.4578, F -2.3021, G 0.0037)] [G loss: 2.3368]\n",
      "9336 (5, 1) [D loss: (-1.0161)(R 0.9293, F -1.9806, G 0.0035)] [G loss: 2.1539]\n",
      "9337 (5, 1) [D loss: (-1.1576)(R 0.5096, F -1.7043, G 0.0037)] [G loss: 1.5301]\n",
      "9338 (5, 1) [D loss: (-1.0475)(R -0.1749, F -0.9165, G 0.0044)] [G loss: 0.9032]\n",
      "9339 (5, 1) [D loss: (-0.9266)(R -1.1137, F 0.1532, G 0.0034)] [G loss: 0.1252]\n",
      "9340 (5, 1) [D loss: (-0.7865)(R -1.1169, F 0.2967, G 0.0034)] [G loss: -0.3808]\n",
      "9341 (5, 1) [D loss: (-0.9330)(R -1.3656, F 0.3993, G 0.0033)] [G loss: -0.4772]\n",
      "9342 (5, 1) [D loss: (-0.7715)(R -1.3589, F 0.5520, G 0.0035)] [G loss: -0.7148]\n",
      "9343 (5, 1) [D loss: (-0.5789)(R -1.0407, F 0.4362, G 0.0025)] [G loss: -0.3355]\n",
      "9344 (5, 1) [D loss: (-1.0149)(R -0.5432, F -0.4990, G 0.0027)] [G loss: 0.5107]\n",
      "9345 (5, 1) [D loss: (-0.6148)(R 0.7893, F -1.4257, G 0.0022)] [G loss: 1.3069]\n",
      "9346 (5, 1) [D loss: (-0.9651)(R 1.4210, F -2.4241, G 0.0038)] [G loss: 2.6072]\n",
      "9347 (5, 1) [D loss: (-1.0818)(R 2.3753, F -3.5005, G 0.0043)] [G loss: 3.4771]\n",
      "9348 (5, 1) [D loss: (-0.7614)(R 3.2153, F -4.0304, G 0.0054)] [G loss: 4.0203]\n",
      "9349 (5, 1) [D loss: (-0.9790)(R 3.2378, F -4.2678, G 0.0051)] [G loss: 4.4086]\n",
      "9350 (5, 1) [D loss: (-0.5509)(R 3.1195, F -3.7166, G 0.0046)] [G loss: 3.4858]\n",
      "9351 (5, 1) [D loss: (-0.2312)(R 2.4761, F -2.7339, G 0.0027)] [G loss: 3.0013]\n",
      "9352 (5, 1) [D loss: (-0.7593)(R 1.3463, F -2.1314, G 0.0026)] [G loss: 1.7205]\n",
      "9353 (5, 1) [D loss: (-0.9706)(R -0.5430, F -0.4499, G 0.0022)] [G loss: 0.6182]\n",
      "9354 (5, 1) [D loss: (-1.2972)(R -0.2975, F -1.0223, G 0.0023)] [G loss: 0.9246]\n",
      "9355 (5, 1) [D loss: (-1.1240)(R 0.3361, F -1.4816, G 0.0022)] [G loss: 1.4850]\n",
      "9356 (5, 1) [D loss: (-1.0484)(R 0.3884, F -1.4765, G 0.0040)] [G loss: 1.4943]\n",
      "9357 (5, 1) [D loss: (-0.9095)(R 0.1869, F -1.1308, G 0.0034)] [G loss: 1.2226]\n",
      "9358 (5, 1) [D loss: (-0.7509)(R 0.1447, F -0.9390, G 0.0043)] [G loss: 0.8957]\n",
      "9359 (5, 1) [D loss: (-0.7578)(R 0.3924, F -1.1963, G 0.0046)] [G loss: 1.3668]\n",
      "9360 (5, 1) [D loss: (-0.8055)(R 0.9140, F -1.7585, G 0.0039)] [G loss: 1.9423]\n",
      "9361 (5, 1) [D loss: (-0.4528)(R 1.9327, F -2.4249, G 0.0039)] [G loss: 2.2892]\n",
      "9362 (5, 1) [D loss: (-0.4546)(R 1.6040, F -2.0994, G 0.0041)] [G loss: 2.0406]\n",
      "9363 (5, 1) [D loss: (-0.7403)(R 1.2331, F -1.9990, G 0.0026)] [G loss: 1.7440]\n",
      "9364 (5, 1) [D loss: (-0.9530)(R 0.0230, F -1.0041, G 0.0028)] [G loss: 1.1249]\n",
      "9365 (5, 1) [D loss: (-0.8317)(R 0.0316, F -0.8925, G 0.0029)] [G loss: 0.8869]\n",
      "9366 (5, 1) [D loss: (-0.9718)(R -0.5886, F -0.4136, G 0.0030)] [G loss: 0.2652]\n",
      "9367 (5, 1) [D loss: (-0.7298)(R -0.9798, F 0.2177, G 0.0032)] [G loss: -0.2346]\n",
      "9368 (5, 1) [D loss: (-0.8165)(R -1.6139, F 0.7647, G 0.0033)] [G loss: -0.4976]\n",
      "9369 (5, 1) [D loss: (-0.7868)(R -1.8005, F 0.9798, G 0.0034)] [G loss: -0.7747]\n",
      "9370 (5, 1) [D loss: (-0.5770)(R -1.4638, F 0.8622, G 0.0025)] [G loss: -0.3067]\n",
      "9371 (5, 1) [D loss: (-1.1621)(R -1.3617, F 0.1746, G 0.0025)] [G loss: -0.2899]\n",
      "9372 (5, 1) [D loss: (-0.7288)(R -0.4854, F -0.2689, G 0.0026)] [G loss: 0.2996]\n",
      "9373 (5, 1) [D loss: (-0.8047)(R -0.1688, F -0.6686, G 0.0033)] [G loss: 0.8744]\n",
      "9374 (5, 1) [D loss: (-0.9978)(R -0.7569, F -0.2773, G 0.0036)] [G loss: 0.5099]\n",
      "9375 (5, 1) [D loss: (-0.8644)(R -0.4548, F -0.4470, G 0.0037)] [G loss: 0.5346]\n",
      "9376 (5, 1) [D loss: (-0.8594)(R -0.5280, F -0.3649, G 0.0034)] [G loss: 0.3650]\n",
      "9377 (5, 1) [D loss: (-0.8610)(R -1.2903, F 0.3989, G 0.0030)] [G loss: -0.5284]\n",
      "9378 (5, 1) [D loss: (-1.1166)(R -2.3263, F 1.1727, G 0.0037)] [G loss: -1.7110]\n",
      "9379 (5, 1) [D loss: (-1.0500)(R -3.3356, F 2.2387, G 0.0047)] [G loss: -2.5023]\n",
      "9380 (5, 1) [D loss: (-0.9898)(R -3.3889, F 2.3555, G 0.0044)] [G loss: -2.4244]\n",
      "9381 (5, 1) [D loss: (-0.9006)(R -3.2206, F 2.2778, G 0.0042)] [G loss: -1.8436]\n",
      "9382 (5, 1) [D loss: (-0.7093)(R -2.3361, F 1.5983, G 0.0028)] [G loss: -1.6382]\n",
      "9383 (5, 1) [D loss: (-1.0280)(R -1.6242, F 0.5680, G 0.0028)] [G loss: -0.8168]\n",
      "9384 (5, 1) [D loss: (-1.0055)(R -1.1657, F 0.1419, G 0.0018)] [G loss: -0.2458]\n",
      "9385 (5, 1) [D loss: (-0.9908)(R -0.9318, F -0.0809, G 0.0022)] [G loss: -0.0865]\n",
      "9386 (5, 1) [D loss: (-0.9631)(R -0.6748, F -0.3173, G 0.0029)] [G loss: 0.4912]\n",
      "9387 (5, 1) [D loss: (-0.7637)(R -0.1106, F -0.6799, G 0.0027)] [G loss: 0.5786]\n",
      "9388 (5, 1) [D loss: (-0.5579)(R 0.3414, F -0.9257, G 0.0026)] [G loss: 1.3730]\n",
      "9389 (5, 1) [D loss: (-0.7205)(R 0.8684, F -1.6133, G 0.0024)] [G loss: 1.8532]\n",
      "9390 (5, 1) [D loss: (-0.8485)(R 1.3613, F -2.2460, G 0.0036)] [G loss: 2.2622]\n",
      "9391 (5, 1) [D loss: (-1.1072)(R 1.7195, F -2.8649, G 0.0038)] [G loss: 2.6274]\n",
      "9392 (5, 1) [D loss: (-1.2085)(R 1.7968, F -3.0427, G 0.0037)] [G loss: 2.7537]\n",
      "9393 (5, 1) [D loss: (-1.1036)(R 2.3116, F -3.4527, G 0.0037)] [G loss: 3.8818]\n",
      "9394 (5, 1) [D loss: (-0.6523)(R 3.4753, F -4.1669, G 0.0039)] [G loss: 4.5032]\n",
      "9395 (5, 1) [D loss: (-1.1109)(R 3.8101, F -4.9733, G 0.0052)] [G loss: 4.9944]\n",
      "9396 (5, 1) [D loss: (-1.0997)(R 5.1812, F -6.3461, G 0.0065)] [G loss: 6.0598]\n",
      "9397 (5, 1) [D loss: (-0.9246)(R 5.5635, F -6.5474, G 0.0059)] [G loss: 6.4892]\n",
      "9398 (5, 1) [D loss: (-1.3467)(R 5.9687, F -7.3684, G 0.0053)] [G loss: 7.0078]\n",
      "9399 (5, 1) [D loss: (-1.1840)(R 6.2523, F -7.4969, G 0.0061)] [G loss: 7.3209]\n",
      "9400 (5, 1) [D loss: (-1.1564)(R 5.4466, F -6.6483, G 0.0045)] [G loss: 6.4082]\n",
      "9401 (5, 1) [D loss: (-1.2654)(R 4.0336, F -5.3288, G 0.0030)] [G loss: 5.1532]\n",
      "9402 (5, 1) [D loss: (-0.7590)(R 3.7894, F -4.5743, G 0.0026)] [G loss: 4.4640]\n",
      "9403 (5, 1) [D loss: (-0.8206)(R 2.3115, F -3.1474, G 0.0015)] [G loss: 2.4786]\n",
      "9404 (5, 1) [D loss: (-0.9119)(R 0.3328, F -1.2611, G 0.0016)] [G loss: 1.0209]\n",
      "9405 (5, 1) [D loss: (-0.5412)(R -1.2067, F 0.6409, G 0.0025)] [G loss: -0.4889]\n",
      "9406 (5, 1) [D loss: (-0.9558)(R -1.2806, F 0.3018, G 0.0023)] [G loss: -0.3968]\n",
      "9407 (5, 1) [D loss: (-0.7276)(R -1.2877, F 0.5335, G 0.0027)] [G loss: -0.5457]\n",
      "9408 (5, 1) [D loss: (-0.6075)(R -1.2843, F 0.6591, G 0.0018)] [G loss: -0.4287]\n",
      "9409 (5, 1) [D loss: (-0.6559)(R -0.3223, F -0.3525, G 0.0019)] [G loss: 0.8349]\n",
      "9410 (5, 1) [D loss: (-1.1986)(R 0.9174, F -2.1401, G 0.0024)] [G loss: 2.5891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9411 (5, 1) [D loss: (-1.1447)(R 2.5594, F -3.7616, G 0.0058)] [G loss: 3.4138]\n",
      "9412 (5, 1) [D loss: (-0.9022)(R 3.1560, F -4.1201, G 0.0062)] [G loss: 4.1679]\n",
      "9413 (5, 1) [D loss: (-1.0477)(R 3.3700, F -4.4707, G 0.0053)] [G loss: 4.4516]\n",
      "9414 (5, 1) [D loss: (-0.9125)(R 3.4864, F -4.4518, G 0.0053)] [G loss: 4.2566]\n",
      "9415 (5, 1) [D loss: (-0.6831)(R 3.3848, F -4.1134, G 0.0045)] [G loss: 3.6964]\n",
      "9416 (5, 1) [D loss: (-0.7533)(R 2.1607, F -2.9478, G 0.0034)] [G loss: 2.8465]\n",
      "9417 (5, 1) [D loss: (-0.7365)(R 0.9017, F -1.6657, G 0.0028)] [G loss: 1.2366]\n",
      "9418 (5, 1) [D loss: (-0.8461)(R 0.0698, F -0.9405, G 0.0025)] [G loss: 0.6858]\n",
      "9419 (5, 1) [D loss: (-0.6795)(R -0.7304, F 0.0147, G 0.0036)] [G loss: 0.1587]\n",
      "9420 (5, 1) [D loss: (-0.8154)(R -1.2768, F 0.4256, G 0.0036)] [G loss: -0.3796]\n",
      "9421 (5, 1) [D loss: (-1.0547)(R -1.6181, F 0.5324, G 0.0031)] [G loss: -0.3894]\n",
      "9422 (5, 1) [D loss: (-0.8207)(R -1.4972, F 0.6383, G 0.0038)] [G loss: -0.4057]\n",
      "9423 (5, 1) [D loss: (-0.8735)(R -0.9867, F 0.0825, G 0.0031)] [G loss: -0.0184]\n",
      "9424 (5, 1) [D loss: (-0.9777)(R -1.0011, F -0.0104, G 0.0034)] [G loss: -0.0055]\n",
      "9425 (5, 1) [D loss: (-0.8987)(R -1.4185, F 0.4803, G 0.0040)] [G loss: -0.6889]\n",
      "9426 (5, 1) [D loss: (-0.6564)(R -1.6262, F 0.9398, G 0.0030)] [G loss: -0.9326]\n",
      "9427 (5, 1) [D loss: (-0.9892)(R -2.5707, F 1.5404, G 0.0041)] [G loss: -2.3131]\n",
      "9428 (5, 1) [D loss: (-0.9540)(R -3.4716, F 2.4750, G 0.0043)] [G loss: -2.5203]\n",
      "9429 (5, 1) [D loss: (-0.7163)(R -4.1630, F 3.3974, G 0.0049)] [G loss: -3.6107]\n",
      "9430 (5, 1) [D loss: (-0.9193)(R -4.8139, F 3.8405, G 0.0054)] [G loss: -4.0104]\n",
      "9431 (5, 1) [D loss: (-1.0563)(R -5.3503, F 4.2412, G 0.0053)] [G loss: -4.4231]\n",
      "9432 (5, 1) [D loss: (-0.7614)(R -4.9454, F 4.1317, G 0.0052)] [G loss: -4.3516]\n",
      "9433 (5, 1) [D loss: (-0.9524)(R -4.3283, F 3.3420, G 0.0034)] [G loss: -3.1396]\n",
      "9434 (5, 1) [D loss: (-0.5983)(R -2.9448, F 2.3180, G 0.0029)] [G loss: -1.9297]\n",
      "9435 (5, 1) [D loss: (-0.6776)(R -2.4980, F 1.7955, G 0.0025)] [G loss: -1.4196]\n",
      "9436 (5, 1) [D loss: (-0.5143)(R -1.2728, F 0.7333, G 0.0025)] [G loss: -0.5040]\n",
      "9437 (5, 1) [D loss: (-0.6787)(R -0.7572, F 0.0517, G 0.0027)] [G loss: 0.3644]\n",
      "9438 (5, 1) [D loss: (-1.0519)(R -0.1039, F -0.9825, G 0.0034)] [G loss: 0.9420]\n",
      "9439 (5, 1) [D loss: (-0.8440)(R 0.1183, F -0.9934, G 0.0031)] [G loss: 1.0423]\n",
      "9440 (5, 1) [D loss: (-0.8155)(R 0.2310, F -1.0816, G 0.0035)] [G loss: 0.9361]\n",
      "9441 (5, 1) [D loss: (-0.7689)(R -0.8302, F 0.0221, G 0.0039)] [G loss: -0.1827]\n",
      "9442 (5, 1) [D loss: (-0.8455)(R -1.6338, F 0.7569, G 0.0031)] [G loss: -0.9442]\n",
      "9443 (5, 1) [D loss: (-0.9862)(R -2.3806, F 1.3602, G 0.0034)] [G loss: -1.3779]\n",
      "9444 (5, 1) [D loss: (-1.0049)(R -1.8685, F 0.8215, G 0.0042)] [G loss: -0.9291]\n",
      "9445 (5, 1) [D loss: (-0.9482)(R -1.9035, F 0.9175, G 0.0038)] [G loss: -0.8982]\n",
      "9446 (5, 1) [D loss: (-0.9552)(R -1.8807, F 0.8887, G 0.0037)] [G loss: -0.7771]\n",
      "9447 (5, 1) [D loss: (-1.0770)(R -1.3634, F 0.2553, G 0.0031)] [G loss: -0.4388]\n",
      "9448 (5, 1) [D loss: (-0.8960)(R -0.3690, F -0.5579, G 0.0031)] [G loss: 0.6201]\n",
      "9449 (5, 1) [D loss: (-1.2544)(R 0.7314, F -2.0204, G 0.0035)] [G loss: 2.0903]\n",
      "9450 (5, 1) [D loss: (-0.5594)(R 2.2638, F -2.8608, G 0.0038)] [G loss: 2.8284]\n",
      "9451 (5, 1) [D loss: (-1.3020)(R 2.1271, F -3.4825, G 0.0053)] [G loss: 3.5743]\n",
      "9452 (5, 1) [D loss: (-0.8711)(R 2.5137, F -3.4432, G 0.0058)] [G loss: 3.3651]\n",
      "9453 (5, 1) [D loss: (-0.7542)(R 2.6747, F -3.4723, G 0.0043)] [G loss: 3.3513]\n",
      "9454 (5, 1) [D loss: (-0.6902)(R 2.1107, F -2.8339, G 0.0033)] [G loss: 2.4016]\n",
      "9455 (5, 1) [D loss: (-1.0346)(R 0.4756, F -1.5318, G 0.0022)] [G loss: 1.5035]\n",
      "9456 (5, 1) [D loss: (-1.0506)(R -0.1878, F -0.8848, G 0.0022)] [G loss: 0.7505]\n",
      "9457 (5, 1) [D loss: (-0.7236)(R -0.5349, F -0.2236, G 0.0035)] [G loss: 0.4963]\n",
      "9458 (5, 1) [D loss: (-0.8556)(R -0.3021, F -0.5945, G 0.0041)] [G loss: 0.9098]\n",
      "9459 (5, 1) [D loss: (-1.0638)(R -0.0239, F -1.0780, G 0.0038)] [G loss: 1.2176]\n",
      "9460 (5, 1) [D loss: (-0.9071)(R 1.5622, F -2.5124, G 0.0043)] [G loss: 2.5428]\n",
      "9461 (5, 1) [D loss: (-1.1044)(R 2.8809, F -4.0236, G 0.0038)] [G loss: 4.1420]\n",
      "9462 (5, 1) [D loss: (-0.4108)(R 5.0506, F -5.5430, G 0.0082)] [G loss: 5.5480]\n",
      "9463 (5, 1) [D loss: (-1.0653)(R 5.1749, F -6.3151, G 0.0075)] [G loss: 6.1811]\n",
      "9464 (5, 1) [D loss: (-1.4686)(R 5.4977, F -7.0490, G 0.0083)] [G loss: 6.3940]\n",
      "9465 (5, 1) [D loss: (-0.8133)(R 4.9691, F -5.8376, G 0.0055)] [G loss: 5.7625]\n",
      "9466 (5, 1) [D loss: (-0.6910)(R 3.7396, F -4.4571, G 0.0027)] [G loss: 4.4235]\n",
      "9467 (5, 1) [D loss: (-0.4983)(R 2.4583, F -2.9775, G 0.0021)] [G loss: 2.6419]\n",
      "9468 (5, 1) [D loss: (-0.6443)(R 0.0350, F -0.6972, G 0.0018)] [G loss: 0.0131]\n",
      "9469 (5, 1) [D loss: (-0.6171)(R -1.6965, F 1.0571, G 0.0022)] [G loss: -0.9381]\n",
      "9470 (5, 1) [D loss: (-0.5861)(R -2.5606, F 1.9525, G 0.0022)] [G loss: -2.4218]\n",
      "9471 (5, 1) [D loss: (-0.8397)(R -3.6827, F 2.8190, G 0.0024)] [G loss: -3.0401]\n",
      "9472 (5, 1) [D loss: (-0.9891)(R -4.0395, F 3.0172, G 0.0033)] [G loss: -3.3568]\n",
      "9473 (5, 1) [D loss: (-1.1308)(R -3.1504, F 1.9994, G 0.0020)] [G loss: -1.8205]\n",
      "9474 (5, 1) [D loss: (-0.6568)(R -2.4082, F 1.7317, G 0.0020)] [G loss: -1.0302]\n",
      "9475 (5, 1) [D loss: (-0.9364)(R -1.1991, F 0.2316, G 0.0031)] [G loss: 0.1625]\n",
      "9476 (5, 1) [D loss: (-0.9408)(R 0.0754, F -1.0482, G 0.0032)] [G loss: 1.2728]\n",
      "9477 (5, 1) [D loss: (-1.3196)(R 0.2081, F -1.5717, G 0.0044)] [G loss: 1.2000]\n",
      "9478 (5, 1) [D loss: (-0.5036)(R 0.5349, F -1.0899, G 0.0051)] [G loss: 0.9913]\n",
      "9479 (5, 1) [D loss: (-0.9033)(R 0.0125, F -0.9523, G 0.0036)] [G loss: 0.8405]\n",
      "9480 (5, 1) [D loss: (-0.6039)(R -1.4956, F 0.8637, G 0.0028)] [G loss: -1.0735]\n",
      "9481 (5, 1) [D loss: (-0.7580)(R -2.9958, F 2.2003, G 0.0038)] [G loss: -2.5417]\n",
      "9482 (5, 1) [D loss: (-0.8314)(R -4.6235, F 3.7465, G 0.0046)] [G loss: -3.8929]\n",
      "9483 (5, 1) [D loss: (-0.9470)(R -5.1226, F 4.1191, G 0.0056)] [G loss: -4.5555]\n",
      "9484 (5, 1) [D loss: (-0.6177)(R -4.7055, F 4.0411, G 0.0047)] [G loss: -3.5888]\n",
      "9485 (5, 1) [D loss: (-0.6384)(R -3.8503, F 3.1815, G 0.0030)] [G loss: -3.1830]\n",
      "9486 (5, 1) [D loss: (-0.7461)(R -3.2240, F 2.4571, G 0.0021)] [G loss: -2.2117]\n",
      "9487 (5, 1) [D loss: (-0.6705)(R -2.0242, F 1.3352, G 0.0019)] [G loss: -1.2332]\n",
      "9488 (5, 1) [D loss: (-0.8737)(R -1.0051, F 0.1097, G 0.0022)] [G loss: -0.0561]\n",
      "9489 (5, 1) [D loss: (-1.1087)(R -0.2812, F -0.8574, G 0.0030)] [G loss: 0.6790]\n",
      "9490 (5, 1) [D loss: (-1.2400)(R -0.0714, F -1.2092, G 0.0041)] [G loss: 1.6439]\n",
      "9491 (5, 1) [D loss: (-1.1309)(R 0.4106, F -1.5822, G 0.0041)] [G loss: 1.4191]\n",
      "9492 (5, 1) [D loss: (-0.7612)(R -0.0691, F -0.7213, G 0.0029)] [G loss: 0.8400]\n",
      "9493 (5, 1) [D loss: (-0.6971)(R -0.2491, F -0.4708, G 0.0023)] [G loss: 0.2850]\n",
      "9494 (5, 1) [D loss: (-1.3046)(R -1.2487, F -0.0807, G 0.0025)] [G loss: -0.0997]\n",
      "9495 (5, 1) [D loss: (-1.1451)(R -1.8744, F 0.7070, G 0.0022)] [G loss: -0.9566]\n",
      "9496 (5, 1) [D loss: (-1.0347)(R -2.1698, F 1.1044, G 0.0031)] [G loss: -1.3386]\n",
      "9497 (5, 1) [D loss: (-0.9913)(R -1.8817, F 0.8648, G 0.0026)] [G loss: -0.7556]\n",
      "9498 (5, 1) [D loss: (-0.9526)(R -0.5181, F -0.4671, G 0.0033)] [G loss: 0.5548]\n",
      "9499 (5, 1) [D loss: (-1.4322)(R 0.6012, F -2.0663, G 0.0033)] [G loss: 2.0742]\n",
      "9500 (5, 1) [D loss: (-1.3076)(R 3.0972, F -4.4683, G 0.0064)] [G loss: 4.5760]\n",
      "9501 (5, 1) [D loss: (-1.0822)(R 5.0408, F -6.2656, G 0.0143)] [G loss: 6.3373]\n",
      "9502 (5, 1) [D loss: (-1.4862)(R 5.9883, F -7.6213, G 0.0147)] [G loss: 7.0714]\n",
      "9503 (5, 1) [D loss: (-1.1524)(R 6.3325, F -7.6243, G 0.0139)] [G loss: 6.8691]\n",
      "9504 (5, 1) [D loss: (-0.7685)(R 5.7387, F -6.5904, G 0.0083)] [G loss: 6.3657]\n",
      "9505 (5, 1) [D loss: (-0.9548)(R 4.9877, F -5.9840, G 0.0041)] [G loss: 5.5704]\n",
      "9506 (5, 1) [D loss: (-1.0653)(R 3.5676, F -4.6494, G 0.0017)] [G loss: 3.5994]\n",
      "9507 (5, 1) [D loss: (-0.4363)(R 1.9482, F -2.3985, G 0.0014)] [G loss: 2.0095]\n",
      "9508 (5, 1) [D loss: (-0.8553)(R -0.3230, F -0.5457, G 0.0013)] [G loss: -0.0054]\n",
      "9509 (5, 1) [D loss: (-1.1794)(R -2.3971, F 1.1985, G 0.0019)] [G loss: -1.4931]\n",
      "9510 (5, 1) [D loss: (-0.4837)(R -3.2635, F 2.7505, G 0.0029)] [G loss: -2.7068]\n",
      "9511 (5, 1) [D loss: (-1.0098)(R -3.6574, F 2.6200, G 0.0028)] [G loss: -2.8032]\n",
      "9512 (5, 1) [D loss: (-0.4519)(R -3.6885, F 3.2186, G 0.0018)] [G loss: -2.7453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9513 (5, 1) [D loss: (-0.1320)(R -2.6000, F 2.4520, G 0.0016)] [G loss: -2.1091]\n",
      "9514 (5, 1) [D loss: (-0.5969)(R -1.7239, F 1.1038, G 0.0023)] [G loss: -0.4153]\n",
      "9515 (5, 1) [D loss: (-1.1898)(R -0.5861, F -0.6370, G 0.0033)] [G loss: 0.6437]\n",
      "9516 (5, 1) [D loss: (-1.0443)(R -0.5989, F -0.4992, G 0.0054)] [G loss: 0.9322]\n",
      "9517 (5, 1) [D loss: (-0.6065)(R -0.5157, F -0.1382, G 0.0047)] [G loss: 0.2990]\n",
      "9518 (5, 1) [D loss: (-1.0586)(R -2.1742, F 1.0767, G 0.0039)] [G loss: -1.4115]\n",
      "9519 (5, 1) [D loss: (-0.5121)(R -3.3513, F 2.8074, G 0.0032)] [G loss: -2.9507]\n",
      "9520 (5, 1) [D loss: (-0.8989)(R -5.1692, F 4.2235, G 0.0047)] [G loss: -4.2795]\n",
      "9521 (5, 1) [D loss: (-1.4074)(R -7.0047, F 5.5120, G 0.0085)] [G loss: -6.1604]\n",
      "9522 (5, 1) [D loss: (-0.7967)(R -7.3976, F 6.5143, G 0.0087)] [G loss: -6.5913]\n",
      "9523 (5, 1) [D loss: (-1.1549)(R -7.4778, F 6.2488, G 0.0074)] [G loss: -6.4175]\n",
      "9524 (5, 1) [D loss: (-0.7310)(R -5.9015, F 5.1326, G 0.0038)] [G loss: -5.0536]\n",
      "9525 (5, 1) [D loss: (-0.7630)(R -4.5920, F 3.8108, G 0.0018)] [G loss: -4.1607]\n",
      "9526 (5, 1) [D loss: (-0.2972)(R -3.9906, F 3.6737, G 0.0020)] [G loss: -3.2741]\n",
      "9527 (5, 1) [D loss: (-1.0121)(R -3.3412, F 2.3091, G 0.0020)] [G loss: -1.6495]\n",
      "9528 (5, 1) [D loss: (-0.7600)(R -2.0180, F 1.2384, G 0.0020)] [G loss: -0.7089]\n",
      "9529 (5, 1) [D loss: (-0.8081)(R -1.4843, F 0.6436, G 0.0033)] [G loss: -0.4246]\n",
      "9530 (5, 1) [D loss: (-0.9470)(R -1.1027, F 0.1207, G 0.0035)] [G loss: -0.4622]\n",
      "9531 (5, 1) [D loss: (-0.9881)(R -0.9951, F -0.0275, G 0.0034)] [G loss: -0.2919]\n",
      "9532 (5, 1) [D loss: (-0.7166)(R -1.0017, F 0.2579, G 0.0027)] [G loss: -0.1958]\n",
      "9533 (5, 1) [D loss: (-0.7381)(R -1.6809, F 0.9121, G 0.0031)] [G loss: -1.0093]\n",
      "9534 (5, 1) [D loss: (-0.7709)(R -2.3906, F 1.5812, G 0.0039)] [G loss: -1.7261]\n",
      "9535 (5, 1) [D loss: (-0.6280)(R -2.4516, F 1.7980, G 0.0026)] [G loss: -1.8093]\n",
      "9536 (5, 1) [D loss: (-0.8305)(R -2.2506, F 1.3949, G 0.0025)] [G loss: -1.4512]\n",
      "9537 (5, 1) [D loss: (-1.0228)(R -1.6805, F 0.6264, G 0.0031)] [G loss: -0.5509]\n",
      "9538 (5, 1) [D loss: (-0.8651)(R -0.6226, F -0.2751, G 0.0033)] [G loss: 0.3115]\n",
      "9539 (5, 1) [D loss: (-0.9162)(R 0.9025, F -1.8588, G 0.0040)] [G loss: 2.0182]\n",
      "9540 (5, 1) [D loss: (-0.9941)(R 2.2389, F -3.3058, G 0.0073)] [G loss: 3.5493]\n",
      "9541 (5, 1) [D loss: (-1.2423)(R 3.5583, F -4.8856, G 0.0085)] [G loss: 4.8676]\n",
      "9542 (5, 1) [D loss: (-1.3783)(R 4.2622, F -5.7455, G 0.0105)] [G loss: 5.6220]\n",
      "9543 (5, 1) [D loss: (-1.1378)(R 4.5204, F -5.7254, G 0.0067)] [G loss: 5.0884]\n",
      "9544 (5, 1) [D loss: (-0.2549)(R 4.0230, F -4.3170, G 0.0039)] [G loss: 4.3519]\n",
      "9545 (5, 1) [D loss: (-1.0833)(R 2.9930, F -4.1081, G 0.0032)] [G loss: 4.0420]\n",
      "9546 (5, 1) [D loss: (-0.7644)(R 2.2653, F -3.0499, G 0.0020)] [G loss: 2.9235]\n",
      "9547 (5, 1) [D loss: (-0.9254)(R 1.2312, F -2.1715, G 0.0015)] [G loss: 2.1583]\n",
      "9548 (5, 1) [D loss: (-0.6908)(R 1.1700, F -1.8767, G 0.0016)] [G loss: 1.6828]\n",
      "9549 (5, 1) [D loss: (-1.0045)(R 0.2843, F -1.3147, G 0.0026)] [G loss: 0.8964]\n",
      "9550 (5, 1) [D loss: (-0.8219)(R 0.2660, F -1.1192, G 0.0031)] [G loss: 1.1347]\n",
      "9551 (5, 1) [D loss: (-0.7486)(R 0.5035, F -1.2914, G 0.0039)] [G loss: 1.6170]\n",
      "9552 (5, 1) [D loss: (-1.2788)(R 1.2720, F -2.5924, G 0.0042)] [G loss: 2.8541]\n",
      "9553 (5, 1) [D loss: (-0.6217)(R 2.5999, F -3.2569, G 0.0035)] [G loss: 3.3411]\n",
      "9554 (5, 1) [D loss: (-1.0084)(R 2.1930, F -3.2338, G 0.0032)] [G loss: 2.8096]\n",
      "9555 (5, 1) [D loss: (-0.9047)(R 1.8618, F -2.7959, G 0.0029)] [G loss: 2.8166]\n",
      "9556 (5, 1) [D loss: (-0.3987)(R 1.5723, F -1.9996, G 0.0029)] [G loss: 1.7126]\n",
      "9557 (5, 1) [D loss: (-0.5607)(R 0.0430, F -0.6234, G 0.0020)] [G loss: 0.3706]\n",
      "9558 (5, 1) [D loss: (-1.2154)(R -2.3346, F 1.0872, G 0.0032)] [G loss: -1.6628]\n",
      "9559 (5, 1) [D loss: (-1.1495)(R -4.3396, F 3.1391, G 0.0051)] [G loss: -3.1585]\n",
      "9560 (5, 1) [D loss: (-1.0300)(R -5.1473, F 4.0288, G 0.0088)] [G loss: -3.8043]\n",
      "9561 (5, 1) [D loss: (-1.0198)(R -5.1204, F 4.0248, G 0.0076)] [G loss: -3.8478]\n",
      "9562 (5, 1) [D loss: (-0.9710)(R -4.7055, F 3.6758, G 0.0059)] [G loss: -3.3976]\n",
      "9563 (5, 1) [D loss: (-0.7854)(R -4.0929, F 3.2624, G 0.0045)] [G loss: -3.0939]\n",
      "9564 (5, 1) [D loss: (-0.8358)(R -3.5244, F 2.6694, G 0.0019)] [G loss: -2.7545]\n",
      "9565 (5, 1) [D loss: (-0.8735)(R -2.8777, F 1.9820, G 0.0022)] [G loss: -2.1491]\n",
      "9566 (5, 1) [D loss: (-0.6089)(R -2.3991, F 1.7702, G 0.0020)] [G loss: -1.3098]\n",
      "9567 (5, 1) [D loss: (-0.8855)(R -1.6932, F 0.7811, G 0.0027)] [G loss: -0.3711]\n",
      "9568 (5, 1) [D loss: (-0.6464)(R -1.0099, F 0.3268, G 0.0037)] [G loss: -0.2276]\n",
      "9569 (5, 1) [D loss: (-0.7499)(R -1.1849, F 0.3954, G 0.0040)] [G loss: -0.2370]\n",
      "9570 (5, 1) [D loss: (-0.9652)(R -1.1419, F 0.1472, G 0.0030)] [G loss: -0.0518]\n",
      "9571 (5, 1) [D loss: (-0.9488)(R -1.6183, F 0.6305, G 0.0039)] [G loss: -0.5169]\n",
      "9572 (5, 1) [D loss: (-0.8673)(R -1.9394, F 1.0362, G 0.0036)] [G loss: -0.9100]\n",
      "9573 (5, 1) [D loss: (-0.5580)(R -1.7854, F 1.1984, G 0.0029)] [G loss: -0.9021]\n",
      "9574 (5, 1) [D loss: (-1.0590)(R -1.7425, F 0.6581, G 0.0025)] [G loss: -0.6883]\n",
      "9575 (5, 1) [D loss: (-0.8220)(R -1.2319, F 0.3872, G 0.0023)] [G loss: -0.3730]\n",
      "9576 (5, 1) [D loss: (-0.9174)(R -0.8835, F -0.0534, G 0.0019)] [G loss: -0.4067]\n",
      "9577 (5, 1) [D loss: (-0.8056)(R -0.8125, F -0.0152, G 0.0022)] [G loss: 0.0892]\n",
      "9578 (5, 1) [D loss: (-0.7256)(R -0.5805, F -0.1739, G 0.0029)] [G loss: 0.2603]\n",
      "9579 (5, 1) [D loss: (-0.8537)(R -0.4339, F -0.4456, G 0.0026)] [G loss: 0.3331]\n",
      "9580 (5, 1) [D loss: (-0.5460)(R -0.4500, F -0.1218, G 0.0026)] [G loss: 0.4021]\n",
      "9581 (5, 1) [D loss: (-0.7160)(R -0.2962, F -0.4510, G 0.0031)] [G loss: 0.5684]\n",
      "9582 (5, 1) [D loss: (-0.7343)(R -0.3494, F -0.4245, G 0.0040)] [G loss: 0.3575]\n",
      "9583 (5, 1) [D loss: (-0.9081)(R -0.4492, F -0.5006, G 0.0042)] [G loss: 0.2221]\n",
      "9584 (5, 1) [D loss: (-1.0989)(R -0.3853, F -0.7519, G 0.0038)] [G loss: 0.5174]\n",
      "9585 (5, 1) [D loss: (-0.9890)(R 0.3273, F -1.3553, G 0.0039)] [G loss: 1.0824]\n",
      "9586 (5, 1) [D loss: (-1.0381)(R 1.1559, F -2.2459, G 0.0052)] [G loss: 2.2053]\n",
      "9587 (5, 1) [D loss: (-0.9537)(R 2.2467, F -3.2608, G 0.0060)] [G loss: 2.9898]\n",
      "9588 (5, 1) [D loss: (-1.3024)(R 2.9600, F -4.3151, G 0.0053)] [G loss: 3.9990]\n",
      "9589 (5, 1) [D loss: (-1.0778)(R 3.8161, F -4.9677, G 0.0074)] [G loss: 4.8974]\n",
      "9590 (5, 1) [D loss: (-0.5446)(R 4.4560, F -5.0652, G 0.0065)] [G loss: 4.6901]\n",
      "9591 (5, 1) [D loss: (-0.9760)(R 3.5871, F -4.6022, G 0.0039)] [G loss: 4.8855]\n",
      "9592 (5, 1) [D loss: (-0.8462)(R 3.9396, F -4.8216, G 0.0036)] [G loss: 4.5670]\n",
      "9593 (5, 1) [D loss: (-0.4369)(R 4.0258, F -4.4953, G 0.0033)] [G loss: 4.2470]\n",
      "9594 (5, 1) [D loss: (-1.0613)(R 3.0842, F -4.1745, G 0.0029)] [G loss: 4.0024]\n",
      "9595 (5, 1) [D loss: (-0.7441)(R 2.3529, F -3.1159, G 0.0019)] [G loss: 3.0672]\n",
      "9596 (5, 1) [D loss: (-0.6712)(R 1.8357, F -2.5308, G 0.0024)] [G loss: 2.0093]\n",
      "9597 (5, 1) [D loss: (-0.7344)(R 0.4087, F -1.1614, G 0.0018)] [G loss: 1.1801]\n",
      "9598 (5, 1) [D loss: (-0.9739)(R -0.4861, F -0.5093, G 0.0021)] [G loss: 0.2001]\n",
      "9599 (5, 1) [D loss: (-0.8527)(R -0.4808, F -0.3930, G 0.0021)] [G loss: 0.2935]\n",
      "9600 (5, 1) [D loss: (-0.7956)(R -0.3529, F -0.4728, G 0.0030)] [G loss: 0.5445]\n",
      "9601 (5, 1) [D loss: (-0.6402)(R -0.2602, F -0.4043, G 0.0024)] [G loss: 0.4642]\n",
      "9602 (5, 1) [D loss: (-0.5392)(R 0.0761, F -0.6412, G 0.0026)] [G loss: 0.2655]\n",
      "9603 (5, 1) [D loss: (-1.1836)(R -0.4162, F -0.8016, G 0.0034)] [G loss: 0.7783]\n",
      "9604 (5, 1) [D loss: (-1.0892)(R -0.6643, F -0.4655, G 0.0041)] [G loss: 0.4063]\n",
      "9605 (5, 1) [D loss: (-0.8498)(R -0.8395, F -0.0464, G 0.0036)] [G loss: -0.4021]\n",
      "9606 (5, 1) [D loss: (-0.7544)(R -2.1172, F 1.3102, G 0.0053)] [G loss: -1.5793]\n",
      "9607 (5, 1) [D loss: (-0.5617)(R -3.1674, F 2.5625, G 0.0043)] [G loss: -2.1974]\n",
      "9608 (5, 1) [D loss: (-0.9091)(R -4.0003, F 3.0463, G 0.0045)] [G loss: -2.9889]\n",
      "9609 (5, 1) [D loss: (-0.8559)(R -4.3190, F 3.4254, G 0.0038)] [G loss: -3.4696]\n",
      "9610 (5, 1) [D loss: (-0.6738)(R -4.9095, F 4.1839, G 0.0052)] [G loss: -4.1120]\n",
      "9611 (5, 1) [D loss: (-1.2060)(R -5.4293, F 4.1801, G 0.0043)] [G loss: -4.3132]\n",
      "9612 (5, 1) [D loss: (-1.1990)(R -6.1625, F 4.9074, G 0.0056)] [G loss: -5.1925]\n",
      "9613 (5, 1) [D loss: (-0.8245)(R -6.0590, F 5.1838, G 0.0051)] [G loss: -4.6157]\n",
      "9614 (5, 1) [D loss: (-0.9292)(R -5.4269, F 4.4537, G 0.0044)] [G loss: -4.1034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9615 (5, 1) [D loss: (-1.0153)(R -5.3809, F 4.3295, G 0.0036)] [G loss: -4.9656]\n",
      "9616 (5, 1) [D loss: (-1.0970)(R -5.6589, F 4.5235, G 0.0038)] [G loss: -5.0012]\n",
      "9617 (5, 1) [D loss: (-0.5667)(R -5.3922, F 4.7929, G 0.0033)] [G loss: -4.8368]\n",
      "9618 (5, 1) [D loss: (-0.9207)(R -5.8044, F 4.8483, G 0.0035)] [G loss: -4.9626]\n",
      "9619 (5, 1) [D loss: (-0.3439)(R -5.3527, F 4.9798, G 0.0029)] [G loss: -4.8525]\n",
      "9620 (5, 1) [D loss: (-0.2266)(R -4.5056, F 4.2597, G 0.0019)] [G loss: -4.1133]\n",
      "9621 (5, 1) [D loss: (-0.8966)(R -4.1748, F 3.2585, G 0.0020)] [G loss: -3.5112]\n",
      "9622 (5, 1) [D loss: (-0.9464)(R -3.8356, F 2.8713, G 0.0018)] [G loss: -2.9341]\n",
      "9623 (5, 1) [D loss: (-0.7413)(R -3.3620, F 2.5951, G 0.0026)] [G loss: -2.4155]\n",
      "9624 (5, 1) [D loss: (-0.7094)(R -2.6664, F 1.9360, G 0.0021)] [G loss: -2.1809]\n",
      "9625 (5, 1) [D loss: (-0.8838)(R -2.6553, F 1.7364, G 0.0035)] [G loss: -1.8553]\n",
      "9626 (5, 1) [D loss: (-0.5009)(R -2.0494, F 1.5243, G 0.0024)] [G loss: -1.4114]\n",
      "9627 (5, 1) [D loss: (-0.9082)(R -1.9876, F 1.0486, G 0.0031)] [G loss: -1.1499]\n",
      "9628 (5, 1) [D loss: (-1.1621)(R -1.8619, F 0.6669, G 0.0033)] [G loss: -0.9234]\n",
      "9629 (5, 1) [D loss: (-0.7786)(R -1.7226, F 0.9071, G 0.0037)] [G loss: -0.9924]\n",
      "9630 (5, 1) [D loss: (-0.7079)(R -1.3338, F 0.5939, G 0.0032)] [G loss: -0.3197]\n",
      "9631 (5, 1) [D loss: (-0.9656)(R -1.5203, F 0.5207, G 0.0034)] [G loss: -0.2614]\n",
      "9632 (5, 1) [D loss: (-0.8235)(R -1.0135, F 0.1536, G 0.0036)] [G loss: -0.2696]\n",
      "9633 (5, 1) [D loss: (-1.1637)(R -0.6410, F -0.5624, G 0.0040)] [G loss: 0.6715]\n",
      "9634 (5, 1) [D loss: (-0.8321)(R -0.2868, F -0.5896, G 0.0044)] [G loss: 0.9483]\n",
      "9635 (5, 1) [D loss: (-1.2285)(R 0.3592, F -1.6261, G 0.0038)] [G loss: 1.4513]\n",
      "9636 (5, 1) [D loss: (-0.7580)(R 1.3165, F -2.1310, G 0.0056)] [G loss: 2.3670]\n",
      "9637 (5, 1) [D loss: (-0.8550)(R 1.9871, F -2.8992, G 0.0057)] [G loss: 2.6692]\n",
      "9638 (5, 1) [D loss: (-1.1728)(R 1.8143, F -3.0340, G 0.0047)] [G loss: 2.9788]\n",
      "9639 (5, 1) [D loss: (-0.8595)(R 2.2536, F -3.1558, G 0.0043)] [G loss: 2.9994]\n",
      "9640 (5, 1) [D loss: (-0.9466)(R 1.6574, F -2.6406, G 0.0037)] [G loss: 2.8376]\n",
      "9641 (5, 1) [D loss: (-1.0293)(R 1.6471, F -2.7074, G 0.0031)] [G loss: 2.5877]\n",
      "9642 (5, 1) [D loss: (-0.7871)(R 1.6350, F -2.4549, G 0.0033)] [G loss: 1.8422]\n",
      "9643 (5, 1) [D loss: (-0.9789)(R 0.9245, F -1.9275, G 0.0024)] [G loss: 1.5763]\n",
      "9644 (5, 1) [D loss: (-0.8172)(R 0.2957, F -1.1340, G 0.0021)] [G loss: 0.9794]\n",
      "9645 (5, 1) [D loss: (-0.9224)(R 0.0713, F -1.0136, G 0.0020)] [G loss: 1.0040]\n",
      "9646 (5, 1) [D loss: (-0.6878)(R 0.6112, F -1.3185, G 0.0019)] [G loss: 1.1462]\n",
      "9647 (5, 1) [D loss: (-0.7353)(R 0.7284, F -1.4897, G 0.0026)] [G loss: 1.4746]\n",
      "9648 (5, 1) [D loss: (-0.9142)(R 0.5101, F -1.4489, G 0.0025)] [G loss: 1.4745]\n",
      "9649 (5, 1) [D loss: (-0.9368)(R 0.6954, F -1.6579, G 0.0026)] [G loss: 1.6125]\n",
      "9650 (5, 1) [D loss: (-0.9528)(R 0.7514, F -1.7450, G 0.0041)] [G loss: 1.5174]\n",
      "9651 (5, 1) [D loss: (-1.3571)(R 0.3219, F -1.7114, G 0.0032)] [G loss: 1.3783]\n",
      "9652 (5, 1) [D loss: (-0.4922)(R 0.4041, F -0.9400, G 0.0044)] [G loss: 0.6897]\n",
      "9653 (5, 1) [D loss: (-0.2841)(R -0.3849, F 0.0736, G 0.0027)] [G loss: 0.0915]\n",
      "9654 (5, 1) [D loss: (-0.7505)(R -0.8572, F 0.0741, G 0.0033)] [G loss: -0.2864]\n",
      "9655 (5, 1) [D loss: (-0.9007)(R -2.0796, F 1.1494, G 0.0029)] [G loss: -1.2256]\n",
      "9656 (5, 1) [D loss: (-0.8407)(R -2.6402, F 1.7629, G 0.0037)] [G loss: -2.0003]\n",
      "9657 (5, 1) [D loss: (-0.8912)(R -3.2359, F 2.2994, G 0.0045)] [G loss: -2.5071]\n",
      "9658 (5, 1) [D loss: (-1.1690)(R -3.5071, F 2.2940, G 0.0044)] [G loss: -2.4083]\n",
      "9659 (5, 1) [D loss: (-1.0193)(R -3.5913, F 2.5261, G 0.0046)] [G loss: -2.5679]\n",
      "9660 (5, 1) [D loss: (-1.2485)(R -3.6258, F 2.3385, G 0.0039)] [G loss: -2.7748]\n",
      "9661 (5, 1) [D loss: (-0.9688)(R -2.7734, F 1.7719, G 0.0033)] [G loss: -2.2088]\n",
      "9662 (5, 1) [D loss: (-0.7269)(R -2.2508, F 1.4987, G 0.0025)] [G loss: -1.4350]\n",
      "9663 (5, 1) [D loss: (-0.9517)(R -2.2021, F 1.2188, G 0.0032)] [G loss: -1.1963]\n",
      "9664 (5, 1) [D loss: (-1.1712)(R -2.8733, F 1.6702, G 0.0032)] [G loss: -1.7358]\n",
      "9665 (5, 1) [D loss: (-1.0967)(R -2.9016, F 1.7758, G 0.0029)] [G loss: -2.2195]\n",
      "9666 (5, 1) [D loss: (-0.9759)(R -3.3450, F 2.3402, G 0.0029)] [G loss: -2.8161]\n",
      "9667 (5, 1) [D loss: (-0.8324)(R -3.4744, F 2.6139, G 0.0028)] [G loss: -2.8973]\n",
      "9668 (5, 1) [D loss: (-0.9957)(R -4.3902, F 3.3617, G 0.0033)] [G loss: -3.6228]\n",
      "9669 (5, 1) [D loss: (-0.7864)(R -4.6684, F 3.8548, G 0.0027)] [G loss: -3.9084]\n",
      "9670 (5, 1) [D loss: (-0.7744)(R -4.3944, F 3.5954, G 0.0025)] [G loss: -3.5286]\n",
      "9671 (5, 1) [D loss: (-0.6504)(R -3.5139, F 2.8472, G 0.0016)] [G loss: -2.5106]\n",
      "9672 (5, 1) [D loss: (-0.8989)(R -2.4367, F 1.5186, G 0.0019)] [G loss: -1.1260]\n",
      "9673 (5, 1) [D loss: (-0.9792)(R -0.9752, F -0.0355, G 0.0032)] [G loss: 0.1375]\n",
      "9674 (5, 1) [D loss: (-0.8376)(R -0.2298, F -0.6558, G 0.0048)] [G loss: 0.6199]\n",
      "9675 (5, 1) [D loss: (-0.7241)(R 0.2926, F -1.0607, G 0.0044)] [G loss: 1.0462]\n",
      "9676 (5, 1) [D loss: (-0.6363)(R 0.8765, F -1.5591, G 0.0046)] [G loss: 1.8346]\n",
      "9677 (5, 1) [D loss: (-0.5664)(R 0.6929, F -1.3162, G 0.0057)] [G loss: 1.3258]\n",
      "9678 (5, 1) [D loss: (-0.7580)(R -0.3881, F -0.3957, G 0.0026)] [G loss: 0.4574]\n",
      "9679 (5, 1) [D loss: (-0.5937)(R -0.7990, F 0.1797, G 0.0026)] [G loss: -0.3402]\n",
      "9680 (5, 1) [D loss: (-0.7971)(R -1.2945, F 0.4752, G 0.0022)] [G loss: -0.4133]\n",
      "9681 (5, 1) [D loss: (-0.9409)(R -2.2459, F 1.2809, G 0.0024)] [G loss: -1.7260]\n",
      "9682 (5, 1) [D loss: (-0.8103)(R -2.3341, F 1.4958, G 0.0028)] [G loss: -1.3636]\n",
      "9683 (5, 1) [D loss: (-0.8833)(R -2.6222, F 1.7043, G 0.0035)] [G loss: -1.5407]\n",
      "9684 (5, 1) [D loss: (-0.8628)(R -2.1155, F 1.2270, G 0.0026)] [G loss: -1.1271]\n",
      "9685 (5, 1) [D loss: (-0.5731)(R -1.8015, F 1.1973, G 0.0031)] [G loss: -0.9864]\n",
      "9686 (5, 1) [D loss: (-0.7150)(R -1.3738, F 0.6289, G 0.0030)] [G loss: -0.3564]\n",
      "9687 (5, 1) [D loss: (-0.7309)(R -0.5932, F -0.1689, G 0.0031)] [G loss: 0.0575]\n",
      "9688 (5, 1) [D loss: (-0.9944)(R -0.2007, F -0.8296, G 0.0036)] [G loss: 0.8215]\n",
      "9689 (5, 1) [D loss: (-0.7757)(R 0.2453, F -1.0684, G 0.0047)] [G loss: 1.3013]\n",
      "9690 (5, 1) [D loss: (-0.8040)(R 0.4510, F -1.2961, G 0.0041)] [G loss: 1.6550]\n",
      "9691 (5, 1) [D loss: (-0.8975)(R -0.1206, F -0.8034, G 0.0027)] [G loss: 0.5075]\n",
      "9692 (5, 1) [D loss: (-0.9857)(R -1.5163, F 0.5079, G 0.0023)] [G loss: -0.7014]\n",
      "9693 (5, 1) [D loss: (-1.0134)(R -2.5756, F 1.5393, G 0.0023)] [G loss: -2.0870]\n",
      "9694 (5, 1) [D loss: (-1.2993)(R -3.8912, F 2.5503, G 0.0042)] [G loss: -2.8362]\n",
      "9695 (5, 1) [D loss: (-0.9297)(R -4.8051, F 3.8253, G 0.0050)] [G loss: -4.4125]\n",
      "9696 (5, 1) [D loss: (-0.2948)(R -5.4074, F 5.0533, G 0.0059)] [G loss: -4.9461]\n",
      "9697 (5, 1) [D loss: (-0.9044)(R -5.3283, F 4.3864, G 0.0037)] [G loss: -4.6486]\n",
      "9698 (5, 1) [D loss: (-0.7449)(R -4.3885, F 3.6202, G 0.0023)] [G loss: -3.2704]\n",
      "9699 (5, 1) [D loss: (-0.8706)(R -3.4305, F 2.5336, G 0.0026)] [G loss: -2.3528]\n",
      "9700 (5, 1) [D loss: (-0.8796)(R -2.5494, F 1.6439, G 0.0026)] [G loss: -1.4950]\n",
      "9701 (5, 1) [D loss: (-1.1376)(R -1.6404, F 0.4745, G 0.0028)] [G loss: -0.4048]\n",
      "9702 (5, 1) [D loss: (-0.4781)(R -0.9041, F 0.3915, G 0.0034)] [G loss: -0.3807]\n",
      "9703 (5, 1) [D loss: (-0.8576)(R -1.6506, F 0.7536, G 0.0039)] [G loss: -0.8333]\n",
      "9704 (5, 1) [D loss: (-0.6309)(R -1.9962, F 1.3305, G 0.0035)] [G loss: -1.6192]\n",
      "9705 (5, 1) [D loss: (-0.8196)(R -3.0928, F 2.2334, G 0.0040)] [G loss: -2.3514]\n",
      "9706 (5, 1) [D loss: (-1.2483)(R -4.1843, F 2.8976, G 0.0038)] [G loss: -3.8183]\n",
      "9707 (5, 1) [D loss: (-1.1516)(R -5.2765, F 4.0704, G 0.0055)] [G loss: -4.2641]\n",
      "9708 (5, 1) [D loss: (-0.7765)(R -4.8517, F 4.0312, G 0.0044)] [G loss: -3.9825]\n",
      "9709 (5, 1) [D loss: (-0.6894)(R -4.3652, F 3.6380, G 0.0038)] [G loss: -3.3345]\n",
      "9710 (5, 1) [D loss: (-0.7671)(R -3.1123, F 2.3215, G 0.0024)] [G loss: -2.0915]\n",
      "9711 (5, 1) [D loss: (-0.7821)(R -1.5893, F 0.7833, G 0.0024)] [G loss: -0.2440]\n",
      "9712 (5, 1) [D loss: (-1.4530)(R 0.7703, F -2.2720, G 0.0049)] [G loss: 2.4819]\n",
      "9713 (5, 1) [D loss: (-1.5821)(R 3.1541, F -4.8212, G 0.0085)] [G loss: 4.9406]\n",
      "9714 (5, 1) [D loss: (-1.9449)(R 4.5109, F -6.6135, G 0.0158)] [G loss: 6.4497]\n",
      "9715 (5, 1) [D loss: (-1.4162)(R 5.0551, F -6.6093, G 0.0138)] [G loss: 6.4080]\n",
      "9716 (5, 1) [D loss: (-0.6936)(R 4.5204, F -5.2942, G 0.0080)] [G loss: 5.1488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9717 (5, 1) [D loss: (-0.5326)(R 2.9136, F -3.4640, G 0.0018)] [G loss: 3.3622]\n",
      "9718 (5, 1) [D loss: (-0.6420)(R 0.9903, F -1.6469, G 0.0015)] [G loss: 1.6880]\n",
      "9719 (5, 1) [D loss: (-0.9464)(R -0.5564, F -0.4035, G 0.0014)] [G loss: 0.1508]\n",
      "9720 (5, 1) [D loss: (-1.2617)(R -2.0862, F 0.8098, G 0.0015)] [G loss: -1.2747]\n",
      "9721 (5, 1) [D loss: (-1.0750)(R -2.9761, F 1.8767, G 0.0024)] [G loss: -1.9597]\n",
      "9722 (5, 1) [D loss: (-0.6699)(R -3.4300, F 2.7280, G 0.0032)] [G loss: -2.4724]\n",
      "9723 (5, 1) [D loss: (-0.8187)(R -2.0773, F 1.2381, G 0.0021)] [G loss: -0.9768]\n",
      "9724 (5, 1) [D loss: (-0.9499)(R -0.0971, F -0.8822, G 0.0029)] [G loss: 1.1614]\n",
      "9725 (5, 1) [D loss: (-1.0924)(R 1.5128, F -2.6542, G 0.0049)] [G loss: 2.3707]\n",
      "9726 (5, 1) [D loss: (-1.2839)(R 1.8432, F -3.1833, G 0.0056)] [G loss: 2.7730]\n",
      "9727 (5, 1) [D loss: (-1.1862)(R 2.5636, F -3.8174, G 0.0067)] [G loss: 3.4078]\n",
      "9728 (5, 1) [D loss: (-0.5664)(R 2.9114, F -3.5385, G 0.0061)] [G loss: 3.1906]\n",
      "9729 (5, 1) [D loss: (-0.8101)(R 0.9055, F -1.7392, G 0.0024)] [G loss: 1.6958]\n",
      "9730 (5, 1) [D loss: (-0.4841)(R -0.2837, F -0.2255, G 0.0025)] [G loss: -0.0845]\n",
      "9731 (5, 1) [D loss: (-0.7686)(R -2.6149, F 1.8292, G 0.0017)] [G loss: -2.3445]\n",
      "9732 (5, 1) [D loss: (-1.3153)(R -5.1009, F 3.7621, G 0.0024)] [G loss: -4.6353]\n",
      "9733 (5, 1) [D loss: (-1.1415)(R -6.5526, F 5.3599, G 0.0051)] [G loss: -5.5854]\n",
      "9734 (5, 1) [D loss: (-1.1128)(R -6.4881, F 5.3352, G 0.0040)] [G loss: -5.3426]\n",
      "9735 (5, 1) [D loss: (-0.7354)(R -5.7232, F 4.9525, G 0.0035)] [G loss: -4.4390]\n",
      "9736 (5, 1) [D loss: (-0.5515)(R -4.3699, F 3.7944, G 0.0024)] [G loss: -3.5520]\n",
      "9737 (5, 1) [D loss: (-0.5488)(R -3.3666, F 2.8023, G 0.0016)] [G loss: -2.3725]\n",
      "9738 (5, 1) [D loss: (-1.1829)(R -2.8713, F 1.6677, G 0.0021)] [G loss: -1.5329]\n",
      "9739 (5, 1) [D loss: (-0.7778)(R -1.7988, F 0.9932, G 0.0028)] [G loss: -1.0322]\n",
      "9740 (5, 1) [D loss: (-1.0576)(R -2.0218, F 0.9248, G 0.0039)] [G loss: -1.1687]\n",
      "9741 (5, 1) [D loss: (-1.0247)(R -1.7940, F 0.7315, G 0.0038)] [G loss: -1.0270]\n",
      "9742 (5, 1) [D loss: (-1.0580)(R -2.5650, F 1.4796, G 0.0027)] [G loss: -2.0583]\n",
      "9743 (5, 1) [D loss: (-1.0166)(R -3.6628, F 2.6124, G 0.0034)] [G loss: -3.0061]\n",
      "9744 (5, 1) [D loss: (-1.1508)(R -5.1259, F 3.9328, G 0.0042)] [G loss: -4.6519]\n",
      "9745 (5, 1) [D loss: (-0.8948)(R -6.2586, F 5.2906, G 0.0073)] [G loss: -5.7791]\n",
      "9746 (5, 1) [D loss: (-1.3148)(R -6.8578, F 5.4839, G 0.0059)] [G loss: -6.1725]\n",
      "9747 (5, 1) [D loss: (-0.7683)(R -6.6157, F 5.7974, G 0.0050)] [G loss: -5.5049]\n",
      "9748 (5, 1) [D loss: (-0.6359)(R -5.2548, F 4.5999, G 0.0019)] [G loss: -4.4330]\n",
      "9749 (5, 1) [D loss: (-0.3749)(R -3.9551, F 3.5622, G 0.0018)] [G loss: -3.6090]\n",
      "9750 (5, 1) [D loss: (-0.6705)(R -2.8727, F 2.1890, G 0.0013)] [G loss: -2.2511]\n",
      "9751 (5, 1) [D loss: (-0.5416)(R -1.9414, F 1.3842, G 0.0016)] [G loss: -0.9724]\n",
      "9752 (5, 1) [D loss: (-1.1926)(R -1.1607, F -0.0601, G 0.0028)] [G loss: -0.1344]\n",
      "9753 (5, 1) [D loss: (-0.9597)(R -0.1701, F -0.8325, G 0.0043)] [G loss: 0.5280]\n",
      "9754 (5, 1) [D loss: (-0.9237)(R -0.0764, F -0.8929, G 0.0046)] [G loss: 0.9927]\n",
      "9755 (5, 1) [D loss: (-0.4926)(R 0.2484, F -0.7820, G 0.0041)] [G loss: 1.1638]\n",
      "9756 (5, 1) [D loss: (-0.7324)(R -0.3770, F -0.3865, G 0.0031)] [G loss: 0.2292]\n",
      "9757 (5, 1) [D loss: (-0.6204)(R -0.9839, F 0.3328, G 0.0031)] [G loss: -0.3034]\n",
      "9758 (5, 1) [D loss: (-0.7966)(R -1.6837, F 0.8527, G 0.0034)] [G loss: -1.3391]\n",
      "9759 (5, 1) [D loss: (-1.0929)(R -2.2082, F 1.0836, G 0.0032)] [G loss: -1.0884]\n",
      "9760 (5, 1) [D loss: (-1.1493)(R -1.6906, F 0.5066, G 0.0035)] [G loss: -0.7702]\n",
      "9761 (5, 1) [D loss: (-0.7955)(R -0.9896, F 0.1584, G 0.0036)] [G loss: 0.2296]\n",
      "9762 (5, 1) [D loss: (-1.0018)(R 0.0645, F -1.1039, G 0.0038)] [G loss: 1.2118]\n",
      "9763 (5, 1) [D loss: (-1.2390)(R 1.0480, F -2.3242, G 0.0037)] [G loss: 2.0968]\n",
      "9764 (5, 1) [D loss: (-0.6669)(R 2.4397, F -3.1654, G 0.0059)] [G loss: 3.2199]\n",
      "9765 (5, 1) [D loss: (-1.4216)(R 2.7625, F -4.2621, G 0.0078)] [G loss: 3.8810]\n",
      "9766 (5, 1) [D loss: (-0.7294)(R 3.4620, F -4.2830, G 0.0092)] [G loss: 4.3166]\n",
      "9767 (5, 1) [D loss: (-0.8889)(R 3.1248, F -4.0703, G 0.0057)] [G loss: 3.8030]\n",
      "9768 (5, 1) [D loss: (-0.7254)(R 2.5228, F -3.2734, G 0.0025)] [G loss: 3.0284]\n",
      "9769 (5, 1) [D loss: (-0.5561)(R 1.4607, F -2.0349, G 0.0018)] [G loss: 1.8369]\n",
      "9770 (5, 1) [D loss: (-0.7406)(R -0.1362, F -0.6219, G 0.0017)] [G loss: 0.3597]\n",
      "9771 (5, 1) [D loss: (-0.7979)(R -1.4431, F 0.6296, G 0.0016)] [G loss: -1.1930]\n",
      "9772 (5, 1) [D loss: (-0.9022)(R -2.5330, F 1.6111, G 0.0020)] [G loss: -1.8225]\n",
      "9773 (5, 1) [D loss: (-0.8379)(R -2.8648, F 1.9980, G 0.0029)] [G loss: -2.1729]\n",
      "9774 (5, 1) [D loss: (-0.6690)(R -2.8690, F 2.1698, G 0.0030)] [G loss: -2.0645]\n",
      "9775 (5, 1) [D loss: (-0.6710)(R -2.1366, F 1.4423, G 0.0023)] [G loss: -1.4550]\n",
      "9776 (5, 1) [D loss: (-0.8579)(R -1.0485, F 0.1659, G 0.0025)] [G loss: 0.0586]\n",
      "9777 (5, 1) [D loss: (-0.8948)(R 0.3162, F -1.2498, G 0.0039)] [G loss: 1.3995]\n",
      "9778 (5, 1) [D loss: (-0.6451)(R 1.6587, F -2.3533, G 0.0050)] [G loss: 2.0557]\n",
      "9779 (5, 1) [D loss: (-0.6667)(R 0.8522, F -1.5620, G 0.0043)] [G loss: 1.7072]\n",
      "9780 (5, 1) [D loss: (-1.0022)(R -0.0191, F -1.0155, G 0.0032)] [G loss: 0.7057]\n",
      "9781 (5, 1) [D loss: (-0.4772)(R -0.2771, F -0.2217, G 0.0022)] [G loss: 0.0202]\n",
      "9782 (5, 1) [D loss: (-0.9806)(R -1.8538, F 0.8519, G 0.0021)] [G loss: -1.2382]\n",
      "9783 (5, 1) [D loss: (-1.1541)(R -3.1764, F 1.9916, G 0.0031)] [G loss: -2.5101]\n",
      "9784 (5, 1) [D loss: (-1.1274)(R -4.6867, F 3.5063, G 0.0053)] [G loss: -4.0180]\n",
      "9785 (5, 1) [D loss: (-1.0978)(R -5.5763, F 4.4050, G 0.0073)] [G loss: -5.0248]\n",
      "9786 (5, 1) [D loss: (-0.8534)(R -5.9656, F 5.0397, G 0.0072)] [G loss: -4.8549]\n",
      "9787 (5, 1) [D loss: (-0.8107)(R -5.6495, F 4.7934, G 0.0045)] [G loss: -4.8662]\n",
      "9788 (5, 1) [D loss: (-0.8082)(R -4.5424, F 3.7066, G 0.0028)] [G loss: -3.9770]\n",
      "9789 (5, 1) [D loss: (-0.5587)(R -3.6431, F 3.0637, G 0.0021)] [G loss: -2.7847]\n",
      "9790 (5, 1) [D loss: (-0.9762)(R -2.6081, F 1.6163, G 0.0016)] [G loss: -1.6814]\n",
      "9791 (5, 1) [D loss: (-0.6683)(R -1.7356, F 1.0474, G 0.0020)] [G loss: -0.8417]\n",
      "9792 (5, 1) [D loss: (-0.9275)(R -0.9459, F -0.0012, G 0.0020)] [G loss: -0.0709]\n",
      "9793 (5, 1) [D loss: (-0.8962)(R -0.9703, F 0.0363, G 0.0038)] [G loss: 0.0488]\n",
      "9794 (5, 1) [D loss: (-0.6178)(R -0.9254, F 0.2739, G 0.0034)] [G loss: -0.7000]\n",
      "9795 (5, 1) [D loss: (-0.8464)(R -2.0177, F 1.1467, G 0.0025)] [G loss: -1.3373]\n",
      "9796 (5, 1) [D loss: (-1.0507)(R -2.7806, F 1.6939, G 0.0036)] [G loss: -2.0563]\n",
      "9797 (5, 1) [D loss: (-1.1318)(R -3.9298, F 2.7543, G 0.0044)] [G loss: -3.0643]\n",
      "9798 (5, 1) [D loss: (-1.0737)(R -4.2775, F 3.1516, G 0.0052)] [G loss: -3.5156]\n",
      "9799 (5, 1) [D loss: (-0.5925)(R -4.1250, F 3.4952, G 0.0037)] [G loss: -3.5157]\n",
      "9800 (5, 1) [D loss: (-0.6337)(R -3.3678, F 2.7094, G 0.0025)] [G loss: -2.3437]\n",
      "9801 (5, 1) [D loss: (-0.2949)(R -2.0599, F 1.7449, G 0.0020)] [G loss: -1.4127]\n",
      "9802 (5, 1) [D loss: (-0.7550)(R -1.3774, F 0.5991, G 0.0023)] [G loss: -0.2454]\n",
      "9803 (5, 1) [D loss: (-1.0629)(R -0.2568, F -0.8405, G 0.0034)] [G loss: 1.0550]\n",
      "9804 (5, 1) [D loss: (-1.1202)(R 1.2262, F -2.4125, G 0.0066)] [G loss: 2.3917]\n",
      "9805 (5, 1) [D loss: (-1.0456)(R 1.9525, F -3.0707, G 0.0073)] [G loss: 3.2899]\n",
      "9806 (5, 1) [D loss: (-0.7305)(R 2.5341, F -3.3437, G 0.0079)] [G loss: 3.7275]\n",
      "9807 (5, 1) [D loss: (-0.9630)(R 1.8750, F -2.8855, G 0.0047)] [G loss: 2.7035]\n",
      "9808 (5, 1) [D loss: (-0.8255)(R 1.0056, F -1.8547, G 0.0024)] [G loss: 2.0354]\n",
      "9809 (5, 1) [D loss: (-0.6275)(R 0.2563, F -0.9002, G 0.0016)] [G loss: 1.0551]\n",
      "9810 (5, 1) [D loss: (-0.5702)(R -0.1841, F -0.4057, G 0.0020)] [G loss: 0.6041]\n",
      "9811 (5, 1) [D loss: (-0.5558)(R -0.7418, F 0.1588, G 0.0027)] [G loss: -0.1012]\n",
      "9812 (5, 1) [D loss: (-1.0489)(R -0.9147, F -0.1576, G 0.0023)] [G loss: -0.1478]\n",
      "9813 (5, 1) [D loss: (-0.9140)(R -0.9166, F -0.0257, G 0.0028)] [G loss: -0.0567]\n",
      "9814 (5, 1) [D loss: (-1.0737)(R -0.6418, F -0.4587, G 0.0027)] [G loss: 0.4573]\n",
      "9815 (5, 1) [D loss: (-0.7211)(R 0.3725, F -1.1302, G 0.0037)] [G loss: 1.0161]\n",
      "9816 (5, 1) [D loss: (-0.8352)(R 0.6967, F -1.5652, G 0.0033)] [G loss: 1.5112]\n",
      "9817 (5, 1) [D loss: (-0.6735)(R 1.2242, F -1.9318, G 0.0034)] [G loss: 2.2030]\n",
      "9818 (5, 1) [D loss: (-0.6537)(R 1.8264, F -2.5243, G 0.0044)] [G loss: 2.5003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9819 (5, 1) [D loss: (-0.5995)(R 1.7765, F -2.4153, G 0.0039)] [G loss: 2.0742]\n",
      "9820 (5, 1) [D loss: (-0.7336)(R 1.4011, F -2.1734, G 0.0039)] [G loss: 2.3530]\n",
      "9821 (5, 1) [D loss: (-0.7481)(R 0.7718, F -1.5490, G 0.0029)] [G loss: 1.6883]\n",
      "9822 (5, 1) [D loss: (-0.8957)(R 0.2030, F -1.1272, G 0.0029)] [G loss: 0.7787]\n",
      "9823 (5, 1) [D loss: (-0.8110)(R -0.8534, F 0.0135, G 0.0029)] [G loss: -0.1503]\n",
      "9824 (5, 1) [D loss: (-0.5563)(R -2.1589, F 1.5661, G 0.0037)] [G loss: -1.4402]\n",
      "9825 (5, 1) [D loss: (-0.6836)(R -3.3858, F 2.6632, G 0.0039)] [G loss: -2.5259]\n",
      "9826 (5, 1) [D loss: (-0.9117)(R -3.5920, F 2.6379, G 0.0042)] [G loss: -2.6291]\n",
      "9827 (5, 1) [D loss: (-1.1551)(R -3.7929, F 2.6018, G 0.0036)] [G loss: -2.5440]\n",
      "9828 (5, 1) [D loss: (-0.5850)(R -2.8495, F 2.2361, G 0.0028)] [G loss: -2.0613]\n",
      "9829 (5, 1) [D loss: (-1.0041)(R -2.3326, F 1.2983, G 0.0030)] [G loss: -1.2703]\n",
      "9830 (5, 1) [D loss: (-1.1193)(R -1.8648, F 0.7143, G 0.0031)] [G loss: -0.5560]\n",
      "9831 (5, 1) [D loss: (-1.1012)(R -1.5121, F 0.3797, G 0.0031)] [G loss: -0.0497]\n",
      "9832 (5, 1) [D loss: (-0.7575)(R -0.7859, F -0.0109, G 0.0039)] [G loss: 0.4591]\n",
      "9833 (5, 1) [D loss: (-0.7739)(R -0.7796, F -0.0208, G 0.0026)] [G loss: -0.0387]\n",
      "9834 (5, 1) [D loss: (-0.8770)(R -1.3256, F 0.4271, G 0.0022)] [G loss: -0.6313]\n",
      "9835 (5, 1) [D loss: (-0.6995)(R -1.5437, F 0.8154, G 0.0029)] [G loss: -0.7722]\n",
      "9836 (5, 1) [D loss: (-0.7540)(R -2.2653, F 1.4793, G 0.0032)] [G loss: -1.6742]\n",
      "9837 (5, 1) [D loss: (-1.1047)(R -3.2104, F 2.0724, G 0.0033)] [G loss: -2.3970]\n",
      "9838 (5, 1) [D loss: (-1.0568)(R -4.1634, F 3.0666, G 0.0040)] [G loss: -3.1810]\n",
      "9839 (5, 1) [D loss: (-0.8375)(R -4.6129, F 3.7282, G 0.0047)] [G loss: -3.6874]\n",
      "9840 (5, 1) [D loss: (-0.8996)(R -4.4602, F 3.5241, G 0.0036)] [G loss: -3.5529]\n",
      "9841 (5, 1) [D loss: (-0.3339)(R -3.8817, F 3.5225, G 0.0025)] [G loss: -3.0323]\n",
      "9842 (5, 1) [D loss: (-0.6129)(R -3.0689, F 2.4361, G 0.0020)] [G loss: -2.3701]\n",
      "9843 (5, 1) [D loss: (-0.7266)(R -2.7264, F 1.9789, G 0.0021)] [G loss: -1.5468]\n",
      "9844 (5, 1) [D loss: (-0.8759)(R -2.4389, F 1.5374, G 0.0026)] [G loss: -1.7647]\n",
      "9845 (5, 1) [D loss: (-0.8112)(R -2.7117, F 1.8732, G 0.0027)] [G loss: -1.7861]\n",
      "9846 (5, 1) [D loss: (-0.9828)(R -2.8959, F 1.8801, G 0.0033)] [G loss: -1.8853]\n",
      "9847 (5, 1) [D loss: (-1.0856)(R -2.8394, F 1.7192, G 0.0035)] [G loss: -2.1333]\n",
      "9848 (5, 1) [D loss: (-0.8311)(R -3.6172, F 2.7414, G 0.0045)] [G loss: -3.0653]\n",
      "9849 (5, 1) [D loss: (-0.6423)(R -3.7358, F 3.0556, G 0.0038)] [G loss: -3.2299]\n",
      "9850 (5, 1) [D loss: (-0.8300)(R -4.0783, F 3.2180, G 0.0030)] [G loss: -3.5734]\n",
      "9851 (5, 1) [D loss: (-0.9422)(R -3.9205, F 2.9505, G 0.0028)] [G loss: -3.1856]\n",
      "9852 (5, 1) [D loss: (-0.9669)(R -3.7317, F 2.7372, G 0.0028)] [G loss: -2.6482]\n",
      "9853 (5, 1) [D loss: (-0.7963)(R -2.6099, F 1.7962, G 0.0017)] [G loss: -1.7532]\n",
      "9854 (5, 1) [D loss: (-0.8833)(R -1.7530, F 0.8496, G 0.0020)] [G loss: -0.7472]\n",
      "9855 (5, 1) [D loss: (-0.4605)(R -0.7389, F 0.2534, G 0.0025)] [G loss: 0.2140]\n",
      "9856 (5, 1) [D loss: (-0.9546)(R 0.3048, F -1.2973, G 0.0038)] [G loss: 1.6709]\n",
      "9857 (5, 1) [D loss: (-1.2190)(R 1.0352, F -2.2973, G 0.0043)] [G loss: 2.2608]\n",
      "9858 (5, 1) [D loss: (-1.3933)(R 1.9129, F -3.3648, G 0.0058)] [G loss: 3.4188]\n",
      "9859 (5, 1) [D loss: (-1.0268)(R 2.3426, F -3.4258, G 0.0056)] [G loss: 3.4641]\n",
      "9860 (5, 1) [D loss: (-0.9970)(R 2.3364, F -3.3982, G 0.0065)] [G loss: 3.8429]\n",
      "9861 (5, 1) [D loss: (-0.8416)(R 2.4063, F -3.2815, G 0.0034)] [G loss: 3.0984]\n",
      "9862 (5, 1) [D loss: (-1.0828)(R 1.7700, F -2.8866, G 0.0034)] [G loss: 2.6081]\n",
      "9863 (5, 1) [D loss: (-1.0737)(R 1.0708, F -2.1685, G 0.0024)] [G loss: 1.8963]\n",
      "9864 (5, 1) [D loss: (-0.5369)(R 0.7907, F -1.3557, G 0.0028)] [G loss: 1.3500]\n",
      "9865 (5, 1) [D loss: (-0.9414)(R 0.5972, F -1.5790, G 0.0040)] [G loss: 1.5272]\n",
      "9866 (5, 1) [D loss: (-1.0141)(R 0.8510, F -1.9013, G 0.0036)] [G loss: 1.6565]\n",
      "9867 (5, 1) [D loss: (-0.6815)(R 1.3104, F -2.0255, G 0.0034)] [G loss: 2.2042]\n",
      "9868 (5, 1) [D loss: (-0.5543)(R 1.8434, F -2.4370, G 0.0039)] [G loss: 2.7653]\n",
      "9869 (5, 1) [D loss: (-0.7496)(R 2.3699, F -3.1469, G 0.0027)] [G loss: 3.0543]\n",
      "9870 (5, 1) [D loss: (-0.9758)(R 3.0052, F -4.0222, G 0.0041)] [G loss: 3.4639]\n",
      "9871 (5, 1) [D loss: (-0.7247)(R 3.1018, F -3.8586, G 0.0032)] [G loss: 3.7554]\n",
      "9872 (5, 1) [D loss: (-1.2032)(R 2.8083, F -4.0451, G 0.0034)] [G loss: 3.8489]\n",
      "9873 (5, 1) [D loss: (-0.8755)(R 2.5985, F -3.5051, G 0.0031)] [G loss: 3.2012]\n",
      "9874 (5, 1) [D loss: (-0.5683)(R 1.9879, F -2.5775, G 0.0021)] [G loss: 2.6845]\n",
      "9875 (5, 1) [D loss: (-0.5036)(R 1.4830, F -2.0147, G 0.0028)] [G loss: 2.1091]\n",
      "9876 (5, 1) [D loss: (-0.4712)(R 0.2163, F -0.7111, G 0.0024)] [G loss: 0.5313]\n",
      "9877 (5, 1) [D loss: (-0.8946)(R -1.2519, F 0.3356, G 0.0022)] [G loss: -0.3782]\n",
      "9878 (5, 1) [D loss: (-1.0737)(R -1.7866, F 0.6908, G 0.0022)] [G loss: -1.0918]\n",
      "9879 (5, 1) [D loss: (-0.8891)(R -1.9392, F 1.0183, G 0.0032)] [G loss: -0.9928]\n",
      "9880 (5, 1) [D loss: (-0.7644)(R -1.9060, F 1.1076, G 0.0034)] [G loss: -0.8970]\n",
      "9881 (5, 1) [D loss: (-0.8893)(R -1.9098, F 0.9870, G 0.0034)] [G loss: -0.5535]\n",
      "9882 (5, 1) [D loss: (-0.7824)(R -1.1200, F 0.3035, G 0.0034)] [G loss: 0.2399]\n",
      "9883 (5, 1) [D loss: (-0.8798)(R -0.3413, F -0.5819, G 0.0043)] [G loss: 0.7461]\n",
      "9884 (5, 1) [D loss: (-0.8534)(R -0.4655, F -0.4333, G 0.0045)] [G loss: 0.3655]\n",
      "9885 (5, 1) [D loss: (-0.5670)(R -0.7956, F 0.2013, G 0.0027)] [G loss: -0.3152]\n",
      "9886 (5, 1) [D loss: (-0.8419)(R -1.5559, F 0.6826, G 0.0031)] [G loss: -0.7018]\n",
      "9887 (5, 1) [D loss: (-0.9052)(R -2.2572, F 1.3175, G 0.0034)] [G loss: -1.5898]\n",
      "9888 (5, 1) [D loss: (-0.8012)(R -3.9167, F 3.0648, G 0.0051)] [G loss: -2.8279]\n",
      "9889 (5, 1) [D loss: (-0.9410)(R -4.5172, F 3.5161, G 0.0060)] [G loss: -3.6249]\n",
      "9890 (5, 1) [D loss: (-0.7011)(R -4.7444, F 3.9817, G 0.0062)] [G loss: -4.0105]\n",
      "9891 (5, 1) [D loss: (-1.1967)(R -5.5914, F 4.3293, G 0.0065)] [G loss: -4.6107]\n",
      "9892 (5, 1) [D loss: (-0.6558)(R -5.4634, F 4.7595, G 0.0048)] [G loss: -4.5293]\n",
      "9893 (5, 1) [D loss: (-0.4654)(R -4.8843, F 4.3867, G 0.0032)] [G loss: -4.1305]\n",
      "9894 (5, 1) [D loss: (-0.8559)(R -4.3593, F 3.4842, G 0.0019)] [G loss: -3.7532]\n",
      "9895 (5, 1) [D loss: (-0.7080)(R -3.6164, F 2.8915, G 0.0017)] [G loss: -3.1565]\n",
      "9896 (5, 1) [D loss: (-1.1009)(R -3.3672, F 2.2438, G 0.0022)] [G loss: -2.5270]\n",
      "9897 (5, 1) [D loss: (-0.8384)(R -3.1235, F 2.2560, G 0.0029)] [G loss: -2.0492]\n",
      "9898 (5, 1) [D loss: (-0.7428)(R -2.7650, F 1.9916, G 0.0031)] [G loss: -1.9657]\n",
      "9899 (5, 1) [D loss: (-0.8474)(R -2.5237, F 1.6484, G 0.0028)] [G loss: -1.6663]\n",
      "9900 (5, 1) [D loss: (-0.5292)(R -2.4703, F 1.9064, G 0.0035)] [G loss: -1.6915]\n",
      "9901 (5, 1) [D loss: (-0.6406)(R -2.5095, F 1.8378, G 0.0031)] [G loss: -1.6069]\n",
      "9902 (5, 1) [D loss: (-0.9503)(R -2.4393, F 1.4584, G 0.0031)] [G loss: -1.8763]\n",
      "9903 (5, 1) [D loss: (-0.9337)(R -2.7995, F 1.8350, G 0.0031)] [G loss: -1.7788]\n",
      "9904 (5, 1) [D loss: (-0.7283)(R -2.0959, F 1.3377, G 0.0030)] [G loss: -1.1142]\n",
      "9905 (5, 1) [D loss: (-0.7765)(R -1.2999, F 0.4886, G 0.0035)] [G loss: -0.4227]\n",
      "9906 (5, 1) [D loss: (-0.9598)(R -0.6560, F -0.3306, G 0.0027)] [G loss: 0.2948]\n",
      "9907 (5, 1) [D loss: (-1.0488)(R 0.2454, F -1.3373, G 0.0043)] [G loss: 1.6363]\n",
      "9908 (5, 1) [D loss: (-1.2151)(R 0.8193, F -2.0863, G 0.0052)] [G loss: 2.0874]\n",
      "9909 (5, 1) [D loss: (-1.0637)(R 1.7895, F -2.9139, G 0.0061)] [G loss: 2.9502]\n",
      "9910 (5, 1) [D loss: (-1.0643)(R 2.1696, F -3.2696, G 0.0036)] [G loss: 3.1326]\n",
      "9911 (5, 1) [D loss: (-0.5829)(R 2.6155, F -3.2252, G 0.0027)] [G loss: 3.2263]\n",
      "9912 (5, 1) [D loss: (-0.3754)(R 2.4552, F -2.8602, G 0.0030)] [G loss: 2.8674]\n",
      "9913 (5, 1) [D loss: (-1.0731)(R 1.3145, F -2.4120, G 0.0024)] [G loss: 2.4560]\n",
      "9914 (5, 1) [D loss: (-0.8174)(R 1.0597, F -1.9007, G 0.0024)] [G loss: 1.5223]\n",
      "9915 (5, 1) [D loss: (-0.9162)(R 0.6875, F -1.6240, G 0.0020)] [G loss: 1.6336]\n",
      "9916 (5, 1) [D loss: (-1.0295)(R 0.4689, F -1.5289, G 0.0031)] [G loss: 1.4645]\n",
      "9917 (5, 1) [D loss: (-0.8907)(R 1.1019, F -2.0297, G 0.0037)] [G loss: 2.2694]\n",
      "9918 (5, 1) [D loss: (-0.5001)(R 1.3484, F -1.8908, G 0.0042)] [G loss: 2.0481]\n",
      "9919 (5, 1) [D loss: (-0.9646)(R 1.8305, F -2.8249, G 0.0030)] [G loss: 2.5834]\n",
      "9920 (5, 1) [D loss: (-1.3232)(R 1.7158, F -3.0709, G 0.0032)] [G loss: 2.7056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9921 (5, 1) [D loss: (-0.6742)(R 1.4935, F -2.2000, G 0.0032)] [G loss: 2.1240]\n",
      "9922 (5, 1) [D loss: (-0.7901)(R 1.6453, F -2.4648, G 0.0029)] [G loss: 2.3238]\n",
      "9923 (5, 1) [D loss: (-1.1559)(R 0.8134, F -1.9964, G 0.0027)] [G loss: 1.7103]\n",
      "9924 (5, 1) [D loss: (-0.9596)(R 0.6617, F -1.6635, G 0.0042)] [G loss: 1.6869]\n",
      "9925 (5, 1) [D loss: (-0.5247)(R 0.2760, F -0.8381, G 0.0037)] [G loss: 0.9463]\n",
      "9926 (5, 1) [D loss: (-0.9730)(R -0.8108, F -0.1951, G 0.0033)] [G loss: 0.1093]\n",
      "9927 (5, 1) [D loss: (-0.4657)(R -1.1318, F 0.6249, G 0.0041)] [G loss: -0.5263]\n",
      "9928 (5, 1) [D loss: (-0.5620)(R -1.8513, F 1.2610, G 0.0028)] [G loss: -0.9822]\n",
      "9929 (5, 1) [D loss: (-0.7106)(R -1.7325, F 0.9981, G 0.0024)] [G loss: -0.8215]\n",
      "9930 (5, 1) [D loss: (-0.7665)(R -1.5560, F 0.7561, G 0.0033)] [G loss: -0.4391]\n",
      "9931 (5, 1) [D loss: (-0.8791)(R -0.9916, F 0.0828, G 0.0030)] [G loss: -0.2771]\n",
      "9932 (5, 1) [D loss: (-0.7449)(R -0.6158, F -0.1508, G 0.0022)] [G loss: 0.1699]\n",
      "9933 (5, 1) [D loss: (-0.8048)(R -1.0220, F 0.1832, G 0.0034)] [G loss: -0.2290]\n",
      "9934 (5, 1) [D loss: (-0.6890)(R -1.4183, F 0.6938, G 0.0036)] [G loss: -0.7163]\n",
      "9935 (5, 1) [D loss: (-0.6375)(R -1.6701, F 0.9984, G 0.0034)] [G loss: -1.0666]\n",
      "9936 (5, 1) [D loss: (-1.0129)(R -2.6536, F 1.6092, G 0.0031)] [G loss: -1.7164]\n",
      "9937 (5, 1) [D loss: (-0.8012)(R -3.2259, F 2.3901, G 0.0035)] [G loss: -2.5626]\n",
      "9938 (5, 1) [D loss: (-1.0275)(R -4.8246, F 3.7450, G 0.0052)] [G loss: -4.1872]\n",
      "9939 (5, 1) [D loss: (-1.4751)(R -5.8271, F 4.2742, G 0.0078)] [G loss: -4.9090]\n",
      "9940 (5, 1) [D loss: (-0.8216)(R -6.3355, F 5.4255, G 0.0088)] [G loss: -5.7560]\n",
      "9941 (5, 1) [D loss: (-0.9136)(R -6.6698, F 5.6734, G 0.0083)] [G loss: -5.6605]\n",
      "9942 (5, 1) [D loss: (-1.1488)(R -6.4291, F 5.2339, G 0.0046)] [G loss: -5.3790]\n",
      "9943 (5, 1) [D loss: (-0.4550)(R -6.0139, F 5.5235, G 0.0035)] [G loss: -5.4173]\n",
      "9944 (5, 1) [D loss: (-0.0238)(R -5.4181, F 5.3682, G 0.0026)] [G loss: -5.0459]\n",
      "9945 (5, 1) [D loss: (-0.6518)(R -4.8556, F 4.1889, G 0.0015)] [G loss: -4.1875]\n",
      "9946 (5, 1) [D loss: (-1.0501)(R -4.2073, F 3.1344, G 0.0023)] [G loss: -3.0735]\n",
      "9947 (5, 1) [D loss: (-0.9804)(R -3.6279, F 2.6245, G 0.0023)] [G loss: -2.7712]\n",
      "9948 (5, 1) [D loss: (-0.8011)(R -3.3883, F 2.5520, G 0.0035)] [G loss: -2.6431]\n",
      "9949 (5, 1) [D loss: (-0.9123)(R -3.2904, F 2.3523, G 0.0026)] [G loss: -2.5999]\n",
      "9950 (5, 1) [D loss: (-0.4716)(R -2.9313, F 2.4407, G 0.0019)] [G loss: -2.2003]\n",
      "9951 (5, 1) [D loss: (-0.7102)(R -2.3721, F 1.6379, G 0.0024)] [G loss: -1.5887]\n",
      "9952 (5, 1) [D loss: (-0.5212)(R -1.8367, F 1.2923, G 0.0023)] [G loss: -1.0286]\n",
      "9953 (5, 1) [D loss: (-0.9093)(R -1.3961, F 0.4556, G 0.0031)] [G loss: -0.0928]\n",
      "9954 (5, 1) [D loss: (-1.2183)(R -0.0878, F -1.1655, G 0.0035)] [G loss: 1.2482]\n",
      "9955 (5, 1) [D loss: (-1.1144)(R 1.2987, F -2.4645, G 0.0051)] [G loss: 2.3228]\n",
      "9956 (5, 1) [D loss: (-1.1365)(R 1.9167, F -3.1167, G 0.0064)] [G loss: 2.9713]\n",
      "9957 (5, 1) [D loss: (-0.8800)(R 2.9987, F -3.9375, G 0.0059)] [G loss: 4.1464]\n",
      "9958 (5, 1) [D loss: (-0.7583)(R 3.7925, F -4.6205, G 0.0070)] [G loss: 4.7250]\n",
      "9959 (5, 1) [D loss: (-0.8967)(R 3.1169, F -4.0503, G 0.0037)] [G loss: 3.5508]\n",
      "9960 (5, 1) [D loss: (-1.0398)(R 2.1602, F -3.2255, G 0.0026)] [G loss: 3.0997]\n",
      "9961 (5, 1) [D loss: (-0.8199)(R 1.7982, F -2.6428, G 0.0025)] [G loss: 3.0797]\n",
      "9962 (5, 1) [D loss: (-0.9066)(R 1.7042, F -2.6358, G 0.0025)] [G loss: 2.6146]\n",
      "9963 (5, 1) [D loss: (-0.7312)(R 1.3036, F -2.0706, G 0.0036)] [G loss: 1.9652]\n",
      "9964 (5, 1) [D loss: (-0.9813)(R 0.7420, F -1.7496, G 0.0026)] [G loss: 1.6625]\n",
      "9965 (5, 1) [D loss: (-0.8414)(R 0.7865, F -1.6676, G 0.0040)] [G loss: 1.5826]\n",
      "9966 (5, 1) [D loss: (-1.0578)(R 1.0381, F -2.1280, G 0.0032)] [G loss: 2.2050]\n",
      "9967 (5, 1) [D loss: (-0.6557)(R 1.9116, F -2.5986, G 0.0031)] [G loss: 2.4338]\n",
      "9968 (5, 1) [D loss: (-0.5961)(R 2.2914, F -2.9217, G 0.0034)] [G loss: 2.9058]\n",
      "9969 (5, 1) [D loss: (-0.7603)(R 1.8562, F -2.6404, G 0.0024)] [G loss: 2.5372]\n",
      "9970 (5, 1) [D loss: (-0.6098)(R 2.6478, F -3.2925, G 0.0035)] [G loss: 3.0759]\n",
      "9971 (5, 1) [D loss: (-1.1111)(R 2.5418, F -3.6764, G 0.0024)] [G loss: 3.5276]\n",
      "9972 (5, 1) [D loss: (-1.3853)(R 2.0379, F -3.4535, G 0.0030)] [G loss: 3.3870]\n",
      "9973 (5, 1) [D loss: (-1.1083)(R 2.1859, F -3.3298, G 0.0036)] [G loss: 3.0771]\n",
      "9974 (5, 1) [D loss: (-0.5559)(R 2.0149, F -2.6031, G 0.0032)] [G loss: 2.5468]\n",
      "9975 (5, 1) [D loss: (-0.2980)(R 0.8348, F -1.1573, G 0.0025)] [G loss: 0.9785]\n",
      "9976 (5, 1) [D loss: (-0.7291)(R -1.3059, F 0.5550, G 0.0022)] [G loss: -0.6212]\n",
      "9977 (5, 1) [D loss: (-0.7599)(R -2.1095, F 1.3236, G 0.0026)] [G loss: -1.6353]\n",
      "9978 (5, 1) [D loss: (-1.1538)(R -3.5888, F 2.4105, G 0.0024)] [G loss: -2.7233]\n",
      "9979 (5, 1) [D loss: (-1.1762)(R -4.3376, F 3.1184, G 0.0043)] [G loss: -3.3900]\n",
      "9980 (5, 1) [D loss: (-1.0136)(R -4.7772, F 3.7171, G 0.0047)] [G loss: -3.7226]\n",
      "9981 (5, 1) [D loss: (-1.2569)(R -4.9174, F 3.6234, G 0.0037)] [G loss: -3.6176]\n",
      "9982 (5, 1) [D loss: (-0.3232)(R -4.1914, F 3.8317, G 0.0036)] [G loss: -3.4159]\n",
      "9983 (5, 1) [D loss: (-1.0980)(R -4.0433, F 2.9081, G 0.0037)] [G loss: -2.8964]\n",
      "9984 (5, 1) [D loss: (-0.7434)(R -3.9818, F 3.2072, G 0.0031)] [G loss: -2.8411]\n",
      "9985 (5, 1) [D loss: (-0.7558)(R -3.8642, F 3.0775, G 0.0031)] [G loss: -3.1370]\n",
      "9986 (5, 1) [D loss: (-0.7170)(R -4.1913, F 3.4442, G 0.0030)] [G loss: -2.9675]\n",
      "9987 (5, 1) [D loss: (-0.7033)(R -3.9371, F 3.1993, G 0.0035)] [G loss: -2.8433]\n",
      "9988 (5, 1) [D loss: (-1.1209)(R -4.3444, F 3.1815, G 0.0042)] [G loss: -3.5893]\n",
      "9989 (5, 1) [D loss: (-1.4696)(R -4.8897, F 3.3741, G 0.0046)] [G loss: -4.1946]\n",
      "9990 (5, 1) [D loss: (-0.6972)(R -5.3433, F 4.6010, G 0.0045)] [G loss: -4.6754]\n",
      "9991 (5, 1) [D loss: (-1.0310)(R -5.7994, F 4.7237, G 0.0045)] [G loss: -4.9664]\n",
      "9992 (5, 1) [D loss: (-0.8021)(R -5.4990, F 4.6628, G 0.0034)] [G loss: -5.1986]\n",
      "9993 (5, 1) [D loss: (-0.5103)(R -5.2299, F 4.6948, G 0.0025)] [G loss: -4.6611]\n",
      "9994 (5, 1) [D loss: (-0.7055)(R -4.0429, F 3.3192, G 0.0018)] [G loss: -2.9658]\n",
      "9995 (5, 1) [D loss: (-0.9797)(R -2.8408, F 1.8369, G 0.0024)] [G loss: -1.5754]\n",
      "9996 (5, 1) [D loss: (-0.9417)(R -1.5092, F 0.5325, G 0.0035)] [G loss: -0.4065]\n",
      "9997 (5, 1) [D loss: (-1.0074)(R -0.3827, F -0.6682, G 0.0044)] [G loss: 1.1821]\n",
      "9998 (5, 1) [D loss: (-0.9769)(R 0.4021, F -1.4306, G 0.0052)] [G loss: 1.3524]\n",
      "9999 (5, 1) [D loss: (-0.9683)(R 0.8327, F -1.8406, G 0.0040)] [G loss: 1.8528]\n",
      "CPU times: user 2h 50s, sys: 19min 55s, total: 2h 20min 45s\n",
      "Wall time: 2h 40min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , n_critic = N_CRITIC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.5, label = 'D_Loss')\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.75, label = 'D_Loss_Real')\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.5, label = 'D_Loss_Fake')\n",
    "plt.plot(gan.g_losses, color='orange', linewidth=0.5, label = \"G_Loss\")\n",
    "\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=18)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "plt.ylim(-50, 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2DTranspose successful\n",
    "'''\n",
    "gan = WGANGP(input_dim = (IMAGE_SIZE, IMAGE_SIZE,1)\n",
    "        , critic_conv_filters = [64,128,256,512]\n",
    "        , critic_conv_kernel_size = [4,4,4,4]\n",
    "        , critic_conv_strides = [2,2,2,2]\n",
    "        , critic_batch_norm_momentum = None\n",
    "        , critic_activation = 'leaky_relu'\n",
    "        , critic_dropout_rate = 0.3\n",
    "        , critic_learning_rate = 0.0002\n",
    "        , generator_initial_dense_layer_size = (4, 4, 512)\n",
    "        , generator_upsample = [1,1,1,1,1]\n",
    "        , generator_conv_filters = [256,128,64,32,1]\n",
    "        , generator_conv_kernel_size = [4,4,4,2,1]\n",
    "        , generator_conv_strides = [2,2,2,2,1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0002\n",
    "        , optimiser = 'adam'\n",
    "        , grad_weight = 10\n",
    "        , z_dim = 100\n",
    "        , batch_size = BATCH_SIZE\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
