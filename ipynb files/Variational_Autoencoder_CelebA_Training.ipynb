{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celeb-A 데이터 셋을 사용한 VAE 네트워크 구조는 이전 MNIST 손글씨 모델과 다음이 다르다.\n",
    "\n",
    "1. 이 데이터셋의 입력 채널은 RGB이므로 3개이다. 따라서 디코더의 마지막에 있는 Conv2DTranspose층의 채널 수를 변경\n",
    "\n",
    "2. 사용하는 latent_space의 차원 수는 2개에서 200개로 늘린다. 얼굴이 숫자 이미지보다 훨씬 복잡하기에 이미지에 있는 상세 정보를 충분히 encoding 하기 위해.\n",
    "\n",
    "3. 훈련 속도를 높이기 위해 각 Conv2D층 뒤에 BatchNormalization층을 추가한다. 각 batch에 대한 실행 속도는 더 걸리더라도, 동일한 수준의 손실에 도달하기 위한 배치 횟수는 크게 줄어든다. (BN, Convolution, Activation 층에 순서에 대한 부분은 논외)\n",
    "\n",
    "4. Dropout층 추가\n",
    "\n",
    "5. 폴더에 있는 이미지 수가 많으므로 python generator를 사용해 VAE로 주입한다. batch 단위로 훈련하기 때문에 사전에 이미지를 메모리에 모두 로드할 필요가 없다. Keras의 내장 메서드인 fit_generator를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from models.VAE import VariationalAutoencoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tensorflow.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'vae'\n",
    "run_id = '0001'\n",
    "data_name = 'faces'\n",
    "RUN_FOLDER = 'run/{}/'.format(section)\n",
    "RUN_FOLDER += '_'.join([run_id, data_name])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n",
    "\n",
    "\n",
    "DATA_FOLDER = './data/celeb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Load\n",
    "INPUT_DIM = (128,128,3)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "\n",
    "NUM_IMAGES = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
    "                                         , target_size = INPUT_DIM[:2] # integer tuple(height, width)\n",
    "                                         , batch_size = BATCH_SIZE\n",
    "                                         , shuffle = True\n",
    "                                         , class_mode = 'input' # input과 동일한 이미지(주로 오토인코더와 같이 사용)\n",
    "                                         , subset = \"training\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hongbeom/.conda/envs/jktest3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "### Model Build\n",
    "vae = VariationalAutoencoder(\n",
    "                input_dim = INPUT_DIM\n",
    "                , encoder_conv_filters=[32,64,64, 64]\n",
    "                , encoder_conv_kernel_size=[3,3,3,3]\n",
    "                , encoder_conv_strides=[2,2,2,2]\n",
    "                , decoder_conv_t_filters=[64,64,32,3]\n",
    "                , decoder_conv_t_kernel_size=[3,3,3,3]\n",
    "                , decoder_conv_t_strides=[2,2,2,2]\n",
    "                , z_dim=200\n",
    "                , use_batch_norm=True\n",
    "                , use_dropout=True)\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 64, 64, 32)   896         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 32)   128         encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 64, 32)   0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 32, 32, 64)   18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 64)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 16, 16, 64)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 64)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 8, 8, 64)     36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 64)     0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 200)          819400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 200)          819400      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 200)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,732,944\n",
      "Trainable params: 1,732,496\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              823296    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 128, 128, 3)       867       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 917,123\n",
      "Trainable params: 916,803\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 10000\n",
    "EPOCHS = 50\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hongbeom/Workspace/JKP/Generative_Model_Drill/models/VAE.py:227: Model.fit_generator (from tensorflow.python.keras.engine.training_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "   2/6331 [..............................] - ETA: 4:40 - loss: 1327.3535 - vae_r_loss: 1097.8716 - vae_kl_loss: 229.4819WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.163995). Check your callbacks.\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 273.9905 - vae_r_loss: 212.0313 - vae_kl_loss: 61.9549\n",
      "Epoch 00001: saving model to run/vae/0001_faces/weights/weights-001-273.99.h5\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 2047s 323ms/step - loss: 273.9905 - vae_r_loss: 212.0313 - vae_kl_loss: 61.9549 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 233.6634 - vae_r_loss: 174.9031 - vae_kl_loss: 58.7604\n",
      "Epoch 00002: saving model to run/vae/0001_faces/weights/weights-002-233.67.h5\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 233.6810 - vae_r_loss: 174.9069 - vae_kl_loss: 58.7604 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 228.6415 - vae_r_loss: 169.5406 - vae_kl_loss: 59.1008\n",
      "Epoch 00003: saving model to run/vae/0001_faces/weights/weights-003-228.64.h5\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 228.6496 - vae_r_loss: 169.5422 - vae_kl_loss: 59.1010 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 226.1606 - vae_r_loss: 166.9784 - vae_kl_loss: 59.1822\n",
      "Epoch 00004: saving model to run/vae/0001_faces/weights/weights-004-226.16.h5\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 226.1606 - vae_r_loss: 166.9784 - vae_kl_loss: 59.1822 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 224.7704 - vae_r_loss: 165.5535 - vae_kl_loss: 59.2169\n",
      "Epoch 00005: saving model to run/vae/0001_faces/weights/weights-005-224.77.h5\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 224.7744 - vae_r_loss: 165.5543 - vae_kl_loss: 59.2170 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 223.7147 - vae_r_loss: 164.5744 - vae_kl_loss: 59.1401\n",
      "Epoch 00006: saving model to run/vae/0001_faces/weights/weights-006-223.71.h5\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 223.7152 - vae_r_loss: 164.5745 - vae_kl_loss: 59.1401 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 222.9991 - vae_r_loss: 163.8846 - vae_kl_loss: 59.1145\n",
      "Epoch 00007: saving model to run/vae/0001_faces/weights/weights-007-223.00.h5\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 222.9927 - vae_r_loss: 163.8834 - vae_kl_loss: 59.1143 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 222.4483 - vae_r_loss: 163.3676 - vae_kl_loss: 59.0826\n",
      "Epoch 00008: saving model to run/vae/0001_faces/weights/weights-008-222.45.h5\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 222.4483 - vae_r_loss: 163.3676 - vae_kl_loss: 59.0826 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 222.0573 - vae_r_loss: 162.9611 - vae_kl_loss: 59.0961\n",
      "Epoch 00009: saving model to run/vae/0001_faces/weights/weights-009-222.06.h5\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 222.0603 - vae_r_loss: 162.9615 - vae_kl_loss: 59.0963 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 221.5405 - vae_r_loss: 162.5035 - vae_kl_loss: 59.0372\n",
      "Epoch 00010: saving model to run/vae/0001_faces/weights/weights-010-221.54.h5\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 221.5471 - vae_r_loss: 162.5047 - vae_kl_loss: 59.0374 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 221.3296 - vae_r_loss: 162.2619 - vae_kl_loss: 59.0673\n",
      "Epoch 00011: saving model to run/vae/0001_faces/weights/weights-011-221.33.h5\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 221.3327 - vae_r_loss: 162.2626 - vae_kl_loss: 59.0674 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 221.0179 - vae_r_loss: 162.0026 - vae_kl_loss: 59.0075\n",
      "Epoch 00012: saving model to run/vae/0001_faces/weights/weights-012-221.01.h5\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 221.0179 - vae_r_loss: 162.0026 - vae_kl_loss: 59.0075 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 220.8321 - vae_r_loss: 161.7878 - vae_kl_loss: 59.0444\n",
      "Epoch 00013: saving model to run/vae/0001_faces/weights/weights-013-220.83.h5\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 220.8285 - vae_r_loss: 161.7872 - vae_kl_loss: 59.0442 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 220.5424 - vae_r_loss: 161.5313 - vae_kl_loss: 59.0129\n",
      "Epoch 00014: saving model to run/vae/0001_faces/weights/weights-014-220.54.h5\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 220.5424 - vae_r_loss: 161.5313 - vae_kl_loss: 59.0129 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 220.3798 - vae_r_loss: 161.3692 - vae_kl_loss: 59.0105\n",
      "Epoch 00015: saving model to run/vae/0001_faces/weights/weights-015-220.38.h5\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 220.3795 - vae_r_loss: 161.3693 - vae_kl_loss: 59.0104 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 220.1676 - vae_r_loss: 161.1747 - vae_kl_loss: 58.9931\n",
      "Epoch 00016: saving model to run/vae/0001_faces/weights/weights-016-220.17.h5\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 220.1812 - vae_r_loss: 161.1774 - vae_kl_loss: 58.9934 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.9817 - vae_r_loss: 160.9727 - vae_kl_loss: 59.0115\n",
      "Epoch 00017: saving model to run/vae/0001_faces/weights/weights-017-219.98.h5\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.9817 - vae_r_loss: 160.9727 - vae_kl_loss: 59.0115 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.9312 - vae_r_loss: 160.9552 - vae_kl_loss: 58.9810\n",
      "Epoch 00018: saving model to run/vae/0001_faces/weights/weights-018-219.94.h5\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.9312 - vae_r_loss: 160.9552 - vae_kl_loss: 58.9810 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 219.7186 - vae_r_loss: 160.7367 - vae_kl_loss: 58.9819\n",
      "Epoch 00019: saving model to run/vae/0001_faces/weights/weights-019-219.72.h5\n",
      "\n",
      "Epoch 00019: saving model to run/vae/0001_faces/weights/weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6332/6331 [==============================] - 313s 50ms/step - loss: 219.7231 - vae_r_loss: 160.7375 - vae_kl_loss: 58.9821 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 219.5744 - vae_r_loss: 160.5742 - vae_kl_loss: 59.0003\n",
      "Epoch 00020: saving model to run/vae/0001_faces/weights/weights-020-219.58.h5\n",
      "\n",
      "Epoch 00020: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.5794 - vae_r_loss: 160.5751 - vae_kl_loss: 59.0005 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.5032 - vae_r_loss: 160.5015 - vae_kl_loss: 58.9955\n",
      "Epoch 00021: saving model to run/vae/0001_faces/weights/weights-021-219.50.h5\n",
      "\n",
      "Epoch 00021: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 219.5032 - vae_r_loss: 160.5015 - vae_kl_loss: 58.9955 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.4413 - vae_r_loss: 160.4053 - vae_kl_loss: 59.0357- ETA: 5\n",
      "Epoch 00022: saving model to run/vae/0001_faces/weights/weights-022-219.44.h5\n",
      "\n",
      "Epoch 00022: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.4413 - vae_r_loss: 160.4053 - vae_kl_loss: 59.0357 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 219.3657 - vae_r_loss: 160.3663 - vae_kl_loss: 58.9996\n",
      "Epoch 00023: saving model to run/vae/0001_faces/weights/weights-023-219.37.h5\n",
      "\n",
      "Epoch 00023: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 219.3704 - vae_r_loss: 160.3670 - vae_kl_loss: 58.9999 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.2476 - vae_r_loss: 160.2098 - vae_kl_loss: 59.0362\n",
      "Epoch 00024: saving model to run/vae/0001_faces/weights/weights-024-219.25.h5\n",
      "\n",
      "Epoch 00024: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 219.2476 - vae_r_loss: 160.2098 - vae_kl_loss: 59.0362 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 219.1787 - vae_r_loss: 160.1443 - vae_kl_loss: 59.0331\n",
      "Epoch 00025: saving model to run/vae/0001_faces/weights/weights-025-219.18.h5\n",
      "\n",
      "Epoch 00025: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.1787 - vae_r_loss: 160.1443 - vae_kl_loss: 59.0331 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 219.2134 - vae_r_loss: 160.1706 - vae_kl_loss: 59.0429\n",
      "Epoch 00026: saving model to run/vae/0001_faces/weights/weights-026-219.21.h5\n",
      "\n",
      "Epoch 00026: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.2137 - vae_r_loss: 160.1708 - vae_kl_loss: 59.0427 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 219.0739 - vae_r_loss: 160.0466 - vae_kl_loss: 59.0274\n",
      "Epoch 00027: saving model to run/vae/0001_faces/weights/weights-027-219.07.h5\n",
      "\n",
      "Epoch 00027: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 219.0706 - vae_r_loss: 160.0459 - vae_kl_loss: 59.0274 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.9011 - vae_r_loss: 159.8995 - vae_kl_loss: 59.0015\n",
      "Epoch 00028: saving model to run/vae/0001_faces/weights/weights-028-218.90.h5\n",
      "\n",
      "Epoch 00028: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.9086 - vae_r_loss: 159.9009 - vae_kl_loss: 59.0017 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.8695 - vae_r_loss: 159.8743 - vae_kl_loss: 58.9955\n",
      "Epoch 00029: saving model to run/vae/0001_faces/weights/weights-029-218.87.h5\n",
      "\n",
      "Epoch 00029: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.8809 - vae_r_loss: 159.8766 - vae_kl_loss: 58.9957 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.8493 - vae_r_loss: 159.8011 - vae_kl_loss: 59.0482\n",
      "Epoch 00030: saving model to run/vae/0001_faces/weights/weights-030-218.85.h5\n",
      "\n",
      "Epoch 00030: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.8574 - vae_r_loss: 159.8028 - vae_kl_loss: 59.0483 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.7821 - vae_r_loss: 159.7269 - vae_kl_loss: 59.0483\n",
      "Epoch 00031: saving model to run/vae/0001_faces/weights/weights-031-218.78.h5\n",
      "\n",
      "Epoch 00031: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.7821 - vae_r_loss: 159.7269 - vae_kl_loss: 59.0483 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.7618 - vae_r_loss: 159.7122 - vae_kl_loss: 59.0495\n",
      "Epoch 00032: saving model to run/vae/0001_faces/weights/weights-032-218.76.h5\n",
      "\n",
      "Epoch 00032: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.7638 - vae_r_loss: 159.7126 - vae_kl_loss: 59.0495 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.7645 - vae_r_loss: 159.6923 - vae_kl_loss: 59.0673\n",
      "Epoch 00033: saving model to run/vae/0001_faces/weights/weights-033-218.76.h5\n",
      "\n",
      "Epoch 00033: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.7645 - vae_r_loss: 159.6923 - vae_kl_loss: 59.0673 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.6560 - vae_r_loss: 159.6066 - vae_kl_loss: 59.0484\n",
      "Epoch 00034: saving model to run/vae/0001_faces/weights/weights-034-218.65.h5\n",
      "\n",
      "Epoch 00034: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.6560 - vae_r_loss: 159.6066 - vae_kl_loss: 59.0484 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.5873 - vae_r_loss: 159.5125 - vae_kl_loss: 59.0717\n",
      "Epoch 00035: saving model to run/vae/0001_faces/weights/weights-035-218.58.h5\n",
      "\n",
      "Epoch 00035: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.5873 - vae_r_loss: 159.5125 - vae_kl_loss: 59.0717 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.6833 - vae_r_loss: 159.5879 - vae_kl_loss: 59.0983\n",
      "Epoch 00036: saving model to run/vae/0001_faces/weights/weights-036-218.69.h5\n",
      "\n",
      "Epoch 00036: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.6833 - vae_r_loss: 159.5879 - vae_kl_loss: 59.0983 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.4949 - vae_r_loss: 159.4302 - vae_kl_loss: 59.0647\n",
      "Epoch 00037: saving model to run/vae/0001_faces/weights/weights-037-218.50.h5\n",
      "\n",
      "Epoch 00037: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.4991 - vae_r_loss: 159.4311 - vae_kl_loss: 59.0647 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.4977 - vae_r_loss: 159.4525 - vae_kl_loss: 59.0453\n",
      "Epoch 00038: saving model to run/vae/0001_faces/weights/weights-038-218.50.h5\n",
      "\n",
      "Epoch 00038: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 313s 49ms/step - loss: 218.4947 - vae_r_loss: 159.4519 - vae_kl_loss: 59.0453 - lr: 5.0000e-04\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.4559 - vae_r_loss: 159.3837 - vae_kl_loss: 59.0723\n",
      "Epoch 00039: saving model to run/vae/0001_faces/weights/weights-039-218.46.h5\n",
      "\n",
      "Epoch 00039: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.4554 - vae_r_loss: 159.3837 - vae_kl_loss: 59.0721 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.4352 - vae_r_loss: 159.3737 - vae_kl_loss: 59.0614\n",
      "Epoch 00040: saving model to run/vae/0001_faces/weights/weights-040-218.44.h5\n",
      "\n",
      "Epoch 00040: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.4351 - vae_r_loss: 159.3736 - vae_kl_loss: 59.0616 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.3032 - vae_r_loss: 159.2509 - vae_kl_loss: 59.0421\n",
      "Epoch 00041: saving model to run/vae/0001_faces/weights/weights-041-218.29.h5\n",
      "\n",
      "Epoch 00041: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.3032 - vae_r_loss: 159.2509 - vae_kl_loss: 59.0421 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.3242 - vae_r_loss: 159.2520 - vae_kl_loss: 59.0723\n",
      "Epoch 00042: saving model to run/vae/0001_faces/weights/weights-042-218.33.h5\n",
      "\n",
      "Epoch 00042: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.3302 - vae_r_loss: 159.2533 - vae_kl_loss: 59.0724 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.2880 - vae_r_loss: 159.2158 - vae_kl_loss: 59.0718\n",
      "Epoch 00043: saving model to run/vae/0001_faces/weights/weights-043-218.29.h5\n",
      "\n",
      "Epoch 00043: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 315s 50ms/step - loss: 218.2936 - vae_r_loss: 159.2169 - vae_kl_loss: 59.0719 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.3434 - vae_r_loss: 159.2443 - vae_kl_loss: 59.0995\n",
      "Epoch 00044: saving model to run/vae/0001_faces/weights/weights-044-218.34.h5\n",
      "\n",
      "Epoch 00044: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.3434 - vae_r_loss: 159.2443 - vae_kl_loss: 59.0995 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "6332/6331 [==============================] - ETA: 0s - loss: 218.2184 - vae_r_loss: 159.1318 - vae_kl_loss: 59.0700\n",
      "Epoch 00045: saving model to run/vae/0001_faces/weights/weights-045-218.20.h5\n",
      "\n",
      "Epoch 00045: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.2184 - vae_r_loss: 159.1318 - vae_kl_loss: 59.0700 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.2711 - vae_r_loss: 159.1733 - vae_kl_loss: 59.0979\n",
      "Epoch 00046: saving model to run/vae/0001_faces/weights/weights-046-218.27.h5\n",
      "\n",
      "Epoch 00046: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.2729 - vae_r_loss: 159.1737 - vae_kl_loss: 59.0980 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.1659 - vae_r_loss: 159.1000 - vae_kl_loss: 59.0656\n",
      "Epoch 00047: saving model to run/vae/0001_faces/weights/weights-047-218.17.h5\n",
      "\n",
      "Epoch 00047: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 313s 50ms/step - loss: 218.1707 - vae_r_loss: 159.1010 - vae_kl_loss: 59.0657 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.1238 - vae_r_loss: 159.0606 - vae_kl_loss: 59.0630\n",
      "Epoch 00048: saving model to run/vae/0001_faces/weights/weights-048-218.13.h5\n",
      "\n",
      "Epoch 00048: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.1356 - vae_r_loss: 159.0632 - vae_kl_loss: 59.0631 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.2051 - vae_r_loss: 159.1179 - vae_kl_loss: 59.0875\n",
      "Epoch 00049: saving model to run/vae/0001_faces/weights/weights-049-218.21.h5\n",
      "\n",
      "Epoch 00049: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.2103 - vae_r_loss: 159.1190 - vae_kl_loss: 59.0875 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "6331/6331 [============================>.] - ETA: 0s - loss: 218.1279 - vae_r_loss: 159.0726 - vae_kl_loss: 59.0552\n",
      "Epoch 00050: saving model to run/vae/0001_faces/weights/weights-050-218.13.h5\n",
      "\n",
      "Epoch 00050: saving model to run/vae/0001_faces/weights/weights.h5\n",
      "6332/6331 [==============================] - 314s 50ms/step - loss: 218.1311 - vae_r_loss: 159.0733 - vae_kl_loss: 59.0552 - lr: 5.0000e-04\n",
      "CPU times: user 9h 4min 46s, sys: 1h 9min 16s, total: 10h 14min 3s\n",
      "Wall time: 4h 51min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vae.train_with_generator(     \n",
    "    data_flow\n",
    "    , epochs = EPOCHS\n",
    "    , steps_per_epoch = NUM_IMAGES / BATCH_SIZE\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
